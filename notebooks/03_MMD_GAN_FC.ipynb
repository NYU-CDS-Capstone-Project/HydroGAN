{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/OctoberChang/MMD-GAN - accompanying the paper MMD-GAN: Towards Deeper Understanding of Moment Matching Network.\n",
    "\n",
    "To check GPU usage, open new terminal inside Jupyter and nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import h5py\n",
    "import timeit\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle as pkl\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run in Jupyter = True\n"
     ]
    }
   ],
   "source": [
    "run_in_jupyter = False\n",
    "try:\n",
    "    cfg = get_ipython().config \n",
    "    run_in_jupyter = True\n",
    "except:\n",
    "    run_in_jupyter = False\n",
    "    pass\n",
    "\n",
    "if run_in_jupyter:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "else: \n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "print(\"Run in Jupyter = \" + str(run_in_jupyter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import colors\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "batch_size = 16       # BATCH_SIZE: batch size for training\n",
    "workers = 2          # WORKERS: number of threads to load data\n",
    "\n",
    "experiment = \"./mmd_gan_fc/\"       # : output directory of saved models\n",
    "model_save_folder = experiment + \"model/\"\n",
    "save_model_every = 10               # (every x epoch) frequency to save the model\n",
    "\n",
    "redshift_info_folder = experiment + \"redshift_info/\"   # save some info here as pickle to speed up processing\n",
    "redshift_file = \"minmax_scale_01_redshift0.h5\"    # redshift cube to be used\n",
    "root_dir = \"\"                                     # should be \"\" fo prince\n",
    "redshift_fig_folder = experiment + \"figures/\"        # folder to save mmd & related plots\n",
    "redshift_3dfig_folder = experiment + \"/3d_figures/\"   # folder to save 3D plots\n",
    "testing_folder = experiment + \"testing/\"   # folder to save 3D plots\n",
    "\n",
    "\n",
    "gpu_device = 0        # GPU_DEVICE: gpu id (default 0)\n",
    "nc = 1                # NC: number of channels in images\n",
    "nz = 2048                # NZ: hidden dimension in z and codespace\n",
    "cube_size = 128       # IMAGE_SIZE: image size of dataset - \n",
    "                        # for our dataset more like one edge of the subcube\n",
    "lr = 5e-5               # LR: learning rate (default 5e-5)\n",
    "max_iter = 150         # MAX_ITER: max iteration for training\n",
    "\n",
    "optimizer_choice = \"rmsprop\"     # adam or rmsprop\n",
    "dist_ae = 'L1'                  # \"L2\" or \"L1\" or \"cos\" -> Autoencoder reconstructruced cube loss choice\n",
    "manual_seed = 1126\n",
    "n_samples = batch_size * 128      # on prince, number of samples to get from the training cube\n",
    "in_testing = False              # True if doing testing\n",
    "\n",
    "viz_multiplier = 3e1    # the norm multiplier in the 3D visualization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n_samples / batch_size > 100, \"The gen_iterations wont work properly!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size = 16\n",
      "Redshift File Used = minmax_scale_01_redshift0.h5\n",
      "Number of Channels in Input = 1\n",
      "Hidden Dimension (codespace) = 2048\n",
      "Length of Edge of a Sampled Subcube = 128\n",
      "Learning Rate = 5e-05\n",
      "Number of Epochs = 150\n",
      "Optimizer = rmsprop\n",
      "Autoencoder Reconstruction Loss  = L1\n",
      "Seed = 1126\n",
      "Number of Samples = 2048\n",
      "Visualization Multiplier = 30.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch Size = \" + str(batch_size))\n",
    "print(\"Redshift File Used = \" + str(redshift_file))\n",
    "print(\"Number of Channels in Input = \" + str(nc))\n",
    "print(\"Hidden Dimension (codespace) = \" + str(nz))\n",
    "print(\"Length of Edge of a Sampled Subcube = \" + str(cube_size))\n",
    "print(\"Learning Rate = \" + str(lr))\n",
    "print(\"Number of Epochs = \" + str(max_iter))\n",
    "print(\"Optimizer = \" + str(optimizer_choice))\n",
    "print(\"Autoencoder Reconstruction Loss  = \" + str(dist_ae))\n",
    "print(\"Seed = \" + str(manual_seed))\n",
    "print(\"Number of Samples = \" + str(n_samples))\n",
    "print(\"Visualization Multiplier = \" + str(viz_multiplier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one edge of the test partition of the whole cube = 1024\n",
      "one edge of the sampled subcubes =  128\n"
     ]
    }
   ],
   "source": [
    "edge_sample = 128\n",
    "edge_test = 1024\n",
    "\n",
    "print(\"one edge of the test partition of the whole cube = \" + str(edge_test))\n",
    "print(\"one edge of the sampled subcubes =  \" + str(edge_sample))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMD Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_MMD = 1.0\n",
      "lambda_AE_X = 8.0\n",
      "lambda_AE_Y = 8.0\n",
      "lambda_rg = 16.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MMD Parameters\n",
    "\n",
    "errD = torch.sqrt(mmd2_D) + lambda_rg * one_side_errD \n",
    "       - lambda_AE_X * L2_AE_X_D - lambda_AE_Y * L2_AE_Y_D\n",
    "       \n",
    "errG = torch.sqrt(mmd2_G) + lambda_rg * one_side_errG\n",
    "\n",
    "The explanations can be found in Ratio Matching MMD Nets (2018) in \n",
    "Equation 3.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "lambda_MMD = 1.0   # not used anywhere\n",
    "lambda_AE_X = 8.0  # used in above calc only \n",
    "lambda_AE_Y = 8.0  # used in above calc only\n",
    "lambda_rg = 16.0   # used in both err calcs\n",
    "\n",
    "print(\"lambda_MMD = \" + str(lambda_MMD))\n",
    "print(\"lambda_AE_X = \" + str(lambda_AE_X))\n",
    "print(\"lambda_AE_Y = \" + str(lambda_AE_Y))\n",
    "print(\"lambda_rg = \" + str(lambda_rg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_list = [1.0, 2.0, 4.0, 8.0, 16.0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sigma for MMD\n",
    "\"\"\"\n",
    "base = 1.0\n",
    "sigma_list = [1, 2, 4, 8, 16]\n",
    "sigma_list = [sigma / base for sigma in sigma_list]\n",
    "print(\"sigma_list = \" + str(sigma_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum variance estimated = 1e-30\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "used at:\n",
    "def _mmd2_and_ratio(K_XX, K_XY, K_YY, \n",
    "                    const_diagonal=False, \n",
    "                    biased=False):\n",
    "    mmd2, var_est = _mmd2_and_variance(K_XX, K_XY, K_YY, \n",
    "                                       const_diagonal=const_diagonal, \n",
    "                                       biased=biased)\n",
    "    loss = mmd2 / torch.sqrt(torch.clamp(var_est, min=min_var_est))\n",
    "    return loss, mmd2, var_est\n",
    "    \n",
    "torch.clamp(input, min, max, out=None) â†’ Tensor\n",
    "    Clamp all elements in input into the range [ min, max ] \n",
    "    and return a resulting tensor\n",
    "\"\"\"\n",
    "\n",
    "# min_var_est = 1e-8\n",
    "min_var_est = 1e-30\n",
    "\n",
    "print(\"minimum variance estimated = \" + str(min_var_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax_scale_01_redshift0.h5\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(root_dir + redshift_file, 'r')\n",
    "print(f.filename)\n",
    "f = f['delta_HI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Info Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create experiment folder if it doesn't exist\n",
    "if Path(redshift_info_folder).exists() == False:\n",
    "    os.mkdir(experiment)\n",
    "    \n",
    "# create redshift info folder if it doesn't exist\n",
    "if Path(redshift_info_folder).exists() == False:\n",
    "    os.mkdir(redshift_info_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_cube(f):\n",
    "    max_list = [np.max(f[i:i+1,:,:]) for i in range(f.shape[0])]\n",
    "    max_cube = max(max_list)\n",
    "    return max_cube\n",
    "\n",
    "def get_min_cube(f):\n",
    "    min_list = [np.min(f[i:i+1,:,:]) for i in range(f.shape[0])]\n",
    "    min_cube = min(min_list)\n",
    "    return min_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if redshift info (min & max exists) as pickle\n",
    "# if not saved, find the max and min and save them for later use\n",
    "min_cube_file = Path(redshift_info_folder + redshift_file + \"_min_cube\" + \".npy\")\n",
    "max_cube_file = Path(redshift_info_folder + redshift_file + \"_max_cube\" + \".npy\")\n",
    "\n",
    "\n",
    "if not min_cube_file.exists() or not max_cube_file.exists():\n",
    "    \n",
    "    f = h5py.File(root_dir + redshift_file, 'r')\n",
    "    f=f['delta_HI']\n",
    "    \n",
    "    # get the min and max\n",
    "    min_cube = get_min_cube(f=f)\n",
    "    print(min_cube)\n",
    "    max_cube = get_max_cube(f=f)\n",
    "    print(max_cube)\n",
    "    \n",
    "    np.save(file = redshift_info_folder + redshift_file + \"_min_cube\",\n",
    "        arr = min_cube,\n",
    "        allow_pickle = True)\n",
    "    np.save(file = redshift_info_folder + redshift_file + \"_max_cube\",\n",
    "        arr = max_cube,\n",
    "        allow_pickle = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of data = 0.0\n",
      "Max of data = 1.0\n"
     ]
    }
   ],
   "source": [
    "min_cube = np.load(file = redshift_info_folder + redshift_file + \"_min_cube\" + '.npy')\n",
    "max_cube = np.load(file = redshift_info_folder + redshift_file + \"_max_cube\" + '.npy')\n",
    "print(\"Min of data = \" + str(min_cube))\n",
    "print(\"Max of data = \" + str(max_cube))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figures folder if it doesn't exist\n",
    "if Path(redshift_fig_folder).exists() == False:\n",
    "    os.mkdir(redshift_fig_folder)\n",
    "if Path(redshift_3dfig_folder).exists() == False:\n",
    "    os.mkdir(redshift_3dfig_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    \"\"\"Function for dividing/truncating cmaps\"\"\"\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "def visualize_cube(cube=None,      # array name\n",
    "             edge_dim=None,        # edge dimension (128 for 128 x 128 x 128 cube)\n",
    "             start_cube_index_x=0,\n",
    "             start_cube_index_y=0,\n",
    "             start_cube_index_z=0,\n",
    "             fig_size=None,\n",
    "             stdev_to_white=1,\n",
    "             norm_multiply=viz_multiplier,\n",
    "             color_map=\"Blues\",\n",
    "             plot_show = False,\n",
    "             save_fig = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    The inputs should be in the interval [0,1]\n",
    "    All the transformations on the input\n",
    "    should be done before passing\n",
    "    into the function.\n",
    "    \"\"\"\n",
    "        \n",
    "    cube_size = edge_dim\n",
    "    edge = np.array([*range(cube_size)])\n",
    "    \n",
    "    end_x = start_cube_index_x + cube_size\n",
    "    end_y = start_cube_index_y + cube_size\n",
    "    end_z = start_cube_index_z + cube_size\n",
    "    \n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    data_value = cube[start_cube_index_x:end_x,\n",
    "                      start_cube_index_y:end_y,\n",
    "                      start_cube_index_z:end_z]\n",
    "    \n",
    "    x,y,z = edge,edge,edge\n",
    "    product = [*itertools.product(x,y,z)]\n",
    "    \n",
    "    X = np.array([product[k][0] for k in [*range(len(product))]])\n",
    "    Y = np.array([product[k][1] for k in [*range(len(product))]])\n",
    "    Z = np.array([product[k][2] for k in [*range(len(product))]])\n",
    "    \n",
    "    ## map data to 1d array that corresponds to the axis values in the product array\n",
    "    data_1dim = np.array([data_value[X[i]][Y[i]][Z[i]] for i in [*range(len(product))]])\n",
    "    \n",
    "    \n",
    "    initial_mean = np.mean(data_1dim) - stdev_to_white*np.std(data_1dim)\n",
    "    mask = data_1dim > initial_mean\n",
    "    mask = mask.astype(np.int)\n",
    "    \n",
    "    data_1dim = np.multiply(mask,data_1dim)\n",
    "    ## mask X,Y,Z to match the dimensions of the data\n",
    "    X, Y, Z, data_1dim = [axis[np.where(data_1dim>0)] for axis in [X,Y,Z,data_1dim]]\n",
    "\n",
    "    \n",
    "    \n",
    "#     if lognormal == False:\n",
    "    \"\"\"\n",
    "    norm_multiply = function argument\n",
    "    data_1dim = data in one dimension, flattened\n",
    "    nn.linalg.norm = return one of eight different matrix norms\n",
    "\n",
    "    The nn.linalg.norm should not be used due to the fact \n",
    "    that each subcube has different norms. Use the maximum of\n",
    "    the whole cube and mitigate with norm_multiply if \n",
    "    no points are seen in the 3D plot.\n",
    "    \"\"\"\n",
    "        \n",
    "#         s = norm_multiply*data_1dim/np.linalg.norm(data_1dim)\n",
    "    s = norm_multiply * data_1dim\n",
    "\n",
    "    # adding this for [-1,1] scaled input\n",
    "    # so that s is between [0,1]\n",
    "#         s = (s + 1.0) / 2.0 \n",
    "    \n",
    "#     else:\n",
    "#         s = np.log(norm_multiply*data_1dim/np.linalg.norm(data_1dim))\n",
    "    try:\n",
    "        # checking min, max , mean of s\n",
    "        print(\"Plotting s (= norm_multiply * data_1dim) stats:\")\n",
    "        print(\"s mean = \" + str(s.mean()))\n",
    "        print(\"s max = \" + str(s.max()))\n",
    "        print(\"s min = \" + str(s.min()))\n",
    "\n",
    "\n",
    "        cmap=plt.get_cmap(color_map)\n",
    "        new_cmap = truncate_colormap(cmap, 0.99, 1,n=10)\n",
    "\n",
    "        ## IGNORE BELOW 3D PLOT FORMATTING \n",
    "\n",
    "        ## plot cube\n",
    "\n",
    "        cube_definition = [(start_cube_index_x, start_cube_index_x, start_cube_index_x),\n",
    "                          (start_cube_index_x, start_cube_index_x+edge_dim, start_cube_index_x),\n",
    "                          (start_cube_index_x + edge_dim, start_cube_index_x, start_cube_index_x),\n",
    "                          (start_cube_index_x, start_cube_index_x, start_cube_index_x+edge_dim)]\n",
    "\n",
    "        cube_definition_array = [\n",
    "            np.array(list(item))\n",
    "            for item in cube_definition\n",
    "        ]\n",
    "\n",
    "        points = []\n",
    "        points += cube_definition_array\n",
    "        vectors = [\n",
    "            cube_definition_array[1] - cube_definition_array[0],\n",
    "            cube_definition_array[2] - cube_definition_array[0],\n",
    "            cube_definition_array[3] - cube_definition_array[0]\n",
    "        ]\n",
    "\n",
    "\n",
    "        points += [cube_definition_array[0] + vectors[0] + vectors[1]]\n",
    "        points += [cube_definition_array[0] + vectors[0] + vectors[2]]\n",
    "        points += [cube_definition_array[0] + vectors[1] + vectors[2]]\n",
    "        points += [cube_definition_array[0] + vectors[0] + vectors[1] + vectors[2]]\n",
    "\n",
    "        points = np.array(points)\n",
    "\n",
    "        edges = [\n",
    "            [points[0], points[3], points[5], points[1]],\n",
    "            [points[1], points[5], points[7], points[4]],\n",
    "            [points[4], points[2], points[6], points[7]],\n",
    "            [points[2], points[6], points[3], points[0]],\n",
    "            [points[0], points[2], points[4], points[1]],\n",
    "            [points[3], points[6], points[7], points[5]]\n",
    "        ]\n",
    "\n",
    "    #     ax.fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        faces = Poly3DCollection(edges, linewidths=1, edgecolors='k',)\n",
    "        faces.set_facecolor((0,0,1,0)) ## set transparent facecolor to the cube\n",
    "\n",
    "        ax.add_collection3d(faces)\n",
    "\n",
    "        ax.scatter(points[:,0], points[:,1], points[:,2], s=0)\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        ax.xaxis.pane.fill = False\n",
    "        ax.yaxis.pane.fill = False\n",
    "        ax.zaxis.pane.fill = False\n",
    "\n",
    "        ax.xaxis.pane.set_edgecolor('w')\n",
    "        ax.yaxis.pane.set_edgecolor('w')\n",
    "        ax.zaxis.pane.set_edgecolor('w')\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(edge_dim))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(edge_dim))\n",
    "        ax.zaxis.set_major_locator(MultipleLocator(edge_dim))\n",
    "\n",
    "        ax.grid(False)\n",
    "\n",
    "        ax.set_xlim3d(0,edge_dim)\n",
    "        ax.set_ylim3d(0,edge_dim)\n",
    "        ax.set_zlim3d(0,edge_dim)\n",
    "    #     ax.get_frame_on()\n",
    "\n",
    "        ax.xaxis._axinfo['tick']['inward_factor'] = 0\n",
    "        ax.xaxis._axinfo['tick']['outward_factor'] = 0\n",
    "        ax.yaxis._axinfo['tick']['inward_factor'] = 0\n",
    "        ax.yaxis._axinfo['tick']['outward_factor'] = 0\n",
    "        ax.zaxis._axinfo['tick']['inward_factor'] = 0\n",
    "        ax.zaxis._axinfo['tick']['outward_factor'] = 0\n",
    "\n",
    "        ax.scatter(X, Y, Z,       ## axis vals\n",
    "                   c=data_1dim,   ## data, mapped to 1-dim\n",
    "                   cmap=new_cmap,\n",
    "                   s=s,           ## sizes - dims multiplied by each data point's magnitude\n",
    "                   alpha=0.7,\n",
    "                   edgecolors=\"face\")\n",
    "\n",
    "        if plot_show:\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        if save_fig:\n",
    "            fig.savefig(save_fig,bbox_inches='tight')\n",
    "\n",
    "        plt.close(fig)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_test(s_test, s_train):\n",
    "    \"\"\"\n",
    "    s_test = one edge of the test partition of the whole cube\n",
    "    s_train = one edge of the sampled subcubes\n",
    "    \"\"\"\n",
    "    #2048/16=128\n",
    "    m = 8\n",
    "    x = random.randint(0,m) * s_train\n",
    "    y = random.randint(0,m) * s_train\n",
    "    z = random.randint(0,m) * s_train\n",
    "    #print(x,y,z)\n",
    "    return {'x':[x,x + s_test], 'y':[y,y + s_test], 'z':[z,z + s_test]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coords(test_coords, train_coords):\n",
    "    valid=True\n",
    "    for i in ['x','y','z']:\n",
    "        r=(max(test_coords[i][0], \n",
    "               train_coords[i][0]), \n",
    "           min(test_coords[i][1],\n",
    "               train_coords[i][1]))\n",
    "        if r[0]<=r[1]:\n",
    "            valid=False\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_2_list = []\n",
    "time_3_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(s_sample, \n",
    "                nsamples, \n",
    "#                 h5_filename,  \n",
    "                test_coords,\n",
    "                f):   # given as f[\"delta_HI\"]\n",
    "    #n is size of minibatch, get valid samples (not intersecting with test_coords)\n",
    "    sample_list=[]\n",
    "    m = 2048 - 128\n",
    "    \n",
    "    \n",
    "    for n in range(nsamples):\n",
    "        #print(\"Sample No = \" + str(n + 1) + \" / \" + str(nsamples))\n",
    "        sample_valid = False\n",
    "        while sample_valid == False:\n",
    "            x = random.randint(0,m)\n",
    "            y = random.randint(0,m)\n",
    "            z = random.randint(0,m)\n",
    "            sample_coords = {'x':[x,x+s_sample], \n",
    "                             'y':[y,y+s_sample], \n",
    "                             'z':[z,z+s_sample]}\n",
    "            \n",
    "            sample_valid = check_coords(test_coords, \n",
    "                                        sample_coords)\n",
    "        \n",
    "        sample_list.append(sample_coords)\n",
    "    \n",
    "#     print(\"Sampling subcube edges finished.\")\n",
    "        \n",
    "    #Load cube and get samples and convert them to np.arrays\n",
    "    sample_array=[]\n",
    "    \n",
    "\n",
    "#     time_1 = time.time()\n",
    "#     f = h5py.File(h5_filename, 'r') \n",
    "#     f=f_deltaHI\n",
    "    \n",
    "    counter = 0\n",
    "    for c in sample_list:\n",
    "#         print(\"Counter = \" + str(counter + 1) + \" / \" + str(len(sample_list)))\n",
    "        a = f[c['x'][0]:c['x'][1],\n",
    "              c['y'][0]:c['y'][1],\n",
    "              c['z'][0]:c['z'][1]]\n",
    "#         time_2 = time.time()\n",
    "        \n",
    "        a = np.array(a)\n",
    "        \n",
    "    \n",
    "        sample_array.append(a)\n",
    "    \n",
    "        counter = counter + 1\n",
    "    \n",
    "#     time_3 = time.time() - time_2\n",
    "#     time_2 = time_2 - time_1\n",
    "    \n",
    "#     print(\"time_2 = \" + str(time_2))\n",
    "#     print(\"time_3 = \" + str(time_3))\n",
    "#     time_2_list.append(time_2)\n",
    "#     time_3_list.append(time_3)\n",
    "#     print_count = random.randint(a=0,b=40)\n",
    "#     if print_count % 40 == 0:\n",
    "#         print(\"time_2 mean = \" + str(np.mean(np.array(time_2_list))))\n",
    "#         print(\"time_3 mean = \" + str(np.mean(np.array(time_3_list))))\n",
    "\n",
    "        \n",
    "#     f = 0\n",
    "    return sample_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [768, 1792], 'y': [896, 1920], 'z': [384, 1408]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcd = define_test(s_test = edge_test, s_train = edge_sample)\n",
    "testcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[2.43170371e-12, 2.39546826e-13, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          5.40747395e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.02261818e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.75265236e-11, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.03687883e-11, 9.33471182e-12, 1.83269754e-11, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.73908381e-12, 4.01158360e-12, 8.44452720e-12, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[2.35032154e-13, 2.31529849e-14, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.26560478e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.20219708e-13, 0.00000000e+00, 5.31671235e-12, ...,\n",
       "          5.17919908e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.99446361e-12, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.51719080e-11, 7.32409099e-12, 1.36642000e-11, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.75697390e-12, 3.01686519e-12, 6.29605786e-12, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.22332488e-13, 0.00000000e+00, 3.10938688e-12, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [9.56767963e-14, 2.12579452e-14, 2.01640852e-12, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.90794090e-13, 4.23915697e-14, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.00940750e-13, 4.61014636e-13, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.87288151e-13, 2.75532917e-12, ...,\n",
       "          5.02945168e-12, 7.70467457e-12, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.41507833e-13, 4.23442271e-12, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [4.65660496e-11, 3.24319738e-11, 1.50796649e-11, ...,\n",
       "          2.16031013e-12, 2.81696506e-11, 1.03185613e-10],\n",
       "         [7.25174504e-11, 3.14611115e-11, 2.11189104e-11, ...,\n",
       "          3.78703525e-13, 4.18285545e-12, 4.58592574e-11],\n",
       "         [8.31468921e-11, 7.90319026e-12, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.04634356e-12]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.81780572e-13, 5.84854051e-13, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.50240104e-13, 1.44092594e-12, ...,\n",
       "          6.38048165e-12, 9.77433412e-12, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.30890827e-13, 2.21443241e-12, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [5.62907256e-11, 7.74747350e-11, 4.70536873e-11, ...,\n",
       "          0.00000000e+00, 8.27924263e-13, 2.05382022e-12],\n",
       "         [6.05656636e-11, 3.88580904e-11, 2.74778290e-11, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.09539071e-12],\n",
       "         [5.23697821e-11, 8.27026555e-12, 1.22053617e-11, ...,\n",
       "          1.13134285e-12, 6.60433026e-13, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [5.29609689e-11, 2.02704381e-11, 3.68801552e-11, ...,\n",
       "          5.36716678e-12, 8.36762517e-12, 4.81658333e-12],\n",
       "         [1.35548794e-10, 1.13007624e-10, 5.94198232e-11, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 9.09165972e-12],\n",
       "         [1.50524287e-10, 1.80166812e-10, 3.05423395e-11, ...,\n",
       "          1.88458971e-12, 1.10014862e-12, 5.13106224e-12]]])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_sample = get_samples(s_sample = edge_sample, \n",
    "                            nsamples = 1, \n",
    "#                             h5_filename = redshift_file, \n",
    "                            test_coords = testcd,\n",
    "                            f = f)\n",
    "trial_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097152,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_sample[0].reshape(-1,).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_plot = trial_sample[0].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [-1,1] -> [0,1] for plotting\n",
    "# trial_plot = (trial_plot + 1.0) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_plot.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0478183813393116"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_plot.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5931218945774503"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_plot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac6d4047d30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "plt.title(\"Trial Sample\")\n",
    "plt.xlim((trial_plot.min(),\n",
    "         trial_plot.max()))\n",
    "bins = np.linspace(trial_plot.min(),\n",
    "                   trial_plot.max(), \n",
    "                   100)\n",
    "plt.hist(trial_plot, bins = bins, \n",
    "         color = \"blue\" ,\n",
    "         alpha = 0.3, \n",
    "         label = \"Trial\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n",
      "edge dim = 128\n",
      "(128, 128, 128)\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 15.059174078219135\n",
      "s max = 15.717275720089674\n",
      "s min = 15.00250650315138\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAI1CAYAAADB12CmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XlAlOXax/HvDDAssoOIqICpuIsaaCqipuSuuWdmai6lqZVllh6zOllmmVlmaeoxl+NeuaSmxzX3fU1FQUBFQNmXGWaG4f2Dt8UKUBl4ZuD6/HWOM8z8UHN+XPf93I8qPz8fIYQQQghrplY6gBBCCCFESUmhEUIIIYTVk0IjhBBCCKsnhUYIIYQQVk8KjRBCCCGsnhQaIYQQQlg9KTRCCCGEsHpSaIQQQghh9aTQCCGEEMLqSaERQgghhNWzfcjny30ShBBCCFGWVA/yJJnQCCGEEMLqSaERQgghhNWTQiOEEEIIqyeFRgghhBBWTwqNEEIIIayeFBohhBBCWD0pNEIIIYSwelJohBBCCGH1pNAIIYQQwupJoRFCCCGE1ZNCI4QQQgirJ4VGCCGEEFZPCo0QQgghrJ4UGiGEEEJYPSk0QgghhLB6UmiEEEIIYfWk0AghhBDC6kmhEUIIIYTVk0IjhBBCCKsnhUYIIYQQVk8KjRBCCCGsnhQaIYQQQlg9KTRCCCGEsHpSaIQQQghh9aTQCCGEEMLqSaERQgghhNWTQiOEEEIIqyeFRgghhBBWTwqNEEIIIayeFBohhBBCWD0pNEIIIYSwelJohBBCCGH1pNAIIYQQwupJoRFCCCGE1ZNCI4QQQgirJ4VGCCGEEFZPCo0QQgghrJ4UGiGEEEJYPSk0QgghhLB6UmiEEEIIYfWk0AghhBDC6kmhEUIIIYTVs1U6gBDi4fzrX//C1taW8ePH4+3trXQcIYSwCKr8/PyHef5DPVkIYT5ZWVm0b9+eU6dOYWtri9FoxNXVleDgYJ5++mleeOEF3N3dlY4phBDmpnqQJ8mSkxBWYM+ePVSpUoXbt2/j6+vLqFGjuHPnDm+99RYGg4F33nkHDw8PPDw8ePLJJ5k/fz4ZGRlKxxZCiDIjhUYICzdhwgQ6depE165duX37Nk5OTuTl5eHr68vbb7/NkSNHyMrK4ubNm7z66qtkZmYyZcoU3Nzc8PLyIiIigoULF5KTk6P0tyKEEKVGlpyEsFBJSUmEhYURExPDd999x+DBgwGoXbs24eHhLF26tMivj42NZdGiRezYsYPLly+j1Wrx8vIiNDSUgQMHMnjwYBwcHMriWxFCiJKQJSchrNWGDRuoUaMGeXl5xMTE/F5mANRqNXl5ecW+RkBAADNnzuTUqVPk5ORw/fp1Ro4cSXx8PGPHjsXR0ZEqVarQo0cPVq5ciV6vL81vSQghSpUUGiEsiMlkYvDgwQwcOJBhw4YRFRWFn5/ffc950ELzV7Vq1eLjjz/m3Llz6HQ6fv31V4YMGUJsbCwjR47EwcGBqlWr0qdPH9atW4fRaDTXtyWEEKVOlpyEsBA3btwgLCyM1NRUfvjhBzp37vyPz2vQoAHBwcGsXr3arO9//vx5Fi9ezK5du4iKisJoNFK1alVat27Ns88+S+/evVGr5WcgIUSZkyUnIazFwoULqVOnDpUrVyYhIaHQMgOPPqEpTpMmTfjiiy+4fPkyer2e48eP06tXL86dO8fAgQOxtbWlRo0aDB48mG3btmEymcyeQQghHpUUGiEUZDQa6dy5M+PGjWPKlCmcPXsWV1fXIr9GrVaXSZkICQnh66+/JjIyEoPBwC+//EKXLl04ceIEvXr1ws7OjsDAQJ5//nl2794tBUcIoShZchJCIefPn6dDhw4YjUZ27dpFixYtHujrmjVrRmBgID/88EMpJyycyWTiwIEDLFu2jP379xMXF4dKpcLf35927doxYsQIwsPDFcsnhChXZMlJCEs1c+ZMmjVrRqNGjUhMTHzgMgOlt+T0MNRqNe3bt2fZsmXcuHEDg8HA9u3bad26NXv27KFDhw7Y2tpSp04dxowZw7FjxxTNK4Qo/2RCI0QZysnJoUOHDpw6dYpPP/2UV1999aFfIzQ0FB8fH3766adSSGgeJpOJbdu2sXLlSg4ePEh8fDw2NjY89thjdOzYkVGjRtG8eXOlYwohrMMDTWik0AhRRg4cOEC3bt1wcnLiwIED1KtX75Fep2XLlnh6erJ9+3YzJyw9RqORTZs2sXr1ag4fPkxCQgK2trbUrl2biIgIRo8eTaNGjZSOKYSwTLLkJISlmDRpEu3bt6dTp04kJCQ8cpkBsLGxUXzJ6WHZ2trSr18/NmzYQHx8PHq9nhUrVhAUFMTatWtp0qQJDg4ONGnShNdff52rV68qHVkIYWVkQiNEKbp37x5t27YlKiqKJUuWMHTo0BK/ZlhYGPb29uzevdsMCS2DXq9nzZo1rF27lhMnTnD37l0cHByoW7cuXbt2ZcyYMdSsWVPpmEIIZciSkxBK2rRpE4MGDcLX15eDBw9SvXp1s7xueHg4NjY27N271yyvZ4m0Wi3//e9/Wb9+PSdPniQ5ORlHR0caNGhAt27dGDVqFP7+/krHFEKUDSk0QijBZDIxfPhwVq5cyQsvvMCiRYvMesJuhw4dyMvL48CBA2Z7TUuXlZXFihUr2LhxI6dPnyY1NRUnJycaNmxIjx49GDVq1N9uESGEKDek0AhR1uLi4ggLC+Pu3bts3LiRbt26mf09OnbsSG5uLgcPHjT7a1uLjIwMli1bxg8//MCZM2dIT0/H2dmZxo0b06tXL0aNGoW3t7fSMYUQ5iGbgoUoS0uWLKFWrVq4u7tz586dUikzULApuKKfyuvq6srEiRPZu3cvaWlpJCcn8+6772JjY8OHH35I5cqVcXV1pW3btsyZM4eUlBSlIwshSplMaIQoIaPRSK9evdixYweTJ0/m448/LtX369q1KykpKXJYXRGSkpJYsmQJW7Zs4cKFC2RlZeHm5kazZs3o27cvw4YNK/YWE0IIiyFLTkKUtosXL9K+fXv0ej3bt2+nTZs2pf6e3bt3JykpiRMnTpT6e5UX8fHxLF68mK1bt3Lp0iVycnLw8PCgefPm9OvXj6FDh+Ls7Kx0TCHEP5MlJyFK0+zZswkODqZevXokJSWVSZkBWXJ6FH5+frzzzjscP36c7OxsYmJiePnll0lNTeX111/HxcUFb29vunTpwpIlS9DpdEpHFkI8JJnQCPGQcnJy6NSpE8eOHWPWrFlMnjy5TN+/T58+xMTEcObMmTJ93/IsKiqKxYsXs337dq5evYpOp6Ny5cqEhoYyaNAgnnnmGTQajdIxhaioZMlJCHM7dOgQXbp0wcHBgX379tGwYcMyz9C/f38iIyM5f/58mb93RXH58mUWL17Mzp07iYyMxGAw4OPjwxNPPMHgwYPp168ftra2SscUoqKQJSchzGny5Mm0bduWdu3acefOHUXKDBTc6VqWnEpX/fr1mTNnDhcuXCA3N5ezZ88yaNAgIiMjGTp0KBqNBj8/P/r378/GjRsxGo1KRxaiwpMJjRDFSElJITw8nKtXr7Jo0SJGjBihaJ5nn32Ws2fP8uuvvyqaoyI7efIkS5cuZffu3URHR5OXl4efnx9hYWE899xzdOvWzayHKQpRwT3QhEZmpkIUYevWrQwYMIDKlSsTFRVlEcfty4RGeSEhIYSEhPz+/48cOcJ//vMf9u7dy4YNG8jPz6d69eq0bduWYcOG0bFjRyk4QpQy+S9MiH9gMpkYMWIEvXr1YuDAgcTExFhEmYGCO1dLobEsrVq1YtGiRVy7dg2j0cjevXt58sknOXz4MF26dMHOzo6aNWsyfPhw9u3bJ39+QpQCmdAI8Re3bt0iLCyMhIQEfvzxR3r16qV0pPvIhMbyhYeHEx4eDhSU4927d/Pdd9+xb98+VqxYgUqlIjAwkA4dOvDCCy/QqlUrhRMLYf1kQiPEnyxfvpyaNWtSqVIl4uPjLa7MQMGE5iH3vgkFqdVqIiIiWLlyJTExMRgMBjZv3kxoaCg7duygTZs22NnZERQUxNixYzl58qTSkYWwSlJohKDg9gW9e/dm+PDhTJw4kUuXLuHp6al0rH8kB+tZN7VaTbdu3Vi9ejU3b97EaDSybt06mjRpwqZNm2jRogUajYb69eszceJEuTxfiAckVzmJCu/y5cu0a9cOrVbLtm3baNu2rdKRijRhwgQ2b95MbGys0lFEKTAajXz//fesXr2ao0ePkpiY+PsEJyIigtGjR1O/fn2lYwpRluQcGiGK89lnn9GoUSNq1apFYmKixZcZkD005Z2trS0DBw7khx9+4M6dO+h0OpYsWUJAQAArV66kQYMGODg4EBwczJQpU4iKilI6shAWQQqNqJB0Oh3h4eFMnjyZDz74gCNHjuDk5KR0rAcie2gqFo1Gw3PPPcfWrVtJSkpCq9Xy9ddf4+fnx5IlS6hduzZOTk48/vjjTJ8+XSZ3osKSJSdR4Rw5coQuXbpga2vL3r17adKkidKRHsqbb77JypUriY+PVzqKsAA5OTmsWLGCDRs2cOrUKVJTU3FycqJBgwb06NGD0aNH4+fnp3RMIUpClpyE+Ku3336bNm3a0Lp1axITE62uzIBMaMT9nJycePHFF9m1axcpKSmkp6cza9YsXFxc+Pzzz6lWrRrOzs60atWKjz76iKSkJKUjC1EqpNCICiEtLY0mTZrw6aef8s0337B9+3arvbmgXOUkiuLq6sqECRPYs2cPqampJCcn8/7772NnZ8esWbOoUqUKrq6uhIWF8cknn5CSkqJ0ZCHMQgqNKPe2b99O1apVSUlJ4fr164wZM0bpSCUiExrxMDw9PZk0aRIHDhwgPT2dxMREpk6dislk4v3338fLywt3d3fat2/PvHnzyMjIUDqyEI9ECo0ot0wmE6NHj6Z79+707duXuLg4AgIClI5VYjKhESXh4+PDW2+9xeHDh8nMzOTOnTu88cYbaLVapk2bhpubG56ennTq1Imvv/6arKwspSML8UCk0IhyKT4+ntq1a7N8+XLWr1/PqlWrys3NAWVCI8zJ19eXf/3rXxw7doysrCxiY2MZP348aWlpvP7667i4uODl5UXnzp1ZvHgxOp1O6chC/KPy8S+8EH+yatUqAgMD0Wg03L59m379+ikdyaxkQiNKk7+/P++//z4nT54kJyeH6OhoXnzxRZKSkpgwYQKOjo74+PjQvXt3li9fjl6vVzqyEIAUGlGOmEwm+vbty9ChQxk7dixXrlzB29tb6VhmZ2dnJxMaUWZq1qzJhx9+yJkzZ9BqtVy5coVhw4Zx8+ZNxowZg729PVWqVKF3796sXr0ao9GodGRRQUmhEeXC1atXqVq1Kjt37mTPnj3MmzdP6UilxsbGRgqNUEzdunX55JNPOH/+PDqdjgsXLvDss89y/fp1hg8fjkajwc/Pj379+rFx40YpOKLMSKERVm/evHk0bNiQgIAAEhISaN++vdKRSpXsoRGWpFGjRsydO5dLly6Rm5vLyZMn6dOnD5cuXeKZZ55Bo9FQvXp1Bg4cyObNm2W5VJQaKTTCaun1etq3b8+kSZOYMWMGx48fx9nZWelYpU720AhL1rx5c7766iuuXLmCwWDgyJEjdO/enTNnztC3b1/s7Ozw9/dnyJAh/Pzzz/J3WZiNdZ4sJiq8EydOEBERgVqt5tSpUzRt2lTpSGXGzs5O6QhCPLCWLVvSsmXL3///wYMHWbp0Kfv372ft2rXk5+fj7+9PeHg4w4YNo3379uXmikRRtuRvjbA677zzDk888QShoaEkJCRUqDIDMqER1i0sLIylS5cSFRWFXq9n586dtG3blv379xMREYFGo6FWrVqMGjWKQ4cOKR1XWBEpNMJqZGRk0KxZMz788EPmz5/Prl270Gg0SscqczKhEeWFWq2mY8eOLF++nJiYGAwGA1u2bKFly5a/Fx07OzuCgoIYO3YsJ06cUDqysGBSaIRV2LVrF76+viQmJnL16lXGjh2rdCTFyFVOorxSq9V07dqV//73v8TFxWE0GtmwYQPBwcFs3ryZli1botFoqF+/PhMmTOD8+fNKRxYWRAqNsHhjx46lc+fO9OrVi1u3blGrVi2lIylKzqERFYVaraZ3796sX7+e27dvo9frWbVqFfXr12fDhg00bdoUe3t7GjVqxKRJk7h8+bLSkYWCVA/5D6P8KyrKTEJCAmFhYdy8eZMVK1YwcOBApSNZhM2bNzNgwAByc3OVjiKEovR6PevXr2fNmjUcP36cpKQk7O3tCQoKokuXLowePZo6deooHVOUnOpBniQTGmGR1q5di7+/P2q1mps3b0qZ+ROZ0AhRQKPRMGTIELZs2UJiYiJarZZvvvmG6tWr85///IegoCAcHR1p3rw506ZNIzY2VunIohRJoREWxWQyMWDAAAYPHsyoUaOIjIzEx8dH6VgWRQ7WE+KfOTg4MHz4cLZt28bdu3fJzs5m3rx5eHt788033xAYGEilSpUICQnh3Xff5datW0pHFmYkS07CYkRFRREWFkZGRgabN2+mY8eOSkeySPv27SMiIgKDwaB0FCGsSkZGBsuXL+f777/nzJkzpKWlUalSJRo1akTPnj0ZOXIkvr6+SscUfydLTsJ6LFiwgLp16+Ln50dCQoKUmSLIhEaIR+Pq6sr48ePZs2cPqamppKam8sEHH2Bvb8/s2bOpWrUqrq6uhIWFMXv2bO7du6d0ZPEQZEIjFKXX6+nWrRt79+5l+vTpvPvuu0pHsnjHjh2jTZs2ctM/Iczs3r17LF26lE2bNnHhwgUyMzNxdXWladOm9OnTh+HDh+Pu7q50zIrogSY0UmiEYk6fPk3Hjh3Jz8/nf//7HyEhIUpHsgonT56kZcuW5OXlKR1FiHItISGBJUuWsGXLFi5evEh2djbu7u40b97894JTEe4fZwFkyUlYrvfee4/Q0FCaNWtGUlKSlJmHUBFPRxZCCb6+vkybNo2jR4+SlZXFzZs3eeWVV0hPT2fKlCm4uLjg5eXFU089xaJFi8jJyVE076+//lqhNzrLhEaUqaysLNq3b8/Zs2eZO3cuEyZMUDqS1bl06RKNGzeW+zkJobCYmBi+/fZbtm/fzuXLl9HpdHh7exMaGsqgQYMYNGgQDg4OZZZnxowZhIaG0qNHjzJ7zzIiExphWfbs2UOVKlW4ffs2ly9fljLziGRCI4RlCAwMZObMmZw+fRqtVktkZCQjRozg1q1bvPjiizg6OlKlShV69uzJqlWr0Ov1pZonOzsbJyenUn0PSyaFRpSJCRMm0KlTJ7p27crt27fl9M4SkKuchLBMderUYfbs2Zw/fx6dTsfFixd59tlniY6O5oUXXsDBwYGqVavSt29fNmzYYPaN/Tk5OVJohCgtSUlJBAUFsXDhQlatWsWGDRtQq+WvXUnI3baFsA4NGzZk7ty5XLp0idzcXE6fPk3//v25fPkyzz77LBqNhmrVqjFgwAA2bdpU4mXknJwcKlWqZKb01kc+WUSp2bhxIzVq1CAvL4+YmBgGDx6sdKRywdbWVukIQohH0LRpU7788ksuX76MXq/n2LFj9OzZk3PnztG/f39sbW3x9/fn2WefZfv27Q9dcB5kyemFF17Ax8eHRo0a/f5rkydPpl69ejRp0oQ+ffqQlpYGgE6nY/DgwTRu3Jj69evz0UcfPfw3XYak0AizM5lMDB48mAEDBjBs2DCioqLw8/NTOla5IXtohCgfQkND+eabb4iMjMRgMHDgwAGeeuqp34uOnZ0dgYGBPP/88+zevbvYgvMgS07Dhw9nx44d9/1aREQEFy9e5Pz58wQFBf1eXNasWUN+fj4XLlzg1KlTLFy4kJiYmBJ9z6VJftQTZnXjxg3atm1LSkoK27dvp3PnzkpHKndkQiNE+RQWFkZYWBhQ8IPhvn37+O6779i/fz8rVqzAzs6uyI3FD7LkFB4e/rdS8tRTT/3+v5944gk2bNgAFFy2np2djdFoRKvVotFocHV1fcTvrvTJhEaYzaJFi6hTpw7e3t4kJCRImSklMqERovxTq9U8+eSTfPfdd/eVnKLk5OTg6OhYovddunQpXbt2BaBLly64ublRtWpV/P39eeONN/D09CzR65cmKTSixIxGI507d2bs2LFMmTKFs2fPWnSLt3YyoRGiYsjLy6NNmzasW7eOt99+u9gLAgwGQ4kuGpg5cya2trYMGTIEgJUrV5KTk0N8fDw3btxgzpw5REdHP/Lrlzb5l1GUyPnz5+nQoQNGo5EjR47QokULpSOVe78Vmry8PGxsbBROI4QoDVlZWTRu3Jh79+5x7tw5Dh06VKr/vS9btoytW7eye/duVKqCc+wOHTpEnz59sLOzw8fHhzZt2nDy5Ekee+yxUstREjKhEY9s5syZNGvWjEaNGpGYmChlpowZDAalIwghSkFsbCw1atQgNzeXGzduUL9+fdLT04udvvxWRB7Wjh07mD17Nps3b75vU3G9evXYs2cPUHAF1dGjR6lXr94jvUdZkEIjHlpOTg4tW7ZkxowZzJkzh/3795fp8d6igBQaIcqfI0eOULduXQICAoiJicHb2xuA9PT0YvfPPciBm4MHD6ZVq1ZcvXqV6tWrs2TJEsaPH09mZiYRERE0bdqUl156CYAXX3wRvV5Po0aNCA0NZcSIETRp0qTk32QpkSUn8VAOHDhAt27dcHJy4uLFixbd1ss7KTRClC9r167l2WefpWfPnvz444/3PZaZmVlkoXnQ08NXr179t18bOXLkPz7XwcGBVatWPdDrWgKZ0IgHNmnSJNq3b0+nTp1ISEiQMqMwKTRClB8zZ85k8ODBvPrqq38rM1B8odHr9RV+Ui4TGlGse/fu0bZtW6Kiovjuu+8YOnSo0pEEUmiEKC9GjBjB8uXLmT9/PuPGjfvH52RlZRVZWCr6fZxACo0oxqZNmxg0aBC+vr5ER0dTvXp1pSOJ/2fuG9sJIcqWyWSiQ4cOHD58mK1bt/5+/ss/yc7OLvKMmYp+p22QJSdRCJPJxPPPP0+fPn147rnnpMxYGJVKJRMaIaxYdnY2QUFBnDp1ijNnzhRZZn57flGFRiY0MqER/yAuLo6wsDDu3r3L1q1b6datm9KRxD+QQiOEdbp16xbBwcHY2dkRHR2Nj49PsV+j1WqLPLC0ot9pG2RCI/5iyZIl1KpVCzc3N+Lj46XMWCiVSiVLTkJYoRMnTlCnTh2qVq1KbGzsA5UZKCg0RRUWWXKSQiP+n9FopFu3bowePZpJkyZx4cIFPDw8lI4liiATGiGsy8aNG2nVqhUdOnTg/Pnz2NvbP/DX6nQ6nJ2dC31clpxkyUkAFy9epH379uj1en755RfatGmjdCRRDJnQCGFdPvnkE6ZMmcLLL7/Ml19++dBf/yCFRpacRIU2e/ZsgoODqVevHklJSVJmrIhMaISwDi+++CJTpkxh7ty5j1RmoOCcGRcXl0IflyUnmdBUWDk5OXTq1Iljx44xa9YsJk+erHQk8RBkQiOE5TOZTDz11FPs27ePTZs20bNnz0d+reIKjSw5SaGpkA4dOkSXLl1wcHDg/PnzNGzYUOlI4hFIoRHCcuXk5NC8eXPi4uI4efIkTZs2LdHrGQwG3Nzciny/oq6CqghkyamCmTx5Mm3btqVdu3bcuXNHyoyVknNohLBc8fHxBAQEkJKSQnR0dInLDBT8AFNcoanoe2hkQlNBpKSkEB4eztWrV1myZAkjRoxQOpIoAVlyEsIynT17ltatW+Pv78/Zs2fNdn8lo9GIu7t7oY/LHhqZ0FQIW7dupVq1amRkZBAVFSVlphyQQiOE5dm8eTMhISGEhYXx66+/mvVmkXl5eXh6ehb6uOyhkUJTrplMJkaMGEGvXr0YOHAgMTEx+Pv7Kx1LmIEsOQlhWT7//HOefvppRo0axc6dO1GrzfvxajKZijwbTJacZMmp3Lp16xZhYWEkJCTw448/0qtXL6UjCTPLy8tTOoIQAhg/fjwLFixg9uzZvPHGG6XyHvn5+Xh5eRX6uCw5SaEpl5YvX87IkSMJCgoiPj6+yDGlsE4yoRFCeSaTie7du7Nr1y7Wr19Pv379Su19AFlyKoYUmnLEaDTSr18/tmzZwmuvvcacOXOUjiRKiUqlkgmNEArS6XSEhIQQFRXF0aNHCQkJKbX3ysjIAECj0RT6HFlykkJTbly+fJl27dqh1WrZv38/bdu2VTqSKEUyoRFCOUlJSTRu3Bij0ci1a9eoXr16qb5fSkoKKpWqyOfIhEY2BZcLn332GY0aNaJWrVokJiZKmakA1Gq1TGiEUMDFixepWbMmrq6u3Lx5s9TLDEBycnKxhSY7OxtHR8dSz2LJpNBYMZ1OR3h4OJMnT+aDDz7gyJEjFb6hVxRy2bYQZW/79u00a9aM0NBQrl69Wmb/3qampmJjY1Pkc/Ly8rC1rdiLLlJorNSxY8eoUqUKly5d4syZM7z99ttKRxJlSPbQCFG2FixYQI8ePRg6dCj79u0z+2XZRUlLSyu20BQ3wakIpNBYoalTp9KqVStat25NYmIiTZo0UTqSKGOyh0aIsjNp0iTGjx/PBx98wNKlS8v8/dPS0oqdvuTn55dRGstVsedTViYtLY3w8HAuX77MN998w5gxY5SOJBQie2iEKH0mk4mnn36abdu2sXr1agYNGqRIjvT0dOzs7BR5b2sihcZKbN++nb59++Ll5cX169cJCAhQOpJQkOyhEaJ06fV6WrRowZUrVzh06BAtW7ZULEtGRkaRhSY/P1+WnJAlJ6swevRounfvTt++fYmLi5MyI2RCI0QpunfvHoGBgcTGxnL16lVFywwUFBp7e/tCH8/NzTXrfaOslUxoLFh8fDxhYWHcvn27VE+hFNZHJjRClI7Lly/TokULKleuTGRkJM7OzkpHIjMzs8hD9eS2BwVkQmOhVq1aRWBgIBqNhlu3bkmZEfeRCY0Q5rdr1y6Cg4MJDg7m+vXrFlFmoKCwFDWBkUP1CkihsTAmk4m+ffsydOhQXnrpJa5cuULlypWVjiUsjExohDCvb7/9li5dujBw4EAOHjxYppdlF+cHLOkxAAAgAElEQVRBCk1Fv+0ByJKTRbl69Srt2rUjKyuLPXv20L59e6UjCQslExohzGfKlCl88sknzJgxgxkzZigd52+KW1KSJacCllNBK7h58+bRsGFD/P39SUhIkDIjiiQTGiHMo3///nz66acsX77cIssMgFarLbKwyJJTAZnQKEyv19O5c2cOHDjAu+++y/Tp05WOJKyAWq3GZDIpHUMIq2U0GnniiSe4cOEC+/fvJywsTOlIhdJqtVSrVq3Qx2XJqYAUGgWdOHGCiIgI1Go1p06domnTpkpHElZCJjRCPLq0tDQaNWpEVlYWV65coWbNmkpHKpJOpytyg7JMaArIkpNC3nnnHZ544glCQ0NJSEiQMiMeio2NjeyhEeIRXLt2DX9/f2xsbIiLi7P4MgMF58wUVWhkD00BKTRlLCMjg+bNm/Phhx8yf/58du3aVeT5AkL8E5nQCPHw9u3bR8OGDWnQoAFRUVG4uroqHemB5ObmFplVJjQFpNCUoV27duHr60tCQgJXr15l7NixSkcSVkr20AjxcL777js6duxInz59OHr0aLE3e7Qker2+2CUn2UMjhabMjB07ls6dO9OrVy9u3bpFrVq1lI4krJharZYJjRAPaPr06YwYMYK33nqLtWvXKh3noRmNRtzc3Ap9XJacClhPRbVSCQkJhIWFcfPmTdasWcPAgQOVjiTKAZnQCPFgBg8ezLp161iyZAkjRoxQOs4jMRgMuLu7F/q4LDkVkEJTitauXcvzzz9PQEAAN2/exMfHR+lIopyQCY0QRTMajYSFhXH69Gl2795t1Wd75eXlFVtoZMlJCk2pMJlMDBo0iI0bN/LSSy+xYMECpSOJckYmNEJAfn4+aZlaXJzssbW1+f3XMzIyaNy4MampqVy6dIk6der8/ljsnRTe+XILMbeTCarpQ7e2jWhU2486AZb7A2deXh4eHh6FPi5LTgWk0JhZVFQUbdu2JS0tjZ07d9KpUyelI4lySG59ICq6hLvpTPxoPbeS0lCrVES0rkezejWoV82JFi1CcHZ2JiYmBk9Pz/u+bsqcH4i/m056ppZ1O06z89AVavh68MHEnrQPDVLouymayWT62/fxZ7LkVEAKjRktWLCAiRMnEhwczJUrV6zmkkBhfWxsbGRCIyqs2Phkur30FQnJGUA+BqOJi9fj8auUQ+S+xTRp0pjjx4//7UomozGP2DspGAx5RN28S35+PqkZ2VT1dmHBmgMWW2jy8/Px8vIq9HEpNAXkKicz0Ov1dOrUiQkTJjBt2jROnTolZUaUKjmHRlRks5bsJDVTizbXQI7OiMGQR07CRS7vXoibXz1+3n3gHy/LtrW1of5jVbhxOxmVWoVKpcLW1oY7yZkKfBcP5rcfXIqb0MgeGpnQlNjp06fp2LEj+fn5HDt2jJCQEKUjiQpAJjSiIou+eY/0rBzy84H8fAx3jpGXcBxbn+Z4NOyOvV3hH22zXuvD3uPXyM7JRW/MQ61SYTKZGPdMeNl9Aw8hLS0NoMhzc2QPTQGZ0JRQaGgo6enptGrVitjYWPmQEWVC9tCIiiwjU4vJBOTno4/ZWVBmarTHrnoYtjZqbGxUhX6tj6cLcyb3JSjQhzr+PlT39eDr6YMtdrkpJSUFlarw7wcKJjSOjo5llMhyyYSmhNRqNf369ePixYs888wzmEwmatWqRY8ePZgwYYJV3CdEWB+Z0IiKzJSfh8lkwnBtI/nZidjV6o2Nqz/55KNWqbBRF/2zet9OzWhcpxp37qZTO8AHv8qFH1qntAcpNPn5+djY2BT5nIpAJjQlZGtrS//+/bl48SK5ubns2LGDJk2asHLlSh577DFcXV3p2LEj//nPf9Dr9UrHFeWETGhERZaVnY3+1+Xka++hqfcMNq7+AKhQkQ9o7Ir/cK8T4EN4SB2LLjNQUGiKKyv5+flllMaySaEpIVtbW1JTU4GCD5mIiAg2bNhAUlISqampTJ06lfT0dMaOHYuDgwOBgYGMGTOG8+fPK5xcWDOZ0IiKKjY2lqs/fwYmI5qGz6N2/OPqHwcHW7w9Cr/nkTVKT0+X6csDkkJTQnZ2dr9v2vord3d33nrrLU6ePIlOp+Pw4cOEh4fz008/ERwcjJOTE61bt+bLL78kJyenjJMLayYTGlERHTt2jLp16+Lu6U2NdhOw0VQClQpUKuzsbLC1sWFk39aoi1lysiZpaWnF3kizuCWpiqL8/KkrxM7OjoyMjAd67hNPPMHy5cu5ffs22dnZfPrpp6jVat566y0qVaqEn58fQ4YM4dChQ6WcWlg7mdCIimbdunW0adOGiIgIrly+xODuLalZzQtnJw3Vq7hRw9eD6S92ZVjvJ5SOalbp6enY2dkV+rgsN/1BNgWXkL29/QMXmj9zcnJi3LhxjBs3DoBLly4xf/58duzYwerVq7Gzs6Nhw4b069ePsWPHFnkGgah4ZEIjKpJZs2YxdepUXnnlFebOnQvAx6/14ePX+nA9Lomom/cI9POibs0qCic1v/T0dDQaTaGPa7VaucLp/8mEpoQcHBweqdD8VcOGDfn666+5ceMGer2exYsX4+npyezZs/Hy8qJy5cr07duX7du3y0/mQiY0osIYNWoU06ZN44svvvi9zPxZbX8fOrasy9Hz0Yx5dxWzl+4kM1unQNLSkZmZWWShkVOC/yATmhJycHAgKyvLrK9pa2vL0KFDGTp0KAAxMTHMnz+frVu30rNnT1QqFUFBQfTu3Zvx48fj5+dn1vcXlk9uTinKO5PJRMeOHTl48CBbtmyhW7du//g8Xa6B4dOWs+/ENdxcHDh39Ta3k9KY99bAMk5cOjIzM3FwcCj0cTkl+A8yoSkhR0dHsrOzS/U9AgMD+fTTT7ly5Qp6vZ4NGzZQq1YtFi5cSLVq1XB3d6dLly6sXbtWPuQqCFtbW/mzFuVWTk4O9erV4/jx45w+fbrQMgMwd/ke9p+8BkBahpaMLC3HL8RiNJaPJdns7Gzs7e2LfFwmNAWk0JSQk5NTqReaP1Or1fTu3ZvNmzeTnJxMYmIir776Knfu3GHo0KHY2dlRu3ZtJk6cyLVr18oslyhbsodGlFe3bt3C39+f9PR0oqOjady4cZHPP3r+Bm4ujuSTj52dmnvp2VTxcsXGpnx8vGVnZxc7oZFCU6B8/IkryMnJSdFLrn18fHj33Xc5d+4cer2eXbt2ERISwrp16wgKCsLZ2Zl27drx7bffysF+5YiNjY1c3SDKnVOnTlGnTh2qVKlCbGwsVaoUv8m3dkBl3JwdcHa0R6sz4OJkz8evPV1uLmUubgIjS05/kEJTQi4uLmi1WqVj/O7JJ59kzZo1JCQkkJ6eznvvvYdWq2XixIk4ODjg7+/PCy+8wOnTp5WOKkrAxsZGJjSiXPnhhx9o2bIl7dq148KFC0VOJf7s7ZGdCa5bncqeznRp04AD300qV1c7abXaYguNTGgKSKEpIWdnZ3Q6y9xR7+rqyuuvv87x48fRarUcP36cTp06/T7FcXR0pGXLlnz22Wdm39gsSpdMaER5MmfOHPr168eLL77Ijh07HupgPG8PZxa9O4TDK99g1ewXqF7FoxSTlj2tVlvkBEb20PxBCk0Jubi4kJubq3SMBxISEsLSpUu5efMmOTk5zJs3DwcHB9555x1cXFzw9fXlmWeeYd++fUpHFcWQCY0oL8aOHcvkyZOZM2cOX3311SO/Tnk6HfjPdDodzs6F385BJjR/KJ9/A8qQNRWaP3NwcGDMmDHs37+frKwsrly5woABAzh58iQdO3ZEo9EQHBzMe++9x71795SOK/5CJjTC2plMJiIiIvj222/54YcfeO2115SOZJFyc3NxcXEp9HHZQ/MHKTQl5O7ujsFgUDpGidWtW5cvv/yS69evk5uby/Lly6latSpz586lcuXKeHl5/X51lVwurDw5WE9YM51OR8OGDTl06BDHjx+nd+/eSkeyWHq9vshCI0tOf5BCU0Jubm7lotD8ma2tLc888ww7duwgLS2NmzdvMmbMGK5du0bfvn3RaDTUq1ePyZMnExsbq3TcCknOoRHWKiEhAX9/f+7evcv169dp3ry50pEsWnGFRpac/iCFpoTc3d0xGo1KxyhV1atX56OPPuLXX39Fr9ezZcsW6tevz7JlywgMDMTNzY2IiAhWrlxZ7n8vLIWcFCys0fnz53nsscfw8PAgLi5OTjl/AAaDATc3t0IflyWnP0ihKSEvL68KtTlTrVbTtWtXfvjhB+7evUtycjJvvvkmycnJjBw5Eo1Gw2OPPca4ceO4fPmy0nHLLVtbW9lDI6zK1q1befzxx2nVqhWXL1+WqcIDMhqNxRYa+b0sIIWmhDw9PSv0T8qenp5MmzaN06dPk5uby4EDB2jVqhU//vgjDRo0oFKlSoSFhbFgwQKLvbzdGskeGmFNvvzyS3r16sWIESPYvXt3ub0iqTTk5eXh4VH4peiyh+YP8reqhCp6ofmrsLAwVq1aRXx8PFlZWXz00UeYTCbeeOMNnJycqF69OsOGDePYsWNKR7VqsodGWIuJEyfyyiuvMGvWLBYtWqR0HKtTXKGRCc0fpNCUkLe3N4B8uPyDSpUqMXHiRA4fPkxOTg5nzpyhW7du7N+/n1atWuHg4EBISAizZ88mLS1N6bhWRS7bFpbOZDLRvXt3FixYwLp163jzzTeVjmSVTCYTnp6ehT4ue2j+IIWmhH47nltO2i1ecHAwixYtIiYmBp1Ox9dff42rqyv//ve/8fDwwMfHhwEDBvC///1PPqyLIRMaYcn0ej3BwcHs2bOHI0eO0L9/f6UjWa38/Hy8vLwKfVyWnP4ghcYMVCoVycnJSsewKhqNhhEjRrBnzx4yMzO5fv06Q4YM4dy5c3Tu3BmNRkPjxo2ZPn06CQkJSse1ODKhEZbq7t27+Pv7Ex8fz9WrVwkNDVU6ktX67apRd3f3Qp8jS05/kEJjBiqVSk7TLaFatWoxd+5cIiMjMRgMrFmzBn9/f7766iuqVq2Kp6cn3bt3Z+PGjTKZQCY0wjJdvHiRmjVr4uzsTGxsLP7+/kpHsmq/LcXb2toW+hytVoujo2NZRbJoUmjMwMbGhpSUFKVjlBtqtZp+/frx008/kZKSwp07d3j55ZeJi4vjmWeewc7OjqCgIF577TWioqKUjqsImdAIS/Pzzz/TrFkzHn/8cSIjI4u8/5B4MMnJyahUqiKfYzKZ5Kqx/ye/C2ZgY2Mjm1pLka+vL//+97+5cOECer2en3/+meDgYFatWkXt2rVxcXHhySef5D//+Q96vV7puGVCJjTCknzzzTd069aNIUOGsH//fvmANZPU1FT5vXwI8jtlBnZ2dqSmpiodo0JQqVR06tSJ9evXk5SURGpqKtOnTycjI4OxY8fi4OBAYGAgY8aM4fz580rHLTUyoRGWYvLkyYwbN47333+fZcuWKR2nXJFC83Dkd8oM7OzsZEKjEHd3d958801OnjyJTqfjyJEjtGvXjm3bttG0aVOcnJxo1aoV8+bNIycnR+m4ZmNnZyeFRiju6aef5rPPPmPVqlVMmzZN6TjlTlpaWpH7Z4Bil6QqEik0ZqDRaMjIyFA6hgBatmzJd999x61bt8jOzubTTz/FxsaGqVOnUqlSJfz8/BgyZAgHDx5UOmqJyIRGKEmv19OsWTN27NjBL7/8wuDBg5WOVC4VV2hMJpMUmj+RQmMGUmgsk6OjI+PGjePgwYNkZ2dz8eJFnn76aY4cOUJ4eDj29vY0b96cmTNnWt2mbrmXk1BKSkoKNWvWJCYmhitXrtC6dWulI5Vb6enp2NnZFfq4XOF0Pyk0ZuDg4EBmZqbSMUQxGjZsyIIFC4iOjkav17NkyRK8vLyYPXs2Xl5eVK5cmT59+rBt2zaL33ArExqhhKtXrxIQEICdnR2xsbEEBgY+0NfduHWPLfsucOTcDfl7+xAyMjLQaDSFPi6nBN+v6MU58UAcHBzkpGArY2try3PPPcdzzz0HQGxsLPPnz2fLli306tULgKCgIHr37s3LL79M9erVlYz7N7KHRpS13bt307VrV0JCQjhw4ECxezt+c+7qLV75aD16g5G7KVk4OWpo0SSQqaM6U7O6dymntm6ZmZlFFho5Jfh+MqExA0dHR7Kzs5WOIUogICCATz75hCtXrqDX6/n++++pU6cOixYtokaNGri7u9OlSxfWrFlDXl6e0nFlQiPK1JIlS3jqqacYMGAAhw8ffuAyA7B80zH0BiPpWTpSM3OIv5vOlegEXplVUHJE4TIzM7G3ty/0cTkl+H5SaMygUqVKUmjKEbVaTa9evdi0aRPJyckkJiby2muvcefOHZ5//nk0Gg21a9dmwoQJREZGKpJRJjSirEydOpXRo0fzr3/9i1WrVj301yenZxMZm8SthFRytHpydHrupmSRlJxJcpr8u1mUrKys3+8X+E9kyel+UmjMwMnJCa1Wq3QMUUp8fHyYMWMG586dQ6/X87///Y+QkBDWr19P3bp1cXZ2pl27dixatIjc3NwyySQTGlEWBgwYwMcff8yyZct47733Huk19AYjapWK/Px88oF8Uz730rKIv5uOh6tsaC1KTk5OsYVGJjR/kEJjBs7OzlJoKpAOHTqwZs0aEhISyMjI4P3330en0/HKK6/g6OhIjRo1eOGFFzh16lSpZZAJjShNRqOR0NBQNm/ezN69e3n++ecf+bVcnR2pG+iDm6sjGjsb1GoVzk72VPZ0RpsrS05FKa6wyB6a+0mhMQMXFxd0Op3SMYQCXFxcmDRpEseOHUOr1XLixAmeeuop/ve//xEaGoqjoyMtWrRgzpw5Zr20Xy7bFqUlLS2Nxx57jMjISC5dukR4eHiJXm9Uv9ao1GocNHbYqNXUq+VLrereVPV2w8Wp8P0hovhCIxOa+0mhMQMXF5cyW2oQlu3xxx9nyZIlxMXFodVq+eKLL3B0dGTGjBm4ubnh6+vLM888w969e0v0PkWdTSHEo4qKiiIgIAAouPKvdu3aJX7NkIYBfDfzeT6e1Ie+nZriYGeHh1sl5kzuh62tTYlfvzzT6XRF7pGRPTT3k8u2zcDV1bXC3BRRPDh7e3tGjx7N6NGjAYiMjGT+/Pls27aN9evXY2NjQ/369enTpw/jxo3Dx8fngV9bJjTC3A4cOEBERATBwcEPfSVTcWpW96ZmdW/6dmpKfn6+nG77gHQ6XZF3LZclp/vJhMYM3N3dpdCIYgUFBfHFF19w/fp1cnNzWbFiBVWrVuXzzz+nSpUqeHl50bNnTzZt2lTswX6yh0aY0/Lly+nQoQO9e/fm+PHjZi0zfyVl5sHpdDpcXFwKfVyWnO4nhcYM3N3dMRgMSscQVsTW1pZBgwaxY8cO0tLSuHnzJmPGjCE6Opp+/fqh0WioV68ekydPJjY29h+/Xoii6A1GrsUmceduepHPmzFjBsOHD+fNN99k3bp1ZZROPAi9Xl9soZElpz9IoTEDd3d3izhsTViv6tWr89FHH3Hp0iX0ej1btmyhQYMGLFu2jMDAQNzc3OjUqRMrVqzAaDTKkpMoUnqmlpHTVzJy+kq6j1vAwNcXM2/FXu6l3n+i+XPPPccHH3zAt99+y0cffaRQWlEYvV6Pm5tboY/LhOZ+UmjMwMvLC6NRLj8U5qFWq+natSvff/89d+/eJTk5mTfffJOUlBRGjRqFRqOhd+/emEwmLl26pHRcYYE27DzNtbgkIJ9biansPnqFlT8d56X3/4tWp8doNNK6dWvWrVvHzp07GTlypNKRxT8wGAxFTmhkD839pNCYgYeHh8XfzFBYL09PT6ZNm8bp06fJzc3lwIEDNGvWDIBGjRpRqVIlwsLCWLBggRwfIAC4mZhKzO0Uzl+LJzsnF4PRhN5g5M7dDM5djqZ27dpcuHCBCxcu0LFjR6XjikIYjUbc3d0LfVwmNPeTQmMGXl5eMv4XZSYsLIzPPvsMlUpFdnY2s2bNwmQy8cYbb+Dk5ES1atV4/vnnOXr0qNJRhQJuJ6WxdsdpMrN15OqNmPLBYMwjPjGNa9ej6Ny+JQaDgdjYWOrWrat0XFGEvLy8YguN7KH5gxQaM/D09ASQKY0oM79d5eTk5MSECRM4fPgwOTk5nDt3jh49enDgwAFat26Ng4MDISEhzJo1i7S0NKVjizKwYPV+cnMNVHK0w9am4IoitVqFISOeeye+pVq1Gty4ceP3f7eE5TKZTEX+OcmS0/2k0JjBb7d3lw8MUVYKu8qpcePGLFy4kJiYGHQ6HQsXLsTNzY0PP/wQDw8PfHx86N+/Pzt37pQCXk7dS82mskcl1Go1tjYFB9c5amNIv7gaD7967N5/6Pd/s4RlK67QyJLT/aTQmIlKpSI5OVnpGKKCeJCTgjUaDcOGDWP37t1kZGQQHR3Nc889x/nz5+natSv29vY0atSIf/3rX9y5c6cMUouy0KtDY2xsbPDzccfF2QH79HMkX9qEX71w5s5fQtXKhV81IyxLfn4+Xl5ehT4uS073k0JjJmq1WgqNKDOPcuuDmjVr8tlnnxEZGYnBYGDt2rUEBgayYMEC/Pz88PDwoFu3bmzYsEGmN1asW3gjZr32NIO6PE7N/HNk3viF92d+wqkDm3m+d0ul44kH9NuVs0XtodFqtUXejbuikUJjJjY2NqSkpCgdQ1QQJb2Xk1qtpm/fvmzdupWUlBTu3LnDhAkTuHXrFoMHD8bOzo6goCBeffVVoqKizJRalAWVSkVY81r89N0HHN7/Mz/99BPTp76Br7er0tFKVX5+PnuPX2XxxkMcOXdD6Tgl9tvniVpd+Me03EbiflJozMTGxobU1FSlY4gKwtw3p/T19eX999/n/PnzGAwGdu7cSXBwMKtXr6Z27dq4uLjQoUMHli5dKrf5sHBZWVkEBQVx+vRpzpw5Q5cuXZSOVCYWbTjI1HmbWfr9YV6fvYFNe84pHalEkpOTpaw8JCk0ZmJra0t6etFHjAthLqV9t+2OHTuyfv16EhMTSU1NZfr06WRlZTFu3DgcHBwICAhg9OjRnDtn3R8a5c3NmzcJCAggKyuL6OhoGjVqpHSkMrNm20lUqoJL1FGpWPXTCaUjlUhKSkqR0xmQ+2L9lRQaM9FoNHKVkygzNv9/9UpZ7HVxd3fnzTff5MSJE+h0Oo4dO0aHDh3Yvn07zZo1w8nJiVatWjFv3jyys7NLPY/4ZydOnCAoKAg/Pz/i4uIe6u7t5cHd1CwiY5IKDhS8eot9JyKZ+OE60jJzlI72SNLS0n7/77wwcv7Z/aTQmIlGo5EJjSgzv/1kpsRNUUNDQ1m2bBm3bt0iJyeHOXPmYGtry9SpU3F2dqZq1aoMGTKEgwcPlnm2imrDhg20atWKjh07cu7cuQp3WbbRmIdapcLWVk2uwUA+4KCx5eSvsXy+fI/S8R5JcYUmLy+v2AlORSO/G2ai0WjIzMxUOoaoYJS+y7uDgwNjx47ll19+ITs7m0uXLtG3b1+OHDlCeHg49vb2NGvWjA8++EA2zZeS2bNnM3DgQF5++WW2bt1aIT/kbGzUeHs406hWVTR2tlRy0ODooMHN2ZErNxKVjvdI0tPTCz1vCgqucJJLtu9X8f7mlxJHR0cpNKLMKV1o/qpBgwZ89dVXREdHo9frWbp0KZUrV+aTTz7By8sLb29vnn76aX766Se5NNwMxowZw1tvvcXnn3/OvHnzlI6jGJVKxdujOqM3mnBy1JCfn09Vb1fSMrS0bBKodLxHkp6eXuReOTkl+O8Kr3/ioTg4OJCVlaV0DFHBWFqh+TNbW1uGDBnCkCFDAIiLi2P+/Pls2bKF3r17AxAUFESvXr0YP3481atXVzKuVTGZTERERHDgwAE2b95Mjx49lI6kuIjW9WlYx49rsUn8dOACsfGpPNEkkHHPtFM62iPJyMgoculQTgn+Oyk0ZuLo6CgbIkWZs+RC81f+/v7Mnj2b2bNnYzKZ+Omnn1i8eDGLFy/m448/xs3NjZYtWzJ8+HAGDBhQ5Li9IsvJyaFZs2bcvHmTkydPEhwcrHQki+FX2Q2/ym60C6mjdJQSy8jIwN7evtDH5ZTgv5MlJzOpVKmSFBpR5n47TdTaqNVqevbsyaZNm7h37x53795l0qRJJCYmMmzYMOzt7alVqxbjx4/n6tWrSse1GPHx8QQEBJCamkp0dLSUmXIsKyur2EIjE5r7SaExk0qVKqHVapWOISoQlUplVROaonh7e/POO+9w9uxZ9Ho9u3fvpkWLFmzcuJF69erh7OxMeHg4ixYtQqfTKR1XEadPn6Z27dp4e3sTFxeHr6/vQ79GXp6JDTtPM+2LzazccpzEexkYjXmlkFaUVFZWVpG3NZA9NH8nM10zkUIjlFBeCs1ftW/fnvbt2wMF/7B/++23rF27lldeeYWXXnqJatWq0alTJ15++WVCQkKUDVsGNm3aRL9+/XjyySfZsWPHI13JpMs1MObdVew9HomTo4bU9BxcKjlQt6YPn77Rjwa1qpZCcvGosrOziyw0MqH5O5nQmImrq2uF/clRKMdal5wehrOzM6+99hpHjx5Fq9Vy8uRJOnfu/PsUx8HBgRYtWvDpp5+SkZGhdFyzmzt3Ln369GH06NHs3LnzkcpMeqaWXuO/5sfd50jPyCHuTgqZObkkpWSSkaVj6rzNpZBclIRWqy2ysMgemr+TQmMmLi4u5ObmKh1DVCDlacnpYTRv3pzFixcTFxeHTqdj/vz5ODk58d577+Hm5oavry+DBg1izx7rPFDtz15++WVef/11PvnkE77++utHeo2Ee+lEjJrHkbPRGPJMGEwmyAfy8zHmmbh4LZ5bCSly6qyFKW4CI0tOfyeFxkxcXV3lpn2izFWECU1RNBoNo0aNYt++fWRmZhIZGcmgQYM4ffo0ERERaDQamjRpwowZM0hKSlI67gMzmUx06dKFhQsXsnHjRl5//fVHen/9liMAACAASURBVB1droHRM/7LtbgkjHl5kJ9fUGZ+l4/BaCLXkCf3BbIwOp2uyAmMLDn9nRQaM3Fzc6uQPy0L5VTUCU1R6tSpw7x587h27RoGg4GVK1dSrVo1vvjiC6pUqYKXlxc9e/bkxx9/tNiD/XQ6HY0bN2b//v0cO3aMPn36PPJrxd1JITE5A53eCPxzYbFRq7ibkknP8V+z7udTj/xewrx0Oh3Ozs6FPi5LTn8nhcZMPDw85MNFlCmVSlXhJzRFUavVDBw4kO3bt5Oamsrt27d56aWXiI6OZsCAAWg0GurWrcsbb7xBbGzsfV+rNxjJ1pb9EnJiYiIBAQEkJiZy7do1Hn/88RK9noO9HTG3k6HQ8qbCkGdCpzeSlJzJ58v3cuxCTIneU5hHbm4uLi4uhT4uE5q/k0JjJu7u7uTlyeWPomxJoXlwfn5+zJw5k0uXLpGbm8vWrVtp2LAhy5cvJzAwEFdXVzp16sSkqTN58oXPeGr0l7wzf0uZXdZ84cIFHnvsMdzc3IiLizPLyckZWTq83CtBEctJKhU4OWiIjU9Gp9cTffNuid9XlFxubi6urq6FPi57aP5OLts2Ew8PDyk0okzJktOjU6vVdOnShS5dugCQkpLCwoULWb16LZ9/PIN8Ux4Ozp5cP1qHyk56JrzQr1TzbNu2jd69exMWFsbu3bvNdoNJNxdHXCo5oLGzQW/4+5RGBdjaqFGRj8mUj8GQR60alc3y3qJkDAZDkYVGJjR/JxMaM/H29rbYNXlRPsmSk/l4enry9ttvs/r7bdTr/g4ewc+S7+TLvZuXmDiyP5UqVaJNmzZ89dVXZj9v6quvvqJHjx4MGzaMvXv3mvVu2TV8PRjVrw02NrZ/m9LY2qpR26io4uWCSq1CpVLx4sC2tGgcaLb3F4/uQQqN7KG5n0xozMTLy0suexRlSgqN+alt1CSnZWHnWh0P9xrk6o1MHtYeZ/0N1qxZw+TJkxk/fjx+fn507NiRsWPH0qpVq0d+v9dee4158+Yxc+ZM/o+9+45r8mr7AP7LHoxAACeKiIoDxYWjuKq1bhBxVVpxobXWSm2ttba19amrVi3VVqt1PuJoxYmjtXXPOrBWxVEHDlxAEhLITt4/fODVahLU3LkTcn0/n+fzvjW33BdCkl/OOdc5kyZNcuJ38v9G9msDAZ+H79L34vqdfJjNFsj8JLBYLGhWPwwcADw+F2MHdUDHlpGM1ECen8lkQkBAgM3HacrpaRRonKTkF89kMtGhesRlKNA4l8lkRnhoMNTFepiMZggDeAgJDsSIxJ4YO3YsAODcuXNYsGABdu3ahdWrV0MgECAqKgp9+/bF6NGj7b4JlbBYLIiPj8fOnTuxdu1aDBgwgNHva2hCa/RoH4Ubd/KxZc9fuJdfiNdfqY/+XZpSu7abMpvNdn+XaMrpafTO6yQlIUahUCAkhOagCfNohMb5IkJDULViAO4+LASfywE4HLRpGvHENVFRUVi0aBEAwGAwYO3atVi1ahVmzJiBTz75BCEhIWjXrh1GjhyJ11577akpJIPBgJiYGFy6dAmHDx9Gy5YtXfK9VZD7oYLcj6aUPITZbIZcLrf5OE05PY0CjRNxOBzk5eVRoCEuQYuCnU8qEeLHzwdhzY4TUBfpEfdqQ9QNt30IpFAoRHJyMpKTkwEA169fx4IFC5CZmYlu3bqBy+UiMjIS8fHxGDNmDIRCIRo2bAi9Xo9Lly4hLCzMVd8a8TBWq9VhoKERmidxnnPdBy0SsYPP52P//v2IjY1luxTiBXx8fPD9999jyJAhbJdCnsFisWDLli1YunQpjhw5AoVCAQ6Hgxo1auDs2bN2N00jhMPhQKFQ2Jx2atq0KU6dOuUtU4Zl+iapy8mJeDweCgoK2C6DeAlvH6G5cScfWdm3oCl2zzPUuFwuEhISkJmZiYKCAty7dw9WqxX79++nMEPsKjlGx16XEwBvCTNlRlNOTsTn86FQKNgug3gJDofjlXsfWa1WTFu8Ext+y4KPRIQQuR8Wff4GKgXbf/FnW8WKFQEAIpGI5UqIuyv5YGyvhZ/CzNNohMaJ+Hw+VCoV22UQL8Hlcr1uhMZqteKzBdswb9Ue3H2owq17Ctx9qMR/tx1nu7QyEwqFbJdA3Fx+fr7DwELbhDyNRmicSCgUQqlUsl0G8RLeOEJz824Bdh+5CD6fB5GAB73BBJVGh2Kt55x0T4GGOKJQKJy6waK3oH8xJxIKhSgsLGS7DOIlvLFt22S2gM/jQu4vhd5ghtFkBqxA707RbJdWZhRoiCMKhQI8Hs/m47Tf2bPRv4gTiUQiqNVqtssgXsIbR2jCqwahRcMaOPrXNXA4HAj4XHz7cT9ER778QY5MKwmf9EZEHFGpVHYDDbVsPxs9s5yIAg1xJS6X63UjNFwuF1+PT8CBU1egKdajRcMaqBwiY7usMinpXCHEEaVSCYFAYPNxCjTPRoHGiaRSKTQaDdtlEC/hjSM0ACAQ8NCpVV22y3hu3raAm7w4lUpFgeYF0BoaJ5JIJCgqKmK7DOIlvHENjSd7fITGbLbgoUIDg5F+fuRphYWFdtda0bEHz0YjNE5EIzTElbhcrleO0HiqkhGauw9VGDvjZ9x7qILFYkXnV+ohJioMXWPrg8+3vW6CeA+1Wm030NBJ289GgcaJfH198eDBA7bLIF6CRmg8S0mg6TQ8DffyVOBwOTCaLMi+fh+RYRVw4lwOvhzTk+UqiTvQaDQQi8U2H6cpp2ejKScn8vX1hU6nY7sM4iVohMb93XmgxPl/cqFSF+PnnScBAHlKDTgcDoq1RhiNZuj1RhQUFuH3oxehLqLXD1K2QENTTk+jERonokBDXMkbu5w8yc+/nsZ3q/fCCitu3lPAUPgQAGAwmmF87OdmBXD7vhIWKyCgKSeCR1NK9gINTTk9G43QOJFMJoNe754H5ZHyx1u7nDxBoUaH+el7IRULkPtAhXyFBmrNo4YBs9mCR7vW///W9RxwKMyQUo6mlGjK6dlohMaJ/P39aa8J4jI0QuO+tHoD7uerUaDSQKs3wWoFLGYTAA7MFgv4PB4sVgssFiu4HA5EQgFCAn3Bo+3uCQCtVguZzPb+SjTl9GwUaJxIJpPRXhPEZbhcLiwWC9tlkH+xWq1YuvEIch8qYTY/doDg/35WAj4PgX5SVAr2w43cApjMFvB4XLw/uCMEAhqlIYBOp4Ovr6/Nx4uLixEYGOjCijwDBRonCgwMpE/MxGVohMY9Xcl5gM1/nIFEJECxzlCSY2DFo/9H5iNGbNOayH2gQs3QYOiNJnyS0hUJnRqzWDVxJ44CDa2heTYKNE4UEBBAbzDEZajLyT1ptAYIBXz4iEUoeuwUcI7VAoCDAJkU01N7QyTg4+bdAoRWCkQVDzm+gbiGXq+Hn5+fzcdpDc2zUaBxIrlcTlMAxGVoUbB7qlujIiqHyFCk1UOhLobVYoVAwIe+GDByONj147uoEhIAAKgU7M9ytcQdGQwGh4GG1tA8jQKNEwUHB1OgIS5DIzTuSSoR4scpg7Dx9zPYf/IyLl67Dx6PB0llA45c45WGGUJsMRgMdhcF05TTs1GgcaKgoCBYrVbHFxLiBBRo3Jdc5oMRibEYkRiLPIUGWr0RRw/sxtHMH9kujXgAo9HosMuJAs3TqEfQifz9Hw0fU+s2cQUej0eBxgMEB/qiWqVAmM1mcDgctsshHsBsNpe+nzwLTTk9GwUaJ+L+bw+J/Px8lish3oBGaDyL0WikQEPKxGw2223LphGaZ6NA42QcDocCDXEJ2ofGs5hMptIPPYTY4yjQ0BqaZ6Nnl5PxeDwUFBSwXQbxAjRC41lMJhON0JAysVqtCAoKsvm4Xq+HUCh0YUWegQKNk1GgIa5CgcazUKAhZeUo0HA4HPpdegYKNE7G5/OhUCjYLoN4AR6PR1NOHoTW0JCy0Ol0AGB3p2Dqpn02CjROxufzoVKp2C6DeAEaofEstIaGlEXJCD/9rjw/2ofGyYRCIQUa4hLUtu1ZjEajW79JXbx+D5v/+AsSkRDxHRuiSoUACAX0FuFqBQUFDkfyaKTv2ei31cko0BBXoS4nz+LOa2iu387D6KlrYTCacTdPhelLdiGiejBS3+yI/l2bsV2eVykoKACPZ/vUdaPRCD6f3rqfxX0/LngokUgEtVrNdhnEC9AIjWdx5ymnY2evQ6c3gs/joqjYAHAAPo+H79bsw/XbeWyX51WUSqXd3xPag8Y293x2eTCxWAyNRsN2GcQL0AiNZ3HnRcEBflJYAegMRlitVnAASEQCcDkcPFDQ65krKRQKuyMwFGhso0DjZBKJhEZoiEtQl5NncecRmtda1UXbprVgMlthtlgh9/eBVm+EVCxA7eohbJfnVQoLCx0GGjr24NloIs7JpFIpiouL2S6DeAGacvIs7hxoBAIevv4gAbkPVbjwz13sOHgOYpEQKYmxkMvozdOVVCoVBAKBzcdpl2DbKNA4mVQqhVKpZLsM4gVoysmzuHOgAR51zlStEICqFQLQ+ZV6bJfjtQoLC+3uAkxTTra577PLQ/n6+kKr1bJdBvECNOXkWdw90BD3oFarIRKJbD5OU0620bPLySjQEFehQONZzGYzBRrikFqthlgstvk4TTnZRs8uJ/Pz84Ner2e7DOIFKNB4FhqhIWVRVFRkN9DQlJNt9OxyMgo0xFUo0HgWk8lkd8M0QgAKNC+DAo2TBQQEwGAwsF0G8QIUaF6eSq3FmYu3cecB8wv5acqJlIWjwEJraGyjLicnk8lkMBqNbJdBvAAFmpdz8nwOxs34BSazGeoiPeqGV0TXNg0wOK4lxCLbbbMvigINKQutVovAwECbjxcVFSEoKMiFFXkOCjROFhAQAJPJxHYZxAtQoHlxZy7eRr/xP0FVWAy90QSAg9wHSuQ+UOHuQxWmvNPD6fekNTSkLHQ6HXx9fW0+TlNOttGzy8nkcjltdkZcwpsCzcXr9/Bd+l6s3HIMhRrdS3+9tNV7oNUZoDWYYLECFqsVBpMZRVoD9p647ISKn2Y2m2kNDXGoLIGGppyejUZonCwwMJACDXEJbwk0P+86hU++2woelwOZnwR/HLuIn6a+CaHgxV++bt1TQF30dDB6qFQjqk6VlynXJppyImWh1+vh5+dn83Fq27aNAo2TBQUFecWbDGGfNwSaw1lXMfm7rchXaGCxWqEsLAaPw8WNO/moU6PiC39ds9nyaKdl85P/fr4SEaaO6fmyZT8TdTmRsjAYDPD397f5OE052UYfF5wsJIQOciOuwefzYbVa2S6DUTsOnINWZ4DeYILRaIa6WI9rt/PA473cS1flEBnCQ4MhEvLB5XLAAdCgVmXsWZ6K2mEVnFP8v9AIDSkLo9HoMNDQlNOz0bPLyUqSMx1QSZjmDSM0BaoiKNVaWIFH/7MCAf4SmEwv932/M7AdAnwlqFU9BGGV5fjinR44vuYjVK8kd0rdz8LEGhqr1VruQ623MRqNkMlkNh+nERrbaMrJyUo+gRUUFNAvHWGUNwQasVAAsZCPYr0RHABCAQ+B/j6Q+Ule6uu2aVoLK6YNxj+3HqJ65UDUDa/knILtcHagOXDyCqYt3oVinR7No2qga2x9xESF0enYHs5kMtkNNLSGxjYKNAzgcrnIy8tDaGgo26WQcswbppxqhVVAzWohyFdpoFLrwOFw8P7gV1Ep2PaQfFnVrBaMmtWCnVBl2Tgz0Kzedhzvf50Bq9UCDoeLs5dz8dvhbERUC8ZPU99EBbntRaXEvZnNZrv70NAIjW005cQALpeLgoICtssg5Zw3jNAMjmuJpvWro2KQP+rVrIR1Xw/FgK7N2S7rhTgr0Pxz8wHmrtoDk9mMIq0RmmI9DEYz7j5U4fZ9JX49dMEJ1RK2WCwWu4HGaDRCKBS6sCLPQSM0DODxeFAoFGyXQco5bxih8fMRY+FnA6FUa+EjEb5UqzbbzGaz3TN6yir3gQpqTTF0+ic38NTpjbhxJw/q4pffp4ewx2Kx2N0JuLw/51+G5746uDE+n0+BhjDOG0ZoAIDD4SDQ3/OH2J01QmO2WJCnerrpoGThtCeHPvIIHW3wYmjKiQECgQAqlYrtMkg55w0jNOWJswKNxWJF9Upy8LicJ/6cy+EgJNAXAS+5YJqwp6Q71t4aGQ6HY/Mxb0eBhgFCoZACDWHcvXv3oFarkZ6e7hUjNZ7OYrGAz3/50ZPI8EqQy6SoUSUIJZlGKOBBJOKjaoUAdG5d76XvQdhRsvaS9it6MfSvxgChUIjCwkK2yyDl2Pz587FgwQJUqFABQ4cOhUAgQN26dTFp0iTcu3eP7fLIM1gsFqeM0IRWDMC3H/dDm2a1ULNaCCJrVEB41SC8El0TP88Z8dIt7YQ9BQUFdsOMwWCAQOD8k+DLC5psZYBYLKZAQxgzevRo/Pjjj5g+fTo+/vhjAMDu3bvxww8/YPHixZg5cyaCgoLw6quv4t1330X79u1ZrpgAzm3bjo4MxaLP34DBaMKpC7dgtVrRtF41iEX0ZufJHAUaatm2jwINA8RiMTQaDdtlkHLGYrGgY8eOOHToEDZt2oT4+PjSxzp37ozOnTsDAG7fvo20tDRs3rwZr776KgQCAaKjo/HWW28hJSXFKZ025Pk5a4TmcUIBH62jw536NQl7lEql3d8ROvbAPppyYoBYLEZRURHbZZBypLCwEBERETh58iSysrKeCDP/FhoaitmzZ+PKlSswGAz48ccfIZFIMHHiREilUoSFheGdd97BlStXXPgdEGetoSHll6NAQ7sE20eBhgE+Pj4UaIjTXL58GdWqVYPRaMSNGzfQsGHDMv9dPp+PIUOGYP/+/SguLsbJkyfRoUMHbNq0CXXq1IG/vz+6du2KjIwMWljMMCbOciLli1KptLtGhqac7KNAwwCpVEqHUxKn+PXXXxEVFYW6devixo0bCA5+ua36mzZtipUrV+Lu3btQKBSYOHEi7t69i4EDB0IoFCIqKgpffvmlU3e61htMmJ++D0Mmr8JXP+7A31fuoFDjfZu/MTHlRMqXwsJCh4GGppxso0DDAB8fH2i1WrbLIB5u/vz56NatGwYOHIjjx487fboiICAAkydPxl9//QW9Xo+NGzciLCwM8+bNQ1BQECpWrIikpCScOHHipe7zXfpepG//E9duPUTa6n2Ie3cREsb9iNPZt5z0nXgGmnIijqjVarvHGtAIjX0UaBjg5+cHnc77PoES53n77bcxbtw4TJ8+HatWrWL8flwuF3Fxcdi+fTuUSiWuXbuGAQMG4MiRI2jZsiUkEgnatGmDxYsXw2AwPNfXPnj6HxRpDTj3z10YjSYUafWwWq2Y+sN2hr4b90SBhjiiVqshEolsPk5raOyjQMMAPz8/6PV6tssgHshisaBDhw5YunQpNm3aVNqW7Wrh4eH47rvvcP36dWi1WsydOxdmsxnvvfcexGIxIiIi8P777+PmzZsOv5a6SIc795UwmszQG80oKjYg+9o93L6vdMF34j4o0BBHHAUaGqGxjwINA/z9/SnQkOf2PJ1MriQSiTB69GgcPXoUOp0OBw8eRExMDNLT0xEWFobAwED06tULO3fufObCYolICH9f8f8/xgGMJjMMRtNT15ZnFGiII0VFRZBIbG+MSGto7KNAw4CAgIDnHpYn3u3fnUxRUVFsl2RTbGws1q1bhwcPHuDBgwcYO3Ysrl69ip49e0IkEqFJkyaYNWsW1Go1AKBezUoIrRiAoAAfiEV8SMVCRFQLRoCfBEp1MS5evweVuvyvOaNAQxxxFGhoysk+CjQMkMlkMBqNbJdBPERJJ1O9evWc0snkSiEhIZg6dSouXLgAo9GI1atXIzg4GF999RX8/f1RtWpV5GZtglysg0QkhFDAR83QYHA4HDSoXQXd3v4eI6ako+/7S3DuSi7b3w6jKNAQR4qLix2O0FCgsY0CDQMCAgJgNpvZLoN4gMc7mY4dO+bRb3hcLhcDBgzA7t27oVarceHCBfTo0QOHDx1A5tLPcXvfbFRS70WYTx5eb1kHm38/g39uPkTOnXwU6wyYtfQ3tr8FRlGgIY5otVq7U0o05WQfPbsYIJfLYTJ51/oA8vzefvttLF68GDNmzMDEiRPZLsfp6tWrh8WLFwN49EK8aNEirFmzBlv+m4ZfDN+AJwmANCQSqNIMDxQCyAPK9ws1BRriiE6nsxtYaMrJPnp2MUAul9Ouq8Qmi8WCV199FUeOHHnqTKbySiqVYvz48Rg/fjwMRhMadx2D3IuHUJh7Buqbx5DPlyAgphX27auHDh06sF0uI6xWK52UTOzS6/Xw9fW1+ThNOdlHgYYBFGiILYWFhYiOjsbDhw+RlZXl1ot/mSIU8DGoX29k7q8JjdYAtSof4aI7uHP1DDp16gQ+n4/o6GgkJSUhJSWl3LyA0wgNcUSv18PPz8/m4zTlZB+toWFAyaJOCjXkcZcuXfKYTiamfTzidXwyshtGD2iHn79Lxb5dv+DKlSvQ6/VYvHgxpFIpPvnkE/j6+qJ69eoYPXo0Ll26xHbZL4VGaIgjBoMB/v7+Nh+nERr7KNAwoOQXjs5zIiV+/fVXNGzY0CM7mZjA5/MQ92ojNKpTFbuPZGPF5mNQqIrA4/GQnJyMffv2oaioCKdPn0bHjh2xZcsW1K1bF/7+/ujSpQs2bNjgcR8YrFYrjdAQuwwGA2Qymc3HaQ2NfRRoGJSfn892CcQNlKdOJmexWq2YseRXJE9eibU7TmDyd1vQKHEaur39Pf66dLv0usaNG2PFihXIzc2FSqXCpEmTcO/ePbzxxhulh2l+8cUXTj1Mkyk05UQcMZlMdgMNjdDYR4GGIVwuF3l5eWyXQVhWcibTzJkzXXImk6dYueUYFqzdhwJVEa7dzkeBqhgKVTEKi7SYOHcTTKantz3w9/fHpEmTSg/T3Lx5M8LCwvDtt9+WHqY5aNAgHD9+nIXvyDGaciKOmEwmBAQE2HycAo19FGgYwuPxPOJTI2GGxWJB+/btS89k+uijj9guya1s+uMvmM0W6A3/H1zMFivOXcnFgwI1irT2d9rmcrno2bPnE4dployAtW7dGhKJBLGxsS90mCZTaMqJOGI2m+2O0BiNRgrFdlCgYQiPx4NCoWC7DMIClUqFiIgInDp1yq3OZHInBaoiqIuePu/MZLYgT1EEqfj5XrTDw8ORlpaGa9euQafT4dtvv4XVasW4ceNKD9NMTU1FTk6Os76F50aBhjhisVggl8vZLsNjUaBhCJ/Ph1LpXacJk0edTNWrV4fRaEROTo5XdzLZIxLwIRDwnvpzPo+LyiH+KNa9+NEhQqEQo0aNwpEjR6DVanH48GG0aNECa9euRY0aNRAYGIiePXtix44dLl1YTFNOxBFHgYbD4biwGs9DgYYhAoGAAo2X+XcnU1BQENslua2wqnLUq1kRfN7/vwQJ+DwIBXw0qFUF/r5ip92rdevWWLt2Le7fv4+HDx9i7NixuH79OuLi4iASidC4cWPMnDkThYWFTrvns1CgIWXh7R2QL4MCDUOEQiFUKhXbZRAX+e6779CtWze88cYb1MlUBhOHvY4APykqyv0gEfERViUQfj4iNK4bijkTEhn7JBocHIypU6fi/PnzMBgMSE9PR4UKFTBt2jTIZDJUqVIFQ4cOxdmzZ51+bwo0xJ6SbT5sLfq1Wq2wWq2uLMnj0KsuQ4RCIeOf+Ih7KDmTaebMmbT4t4zq1KiIjHkjcfu+ApkHzuH8P7mIqlUFo/q1hVQidEkNXC4X/fv3R//+/QEA2dnZSEtLw44dO7By5UpIJBLExMRg2LBhGDRo0EuHVAo0xB5HXbEGgwEikchF1XgmCjQMEYvFUKvVbJdBGOSNZzI5k1QiRJ0aFTG+RkW2SwHw6DDNRYsWAXj0aXnx4sVIT09HSkoKhg4dioiICCQkJGDcuHGoUqXKc399CjTEnoKCAnC5tidN6NgDx2jKiSFisRgajYbtMghDVCoVatasSZ1M5ZRUKkVqaipOnDgBvV6P3bt3o2HDhvjpp59QtWpVBAUFITExEXv27Cnz17RarRAKXTP6RDyPo0BDuwQ7RoGGIRKJBEVFRWyXQRhQ0slkMplw8+ZN6mTyAh07dkRGRgby8/Nx584djBgxAn///Tc6d+4MkUiEmJgYfPvtt3aPO6ERGmKPUqkEj/d0518J2lTPMQo0DPHx8aFAUw6VdDLVr18fN27coD0jvFCVKlUwa9YsXL58GXq9HkuWLIGPjw8mT55cepjm22+//czDNCnQEFuUSqXddVo05eQYBRqGSKVSOpyynElLSyvtZDp69Ch1MhHw+XwMHjz4qcM0t27dirp168LPzw+vv/46NmzYQFNOxC6VSuUw0NAIjX0UaBji6+sLnU7HdhnESUaNGoX3338fM2fOxMqVK9kuh7ipfx+mOXnyZDx48ABvvPEGrFYrevfujSlTptA5b+QphYWFdgMvraFxjAINQ3x9faHVatkug7ykkjOZli1bhs2bN1NbNikzf39/fPzxxzhz5gz0+kfHPFSvXh1paWkICQlBhQoVSkf7CHEUaGiExjEaM2eIv79/6YsY8UxKpRKNGzdGXl4esrKyaPGvHQdOXsFPG4+Ay+GgV4eGiI6siohqIbRV+/+UdK+sWrUKoaGhyMnJwdy5c5GZmYnY2FiIRCI0adIEycnJGDp0KE1NeSG1Wm13nxlaQ+MYjdAwxN/f321O+SXP79KlSwgLC6NOJgesVisWpO/DwAlLsf/PS9h16DxSpqzGoAnL8J+FO2hn038pWRQcFhaGtLQ0XL16tfQwTQ6Hg9TUVIjFYtSsWRPjxo3DjRs32C2YuIxGo7EbaGjKyTEKNAyhQOO5du3aRZ1MZbTvz8v4ft1+FBXr8aBADVVhMbQ6I/IUGvx6+ALOXLzNdolu5VldTiWHaR4+fLj0MM1WrVph3bp1CA8PGY5QXQAAIABJREFUR0BAAHr27InMzEyXHqZJXKuoqAgSicTm4zTl5BgFGoYEBgbCZDKxXQZ5TmlpaejevTt1MpXRiXM5KNRoYTCYgJLRGKsV9/MLcfOeAppimnZ9XFmmklq3bo01a9aUHqaZmpqK69evo3fv3hCJRIiOjsaMGTPoaJVypiyBhqac7KNAw5CAgAAKNB5m5MiR1Mn0nIqK9VCotQCenFqyWAGd3khTTv/yvGtjgoOD8cUXX5Qeprl27VpUqlQJM2bMKD1Mc8iQIThz5gxDFRNX0Wq1dgMNTTk5RoGGIYGBgTCbzWyXQcrAYrGgXbt2WL58OXUyPSepVAg+7+mXEQ6A0IoB4D3jMW9UMlX0MiN+XC4Xffv2xa+//orCwkJcvHgR8fHx2LNnD5o2bQofHx+0b98eK1eupA9THsjRCAxNOTlGrzYMCQ4OpkDjAZRKJWrWrInTp08jKysLcXFxbJfkUeqGV4JEKAAe72biACIRH5VDZGhcN5S94txIyXo6e2f1PK/IyEgsXLgQN2/ehEajwfTp01FcXIyRI0dCJBKhTp06+Oijj5Cbm+u0exLm6HQ6CjQviQINQ+RyOQ23u7mSM5nMZjN1Mr2gnu0bolZYCIQCPjgcDgR8Lvg8LppEhmLVjCHwkdju2vAmTDcISKVSjBs37qnDNJctW1Z6mGafPn3wxx9/MFoHeXF6vR5+fn42H6c1NI5RoGFIcHAwAFBXgpsq6WRq0KABrl+/Tp1ML4jH4+KLMT3RoFYV1I2ojGC5H7q1aYBtC8cgONCX7fLchqs7HksO08zLy0Nubi5SUlJw/vx5vP766xCJRGjevDnmzZtHx7O4EUeBhtbQOEaBhiEli/+oE8H9fPvtt+jevTsGDRpEnUxO0Ll1Pcz7uB+G94nFtx/3x5rZw2lk5l/Y3MKhcuXKmDlzJi5dugS9Xo+lS5fCz88Pn376aelhmqNGjcLFixdZq5E8+h1xNEJDgcY+CjQM4nA4yM/PZ7sM8piRI0di/PjxmDVrFlasWMF2OeVGy4Y1MOaN9oh7tRH4fB7b5bgdo9HIdgkAHi1KfvPNN7F3714UFRXhzJkz6NSpEzIzM1GvXj34+fmhc+fO+Pnnn2l02cWMRiNkMpnNx2nKyTEKNAzicDgoKChguwyCpzuZJkyYwHZJxIsYDAa3PAaiUaNGWL58Oe7cuVN6mGZeXh6SkpIgFApRv359fP7553SYpgsYjUYEBATYfNzRPjWEAg2jeDwevRC4AepkImzzhF3DSw7TzMrKgl6vx9atWxEREYH58+eXHqY5cOBAHDlyhO1SyyWz2Ww30JjNZpoed4ACDYP4fD6USiXbZXi1ixcvUicTYZ3RaHTLERpbuFwuunfvjm3btkGhUODGjRtISkrCiRMn0KZNG0gkErzyyitYuHChR4Q1T2A2m+1OOXnS7w9bKNAwiAINu3bu3ImGDRsiKiqKOpkIq9xlDc2LCgsLw7x580oP00xLSwOHw8H48eMhFosRHh6O9957D9evX2e7VI9lsVjoNeolUaBhkEAgoEDDkm+//RY9evRAUlISjhw5QkO1hFWeNkJjj1AoxMiRI0sP0zx69CheeeUVrF+/HjVr1kRAQAB69OiBbdu20cLi5+Ao0NC+Zo5RoGGQUCiktm0WUCcTcTfl+SiCli1bIj09Hffv30d+fj7ef/995OTkICEhofQwzWnTptGHOztKgp+tQENhpmwo0DBIJBJRoHEh6mQi7qo8jdDYI5fLMWXKFJw7dw4GgwHr1q1D5cqVMWvWLAQGBqJy5cpITk7G6dOn2S7VrZRscGhrnxm9Xk8dTmVAgYZBIpEIarWa7TK8QkknU1ZWFnUyEbfjrm3bTOJyuUhMTMSuXbtQWFiIS5cuoXfv3ti3bx+aN28OqVSK9u3bY8WKFeV6BKssHO1XRrsElw0FGgZJJBJoNBq2yyj3Hu9kysnJoU4m4na8ZYTGnjp16mDhwoXIyclBUVERZs6cCa1Wi1GjRpUepjlhwgTcuXOH7VJdLj8/3+7BpbRLcNlQoGGQRCJBUVER22WUa9TJRDwBBZonSSQSvPfee/jzzz+h1+vxxx9/lG7yFxoaiqCgICQkJHjNYZoKhcJhoKFdgh2jQMMgqVRKgYZBJZ1Mb775JnUyEbdmMpko0NjRoUMHbNiwAXl5ebh79y5GjhyJ7OxsvP766xAKhWjevDnmzJlTbl9PlUql3dcvGqEpGwo0DPL19YVWq2W7jHLp8U6m5cuXs10OIXbRCE3ZVapUCTNmzMDFixeh1+uxfPly+Pv7Y8qUKfDz80O1atUwcuRIXLhwge1SnUapVILHs30GGq2hKRsKNAzy8fGhQONkFosFbdu2pU4m4lEo0LwYPp+PpKQk7NmzBxqNBmfOnEHnzp2xfft2NGjQAH5+fnjttdewfv16j97zRqlUQiAQ2HycRmjKhgINg3x9faHT6dguo9wo6WQ6c+YMzpw5Q51MxGNQoHGORo0aYdmyZbhz5w4KCwvx2WefIT8/H2+++SYEAgHq1auHzz77DA8fPmS71OdSWFjoMNDQGhrHKNAwSCaTQa/Xs11GuZCdnf1EJ1ODBg3YLomQMjOZTHYXfZLn5+fnh48++qj0MM3MzEzUrl0bCxYsQIUKFUoP0zx8+DDbpTqkVqshFAptPk5TTmVDzzAG+fn50cFtTrBz5040atSIOpmIx6IRGmZxuVx069YNW7duhUKhQE5ODt58802cOHECbdu2hVgsRuvWrfHDDz+45ai5Wq2GSCSy+ThNOZUNBRoGyWQyCjQviTqZSHlAIzSuVb16dcydO7f0MM0FCxaAx+Phww8/hFQqRXh4OMaOHYtr166xXSoAQKPRQCwW23ycppzKhp5hDAoMDPT6HTBfBnUykfKCRmjYIxQKMWLECBw6dAjFxcU4duwYYmNj8csvvyAiIgIymQzdu3fH1q1bWVtYrNFo7B5tQCM0ZUOBhkEBAQEUaF4AdTKR8oZGaNxHixYtsHr1aty7dw/5+fn44IMPcOvWLfTp0wcikQiNGjXCV1995dLDNIuLi+0GGlpDUzb0DGOQXC6H2WxmuwyPolQqER4eTp1MpFyhQOOe5HI5Pv/8c/z9998wGAxYv349qlSpgtmzZ5cepjl48GCcOnWK0Tq0Wq3dwEIjNGVDzzAGBQUFefTeCK5W0slktVqpk8nFDp3+B3NW/o6M307DaHy+UcXT2bew+JdDyNz/N0ymsgd4q9WKvX9ewopNR3HiXM7zluxRaKdg98flctGnTx/s2rULKpUKly9fRkJCAvbv34+YmBhIpVK0a9cOy5cvd/rIe1kCDa2hcYxWWDIoKCgIVquV7TI8ws6dOxEXF4eYmBgcOHDAaxf/3nmgxO37SoRVlqNSsD/j97NarZix5Fcs33wUEhEfBYVafDhnE1o1Csf0cXEIDw22+Xe1OgPmrPwdq7b+CYlIAIlYgNMXbuHz0d3LdO9FPx/Eqq3H8ehtnoPJI7ugR/uGTvm+3I3ZbKYRGg9Tu3Zt/PDDDwAAnU6HJUuWYPXq1Rg9ejSGDx+OiIgIxMfHIzU1FaGhoS91L61Wazew0JRT2dAzjEEl7cU0SmMfdTI9snF3FuLHLsL7M3/Gq0PmYdBHy7Fux0mYzcz9/ixafxDz1+zDwwI1rtzMQ4GyCPlKDW7eLcCEuZtsBvKc3AK0GTwHM3/6DbfuKXD9Th4UhcXYcfActDrHnX1WqxXrdpxESKAvKofI4OcjQvr2k07+7twHjdB4NrFYjLFjx+L48ePQ6XTYt28fGjdujBUrVqBatWqQy+Xo3bs3du/e/UJfX6/Xw8/Pz+bjNOVUNt75zuEiJW/MBQUFCA62/UnXm6WkpGDp0qWYNWuWVy/+/eW303j3q/UwmU3QGx5N2+QXFuH67Txo9UYMTWjt9Hs+ChUnYLFYoTc+uqcVgMlsgVJdDIvVCqPJDKHgyZeJf24+QK8xC3HzrgIWqwUAB0aTGTfvKpD7QIW3Jq3EjNR41A6rYPPeHA4HErEARpMZAj4PBqMJvlLb+3B4OlpDU760a9cO7dq1AwDcu3cP3333HTZu3IiuXbuCx+OhYcOGGDRoEEaNGgVfX1+HX68sgYamnByjZxjDOBwO8vPz2S7D7ZR0Mq1YsQJbt2716jCj1Rnw3eq9MJpMKNaZYLZYYbZYoS7S44FCjd+OMHMIH4fDgUJdjKLiJzcas1qBhwUaRNWq/FSYAYCvftyFYp0B4OBRArJaH/1fABarFXcfqPDBNxsdTrd+ktIVxToD8pRF4PF4SH3rVSd9Z+6HAk35ValSJUyfPh0XL16E0WjE8uXLIZPJSg/TDA0NRUpKCs6fP2/zaxgMBvj7255ifpkpp127diEyMhK1atXCzJkzX+hreAp6hjGMy+WioKCA7TLcyr87mXr27Ml2SawyGM14WKCBVv/0QsMH+WrkKYsYu7dAwH/mKb++UiFmpPZ+5t95UKBGlRAZrJZ/BxYrrBYr8guLkK/QoEhrf+qpXfPaWDd7OOZN7Iuf5wxH/YjKL/ptuD0KNN6By+U+cZjm2bNn0aVLF+zcuRNRUVHw9fVFp06dsHbt2ieWIhiNRshkMptf11Fbty1msxljxozBzp07ceHCBaxdu7ZcnVL+b/QMYxiPx6MRmsdQJ9PThAIe9IZnd03weVyIRczNDFerJEeDWpXB/d/yDg6AikF+qF+rKoIDnz1U3q1NA4DDgVDw7yDEAThAvrII4aHB8JHYPpumROUQGZrWqwa5rHwPp5tMpmcGR1K+NWzYEEuXLsXt27ehVqsxZcoUKBQKJCcnlx6mOXnyZBgMBruBxmKxvNDvz59//olatWqhZs2aEAqFGDhwILZs2fIy35Jbo0DDMB6P59INmtxZyZlMDRs2xLVr1+hMpsdUDvFH9cqBT/wZlwP4+ohQP6IKY/f9JKULREI+ggJ8IRUL0KR+NVQOkaFFwzCbf2f0gLZIfasjAv2l4PO4AIfz6H94NI1Vq3ow5n6USItgH0MjNMTX1xcTJkzA6dOnYTAYsGPHDtSpUwdpaWnQ6XR211m+6HPpzp07qFatWul/h4aG4s6dOy/0tTwBPcMYJhAIKNDgyU6mw4cPe20n07NIxEL069IMgf5SSEQCCAU8+PmIIBQKEF41GBOGvMbYvVs0rIFf5qZg3TfDMDShNSrI/dCjXRQ+SO5k8+/w+TwM6NoMraJrIqp2FQT4ScDnc8HncZHQKRq7Fo1FBbntBY7eiNq2yb916dIFn376KQwGA+Li4tC9u+3tDmj7j7KhdxWGCQQCqFQqtstgFXUyOZb61qto0TAMR85cw9a9Z2E2WxDTsAZmjIuHtAxTNy8jONAXwYG+eKVxxHP9vY9HvI4PZmegVvUQWCxWfP1BAmKbPN/X8BY0QkP+LSsrC7GxsejcuTNj00BVq1bFrVu3Sv/79u3bqFq1KiP3cgcUaBgmFAq9NtCYzWa0b98ex48fx9atW71+8a89HA4HsU0iENskAh8kd4LeYIJEzGyQeVnRkaH4ZW4Kch8oUaVCAAL9aZ8MW2gNDXnc2bNn0apVK3Ts2BHbt2+3e+3LjM7ExMTgypUruH79OqpWrYp169ZhzZo1L/z13B0FGoaJRCKo1Wq2y3A5pVKJ6OhoFBQU4MyZM7T49zlwuVy3DzMlAv2lFGTKgKacSInz588jJiYGbdu2xa5duxxev2nTphfulOXz+ViwYAG6dOkCs9mMYcOGlevXYgo0DBOLxV4XaLKzs9GyZUsEBAQgJyeHFv8Sr2c2m2mEhiA7OxvNmjVD69at8fvvvzu8fteuXfjmm2+QlZX1wvfs3r273fU55Ql9ZGCYRCKBRqNhuwyXoU4mQp5GU07k8uXLaNq0KZo3b449e/Y4vP7333/HlClTsG3bNgQGBjq8nlCgYZxEIkFREXMbo7mTefPmoUePHnjrrbeok4mQx9CUk3e7evUqGjdujOjoaBw4cMDh78K+ffswadIkbNu2DUFBQS6q0vPROw7DpFIpiouL2S6DcSNGjMCyZcswe/ZsfPDBB2yXQ4hbedGN0Yjnu3HjBho1aoT69evjyJEjDsPMwYMH8eGHHyIzMxMVKtg+D408jQINw3x9fZGXl8d2GYwxmUzo0KEDdTIRYgeN0HinmzdvIioqCpGRkfjzzz8d/g4cPXoUqamp2LZtGypVquSiKssPCjQM8/HxgU6nc3yhB6JOJkLKhhYFe5/bt2+jQYMGqFmzJk6ePOkwzJw4cQJjxozBli1bUKUKc7uDl2f0kYFhfn5+5TLQ0JlMhJQdBRrvkpubi/r16yMsLAxnzpxxGGZOnz6NkSNHYtOmTU8cVUCeDwUahvn5+UGv17NdhlPt2LGDOpkIeQ4UaLzH/fv3Ua9ePVStWrVMYeavv/7CsGHDkJGRgbAw22eoEcco0DBMJpPBYDCwXYbTzJ07Fz179qROJkKeAwUa7/Dw4UNERkaiYsWK+Pvvvx2+Pp4/fx7Jycn45ZdfULNmTRdVWX7RuxHDZDIZjEYj22U4BXUyEfJiKNCUf/n5+YiMjERQUBDOnTvnMMxcvHgRSUlJWLduHWrXru2iKss3CjQMCwgI8PhA83gnU2ZmptfsOkmIs1DbdvmmVCoRGRkJmUyG7OxsCIX2jy65cuUKBg4ciPT0dNStW9dFVZZ/FGgYJpfLYTab2S7jhSmVSjRq1AgKhQJnz55FvXr12C6JEI9jNptperacUqlUqF27Nnx8fMoUZq5du4Z+/fph5cqV1EzhZLSGhmGBgYEeG2hKOpkAICcnh8LMY0wm80udgku8C43QlE+FhYWoU6cOxGIxLl26BLFYbPf6nJwcJCYmYtmyZYiOjnZRld6DPjIwTC6Xw2KxsF3Gc9uxYwfi4+PRokUL7N+/nz5d/o/ZbMHs5buxdd/f4HE56NWhIWKbRKB1dDhtnEZsohGa8kej0SAyMhI8Hq9MYebWrVtISEjA4sWL0bRpUxdV6V3oFZhhISEhHvdJnjqZbNt56Dw27/kLflIh/rn5ELOW7cb7szbgqx93edzPmbgOjdCUL8XFxYiMjATw6NBJqVRq9/rc3FzEx8fj+++/R0xMjCtK9EoUaBgWEBAA4NHCWk8wYsQIfPjhh5g9ezaWLVvGdjlu5+bdAvB5XNzPV8NitULI58HfV4zfjlzAvbxCtssjbopGaMoPnU6HyMhImEwmXLp0Cb6+vnavv3fvHuLi4pCWlobWrVu/0D2HDRuGChUqICoqqvTPJkyYgLp166JRo0ZISEiAUqksre+NN95Aw4YNUa9ePcyYMeOF7umJKNAwrGQaIj8/n+VK7DOZTIiNjcXKlSuRmZlJbdk2NK1fHRYLoNebYDJZwONxIREJAXDYLo24MRqhKR9Kwoxer8eVK1fg7+9v9/qHDx+iV69e+Oabb9C2bdsXvu+QIUOwa9euJ/6sc+fOOHfuHM6ePYs6deqUBpd169bBarXi77//xqlTp/Djjz/ixo0bL3xvT0KBxgU4HI5bH1CpVCpRs2ZNnD17FmfPnqW2bDtaNQrHlNHdEV2vKgL9JagSIkOBqgg92kehUrD9FzfivSwWC43QeDiDwYB69epBo9Hg8uXLDsNMfn4+evbsiRkzZqBDhw4vde927do9tSP766+/Xvo71apVK9y+fRsAUKlSJRQVFcFkMkGr1UIoFDqstbygZ5gLcLlcKBQKtst4puzsbLRo0QKBgYG4detW6RQZsa1Lm/ro0qY+Hio0OHvpNvx9JWjeoDo4HBqlIc9GgcazlYQZlUqFf/75x+HrpEKhQM+ePfHll1/itddeY7y+ZcuWYcCAAQCArl27YvXq1ahcuTKKi4sxb948rzmehkZoXIDH46GgoIDtMp5SciZTo0aNcO3aNQozzykk0BedWtVFTFQYhRliF005eS6TyYSoqCgUFBTg8uXLDsOBSqVCr169MHnyZHTt2pXx+qZNmwY+n4+kpCQAwOrVq1FcXIzc3Fxcv34dc+bMwbVr1xivwx1QoHEBPp/vdiM0c+bMoU4mQlyERmg8U0mYuX//PrKzsxEcHGz3+sLCQvTq1QsffPABevbsyXh9K1asQGZmJtLT00s/VB0+fBgJCQkQCASoUKECYmNjcfLkScZrcQcUaFxAIBCUrkB3B8OHD8eECROok4kQF6FA43ksFguio6ORm5uL7OxsVKpUye71Go0G8fHxGDt2LBISEhivb9euXfj666+xdevWJ9rG69atiz179gAAioqKcOzYMa85XoGeYS4gEAigUqnYLgMmkwnt27fHn3/+SWcyEeJCVquVAo0HsVgsaNy4MW7evIns7GxUqVLF7vXFxcXo3bs3UlJS0K9fP6fX88Ybb2Dfvn3Iy8tDaGgovvzyS8yYMQN6vR6dO3cG8Ghh8KJFizBq1CgMHz4cUVFRsFgsGDp0KBo1auT0mtwRPcNcQCgUsh5oFAoFoqOj6UwmQlhAIzSew2KxoFmzZrh27RouXLiA0NBQu9drtVokJCTgrbfewqBBgxipae3atU/92fDhw595rVgsRnp6OiN1uDuacnIBsVgMtVrN2v0fP5Pp1q1bFGYIcTEKNJ7BYrGgRYsWuHz5Ms6fP1/6ummLTqdDYmIi+vfvj+TkZBdVSWyhQOMCIpEIGo2GlXuXdDJFR0dTJxMhLKFA4/4sFgteeeUVXLhwAWfPnkVYWJjd6w0GA/r374+4uDiboyXEtSjQuIBEImFlhKakk2nw4ME4dOgQvaASwhKr1QqBQMB2GcQGi8WCtm3b4q+//sJff/2FiIgIu9cbjUYMHDgQnTt3xttvv+2iKokj9A7nAlKpFMXFxS6957Bhw7BixQp88803GD9+vEvvTQh5Eo3QuLeOHTvi1KlTyMrKQu3ate1eazKZkJSUhDZt2mDs2LEuqpCUBT3DXEAqlaKw0DUHF1InEyHuh0Zo3FenTp1w7NgxnDp1yuH6QrPZjOTkZDRt2pQ+KLohCjQu4OPjg3v37jF+n4KCAjRu3Jg6mQhxMzRC4566dOmCQ4cO4cSJE2jQoIHday0WC4YNG4a6devi448/dlGF5HnQGhoX8PPzg06nY/Qe2dnZpYvYqJOJEPdCIzTup0ePHti7dy+OHj3qcJ8Wi8WCkSNHonr16vjss89cVCF5XhRoXMDX1xd6vZ6xr799+3bqZCLEjVGgcS/x8fH47bffcOTIETRt2tTutVarFWPGjEFwcDCmTp3qogrJi6BA4wL+/v6MBZo5c+agV69eSE5Opk4mQtwU7RTsPvr27YsdO3bg0KFDaN68ud1rrVYrxo0bB6lUihkzZtAhtG6OnmEuIJPJYDAYnP51qZOJuJrZbEHuQxV8JELIZT5sl+MxaITGPQwYMABbtmzBvn370LJlS7vXWq1WfPjhhwCAb775hsKMB6BA4wIymQxGo9FpX486mQgbirR6vD9rAy5cuwcOgLFJr6J/F/vD9eQRGqFhX1JSEjIyMrBnzx7ExsbavdZqtWLSpEkoLi7GDz/8QGHGQ9AzzAUCAgKcFmhKOpmUSiV1MhGXytidhbOX7yDATwIrgPnpe9EhpjYqyP3YLs3t0QgNu5KTk7F+/Xr89ttvaNeuncPrp0yZgry8PCxevJjCjAehQOMCcrkcZrP5pb9OdnY2WrRoAblcjps3b9LiX+JSuQ9UuHVPgRt38gEAcpkPCjVaCjRlQCM07Bk+fDhWr16NXbt2oWPHjg6v/89//oOcnBwsX74cXC4tM/Uk9NNyAWcEmszMzNJOpqtXr1KYIS5ntlig1T8aabRYrFCqiyHg81iuyjNYrVYIhUK2y/A6b7/9NlasWIHMzEx07tzZ4fWzZs1CdnY2li1bRmHGA9FPzAXkcjmsVusL//05c+YgLi6OOpkIq3wlYtSoLEcFuR9CKwWiRpVgGE0vP/LoDWjKyfXeffddLFmyBFu2bEG3bt0cXj937lycPHkSq1atAo9HQd0TUaBxgaCgoBcONMOGDcOECRMwd+5c/PTTT06ujJCy69QqEr4+Yvj7SiAS8lGrejCqV5azXZbHoEDjOqmpqVi4cCE2btyInj17Orx+/vz5OHToENasWUMfGD0Y/eRcwN/fHwCg0+kgFovL9HdMJhPatWuHEydOUCcTcQtRtavg+08H4NfD2Qj0k6Bfl2YQCuglpCxohMZ1PvzwQ8yfPx/r169HfHy8w+sXLVqE3377DRkZGfQz8nD0auQCJXOxBQUFqFKlisPrqZOJuKuGtauiYe2qbJfhcWgNjWt8/PHHmDdvHtasWYO+ffs6vH7p0qXYunUrNm7cSD+fcoCmnFyEw+EgLy/P4XUXLlxAWFgYOBwObt68SWGGkHKCPv0z69NPP8XXX3+NVatWYcCAAQ6vX7VqFdavX4+MjIwyj5wT90aBxkV4PB4KCgrsXpOZmYno6Gg0btyYOpkIKWdoBIA5X3zxBaZPn47ly5cjKSnJ4fVr1qzBypUrsXnzZkgkEhdUSFyBAo2L8Hg8KBQKm48/3sl08OBBWphGSDlCa2iYM23aNEydOhVLlixBcnKyw+t/+eWX0u4nqVTqggqJq9C7povw+XybIzRDhw7FypUrMXfuXKSmprq4MkKIK9AIjfPNmjULn332GRYuXIjhw4c7vH7z5s2YP38+tm/fDl9fXxdUSFyJAo2LCAQCqFSqJ/7s8U6m7du3l2mvBEKIZ6JA41xz5szBpEmTsGDBAowaNcrh9ZmZmfjmm2+wfft2+PnR7tblEQUaFxEIBCgsLCz9b+pkIsS7UKBxnrS0NEyYMAHz5s3DO++84/D6Xbt2Ydq0adixYwdkMpkLKiRsoDU0LiIUCktHaM6fP0+dTIR4GQo0zvH999/j/fffx+zZszFu3DiH1//++++YMmUKMjMzERgY6IIKCVso0LiIWCyGWq1GZmYmGjduTJ1MhHgJi8UCALTQ3wnddm+6AAAgAElEQVQWL16MsWPHYvr06fjggw8cXr9v3z5MmjQJ27ZtQ1BQkAsqJGziPOeW/C9+IJGXi4qKgsFgwD///IPhw4djyZIlbJdECHEBvV4PsVj8Uue5kUeb4KWkpGDq1Kn49NNPHV5/6NAhpKamIjMzE5UqVXJBhYRBnLJcRB8ZXMRgMODKlStITk6mMEOIFzEajWyX4PFWrlyJlJQUTJkypUxh5ujRo3jvvfcozHgZmnJykRkzZiAyMhL//e9/IRaL0aFDB2zatKl0OJoQUj4ZDAa2S/Bo6enpGDp0KCZPnowpU6Y4vP7EiRN45513sGXLljIdNUPKDwo0LpKYmIiLFy9Cr9dj3rx5UKvV6NevH8RiMV555RWkp6dTuCGkHKJA8+LWr1+PwYMHY8KECfjPf/7j8PqsrCykpKRg06ZNqFatmgsqJO6EAo2L8fl8jB49GqdOnYLBYMCSJUtgsVgwZMgQiEQiNG/eHD/99BNMJhPbpRJCnIACzYvJyMjAoEGDkJqailmzZjm8/uzZsxg6dCgyMjJQo0YN5gskbocCDYu4XC6Sk5Nx7Ngx6PV6pKenQyqVYsyYMRCJRGjcuDHmz59PL4iEeDCj0QgOp0xrGsn/bN68Gf3798e7776LOXPmOLz+/PnzeOutt/DLL78gIiLCBRUSd0SBxk1wuVz0798fBw4cgF6vx6ZNmxAUFISPPvoIEokEDRo0wNdffw2dTsd2qYSQ50AfSJ7Ptm3bkJiYiLfffhtpaWkOr7948SKSkpKwfv161K5d2wUVEndFgcZJrl69iuLiYqd9vbi4OPzxxx/QarX47bffUL16dUydOhVSqRR16tTBl19+CbVa7bT7EUKYQV1OZbdz50707t0bKSkp+P777x1ef+XKFQwcOBDp6emoW7euCyok7owCjZPs27cPbdq0Qb9+/bBu3Tqnho1OnTph586d0Gg0OHjwIOrXr485c+ZAJpOhZs2amDRpks2DLwkh7DIYDDTlVAa7d+9Gr169MHToUCxatMjh9deuXUO/fv2wcuVKNGjQwAUVEndHG+s5kdVqxfnz55GRkYHMzExUrVoViYmJ6NWrFyM7Ap8+fRozZ87E7t27oVQqUa1aNSQmJmLixIm09wIhbuLo0aNo27YtLfS3Y8+ePXj99deRlJSElStXOrw+JycHvXv3xtKlS9G0aVMXVEhYVqZPBBRoGHTx4kVkZGSUbrvdt29fxMfHQy6XO/1e58+fx6xZs7Bjxw7k5+ejcuXKiI+Px6RJk1C9enWn348QUjYHDhxAx44dKdDYUPLvM2DAAKSnpzu8/vbt24iLi8OPP/6ImJgYF1RI3AAFGndy9epVZGRkYMuWLfD19UViYiJ69+6NChUqMHKvmTNnYtu2bbh//z5CQkLQo0cPfPLJJ7RojhAX++OPP9C1a1daS/MMhw8fRocOHZCQkICff/7Z4fW5ubno1asXFixYgNatW7ugQuImKNC4q5ycHGRkZGDz5s0QCARITExEQkICKleu7PR73b59G7NmzcKmTZtw584dyOVydO3aFZMmTUJUVJTT70cIedLOnTsRHx9P3U7/cuzYMbRt2xZxcXHIyMhweP39+/fRo0cPzJs3D23btnVBhcSNUKDxBHfu3MHGjRuxceNGWCwW9OnTB3369GFkl8sHDx5g9uzZ+Pnnn3Hz5k3IZDK89tpr+Pjjj9G8eXOn348QAmzduhX9+vWDXq9nuxS3ceLECcTGxqJ79+7YvHmzw+sfPnyIHj16YNasWXj11VddUCFxMxRoPM29e/ewefNmZGRkQKvVonfv3khMTER4eLjT76VUKjFnzhysWbMG169fh4+PDzp06ICJEyeiTZs2Tr8fId4qIyMDSUlJtIfU/2RlZaFly5bo3Lkztm/f7vD6/Px8dO/eHV999RU6d+7sggqJG6JA48ny8vKwZcsWbNiwAUqlEvHx8UhMTGRkDYxGo0FaWhr++9//4vLly5BIJGjTpg3Gjx+PLl26OP1+nkhTrMfiXw7i0o0HaFa/Onq1j0KI3A98Po/t0oibW79+PYYMGQKtVst2Kaw7e/YsYmJi0KFDB/z6668Or1coFOjRowc+++wzdOvWzQUVEjdFgaa8UCgU2Lp1KzZs2ID79++jV69e6Nu3L+rVq+f0e+l0Onz//fdYsWIFLly4AKFQiFatWiE1NRW9evUCl+udWxd9+M1GHM66CgC4kvMA8gAfNKlbDd9N6oeKQf4sV0fcWXp6OlJSUpy68aYnOn/+PJo2bYo2bdrgjz/+cHi9SqVCjx49MHHiRPTq1csFFRI3VqZA453vTh4mMDAQycnJ2LZtG37//XdERERg8uTJaN68OT7//HOcPXsWzxlMbRKLxfjggw/w999/Q6/XY86cOVCpVEhMTIREIkFsbCzWrl3rVSeDW61WHDr9DwrVWly4ehcmswUGgwl37ivx3eq9bJdH3JzJZPL6jfUuXryIZs2aoVWrVmUKM2q1Gr169cL48eMpzJAyo0DjYfz9/TFo0CBs3LgR+/btQ1RUFKZNm4ZmzZrhk08+walTp5wWbvh8Pt555x2cPn0aBoMBixYtgslkwuDBgyESiRATE4OlS5eW+3DD4XCg0uhwN68QZrMFBqMJBqMZPhIhch+q2C6PuDlvP5zy8uXLaNKkCZo3b469ex1/ACgqKkJcXBzeffdd9OnTxwUVkvKCAo0H8/X1Rf/+/bF+/XocOnQIMTExmDt3Lpo0aYIJEybg+PHjTgs3XC4XQ4cOxfHjx6HX67F69WqIxWK88847EAqFaNKkCRYsWFBuW1P9pCJIJUJwuVxwuVyYLRYUFunQ5ZX6bJdG3Jw3B5qrV6+icePGiI6OxoEDBxxOWRcXFyM+Ph4jRoxA//79XVQlKS8o0JQTUqkUCQkJSE9Px7Fjx9C+fXssXLgQjRs3RmpqKg4dOuS0kRQul4sBAwbg4MGD0Ov12LhxIwIDAzFhwgRIJBJERUVh9uzZ5aqrI6p2FdSoIkebphGoHOyPiGrBmDjsdQzo1ozt0oibM5lMXrn27MaNG2jUqBHq16+PI0eOOPw30Ol0SEhIwFtvvYWkpCQXVUnKE1oUXM4ZDAbs2bMHGRkZOH78ONq1a4fExES0bdsWfD7f6ffbvXs35syZg4MHD0Kr1aJ27dpISkrC+PHj4evr6/T7ucqdB0pMTtuKKzkPEB0Ziq/e6wW5zIftsogHmDt3LqZOnQqlUsl2KS5z8+ZN1K9fH7Vr18apU6cchhm9Xo8+ffogISEBI0aMcFGVxINQlxN5kslkwv79+7FhwwYcPnwYrVu3Rt++fdGhQwcIBAKn3+/QoUOYPXs29u7dC41Gg/DwcAwYMAAffvghI+dZuYLVavXa6QPyYr7++mvMnDkTBQUFbJfiErdv30a9evUQHh6OM2fOOAwzBoMBffv2Rbdu3TB69GgXVUk8DHU5kSfx+Xx06tQJCxcuRFZWFpKSkrBt2zY0a9YMw4YNw44dO5y6BqZNmzbYsmULCgsL8eeff6Jp06ZYuPD/2rv3sBrz9X/gb1RCDDIOlYxTkdNGhSjkUEqp1jMmcj4MgxmHKWTmMrbZdBoaYTONYeTMs9LqNNqVXbZMDpOiZkp8iUITE6kkq7V+f+zr17Xn2ntmRWu1WvV+/Vc+z3PfzTUrb2t9ns+9D8bGxjA3N8e6devw66+/qq1eQ2CYoTfVnPbQPHr0CFZWVjA3N69TmHn9+jW8vb0xefJkhhmqNwaaZqpVq1ZwcHBAWFgYMjMzsWTJEiQnJ8PGxgbz5s2DTCZT6x4Ya2trnDlzBqWlpcjOzoaDgwMiIiLQrVs3mJiYYOXKlSgsLFRbPaLGornsoSkuLsaAAQNgamqKrKwslT+zXC7HnDlzMHbsWHzyyScN1CU1ZU3/VUYqtWzZEnZ2dtixYwcyMzPx8ccf49KlSxg9ejRmzZoFqVSKiooKtdUbNGgQjh49iidPnuD27dtwcXGBKIro2bMnunXrhiVLluDOnTtqq0ekTc0h0JSUlMDS0hLdunXDzZs3Ve7Pq6mpwfz58zF8+HB8+umnDdQlNXVN+1XWAM6dOwdLS0v069cPgYGB2m6n3lq0aAEbGxsEBQXh+vXr2LBhA65fvw57e3sIgoCTJ0/ixYsXaqvXt29fHDhwAMXFxSgoKIAgCIiPj0e/fv3QpUsXzJkzBzk5OWqrR9TQmnqgefr0KSwtLWFsbIzs7GyVYUahUGDx4sWwtLTExo0bG6hLag64KbgeampqYGFhgcTERJiZmcHGxgYnTpyAlVXTO5tEqVQiJycHUqkUsbGxMDU1hUQigZubGzp27Kj2er/++iuCgoJw5swZPHjwAB07dsTkyZPh7++PESNGqL0ekab4+fnh2LFjePjwobZbUbtnz56hX79+MDIywq1bt2BgYPCn6xUKBZYtW4bu3bvjyy+/bKAuqQngpmBNu3LlCvr164c+ffrAwMAA3t7ekMlk2m5LI1q0aIHBgwfjiy++wNWrVxEYGIj79+/D2dkZrq6uOHTokFqf4ujatSt27NiB+/fv4+nTp/joo4+QkZEBa2trdOjQATNmzEBaWpra6hFpSlN9h+b58+fo378/2rZti9zcXJVhRqlUYtWqVejcuTO2bt3aQF1Sc9L0XmUNqKioCD179qz92szMDEVFRVrsqOEMGDAAn332GdLT0xEWFoaSkhK4ubnByckJ4eHhan16qXPnzti+fTvu3LmDsrIy+Pr6Ijc3F/b29mjXrh2cnZ2RmJiotnpE6tQUA82LFy9gYWGB1q1b49atWzA0NPzT9UqlEmvWrIGhoSECAwObzVNf1LCa1quMtKJv375Yv3490tLSEB4ejvLycgiCgEmTJmHv3r149OiR2moZGRlh8+bNyMvLQ2VlJbZs2YLCwkI4OzujTZs2cHR0RHR0tNrqEdVXUws05eXlsLCwQKtWreocZvz8/KBQKLBjxw6GGdKYpvMq0wJTU1M8ePCg9uvCwkKYmppqsSPt69WrF9atW4cLFy4gIiICCoUCs2fPxvjx47Fr167f/feqL0NDQ/j5+SE7OxsvX75ESEgISktL4eXlhdatW2PcuHE4depUkx+eSY1bUwo0lZWVsLS0BPDvoZNt27b90/VKpRKbNm1CeXk5wsLCGGZIo7gpuB7kcjksLCyQnJwMU1NT2NjY4Pjx4xg0aJC2W2t0Hj9+jKioKEilUrx8+RIeHh6QSCTo3bu32mvJ5XIcPnwY+/fvR2ZmJgBgxIgRWL58OebPn99k/nIh3bBo0SJcuHABt2/f1nYr9VJVVYX+/fujuroa+fn56NChg8prvvjiCxQWFuLbb7/l647qg5uCNU1PTw979uyBk5MTBg4ciJkzZzLM/IHu3btj+fLlSExMRFRUFDp16oQVK1ZgzJgxCAgIQH5+vtpq6enpYfHixbh69SpevXqFiIgI6OnpYfny5TAwMMCIESPw97//HXK5XG01if5ITU2Nzv9lXlVVBUtLS1RVVSEvL69OYeZvf/sb7t69i/DwcJ3/+Uk38B0a0qrS0lJER0dDFEUUFxfDzc0NEolEI4++KxQKxMTE4Ouvv0Z6ejqqq6thZWWFBQsWYOXKlSr3AhC9DR8fH2RkZOCXX37Rditvpbq6GpaWligrK0N+fn6d5rAFBwcjMzMTR44cQatWrRqgS2riOJySdEtZWRliY2MhiiIKCgrg6uoKQRAwZMgQjXz2npCQgJ07d+LixYt4+fIlLCwsMHfuXKxevVqnJ4NT4+Lt7Y2bN2/q5AGR1dXVGDhwIEpLS3Hr1i106dJF5TWhoaH48ccfcfz4cZWH7BHVEQMN6a7y8nLEx8dDFEXcvn0bzs7OkEgkGDFihEbCzYULFxASEoKUlBRUVFSgd+/emDVrFnx9fTVycCA1H4Ig4NatW7hx44a2W3kjcrkcVlZWKCkpQX5+fp3CzJ49e5CcnIzTp09DX1+/AbqkZoKBhpqGyspKJCQkQBRF5OTkYMqUKZBIJLC1tdXIZ/NXr15FUFAQkpKS8Pz5c5ibm+P999/H+vXr0bVrV7XXo6bN09MTd+/erd2grgvkcjkGDx6MR48eIS8vD927d1d5zTfffFP7Dmvr1q0boEtqRhhoqOmpqqpCUlISRFFERkYGHB0dIQgC7OzsNBJusrOzERAQgHPnzuG3336DiYkJvLy8sGHDBpiZmam9HjU9bm5uePjwIX766Sdtt1InCoUCQ4YMwYMHD5CbmwsTExOV1xw8eBCiKCIyMpJ70UgTGGioaauursb58+chlUpx+fLl2gGa9vb2GvnsPj8/HwEBAYiNjUVJSQm6desGNzc3bNq0SSOPn1PT4OLigpKSEly9elXbraikUCgwfPhw3LlzB7m5uXUK7RERETh69ChkMhnatGnTAF1SM8RAQ82HXC5HamoqRFFEWloaxowZA0EQMGHCBI18ln///n0EBgYiKioKjx49grGxMVxcXODv74+BAweqvR7pLicnJzx//hzp6enabuVPKRQKjBw5Evn5+fj5559hbm6u8poTJ07gwIEDiImJUXnIHlE9MNBQ81RTU4O0tDSIooiUlBRYW1vXjmLQxGf7jx8/RnBwMERRrJ0MPmXKFGzcuJGTwQmTJ0/Gy5cvG/UwVYVCAVtbW/z888/Iycmp0zuOZ86cwd69exEbG8unAknTGGiIFAoF0tPTIZVKkZSUhKFDh0IQBEydOlUjb4//9ttvCAkJwalTp3Dv3j0YGRnB0dERGzZswJgxY9Rejxq/iRMnoqamBhcuXNB2K/+TQqGAnZ0dbty4gZs3b6Jv374qr4mKisKOHTsQFxdXp0P2iOqJgYboPymVSly7dg2iKCIhIQEDBw6EIAhwdnZGu3bt1F6vrKwMoaGhOHbsGG7fvo22bdvC3t4evr6+mDRpktrrUePk4OCAVq1a4Z///Ke2W/kvCoUC9vb2yMjIwI0bN9C/f3+V18TGxiIgIABxcXE80oAaCgMN0R9RKpXIysqCKIqIj49Hnz59IAgCXF1d0b59e7XXq6ysxJ49e3D48GHk5ubCwMAAdnZ2WLt2LaZPn672etR4jB07FoaGhkhOTtZ2K/9lwoQJSE9Px/Xr1+u09yshIQFffPEF4uPj63RiMJGaMNAQ1YVSqUROTg5EUURcXBxMTEwgCALc3Nw08i/Q6upqfPPNN/juu+9w8+ZN6OnpYdSoUVi1ahUEQeDcmyZm9OjReOedd5CQkKDtVn5n0qRJuHjxIn766ScMHjxY5frk5GRs2rQJcXFxdTpkj0iNGGiI3kZubi6kUiliYmJgbGwMQRDg7u4OY2NjtdeSy+X4/vvvsX//fmRlZQEARo4ciY8++ghz585luGkCbGxs8O677yI+Pl7brdRycnJCSkoKrl69iqFDh6pcn5qaCl9fX8TFxfFwSdIGBhqi+rpz5w6kUimioqJgZGQEQRDg4eGhkV/qCoUCJ06cwN69e3Ht2jUoFAoMGzYMS5YswdKlSzkXR0eNHDkSJiYmiImJ0XYrAABXV1ckJiYiPT29Tk/hXbx4EWvWrEFsbGydTgwm0gAGGiJ1KigoqA03+vr68PLygpeXF3r06KH2WgqFAjKZDLt27UJ6ejpev36NQYMGYcGCBVixYgVPY9Uhw4cPR69evRAVFaXtVjBjxgzEx8fjxx9/hLW1tcr16enpWLFiBWJiYmBqatoAHRL9Tww0RJpSVFSEyMhIREZGQqFQ1Iabnj17aqTeDz/8gNDQUFy8eBFVVVWwtLTEnDlzsHbtWh5o1sgNHToU/fv3h1Qq1WofgiBAJpPh4sWLGDVqlMr1165dw9KlSxEdHa2x/6+J6oiBhqghPH78GFFRUZBKpXj58iU8PDwgkUg0Ng4hJSUFX331FVJTU1FRUYE+ffpg9uzZ8PX15ZkgjdDgwYNhZWWF06dPa62HDz74AJGRkUhJScHYsWNVrr9+/ToWLVqEs2fP4r333tN8g0R/joGGqKGVlJRAJpNBKpXi2bNncHd3hyAIdTrf421cvnwZwcHBSEpKwosXL2Bubo6ZM2di/fr1fBKlkRg4cCCGDx+O48ePa6X+nDlzcPLkSSQlJWHChAkq19+4cQPz5s2DVCqt0yF7RA2AgYZIm0pLSxEdHQ1RFFFcXAw3NzdIJBJYWVlppN6NGzcQGBiIc+fOobS0FKampvDy8sLGjRvrNDGZNMPS0hKjRo1CREREg9desGABjh49in/84x9wdHRUuf7nn3/G7Nmzcfr0aVhYWDRAh0R1wkBD1FiUlZUhNjYWoiiioKAArq6uEAQBQ4YMQYsWdXqtvpG8vDwEBgYiLi4OJSUl6N69O9zc3ODv78/J4A2sf//+GDduHA4dOtSgdZcsWYJDhw7h3LlzmDJlisr1eXl5mDlzJk6ePMkBq9TYMNAQNUbl5eWIj4+HKIq4ffs2nJycIAgCRowYoZFwU1BQgICAAMhkMjx+/BhdunSBi4sLNm3aBEtLS7XXo9/r27cvHB0d8e233zZYzeXLl+Pbb79FbGwspk2bpnL97du3IQgCjh49WqdD9ogaGAMNUWNXWVmJhIQEiKKInJwcTJkyBRKJBLa2tho5VO/hw4cICgpCZGQkCgsL0alTJ0ydOhUbN27EX/7yF7XXI+C9997DtGnTsG/fvgapt2rVKuzbtw9nz56Fu7u7yvV3796Fp6cnDh8+jGHDhjVAh0RvjIGGSJdUVVUhKSkJoigiIyMDjo6OEAQBdnZ2Ggk3T548QUhICE6fPo2CggK0b9++djL46NGj1V6vuTI3N8eMGTOwe/dujddas2YNdu/eDVEU4enpqXJ9QUEBPDw8cODAAYwcOVLj/RG9JQYaIl1VXV2N8+fPQyqV4vLly7C3t4cgCLC3t9fIicFlZWXYuXMnjh8/XjsZfPz48fD19cXEiRPVXq85MTMzw/vvv4/Q0FCN1vH19UVoaChOnToFQRBUri8sLIS7uzv2798PW1tbjfZGVE8MNERNgVwuR2pqKkRRRFpaGsaMGQOJRIKJEydCX19f7fUqKysRFhaGiIgI5ObmwtDQEHZ2dli3bh1cXFzUXq+pMzExgY+PD0JCQjRWw9/fH8HBwTh+/Dg++OADlesfPnwINzc37N69G3Z2dhrri0hNGGiImpqamhqkpaVBFEWkpKTA2toagiBg0qRJaN26tdrrVVdXY9++fTh48CCys7Ohr6+PUaNG4eOPP4aXlxeHZ9ZBjx49MH/+fAQGBmrk/p9//jm2b9+OI0eOwMfHR+X64uJiuLq6IjQ0FPb29hrpiUjN6hRo+NuISIe0atUKDg4OCAsLQ2ZmJpYsWYKkpCTY2tpi7ty5kMlkePnypdrqGRgYYPXq1cjKysKrV68QFhaGiooKeHt7w9DQEGPGjEFERAQUCoXaajY1CoVCY4NFt2zZgu3bt+PQoUN1CjMlJSVwc3NDSEgIwww1OQw0RDqqZcuWsLOzw86dO5GZmYlPPvkEly5dwpgxYzBr1ixIpVJUVFSorZ6enh4+/PBDXLt2DdXV1Th48CCAf593YmBgAGtra4SHh0Mul6utZlOgqUCzbds2bN26FeHh4Zg/f77K9U+fPoWbmxu2bdvGfVHUJPEjJ6ImRqlUIisrC6IoIj4+Hn369IEgCHB1dUX79u3VXk+hUODs2bMICwvD5cuXayeDL1q0CCtWrICBgYHaa+oSY2NjrFu3Dp999pna7hkUFAR/f3/s27cPy5YtU7m+tLQULi4u2Lx5c53OpSFqZLiHhqi5UyqVyMnJgSiKiIuLg4mJCQRBgJubGzp27KiRmvHx8QgNDUVaWlrtZPB58+Zh9erVzXIyeOfOnbFhwwZs2LBBLffbsWMH/Pz8EBYWhlWrVqlc//z5c7i6umLDhg1wc3NTSw9EDYyBhoh+Lzc3F1KpFNHR0ejSpQsEQYC7uzuMjY01Ui8lJQUhISFITU1FZWUl+vbtCx8fH6xbt67ZTAbv1KkTPv/8c3z66af1vteuXbuwdu1a7Ny5E2vWrFG5/sWLF5g+fTpWr14NLy+vetcn0hIGGiL6Y3fu3IFUKkVUVBSMjIwgCAI8PDzQtWtXjdS7fPkygoKCkJycjBcvXqBXr161k8E1Fagag3feeQdbt27F6tWr63WfvXv34uOPP0ZISEidwlFFRQWmT5+O5cuX1+lRbqJGjIGGiOqmoKCgNtzo6+vDy8sLnp6eGpvSnZmZiaCgICQkJKC0tBRmZma1k8F79OihkZra0qFDBwQGBmLFihVvfY/w8HAsX74c27dvx8aNG1Wur6yshLu7OxYuXFinp5+IGjkGGiJ6c0VFRYiMjERkZCQUCgU8PT0hkUjQs2dPjdTLy8tDQEAA4uLi8OTJE3Tv3h0zZsyAv78/evXqpZGaDcnIyAg7d+7Ehx9++FbXf/fdd1i6dCm2bt2Kzz//XOX6qqoqeHh4wNvbGwsWLHirmkSNDAMNEdXP48ePERUVBalUisrKytpw07t3b43Uu3v3LgICAhATE4PHjx/j3XffhYuLC/z9/XV2Mni7du2wZ88eLFy48I2vPXz4MBYuXIjNmzdjy5YtKte/evUKXl5e8PDwwNKlS9+iW6JGiYGGiNSnpKQEMpkMUqkUz549g7u7OwRBQP/+/TVS7+HDhwgMDERkZCSKiorQqVMnODk5wd/fH0OHDtVITU1o27YtwsPDMWfOnDe67tixY5g7dy78/f2xbds2leurq6vx/vvvw8nJqV4fbxE1Qgw0RKQZpaWliI6OhiiKKC4uxvTp0yEIAqysrDRS78mTJwgODsbp06dx//59tG/fHpMmTcLGjRsb/WDFNm3a4Pvvv3+jjbmnTp3C7Nmz4evri6CgIJXrX79+DW9vbzg4ONR78zFRI8RAQ0SaV1ZWhtjYWIiiiIKCAri6ukIQBAwZMgQtWtTp99AbefbsGXbu3IkTJ3al4awAAArjSURBVE7gzp07aNeuHcaPH4/169fDwcFB7fXqy9DQEMeOHYNEIqnTeqlUipkzZ2LNmjXYsWOHyvVyuRw+Pj6wsbGBr69vfdslaowYaIioYZWXlyM+Ph6iKCI/Px/Ozs4QBAEjRozQSLiprKzErl27EBERgby8PBgaGmLcuHFYu3ZtozkRt3Xr1jhz5gzc3d1Vro2KioJEIsGqVauwa9culetramowf/58DBo0CP7+/upol6gxYqAhIu2prKxEQkICRFFEdnY2pk6dColEAltbW41M6a6qqsL+/ftx8OBB5OTkQF9fH6NHj8Ynn3wCDw8PrU0GNzAwgEwmUxmwYmJi4OHhgeXLl2Pv3r0q76tQKLB48WL07t0bmzdvVle7RI0RAw0RNQ5VVVVISkqCKIrIyMiAo6MjBEGAnZ2dRoKGXC7Hd999h/DwcGRlZaFly5awtrbGypUrMWvWrAYNN/r6+vjhhx8wefLkP1zzww8/YPr06Vi8eDHCw8NV3lOhUGDZsmXo1q0bvvzyS428+0XUiDDQEFHjU11djfPnz0MqleLy5cuwt7eHIAiwt7fXyFRqhUKBI0eOYN++fcjIyIBSqcSwYcOwbNkyLFy4UCM1/5Oenh6Sk5Mxfvz4//nnSUlJcHZ2xrx582onmP8ZpVKJlStXon379ggMDGSYoeaAgYaIGje5XI7U1FSIooiLFy/Czs4OEokEEydOhL6+vtrrKRQKiKKIPXv24MqVK3j9+jUGDx6MJUuWYNmyZRqZDK6np4cLFy7Azs7uv/7s/PnzmDp1Knx8fHD48GGV91IqlVizZg1atmyJnTt3MsxQc8FAQ0S6o6amBmlpaRBFESkpKbC2toYgCJg0aRJat26tkZqxsbH4+uuvcenSJbx69QqWlpZYsGABVq1apbbJ4K1atUJ6ejpsbGx+9/0LFy7A0dERH3zwAY4dO6byPkqlEn5+fqiqqsLu3bsZZqg5YaAhIt2kUCiQnp4OURSRnJyMoUOHQhAETJ06FW3atNFIzfPnz+Orr77ChQsXUFlZiX79+sHHxwdr166t12Twli1b4vr16xg2bFjt99LS0jBhwgR4enri9OnTKu+hVCrx2Wef4enTp9i3b5/WNjgTaQkDDRHpPqVSiWvXrkEURSQkJGDAgAEQBAHTpk1Du3btNFLzxx9/RHBwMJKTk1FeXo5evXrB29sbfn5+6Ny58xvdq2XLlsjOzq49dDA9PR329vZwc3NDZGRkne6xZcsW3L9/HwcOHGCYoeaIgYaImhalUomsrCyIooj4+Hj06dMHgiDA1dUV7du310jNzMxMBAYGIiEhAc+ePYOZmRkEQcCGDRvQvXt3lde3bNkSeXl56N+/P65evYqxY8di2rRpkMlkdaq/bds25OXl4dChQ2jVqlV9fxwiXcRAQ0RNl1KpRE5ODkRRRFxcHExMTCAIAtzc3NCxY0eN1Pzll18QGBiIuLg4PH36FD169KidDG5ubv4/r2nRogXu3buH3377DaNGjcLkyZMRHx9fp3rBwcG4fv06jh49yjBDzRkDDRE1H7m5uZBKpYiOjkaXLl0gkUgwY8YMGBsba6Te3bt3sX37dsTExKC4uBjvvvsuXF1dsWnTpt8N7GzRogUSExPh6uqKCRMmICEhoU73Dw0NxaVLl3DixAmNP1pO1Mgx0BBR83Tnzh1IpVJERUXByMgIgiDAw8MDXbt21Ui9wsJCBAUF4ezZsygqKkLnzp3h7OwMf39/DBkyBHp6enBwcEBycnKd7rd3714kJibizJkzGnl8nUjHMNAQEd27dw+RkZGIioqCnp4eJBIJPD09YWJiopF6v/76K0JCQnDmzBkUFBQAAMaNG4d//etfdbo+PDwcMTExEEVRY4+rE+kYBhoiov9UVFSEyMhIREZGQqFQwNPTExKJBD179tRIvWfPnuHIkSNYuXJlnZ5OOnjwIM6cOYOzZ8/C0NBQIz0R6SAGGiKiP/L48WNERUVBKpWisrKyNtz07t1bK/0cOXIER44cgUwm09hZO0Q6ioGGiKguSkpKIJPJIJVKUVpaihkzZkAikcDCwqJB6p84cQIHDhxAdHS0xs7WIdJhDDRERG+qtLQU0dHREEURxcXFmD59OgRBqD0YT93+/2yp2NhYGBkZaaQGkY5joCEiqo+ysjLExsZCFEUUFBTA1dUVgiBgyJAhapmlJJPJ8NVXXyEuLq5e4xWImjgGGiIidSkvL0d8fDxEUUR+fj6cnZ0hCAJGjBjxVuEmLi4O27ZtQ3x8vMYOAiRqIhhoiIg0obKyEgkJCRBFEdnZ2ZgyZQoEQYCtrW2dnmZKSEjAli1bEBcX98azoYiaIQYaIiJNq6qqQmJiIqRSKTIyMuDo6AiJRAI7O7v/Oa4gOTkZ/v7+iI+PR5cuXbTQMZHOYaAhImpI1dXVOH/+PERRxJUrV2Bvbw9BEGBvbw89PT2kpqbC19cXcXFxGju1mKgJYqAhItIWuVyO1NRUiKKIixcvonfv3vi///s/JCYmokePHtpuj0iXMNAQETUGNTU1iIiIwKBBg2Bra6vtdoh0DQMNERER6bw6BRrV2/GJiIiIGjkGGiIiItJ5DDRERESk8xhoiIiISOcx0BAREZHOY6AhIiIincdAQ0RERDqPgYaIiIh0HgMNERER6TwGGiKiRuzcuXOwtLREv379EBgYqO12iBotjj4gImqkampqYGFhgcTERJiZmcHGxgYnTpyAlZWVtlsjakgcfUBEpMuuXLmCfv36oU+fPjAwMIC3tzdkMpm22yJqlBhoiIgaqaKiIvTs2bP2azMzMxQVFWmxI6LGi4GGiOgPLFq0CF27dsXgwYNrv+fn54cBAwZg6NCh8PT0xLNnzwAAVVVVmDVrFoYMGYKBAwciICBAW20TNUsMNEREf2DBggU4d+7c7743ZcoUZGdn48aNG7CwsKgNLidPnoRSqcTNmzfx008/4ZtvvsG9e/fqVd/U1BQPHjyo/bqwsBCmpqb1uidRU8VAQ0T0BxwcHNC5c+fffW/q1KnQ09MDAIwePRqFhYUAgO7du6OiogJyuRwvX76EgYEBOnToUK/6NjY2yM/Px927d1FdXY2TJ0/C3d29XvckaqoYaIiI3tLBgwcxbdo0AICzszPeeecd9OjRA+bm5vD19f2vMPSm9PT0sGfPHjg5OWHgwIGYOXMmBg0apI7WiZocPW03QESki7Zt2wY9PT34+PgAAI4ePYrKyko8fPgQpaWlsLe3x+TJk9GnT5961XFxcYGLi4s6WiZq0vgODRHRG/r+++8RGxuLY8eOoUWLfx+RkZaWBk9PT+jr66Nr164YO3Ysrl27puVOiZoPBhoiojdw7tw5BAcHIzo6Gm3btq39/oABA3D+/HkAQEVFBdLT0zFgwABttUnU7PCkYCKiPzBr1iykpKTgyZMn6NatG/76178iICAAr169grGxMYB/bwzev38/qqqqsHjxYmRlZUGhUGDhwoXw8/PT8k9A1CTU6aRgBhoiIiJqzDj6gIiIiJoHBhoiIiLSeQw0REREpPMYaIiIiEjnMdAQERGRzmOgISIiIp3HQENEREQ6j4GGiIiIdB4DDREREem8N522XafT+oiIiIgaEt+hISIiIp3HQENEREQ6j4GGiIiIdB4DDREREek8BhoiIiLSeQw0REREpPMYaIiIiEjnMdAQERGRzmOgISIiIp3HQENEREQ67/8BWyHzzYyBKOAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac6d4106a90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial_visual = trial_sample[0]\n",
    "print(trial_visual.shape)\n",
    "trial_visual_edge = trial_visual.shape[0]\n",
    "print(\"edge dim = \" + str(trial_visual_edge))\n",
    "\n",
    "# from [-1,1] to [0,1]\n",
    "trial_visual = (trial_visual + 1.0) / 2.0\n",
    "print(trial_visual.shape)\n",
    "\n",
    "visualize_cube(cube=trial_visual,      ## array name\n",
    "             edge_dim=trial_visual_edge,        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "             start_cube_index_x=0,\n",
    "             start_cube_index_y=0,\n",
    "             start_cube_index_z=0,\n",
    "             fig_size=(10,10),\n",
    "             stdev_to_white=-2,\n",
    "             norm_multiply=viz_multiplier,\n",
    "             color_map=\"Blues\",\n",
    "             plot_show = True,\n",
    "             save_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Duplicates in Sampled Subcubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [768, 1792], 'y': [128, 1152], 'z': [256, 1280]}\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_sample = edge_sample \n",
    "nsamples = 10000\n",
    "\n",
    "testcd = define_test(s_test = edge_test,\n",
    "                     s_train = edge_sample)\n",
    "print(testcd)\n",
    "\n",
    "sample_list=[]\n",
    "m = 2048 - 128\n",
    "\n",
    "\n",
    "for n in range(nsamples):\n",
    "    #print(\"Sample No = \" + str(n + 1) + \" / \" + str(nsamples))\n",
    "    sample_valid = False\n",
    "    while sample_valid == False:\n",
    "        x = random.randint(0,m)\n",
    "        y = random.randint(0,m)\n",
    "        z = random.randint(0,m)\n",
    "        sample_coords = {'x':[x,x+s_sample], \n",
    "                         'y':[y,y+s_sample], \n",
    "                         'z':[z,z+s_sample]}\n",
    "\n",
    "        sample_valid = check_coords(testcd, \n",
    "                                    sample_coords)\n",
    "\n",
    "    sample_list.append(sample_coords)\n",
    "\n",
    "print(len(sample_list))\n",
    "# print(len(list(set(sample_list))))\n",
    "sample_df = pd.DataFrame.from_dict(sample_list)\n",
    "dropped_sample_df = sample_df.applymap(lambda x: x[0]).drop_duplicates()\n",
    "\n",
    "sample_df.shape[0] == dropped_sample_df.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydrogenDataset2(Dataset):\n",
    "    \"\"\"Hydrogen Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, h5_file, root_dir, s_test, s_train,\n",
    "                 s_sample, nsamples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h5_file (string): name of the h5 file with 32 sampled cubes.\n",
    "            root_dir (string): Directory with the .h5 file.\n",
    "        \"\"\"\n",
    "        file_size = os.path.getsize(root_dir + h5_file) / 1e6 # in MBs\n",
    "#         print(\"The whole file size is \" + str(int(file_size)) + \" MBs\")\n",
    "        \n",
    "        # self.subcubes = h5py.File('../data/sample_32.h5', 'r')\n",
    "#         self.f = f_deltaHI\n",
    "        self.h5_file = h5_file\n",
    "        self.root_dir = root_dir\n",
    "        self.s_test = s_test\n",
    "        self.s_train = s_train\n",
    "        self.t_coords = define_test(self.s_test,\n",
    "                                    self.s_train)\n",
    "        self.s_sample = s_sample\n",
    "        self.nsamples = nsamples\n",
    "        self.h5_filename = self.root_dir + self.h5_file\n",
    "        \n",
    "#         self.samples = get_samples(s_sample = self.s_sample,\n",
    "#                              nsamples = self.nsamples,\n",
    "#                              h5_filename = self.h5_filename,\n",
    "#                              test_coords = self.t_coords)\n",
    "#         print(\"Got self.samples\")\n",
    "        \n",
    "        self.min_val = min_cube\n",
    "#         print(\"min = \" + str(self.min_val))\n",
    "        self.max_val = max_cube\n",
    "#         print(\"max = \" + str(self.max_val))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Function called when len(self) is executed\n",
    "        \n",
    "        #print(len(self.subcubes))\n",
    "#         return len(self.nsamples)\n",
    "        return self.nsamples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This can be implemented in such a way that the whole h5 file read \n",
    "        using h5py.File() and get_sample() function is called to return\n",
    "        a random subcube. This won't increase memory usage because the\n",
    "        subcubes will be read in the same way and only the batch will\n",
    "        be read into memory.\n",
    "        \n",
    "        Here we have implemented it so that it can be used with data\n",
    "        generated by get_sample() function.\n",
    "        \n",
    "        The output of this function is one subcube with the dimensions\n",
    "        specified by get_sample() implementation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # default version -> error in training because of dimensions\n",
    "#         sample = self.subcubes[idx]\n",
    "        \n",
    "        # reshaped version to add another dimension\n",
    "#         sample = self.subcubes[idx].reshape((1,128,128,128))\n",
    "\n",
    "        # On prince using get_samples()\n",
    "#         print(\"nsamples = \" + str(self.nsamples))\n",
    "        sample = get_samples(s_sample = self.s_sample,\n",
    "                             nsamples = 1,\n",
    "#                              h5_filename = self.h5_filename,\n",
    "                             test_coords = self.t_coords,\n",
    "                            f = f)\n",
    "    \n",
    "#         sample = self.samples[idx].reshape((1,128,128,128))\n",
    "\n",
    "        sample = np.array(sample).reshape((1,self.s_sample,self.s_sample,self.s_sample))\n",
    "        \n",
    "        # added division by 1e6 for exploding variance\n",
    "        # and resulting in inf during reparametrization trick part\n",
    "#         sample = sample/1e6\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on prince\n",
    "sampled_subcubes = HydrogenDataset2(h5_file=redshift_file,\n",
    "                                    root_dir = root_dir,\n",
    "                                    s_test = edge_test, \n",
    "                                    s_train = edge_sample,\n",
    "                                    s_sample = edge_sample, \n",
    "                                    nsamples = n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "trn_loader = torch.utils.data.DataLoader(sampled_subcubes, \n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle=True, \n",
    "                                         num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider linear time MMD with a linear kernel:\n",
    "# K(f(x), f(y)) = f(x)^Tf(y)\n",
    "# h(z_i, z_j) = k(x_i, x_j) + k(y_i, y_j) - k(x_i, y_j) - k(x_j, y_i)\n",
    "#             = [f(x_i) - f(y_i)]^T[f(x_j) - f(y_j)]\n",
    "#\n",
    "# f_of_X: batch_size * k\n",
    "# f_of_Y: batch_size * k\n",
    "def linear_mmd2(f_of_X, f_of_Y):\n",
    "    loss = 0.0\n",
    "    delta = f_of_X - f_of_Y\n",
    "    loss = torch.mean((delta[:-1] * delta[1:]).sum(1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider linear time MMD with a polynomial kernel:\n",
    "# K(f(x), f(y)) = (alpha*f(x)^Tf(y) + c)^d\n",
    "# f_of_X: batch_size * k\n",
    "# f_of_Y: batch_size * k\n",
    "def poly_mmd2(f_of_X, f_of_Y, d=2, alpha=1.0, c=2.0):\n",
    "    K_XX = (alpha * (f_of_X[:-1] * f_of_X[1:]).sum(1) + c)\n",
    "    K_XX_mean = torch.mean(K_XX.pow(d))\n",
    "\n",
    "    K_YY = (alpha * (f_of_Y[:-1] * f_of_Y[1:]).sum(1) + c)\n",
    "    K_YY_mean = torch.mean(K_YY.pow(d))\n",
    "\n",
    "    K_XY = (alpha * (f_of_X[:-1] * f_of_Y[1:]).sum(1) + c)\n",
    "    K_XY_mean = torch.mean(K_XY.pow(d))\n",
    "\n",
    "    K_YX = (alpha * (f_of_Y[:-1] * f_of_X[1:]).sum(1) + c)\n",
    "    K_YX_mean = torch.mean(K_YX.pow(d))\n",
    "\n",
    "    return K_XX_mean + K_YY_mean - K_XY_mean - K_YX_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mix_rbf_kernel(X, Y, sigma_list):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X -> f_enc_X_D ->\n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        Y -> f_enc_Y_D -> \n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        sigma_list -> \n",
    "            base = 1.0\n",
    "            sigma_list = [1, 2, 4, 8, 16]\n",
    "            sigma_list = [sigma / base for sigma in sigma_list] \n",
    "            \n",
    "    m = batch_size\n",
    "    torch.cat(seq, dim=0, out=None) â†’ Tensor\n",
    "        Concatenates the given sequence of seq tensors \n",
    "        in the given dimension\n",
    "    Z size = [2 x batch_size, nz]\n",
    "    \n",
    "    torch.mm(mat1, mat2, out=None) â†’ Tensor\n",
    "        Performs a matrix multiplication of the matrices mat1 and mat2\n",
    "    ZZT size = [2 x batch_size, 2 x batch_size]\n",
    "    \n",
    "    torch.diag(input, diagonal=0, out=None) â†’ Tensor\n",
    "        If input is a matrix (2-D tensor), then returns a 1-D tensor \n",
    "        with the diagonal elements of input\n",
    "    torch.unsqueeze(input, dim, out=None) â†’ Tensor\n",
    "        Returns a new tensor with a dimension of size \n",
    "        one inserted at the specified position\n",
    "    diag_ZZT = [2 x batch_size, 1]\n",
    "    \n",
    "    expand_as(other) â†’ Tensor\n",
    "        Expand this tensor to the same size as other\n",
    "    Z_norm_sqr = [2 x batch_size, 2 x batch_size]\n",
    "    \n",
    "    torch.exp(tensor, out=None) â†’ Tensor\n",
    "        Returns a new tensor with the exponential of the elements of input\n",
    "        y_i = e^(x_i)\n",
    "        \n",
    "    exponent size = [2 x batch_size, 2 x batch_size]\n",
    "    K size = [2 x batch_size, 2 x batch_size]\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(X.size(0) == Y.size(0))\n",
    "    m = X.size(0)\n",
    "\n",
    "    Z = torch.cat((X, Y), dim = 0)\n",
    "#     print(\"Z size = \" + str(Z.size()))\n",
    "    \n",
    "    ZZT = torch.mm(Z, Z.t())\n",
    "#     print(\"ZZT size = \" + str(ZZT.size()))\n",
    "    \n",
    "    diag_ZZT = torch.diag(ZZT).unsqueeze(1)\n",
    "#     print(\"diag_ZZT size = \" + str(diag_ZZT.size()))\n",
    "    \n",
    "    Z_norm_sqr = diag_ZZT.expand_as(ZZT)\n",
    "#     print(\"Z_norm_sqr size = \" + str(Z_norm_sqr.size()))\n",
    "    \n",
    "    exponent = Z_norm_sqr - 2 * ZZT + Z_norm_sqr.t()\n",
    "#     print(\"exponent size = \" + str(exponent.size()))\n",
    "#     print(\"exponent = \" + str(exponent))\n",
    "\n",
    "    K = 0.0\n",
    "    for sigma in sigma_list:\n",
    "        gamma = 1.0 / (2 * sigma**2)\n",
    "        K += torch.exp(-gamma * exponent)\n",
    "#     print(\"K size = \" + str(K.size()))\n",
    "\n",
    "    return K[:m, :m], K[:m, m:], K[m:, m:], len(sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_rbf_mmd2(X, Y, sigma_list, biased=True):\n",
    "    \"\"\"\n",
    "    How it is used in the training loop:\n",
    "        mmd2_D = mix_rbf_mmd2(f_enc_X_D,  f_enc_Y_D,  sigma_list)\n",
    "        X -> f_enc_X_D ->\n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        Y -> f_enc_Y_D -> \n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        sigma_list -> \n",
    "            base = 1.0\n",
    "            sigma_list = [1, 2, 4, 8, 16]\n",
    "            sigma_list = [sigma / base for sigma in sigma_list]\n",
    "        \n",
    "    _mix_rbf_kernel's internal K has [2 x batch_size, 2 x batch_size] size\n",
    "    K_XX = K[:m, :m] (left upper quadrant) -> size = [batch_size, batch_size]\n",
    "    K_XY = K[:m, m:] (right upper and left lower quadrant) -> size = [batch_size, batch_size]\n",
    "    K_YY = K[m:, m:] (right lower quadrant) -> size = [batch_size, batch_size]\n",
    "    d = len(sigma_list)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    K_XX, K_XY, K_YY, d = _mix_rbf_kernel(X, Y, sigma_list)\n",
    "#     print(\"K_XX size = \" + str(K_XX.size()))\n",
    "#     print(\"K_XY size = \" + str(K_XY.size()))\n",
    "#     print(\"K_YY size = \" + str(K_YY.size()))\n",
    "    # return _mmd2(K_XX, K_XY, K_YY, const_diagonal=d, biased=biased)\n",
    "    return _mmd2(K_XX, K_XY, K_YY, const_diagonal=False, biased=biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_rbf_mmd2_and_ratio(X, Y, sigma_list, biased=True):\n",
    "    K_XX, K_XY, K_YY, d = _mix_rbf_kernel(X, Y, sigma_list)\n",
    "    # return _mmd2_and_ratio(K_XX, K_XY, K_YY, const_diagonal=d, biased=biased)\n",
    "    return _mmd2_and_ratio(K_XX, K_XY, K_YY, const_diagonal=False, biased=biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\tilde{K}_XX * e = K_XX * e - diag_X $\n",
    "* $ \\tilde{K}_YY * e = K_YY * e - diag_Y $ \n",
    "* $ K_{XY}^T * e $\n",
    "\n",
    "\n",
    "* $ e^T * \\tilde{K}_XX * e $\n",
    "* $ e^T * \\tilde{K}_YY * e $ \n",
    "* $ e^T * K_{XY} * e $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Helper functions to compute variances based on kernel matrices\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def _mmd2(K_XX, K_XY, K_YY, const_diagonal=False, biased=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        K_XX = K[:m, :m] size = [batch_size, batch_size]\n",
    "        K_XY = K[:m, m:] size = [batch_size, batch_size]\n",
    "        K_YY = K[m:, m:] size = [batch_size, batch_size]\n",
    "        \n",
    "    m = batch_size\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    m = K_XX.size(0)    # assume X, Y are same shape\n",
    "\n",
    "    # Get the various sums of kernels that we'll use\n",
    "    # Kts drop the diagonal, but we don't need to compute them explicitly\n",
    "    if const_diagonal is not False:\n",
    "        diag_X = diag_Y = const_diagonal\n",
    "        sum_diag_X = sum_diag_Y = m * const_diagonal\n",
    "    else:\n",
    "        diag_X = torch.diag(K_XX)                       # (m,)\n",
    "        diag_Y = torch.diag(K_YY)                       # (m,)\n",
    "        sum_diag_X = torch.sum(diag_X)\n",
    "        sum_diag_Y = torch.sum(diag_Y)\n",
    "\n",
    "    Kt_XX_sums = K_XX.sum(dim=1) - diag_X             # \\tilde{K}_XX * e = K_XX * e - diag_X\n",
    "    Kt_YY_sums = K_YY.sum(dim=1) - diag_Y             # \\tilde{K}_YY * e = K_YY * e - diag_Y\n",
    "    K_XY_sums_0 = K_XY.sum(dim=0)                     # K_{XY}^T * e\n",
    "\n",
    "    Kt_XX_sum = Kt_XX_sums.sum()                       # e^T * \\tilde{K}_XX * e\n",
    "    Kt_YY_sum = Kt_YY_sums.sum()                       # e^T * \\tilde{K}_YY * e\n",
    "    K_XY_sum = K_XY_sums_0.sum()                       # e^T * K_{XY} * e\n",
    "\n",
    "    if biased:\n",
    "        mmd2 = ((Kt_XX_sum + sum_diag_X) / (m * m)\n",
    "            + (Kt_YY_sum + sum_diag_Y) / (m * m)\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "    else:\n",
    "        mmd2 = (Kt_XX_sum / (m * (m - 1))\n",
    "            + Kt_YY_sum / (m * (m - 1))\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "\n",
    "    return mmd2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mmd2_and_ratio(K_XX, K_XY, K_YY, const_diagonal=False, biased=False):\n",
    "    mmd2, var_est = _mmd2_and_variance(K_XX, K_XY, K_YY, const_diagonal=const_diagonal, biased=biased)\n",
    "    loss = mmd2 / torch.sqrt(torch.clamp(var_est, min=min_var_est))\n",
    "    return loss, mmd2, var_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mmd2_and_variance(K_XX, K_XY, K_YY, const_diagonal=False, biased=False):\n",
    "    m = K_XX.size(0)    # assume X, Y are same shape\n",
    "\n",
    "    # Get the various sums of kernels that we'll use\n",
    "    # Kts drop the diagonal, but we don't need to compute them explicitly\n",
    "    if const_diagonal is not False:\n",
    "        diag_X = diag_Y = const_diagonal\n",
    "        sum_diag_X = sum_diag_Y = m * const_diagonal\n",
    "        sum_diag2_X = sum_diag2_Y = m * const_diagonal**2\n",
    "    else:\n",
    "        diag_X = torch.diag(K_XX)                       # (m,)\n",
    "        diag_Y = torch.diag(K_YY)                       # (m,)\n",
    "        sum_diag_X = torch.sum(diag_X)\n",
    "        sum_diag_Y = torch.sum(diag_Y)\n",
    "        sum_diag2_X = diag_X.dot(diag_X)\n",
    "        sum_diag2_Y = diag_Y.dot(diag_Y)\n",
    "\n",
    "    Kt_XX_sums = K_XX.sum(dim=1) - diag_X             # \\tilde{K}_XX * e = K_XX * e - diag_X\n",
    "    Kt_YY_sums = K_YY.sum(dim=1) - diag_Y             # \\tilde{K}_YY * e = K_YY * e - diag_Y\n",
    "    K_XY_sums_0 = K_XY.sum(dim=0)                     # K_{XY}^T * e\n",
    "    K_XY_sums_1 = K_XY.sum(dim=1)                     # K_{XY} * e\n",
    "\n",
    "    Kt_XX_sum = Kt_XX_sums.sum()                       # e^T * \\tilde{K}_XX * e\n",
    "    Kt_YY_sum = Kt_YY_sums.sum()                       # e^T * \\tilde{K}_YY * e\n",
    "    K_XY_sum = K_XY_sums_0.sum()                       # e^T * K_{XY} * e\n",
    "\n",
    "    Kt_XX_2_sum = (K_XX ** 2).sum() - sum_diag2_X      # \\| \\tilde{K}_XX \\|_F^2\n",
    "    Kt_YY_2_sum = (K_YY ** 2).sum() - sum_diag2_Y      # \\| \\tilde{K}_YY \\|_F^2\n",
    "    K_XY_2_sum  = (K_XY ** 2).sum()                    # \\| K_{XY} \\|_F^2\n",
    "\n",
    "    if biased:\n",
    "        mmd2 = ((Kt_XX_sum + sum_diag_X) / (m * m)\n",
    "            + (Kt_YY_sum + sum_diag_Y) / (m * m)\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "    else:\n",
    "        mmd2 = (Kt_XX_sum / (m * (m - 1))\n",
    "            + Kt_YY_sum / (m * (m - 1))\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "\n",
    "    var_est = (\n",
    "        2.0 / (m**2 * (m - 1.0)**2) * (2 * Kt_XX_sums.dot(Kt_XX_sums) - Kt_XX_2_sum + 2 * Kt_YY_sums.dot(Kt_YY_sums) - Kt_YY_2_sum)\n",
    "        - (4.0*m - 6.0) / (m**3 * (m - 1.0)**3) * (Kt_XX_sum**2 + Kt_YY_sum**2)\n",
    "        + 4.0*(m - 2.0) / (m**3 * (m - 1.0)**2) * (K_XY_sums_1.dot(K_XY_sums_1) + K_XY_sums_0.dot(K_XY_sums_0))\n",
    "        - 4.0*(m - 3.0) / (m**3 * (m - 1.0)**2) * (K_XY_2_sum) - (8 * m - 12) / (m**5 * (m - 1)) * K_XY_sum**2\n",
    "        + 8.0 / (m**3 * (m - 1.0)) * (\n",
    "            1.0 / m * (Kt_XX_sum + Kt_YY_sum) * K_XY_sum\n",
    "            - Kt_XX_sums.dot(K_XY_sums_1)\n",
    "            - Kt_YY_sums.dot(K_XY_sums_0))\n",
    "        )\n",
    "    return mmd2, var_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, dim=1):\n",
    "    \"\"\"\n",
    "    used only in match() when dist == cos\n",
    "    \"\"\"\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "\n",
    "def match(x, y, dist):\n",
    "    '''\n",
    "    Computes distance between corresponding points points in `x` and `y`\n",
    "    using distance `dist`.\n",
    "    \n",
    "    # compute L2-loss of AE\n",
    "    L2_AE_X_D = match(x.view(batch_size, -1), f_dec_X_D, 'L2')\n",
    "    L2_AE_Y_D = match(y.view(batch_size, -1), f_dec_Y_D, 'L2')\n",
    "    \n",
    "    '''\n",
    "    if dist == 'L2':\n",
    "        return (x - y).pow(2).mean()\n",
    "    elif dist == 'L1':\n",
    "        return (x - y).abs().mean()\n",
    "    elif dist == 'cos':\n",
    "        x_n = normalize(x)\n",
    "        y_n = normalize(y)\n",
    "        return 2 - (x_n).mul(y_n).mean()\n",
    "    else:\n",
    "        assert dist == 'none', 'wtf ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm(m, norm_type=2):\n",
    "    total_norm = 0.0\n",
    "    for p in m.parameters():\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm ** norm_type\n",
    "    total_norm = total_norm ** (1. / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.1)\n",
    "#         m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: batch_size * k * 1 * 1\n",
    "# output: batch_size * nc * image_size * image_size\n",
    "\n",
    "\"\"\"\n",
    "# construct encoder/decoder modules\n",
    "hidden_dim = nz\n",
    "G_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "D_encoder = Encoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ndf=16)\n",
    "D_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ngf=16)\n",
    "                    \n",
    "What is ngf?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, isize, nc, k=100, ngf=64):\n",
    "        super(Decoder, self).__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        cngf, tisize = ngf // 2, 4\n",
    "        print(\"cngf = \" + str(cngf))\n",
    "        print(\"tisize = \" + str(tisize))\n",
    "        \n",
    "        while tisize != isize:\n",
    "            cngf = cngf * 2\n",
    "            tisize = tisize * 2\n",
    "            \n",
    "        print(\"cngf = \" + str(cngf))\n",
    "        print(\"tisize = \" + str(tisize))\n",
    "        \n",
    "        \"\"\"\n",
    "        This part has been added to introduce FC layers to\n",
    "        the decoder part of the GAN. We believe that these layers\n",
    "        will be effective to learn the sparsity of the input data\n",
    "        \"\"\"\n",
    "        fc_main = nn.Sequential()\n",
    "        \n",
    "        fc_main.add_module(\"first_decoder_FC\",\n",
    "                        nn.Linear(in_features = k,\n",
    "                                  out_features = k * 2,\n",
    "                                  bias = False))\n",
    "        fc_main.add_module(\"second_decoder_FC\",\n",
    "                        nn.Linear(in_features = k * 2,\n",
    "                                  out_features = k,\n",
    "                                  bias = False))\n",
    "\n",
    "        self.fc_main = fc_main\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        Deconvolution Part\n",
    "        \"\"\"\n",
    "        \n",
    "        main = nn.Sequential()\n",
    "        \n",
    "        main.add_module('initial_{0}-{1}_convt'.format(k, cngf), \n",
    "                        nn.ConvTranspose3d(in_channels = k,\n",
    "                                           out_channels = cngf,\n",
    "                                           kernel_size = 4, \n",
    "                                           stride = 1,\n",
    "                                           padding = 0, \n",
    "                                           bias=False))\n",
    "        main.add_module('initial_{0}_batchnorm'.format(cngf), \n",
    "                        nn.BatchNorm3d(num_features = cngf))\n",
    "#         main.add_module('initial_{0}_relu'.format(cngf), \n",
    "#                         nn.ReLU(True))\n",
    "        main.add_module('initial_{0}_leakyrelu'.format(cngf), \n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        csize = 4\n",
    "#         cize = 8\n",
    "        while csize < isize // 2:\n",
    "            main.add_module('pyramid_{0}-{1}_convt'.format(cngf, cngf // 2),\n",
    "                            nn.ConvTranspose3d(in_channels = cngf,\n",
    "                                               out_channels = cngf // 2,\n",
    "                                               kernel_size = 4,\n",
    "                                               stride = 2,\n",
    "                                               padding = 1,\n",
    "                                               bias=False))\n",
    "            main.add_module('pyramid_{0}_batchnorm'.format(cngf // 2),\n",
    "                            nn.BatchNorm3d(num_features = cngf // 2))\n",
    "#             main.add_module('pyramid_{0}_relu'.format(cngf // 2),\n",
    "#                             nn.ReLU(True))\n",
    "            main.add_module('initial_{0}_leakyrelu'.format(cngf // 2), \n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cngf = cngf // 2\n",
    "            csize = csize * 2\n",
    "\n",
    "        main.add_module('final_{0}-{1}_convt'.format(cngf, nc), \n",
    "                        nn.ConvTranspose3d(in_channels = cngf,\n",
    "                                           out_channels = nc,\n",
    "                                           kernel_size = 4,\n",
    "                                           stride = 2,\n",
    "                                           padding = 1,\n",
    "                                           bias=False))\n",
    "#         main.add_module('final_{0}_tanh'.format(nc),\n",
    "#                         nn.Tanh())\n",
    "#         main.add_module('final_{0}_sigmoid'.format(nc),\n",
    "#                 nn.Sigmoid())\n",
    "#         main.add_module('final_{0}_leakyrelu'.format(nc),\n",
    "#                 nn.LeakyReLU(negative_slope=0.0001,\n",
    "#                              inplace = True))\n",
    "        main.add_module('final_{0}_relu'.format(nc),\n",
    "                        nn.ReLU(False))\n",
    "#         main.add_module('final_{0}_linear'.format(nc),\n",
    "#                         nn.Linear(in_features = isize, \n",
    "#                                   out_features = isize))\n",
    "    \n",
    "        self.main = main\n",
    "        \n",
    "        # to print out the resulting structure\n",
    "#         print(main)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # FC Layers\n",
    "        out = self.fc_main(input)\n",
    "#         print(\"Decoder FC Layer output size = \" + str(out.shape))\n",
    "        \n",
    "        # Transformation\n",
    "        out = out.view(batch_size, nz, 1,1,1)\n",
    "#         print(\"Decoder FC Out Transformed Shape \\n Input to ConvTranspose3D Layers = \" + str(out.shape))     \n",
    "\n",
    "        \n",
    "        # Deconvolution Layers\n",
    "#         output = self.main(input)\n",
    "        output = self.main(out)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetG is a decoder\n",
    "# input: batch_size * nz * 1 * 1\n",
    "# output: batch_size * nc * image_size * image_size\n",
    "class NetG(nn.Module):\n",
    "    def __init__(self, decoder):\n",
    "        super(NetG, self).__init__()\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.decoder(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: batch_size * nc * 64 * 64\n",
    "# output: batch_size * k * 1 * 1\n",
    "\n",
    "\"\"\"\n",
    "# construct encoder/decoder modules\n",
    "hidden_dim = nz\n",
    "G_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "D_encoder = Encoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ndf=16)\n",
    "D_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ngf=16)\n",
    "\"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, isize, nc, k=100, ndf=64):\n",
    "        \"\"\"\n",
    "        isize = image_size\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        \"\"\"\n",
    "        Convolution Part\n",
    "        \"\"\"\n",
    "        \n",
    "        # input is nc x isize x isize\n",
    "        main = nn.Sequential()\n",
    "        main.add_module('initial_conv_{0}-{1}'.format(nc, ndf),\n",
    "                        nn.Conv3d(in_channels = nc,\n",
    "                                  out_channels = ndf,\n",
    "                                  kernel_size = 4,\n",
    "                                  stride = 2,\n",
    "                                  padding = 1,\n",
    "                                  bias=False))\n",
    "        main.add_module('initial_relu_{0}'.format(ndf),\n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        \n",
    "        csize, cndf = isize / 2, ndf\n",
    "        print(\"csize = \" + str(csize))\n",
    "        print(\"cndf = \" + str(cndf))\n",
    "\n",
    "\n",
    "        while csize > 4:\n",
    "#         while csize > 8:\n",
    "            in_feat = cndf\n",
    "            out_feat = cndf * 2\n",
    "            main.add_module('pyramid_{0}-{1}_conv'.format(in_feat, out_feat),\n",
    "                            nn.Conv3d(in_channels = in_feat,\n",
    "                                      out_channels = out_feat,\n",
    "                                      kernel_size = 4,\n",
    "                                      stride = 2,\n",
    "                                      padding = 1,\n",
    "                                      bias=False))\n",
    "            main.add_module('pyramid_{0}_batchnorm'.format(out_feat),\n",
    "                            nn.BatchNorm3d(num_features = out_feat))\n",
    "            main.add_module('pyramid_{0}_relu'.format(out_feat),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cndf = cndf * 2\n",
    "            csize = csize / 2\n",
    "\n",
    "            \n",
    "        main.add_module('final_{0}-{1}_conv'.format(cndf, 1),\n",
    "                        nn.Conv3d(in_channels = cndf,\n",
    "                                  out_channels = k,\n",
    "                                  kernel_size = 4,\n",
    "                                  stride = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias=False))\n",
    "\n",
    "        self.main = main\n",
    "        \n",
    "        \"\"\"\n",
    "        Fully Connected Layer Part\n",
    "        This part has been added to introduce FC layers to\n",
    "        the encoder part of the GAN. We believe that these layers\n",
    "        will be effective to learn the sparsity of the input data\n",
    "        \"\"\"\n",
    "        fc_main = nn.Sequential()\n",
    "        \n",
    "        fc_main.add_module(\"first_decoder_FC\",\n",
    "                        nn.Linear(in_features = k,\n",
    "                                  out_features = k * 2,\n",
    "                                  bias = False))\n",
    "        fc_main.add_module(\"second_decoder_FC\",\n",
    "                        nn.Linear(in_features = k * 2,\n",
    "                                  out_features = k,\n",
    "                                  bias = False))\n",
    "        \n",
    "        self.fc_main = fc_main\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        # Convolution Layers\n",
    "        out = self.main(input)\n",
    "#         print(\"Encoder Conv Out Shape = \" + str(out.shape))             \n",
    "        \n",
    "        # Transformation\n",
    "        out = out.view(batch_size, -1)\n",
    "#         print(\"Encoder Conv Out Transformed Shape \\n Input to FC Layers = \" + str(out.shape))     \n",
    "        \n",
    "        # FC Layers\n",
    "        output = self.fc_main(out)\n",
    "#         print(\"Encoder FC Out Shape = \" + str(output.shape))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetD is an encoder + decoder\n",
    "# input: batch_size * nc * image_size * image_size\n",
    "# f_enc_X: batch_size * k * 1 * 1\n",
    "# f_dec_X: batch_size * nc * image_size * image_size\n",
    "class NetD(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(NetD, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        \"\"\"\n",
    "        This part has been added to introduce FC layers to\n",
    "        the encoder part of the GAN. We believe that these layers\n",
    "        will be effective to learn the sparsity of the input data\n",
    "        \"\"\"\n",
    "#         # \"first_encoder_FC\"\n",
    "#         self.fc1 = nn.Linear(in_features = k,\n",
    "#                       out_features = k * 2,\n",
    "#                       bias = False)\n",
    "#         # \"second_encoder_FC\"\n",
    "#         self.fc2 = nn.Linear(in_features = k * 2,\n",
    "#                       out_features = k,\n",
    "#                       bias = False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        f_enc_X = self.encoder(input)\n",
    "#         print(\"f_enc_X outputted.\")\n",
    "        \n",
    "#         # The FC Layers\n",
    "#         f_enc_X = self.fc1(f_enc_X)\n",
    "#         f_enc_X = self.fc1(f_enc_X)\n",
    "        \n",
    "        f_dec_X = self.decoder(f_enc_X)\n",
    "#         print(\"f_dec_X outputted.\")\n",
    "\n",
    "        f_enc_X = f_enc_X.view(input.size(0), -1)\n",
    "        f_dec_X = f_dec_X.view(input.size(0), -1)\n",
    "        return f_enc_X, f_dec_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONE_SIDED(nn.Module):\n",
    "    \"\"\"\n",
    "    rank hinge loss\n",
    "    one_side_errD = one_sided(f_enc_X_D.mean(0) - f_enc_Y_D.mean(0))\n",
    "        always 0!\n",
    "    one_side_errG = one_sided(f_enc_X.mean(0) - f_enc_Y.mean(0))\n",
    "        always 0!\n",
    "    \n",
    "    torch.mean(input, dim, keepdim=False, out=None) â†’ Tensor\n",
    "        Returns the mean value of each row of the input tensor \n",
    "        in the given dimension dim\n",
    "        0 = dim -> rows\n",
    "        \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ONE_SIDED, self).__init__()\n",
    "\n",
    "        main = nn.ReLU()\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(-input)\n",
    "        output = -output.mean()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if args.experiment is None:\n",
    "#     args.experiment = 'samples'\n",
    "# os.system('mkdir {0}'.format(args.experiment))\n",
    "\n",
    "if model_save_folder is None:\n",
    "    model_save_folder = 'samples'\n",
    "os.system('mkdir {0}'.format(model_save_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "#     args.cuda = True\n",
    "    cuda = True\n",
    "#     torch.cuda.set_device(args.gpu_device)\n",
    "    torch.cuda.set_device(gpu_device)\n",
    "    print(\"Using GPU device\", torch.cuda.current_device())\n",
    "else:\n",
    "    raise EnvironmentError(\"GPU device not available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(seed=args.manual_seed)\n",
    "# random.seed(args.manual_seed)\n",
    "# torch.manual_seed(args.manual_seed)\n",
    "# torch.cuda.manual_seed(args.manual_seed)\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "np.random.seed(seed=manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed(manual_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cngf = 8\n",
      "tisize = 4\n",
      "cngf = 256\n",
      "tisize = 128\n",
      "csize = 64.0\n",
      "cndf = 16\n",
      "cngf = 8\n",
      "tisize = 4\n",
      "cngf = 256\n",
      "tisize = 128\n"
     ]
    }
   ],
   "source": [
    "# construct encoder/decoder modules\n",
    "\n",
    "\"\"\"\n",
    "ngf = \n",
    "ndf = \n",
    "\n",
    "\"\"\"\n",
    "hidden_dim = nz\n",
    "G_decoder = Decoder(cube_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "D_encoder = Encoder(cube_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ndf=16)\n",
    "D_decoder = Decoder(cube_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ngf=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netD: NetD(\n",
      "  (encoder): Encoder(\n",
      "    (main): Sequential(\n",
      "      (initial_conv_1-16): Conv3d(1, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (initial_relu_16): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_16-32_conv): Conv3d(16, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_32_batchnorm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_32_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_32-64_conv): Conv3d(32, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_64_batchnorm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_64_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_64-128_conv): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_128_batchnorm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_128_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_128-256_conv): Conv3d(128, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_256_batchnorm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_256_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (final_256-1_conv): Conv3d(256, 2048, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (fc_main): Sequential(\n",
      "      (first_decoder_FC): Linear(in_features=2048, out_features=4096, bias=False)\n",
      "      (second_decoder_FC): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc_main): Sequential(\n",
      "      (first_decoder_FC): Linear(in_features=2048, out_features=4096, bias=False)\n",
      "      (second_decoder_FC): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "    )\n",
      "    (main): Sequential(\n",
      "      (initial_2048-256_convt): ConvTranspose3d(2048, 256, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
      "      (initial_256_batchnorm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_256_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_256-128_convt): ConvTranspose3d(256, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_128_batchnorm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_128_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_128-64_convt): ConvTranspose3d(128, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_64_batchnorm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_64_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_64-32_convt): ConvTranspose3d(64, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_32_batchnorm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_32_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_32-16_convt): ConvTranspose3d(32, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_16_batchnorm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_16_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (final_16-1_convt): ConvTranspose3d(16, 1, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (final_1_relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = NetD(D_encoder, D_decoder)\n",
    "print(\"netD:\", netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netG: NetG(\n",
      "  (decoder): Decoder(\n",
      "    (fc_main): Sequential(\n",
      "      (first_decoder_FC): Linear(in_features=2048, out_features=4096, bias=False)\n",
      "      (second_decoder_FC): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "    )\n",
      "    (main): Sequential(\n",
      "      (initial_2048-256_convt): ConvTranspose3d(2048, 256, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
      "      (initial_256_batchnorm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_256_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_256-128_convt): ConvTranspose3d(256, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_128_batchnorm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_128_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_128-64_convt): ConvTranspose3d(128, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_64_batchnorm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_64_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_64-32_convt): ConvTranspose3d(64, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_32_batchnorm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_32_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_32-16_convt): ConvTranspose3d(32, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_16_batchnorm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_16_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (final_16-1_convt): ConvTranspose3d(16, 1, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (final_1_relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = NetG(G_decoder)\n",
    "print(\"netG:\", netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " oneSide: ONE_SIDED(\n",
      "  (main): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "one_sided = ONE_SIDED()\n",
    "print(\"\\n \\n oneSide:\", one_sided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ONE_SIDED(\n",
       "  (main): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "one_sided.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put variable into cuda device\n",
    "fixed_noise = torch.cuda.FloatTensor(64, nz, 1, 1).normal_(0, 1)\n",
    "one = torch.tensor(1.0).cuda()\n",
    "#one = torch.cuda.FloatTensor([1])\n",
    "mone = one * -1\n",
    "if cuda:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    one_sided.cuda()\n",
    "fixed_noise = Variable(fixed_noise, \n",
    "                       requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_choice == \"rmsprop\":\n",
    "#     setup optimizer\n",
    "    optimizerG = torch.optim.RMSprop(netG.parameters(), \n",
    "                                     lr=lr)\n",
    "    optimizerD = torch.optim.RMSprop(netD.parameters(), \n",
    "                                     lr=lr)\n",
    "elif optimizer_choice == \"adam\":\n",
    "    # Why not try adam?\n",
    "    optimizerG = torch.optim.Adam(netG.parameters(), \n",
    "                                     lr=lr)\n",
    "    optimizerD = torch.optim.Adam(netD.parameters(), \n",
    "                                     lr=lr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 2673234.024434277\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch = 1 / 150\n",
      "----------------------------------------------- \n",
      "\n",
      "len(trn_loader) = 128\n",
      "Optimize over NetD\n",
      "gen_iterations = 0\n",
      "j / Diter = 1 / 100\n",
      "23.493532180786133\n",
      "max(x[0]) = [0.03327959]\n",
      "max(y[0]) = [0.995662]\n",
      "min(x[0]) = [0.]\n",
      "min(y[0]) = [0.]\n",
      "len(real_plot) - nonzero elements = 1100811\n",
      "len(recon_plot) - nonzero elements = 1171562\n",
      "max(real_plot) = 0.033279594\n",
      "max(recon_plot) = 0.995662\n",
      "min(real_plot) = 1.0785178e-18\n",
      "min(recon_plot) = 1.1920929e-07\n",
      "real_ae_cube max = 0.6300882, min = 0.0\n",
      "noise_ae_cube max = 0.94204885, min = 0.0\n",
      "noise_gen_cube max = 1.0268998, min = 0.0\n",
      "real_cube max = 0.25173032, min = 0.0\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 6.061087020334573\n",
      "s max = 18.90264630317688\n",
      "s min = 4.333447962999344\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Noise-Input Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 8.963782825488718\n",
      "s max = 28.261465430259705\n",
      "s min = 6.411337852478027\n",
      "\n",
      "Noise-Input Generated Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 11.082706656806115\n",
      "s max = 30.806994438171387\n",
      "s min = 8.443863093852997\n",
      "\n",
      "Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.3149413078678593\n",
      "s max = 7.551909685134888\n",
      "s min = 0.014854099717922509\n",
      "j / Diter = 2 / 100\n",
      "12.01629626750946\n",
      "j / Diter = 3 / 100\n",
      "8.29537526766459\n",
      "j / Diter = 4 / 100\n",
      "6.436480283737183\n",
      "j / Diter = 5 / 100\n",
      "5.319028997421265\n",
      "j / Diter = 6 / 100\n",
      "4.631300052007039\n",
      "j / Diter = 7 / 100\n",
      "4.473994255065918\n",
      "j / Diter = 8 / 100\n",
      "4.2729988396167755\n",
      "j / Diter = 9 / 100\n",
      "3.967646016014947\n",
      "j / Diter = 10 / 100\n",
      "3.779212403297424\n",
      "j / Diter = 11 / 100\n",
      "3.5998009768399326\n",
      "j / Diter = 12 / 100\n",
      "3.4037996927897134\n",
      "j / Diter = 13 / 100\n",
      "3.369060516357422\n",
      "j / Diter = 14 / 100\n",
      "3.187360950878688\n",
      "j / Diter = 15 / 100\n",
      "3.1408368587493896\n",
      "j / Diter = 16 / 100\n",
      "2.99783593416214\n",
      "j / Diter = 17 / 100\n",
      "2.939778818803675\n",
      "j / Diter = 18 / 100\n",
      "2.8232678837246366\n",
      "j / Diter = 19 / 100\n",
      "2.8239838324095072\n",
      "j / Diter = 20 / 100\n",
      "2.726820242404938\n",
      "j / Diter = 21 / 100\n",
      "2.6927082992735363\n",
      "j / Diter = 22 / 100\n",
      "2.6102514158595693\n",
      "j / Diter = 23 / 100\n",
      "2.5853267130644424\n",
      "j / Diter = 24 / 100\n",
      "2.515843798716863\n",
      "j / Diter = 25 / 100\n",
      "2.4966455459594727\n",
      "j / Diter = 26 / 100\n",
      "2.433622827896705\n",
      "j / Diter = 27 / 100\n",
      "2.4226058853997126\n",
      "j / Diter = 28 / 100\n",
      "2.366042103086199\n",
      "j / Diter = 29 / 100\n",
      "2.356255087359198\n",
      "j / Diter = 30 / 100\n",
      "2.3073010206222535\n",
      "j / Diter = 31 / 100\n",
      "2.2974961573077786\n",
      "j / Diter = 32 / 100\n",
      "2.252782665193081\n",
      "j / Diter = 33 / 100\n",
      "2.2490467952959463\n",
      "j / Diter = 34 / 100\n",
      "2.208718447124257\n",
      "j / Diter = 35 / 100\n",
      "2.2036798885890416\n",
      "j / Diter = 36 / 100\n",
      "2.1658609641922846\n",
      "j / Diter = 37 / 100\n",
      "2.162152625418998\n",
      "j / Diter = 38 / 100\n",
      "2.127900525143272\n",
      "j / Diter = 39 / 100\n",
      "2.125511652384049\n",
      "j / Diter = 40 / 100\n",
      "2.09308779835701\n",
      "j / Diter = 41 / 100\n",
      "2.0928782602635825\n",
      "j / Diter = 42 / 100\n",
      "2.0637251479285106\n",
      "j / Diter = 43 / 100\n",
      "2.062651589859364\n",
      "j / Diter = 44 / 100\n",
      "2.0344426252625207\n",
      "j / Diter = 45 / 100\n",
      "2.0331214904785155\n",
      "j / Diter = 46 / 100\n",
      "2.0069019949954487\n",
      "j / Diter = 47 / 100\n",
      "2.005526912973282\n",
      "j / Diter = 48 / 100\n",
      "1.982072616616885\n",
      "j / Diter = 49 / 100\n",
      "1.9842728206089564\n",
      "j / Diter = 50 / 100\n",
      "1.9617347383499146\n",
      "j / Diter = 51 / 100\n",
      "1.9638535041435092\n",
      "j / Diter = 52 / 100\n",
      "1.9430592747835012\n",
      "j / Diter = 53 / 100\n",
      "1.9440925886046212\n",
      "j / Diter = 54 / 100\n",
      "1.9241234240708527\n",
      "j / Diter = 55 / 100\n",
      "1.9255544359033758\n",
      "j / Diter = 56 / 100\n",
      "1.9065988787582941\n",
      "j / Diter = 57 / 100\n",
      "1.9075002712115907\n",
      "j / Diter = 58 / 100\n",
      "1.8895641770856133\n",
      "j / Diter = 59 / 100\n",
      "1.8915069992259397\n",
      "j / Diter = 60 / 100\n",
      "1.8743337631225585\n",
      "j / Diter = 61 / 100\n",
      "1.87800931930542\n",
      "j / Diter = 62 / 100\n",
      "1.8617985748475598\n",
      "j / Diter = 63 / 100\n",
      "1.8643264581286718\n",
      "j / Diter = 64 / 100\n",
      "1.8486155234277248\n",
      "j / Diter = 65 / 100\n",
      "1.8518653319432186\n",
      "j / Diter = 66 / 100\n",
      "1.8369489799846301\n",
      "j / Diter = 67 / 100\n",
      "1.8401390474234054\n",
      "j / Diter = 68 / 100\n",
      "1.826881016001982\n",
      "j / Diter = 69 / 100\n",
      "1.8282096627829731\n",
      "j / Diter = 70 / 100\n",
      "1.81498601096017\n",
      "j / Diter = 71 / 100\n",
      "1.8191968387281392\n",
      "j / Diter = 72 / 100\n",
      "1.8055885235468547\n",
      "j / Diter = 73 / 100\n",
      "1.8086957278316969\n",
      "j / Diter = 74 / 100\n",
      "1.7957072386870514\n",
      "j / Diter = 75 / 100\n",
      "1.798479684193929\n",
      "j / Diter = 76 / 100\n",
      "1.785965389326999\n",
      "j / Diter = 77 / 100\n",
      "1.789156489558034\n",
      "j / Diter = 78 / 100\n",
      "1.7781406121376233\n",
      "j / Diter = 79 / 100\n",
      "1.7814219058314456\n",
      "j / Diter = 80 / 100\n",
      "1.7710495620965958\n",
      "j / Diter = 81 / 100\n",
      "1.7731522483590207\n",
      "j / Diter = 82 / 100\n",
      "1.7633687025163232\n",
      "j / Diter = 83 / 100\n",
      "1.76451953347907\n",
      "j / Diter = 84 / 100\n",
      "1.7559069309915816\n",
      "j / Diter = 85 / 100\n",
      "1.7568447898415958\n",
      "j / Diter = 86 / 100\n",
      "1.748600679774617\n",
      "j / Diter = 87 / 100\n",
      "1.7490661473109805\n",
      "j / Diter = 88 / 100\n",
      "1.7418783848935908\n",
      "j / Diter = 89 / 100\n",
      "1.741898617047942\n",
      "j / Diter = 90 / 100\n",
      "1.7349904696146647\n",
      "j / Diter = 91 / 100\n",
      "1.7350045927278288\n",
      "j / Diter = 92 / 100\n",
      "1.7281392994134321\n",
      "j / Diter = 93 / 100\n",
      "1.7285819053649902\n",
      "j / Diter = 94 / 100\n",
      "1.72172756144341\n",
      "j / Diter = 95 / 100\n",
      "1.7218996675390945\n",
      "j / Diter = 96 / 100\n",
      "1.7155589237809181\n",
      "j / Diter = 97 / 100\n",
      "1.7159834276769579\n",
      "j / Diter = 98 / 100\n",
      "1.7093983353400717\n",
      "j / Diter = 99 / 100\n",
      "1.7103601561652289\n",
      "j / Diter = 100 / 100\n",
      "1.7035492610931398\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 100\n",
      "len(trn_loader) = 128\n",
      "j / Giter = 1 / 1\n",
      "errG = tensor(3.1591, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "run_time = 3.910955590972056\n",
      "[  0/150][101/128] [    1] (3.91 m) MMD2_D 9.979161 hinge -0.000000 L2_AE_X 0.000906 L2_AE_Y 0.062994 loss_D 2.647778 Loss_G 3.159127 f_X 0.070893 f_Y -1.094725 |gD| 0.6246 |gG| 0.1730\n",
      "Optimize over NetD\n",
      "gen_iterations = 1\n",
      "j / Diter = 1 / 100\n",
      "1.6939175128936768\n",
      "j / Diter = 2 / 100\n",
      "1.6857033687479355\n",
      "j / Diter = 3 / 100\n",
      "1.6777888038783397\n",
      "j / Diter = 4 / 100\n",
      "1.6800212562084198\n",
      "j / Diter = 5 / 100\n",
      "1.6730434962681362\n",
      "j / Diter = 6 / 100\n",
      "1.6752605415740103\n",
      "j / Diter = 7 / 100\n",
      "1.6684561310527481\n",
      "j / Diter = 8 / 100\n",
      "1.6707006714962147\n",
      "j / Diter = 9 / 100\n",
      "1.664151578868201\n",
      "j / Diter = 10 / 100\n",
      "1.6660276087847623\n",
      "j / Diter = 11 / 100\n",
      "1.6597620281013283\n",
      "j / Diter = 12 / 100\n",
      "1.661992875593049\n",
      "j / Diter = 13 / 100\n",
      "1.6559440330066513\n",
      "j / Diter = 14 / 100\n",
      "1.6578531620795267\n",
      "j / Diter = 15 / 100\n",
      "1.6525057606075122\n",
      "j / Diter = 16 / 100\n",
      "1.6545661564530998\n",
      "j / Diter = 17 / 100\n",
      "1.6484956048492692\n",
      "j / Diter = 18 / 100\n",
      "1.6505650605185558\n",
      "j / Diter = 19 / 100\n",
      "1.6448116843439953\n",
      "j / Diter = 20 / 100\n",
      "1.6467513899008432\n",
      "j / Diter = 21 / 100\n",
      "1.640783467568642\n",
      "j / Diter = 22 / 100\n",
      "1.6429249654050733\n",
      "j / Diter = 23 / 100\n",
      "1.6375025171574538\n",
      "j / Diter = 24 / 100\n",
      "1.6386757646837542\n",
      "j / Diter = 25 / 100\n",
      "1.6330671882629395\n",
      "j / Diter = 26 / 100\n",
      "1.6329709726666648\n",
      "j / Diter = 27 / 100\n",
      "1.6253805930220235\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 128\n",
      "len(trn_loader) = 128\n",
      "Breaking from the Generator training loop\n",
      "run_time = 4.526642144533495\n",
      "[  0/150][128/128] [    1] (4.53 m) MMD2_D 9.988073 hinge -0.000000 L2_AE_X 0.000569 L2_AE_Y 0.061694 loss_D 2.662287 Loss_G 3.159127 f_X 0.082450 f_Y -1.100179 |gD| 0.3648 |gG| 0.1730\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch = 2 / 150\n",
      "----------------------------------------------- \n",
      "\n",
      "len(trn_loader) = 128\n",
      "Optimize over NetD\n",
      "gen_iterations = 1\n",
      "j / Diter = 1 / 100\n",
      "1.637376507744193\n",
      "max(x[0]) = [0.00499112]\n",
      "max(y[0]) = [0.99678314]\n",
      "min(x[0]) = [0.]\n",
      "min(y[0]) = [0.]\n",
      "len(real_plot) - nonzero elements = 928395\n",
      "len(recon_plot) - nonzero elements = 1182088\n",
      "max(real_plot) = 0.0049911235\n",
      "max(recon_plot) = 0.99678314\n",
      "min(real_plot) = 1.7724131e-20\n",
      "min(recon_plot) = 6.891787e-08\n",
      "real_ae_cube max = 0.86986655, min = 0.0\n",
      "noise_ae_cube max = 0.556911, min = 0.0\n",
      "noise_gen_cube max = 1.0713885, min = 0.0\n",
      "real_cube max = 0.33808798, min = 0.0\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 1.8158354778639918\n",
      "s max = 26.095996499061584\n",
      "s min = 0.47254180535674095\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Noise-Input Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 6.327510753203524\n",
      "s max = 16.707329750061035\n",
      "s min = 4.478238523006439\n",
      "\n",
      "Noise-Input Generated Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 10.866072782056138\n",
      "s max = 32.14165449142456\n",
      "s min = 8.301277756690979\n",
      "\n",
      "Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.4149222450407204\n",
      "s max = 10.14263927936554\n",
      "s min = 0.027267949772067368\n",
      "j / Diter = 2 / 100\n",
      "1.6292552042377086\n",
      "j / Diter = 3 / 100\n",
      "1.6232522139182457\n",
      "j / Diter = 4 / 100\n",
      "1.6174301518738725\n",
      "j / Diter = 5 / 100\n",
      "1.6117296128562002\n",
      "j / Diter = 6 / 100\n",
      "1.60615955438829\n",
      "j / Diter = 7 / 100\n",
      "1.600636348795535\n",
      "j / Diter = 8 / 100\n",
      "1.6045442333927862\n",
      "j / Diter = 9 / 100\n",
      "1.5990588174146765\n",
      "j / Diter = 10 / 100\n",
      "1.602471438637615\n",
      "j / Diter = 11 / 100\n",
      "1.597089802009472\n",
      "j / Diter = 12 / 100\n",
      "1.6005852719862683\n",
      "j / Diter = 13 / 100\n",
      "1.5953051107270377\n",
      "j / Diter = 14 / 100\n",
      "1.5989164359180639\n",
      "j / Diter = 15 / 100\n",
      "1.594186997749436\n",
      "j / Diter = 16 / 100\n",
      "1.597476349010334\n",
      "j / Diter = 17 / 100\n",
      "1.5922685629791684\n",
      "j / Diter = 18 / 100\n",
      "1.595658458512405\n",
      "j / Diter = 19 / 100\n",
      "1.5906058811161616\n",
      "j / Diter = 20 / 100\n",
      "1.5940180651995601\n",
      "j / Diter = 21 / 100\n",
      "1.5895371082666758\n",
      "j / Diter = 22 / 100\n",
      "1.5922447371002812\n",
      "j / Diter = 23 / 100\n",
      "1.5879476722081503\n",
      "j / Diter = 24 / 100\n",
      "1.5913304240498323\n",
      "j / Diter = 25 / 100\n",
      "1.5868242681026459\n",
      "j / Diter = 26 / 100\n",
      "1.5896191191829108\n",
      "j / Diter = 27 / 100\n",
      "1.5853120336284885\n",
      "j / Diter = 28 / 100\n",
      "1.587875643084126\n",
      "j / Diter = 29 / 100\n",
      "1.5832373759685419\n",
      "j / Diter = 30 / 100\n",
      "1.5861798380590548\n",
      "j / Diter = 31 / 100\n",
      "1.5817352186275433\n",
      "j / Diter = 32 / 100\n"
     ]
    }
   ],
   "source": [
    "time_loop = timeit.default_timer()\n",
    "print(\"time = \" + str(time_loop))\n",
    "\n",
    "gen_iterations = 0  # the code default is = 0\n",
    "\n",
    "# lists for tracking - Discriminator side\n",
    "mmd2_D_before_ReLU_list = []\n",
    "mmd2_D_after_ReLU_list = []\n",
    "one_side_errD_list = []\n",
    "L2_AE_X_D_list = []\n",
    "L2_AE_Y_D_list = []\n",
    "errD_list = []\n",
    "\n",
    "# lists for tracking - Generator side\n",
    "mmd2_G_before_ReLU_list = []\n",
    "mmd2_G_after_ReLU_list = []\n",
    "one_side_errG_list = []\n",
    "errG_list = []\n",
    "# errG = torch.Tensor(np.array(0.0))\n",
    "# print(errG.item())\n",
    "\n",
    "# lists for tracking count of nonzero voxels\n",
    "log_nonzero_recon_over_real_list = []\n",
    "\n",
    "# list for tracking gradient norms for generator and discriminator\n",
    "grad_norm_D = []\n",
    "grad_norm_G = []\n",
    "\n",
    "\n",
    "for t in range(max_iter):\n",
    "    print(\"\\n-----------------------------------------------\")\n",
    "    print(\"Epoch = \" + str(t+1) + \" / \" + str(max_iter))\n",
    "    print(\"----------------------------------------------- \\n\")\n",
    "    \n",
    "    data_iter = iter(trn_loader)\n",
    "    print(\"len(trn_loader) = \" + str(len(trn_loader)))\n",
    "    i = 0\n",
    "    plotted = 0\n",
    "    plotted_2 = 0\n",
    "    plotted_3 = 0\n",
    "    plotted_4 = 0   # grad norm plotting controller\n",
    "    \n",
    "    while (i < len(trn_loader)):\n",
    "        \n",
    "        # ---------------------------\n",
    "        #        Optimize over NetD\n",
    "        # ---------------------------\n",
    "        print(\"Optimize over NetD\")\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        What does the below if-else do?\n",
    "        Trains the discriminator for a lot more when the training\n",
    "        is starting, then switches to a more frequent generator\n",
    "        training regime.\n",
    "        \"\"\"\n",
    "        print(\"gen_iterations = \" + str(gen_iterations))\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "#         if gen_iterations < 5 or gen_iterations % 500 == 0:\n",
    "            Diters = 100\n",
    "            Giters = 1\n",
    "        else:\n",
    "            Diters = 5\n",
    "            Giters = 1\n",
    "\n",
    "        for j in range(Diters):\n",
    "            if i == len(trn_loader):\n",
    "                break\n",
    "\n",
    "            time_1 = time.time()\n",
    "            print(\"j / Diter = \" + str(j+1) + \" / \" + str(Diters))\n",
    "            # clamp parameters of NetD encoder to a cube\n",
    "            # do not clamp parameters of NetD decoder!!!\n",
    "            # exactly like numpy.clip()\n",
    "            \"\"\"\n",
    "            Given an interval, values outside the interval are clipped to the interval edges. \n",
    "            For example, if an interval of [0, 1] is specified, values smaller than 0 become 0, \n",
    "            and values larger than 1 become 1.\n",
    "            \n",
    "            Below code clamps the encoder parameters of the \n",
    "            dsicriminator between -0.01 and 0.01\n",
    "            \"\"\"\n",
    "            for p in netD.encoder.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            data = data_iter.next()\n",
    "#             print(\"data shape = \" + str(data.shape))\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            netD.zero_grad()\n",
    "\n",
    "#             x_cpu, _ = data\n",
    "            x_cpu = data\n",
    "            x = Variable(x_cpu.cuda().float())\n",
    "            batch_size = x.size(0)\n",
    "#             print(\"batch_size = \" + str(batch_size))\n",
    "\n",
    "            # output of the discriminator with real data input\n",
    "            \"\"\"\n",
    "            2097152^(1/3) = 128 (= one side of our cube so the\n",
    "            reconstructed cube is the same size as the original one)\n",
    "            This one just acts like an autoencoder\n",
    "            \"\"\"\n",
    "            f_enc_X_D, f_dec_X_D = netD(x)\n",
    "#             print(\"netD(x) outputs:\")\n",
    "#             print(\"f_enc_X_D size = \" + str(f_enc_X_D.size()))\n",
    "#             print(\"f_dec_X_D size = \" + str(f_dec_X_D.size()))\n",
    "#             print(\"f_dec_X_D min = \" + str(f_dec_X_D.min().item()))\n",
    "#             print(\"f_dec_X_D max = \" + str(f_dec_X_D.max().item()))\n",
    "#             print(\"f_dec_X_D mean = \" + str(f_dec_X_D.mean().item()))\n",
    "            \n",
    "\n",
    "            noise = torch.cuda.FloatTensor(batch_size, \n",
    "                                            nz).normal_(0, 1)\n",
    "            with torch.no_grad():\n",
    "                #noise = Variable(noise, volatile=True)  # total freeze netG\n",
    "                noise = Variable(noise)\n",
    "#             print(\"noise shape = \" + str(noise.shape))\n",
    "\n",
    "            # output of the generator with noise input\n",
    "#             y = Variable(netG(noise).data)\n",
    "            y = Variable(netG(noise))\n",
    "#             print(\"y shape = \" + str(y.shape))\n",
    "#             print(\"y[0] shape = \" + str(y[0].shape))\n",
    "#             print(\"y[0][0] shape = \" + str(y[0][0].shape))\n",
    "#             sample_cube_viz = y[0][0].cpu().detach().numpy()\n",
    "#             print(\"sample_cube_viz shape = \" + str(sample_cube_viz.shape))\n",
    "        \n",
    "\n",
    "\n",
    "            # output of the discriminator with noise input\n",
    "            # this tests discriminator \n",
    "            f_enc_Y_D, f_dec_Y_D = netD(y)\n",
    "#             print(\"netD(y) outputs:\")\n",
    "#             print(\"f_enc_Y_D size = \" + str(f_enc_Y_D.size()))\n",
    "#             print(\"f_dec_Y_D size = \" + str(f_dec_Y_D.size()))\n",
    "#             print(\"f_dec_Y_D min = \" + str(f_dec_Y_D.min().item()))\n",
    "#             print(\"f_dec_Y_D max = \" + str(f_dec_Y_D.max().item()))\n",
    "#             print(\"f_dec_Y_D mean = \" + str(f_dec_Y_D.mean().item()))\n",
    "\n",
    "            # compute biased MMD2 and use ReLU to prevent negative value\n",
    "            mmd2_D = mix_rbf_mmd2(f_enc_X_D, \n",
    "                                  f_enc_Y_D, \n",
    "                                  sigma_list)\n",
    "#             mmd2_D = poly_mmd2(f_enc_X_D, f_enc_Y_D)\n",
    "#             mmd2_D = linear_mmd2(f_enc_X_D, f_enc_Y_D)\n",
    "            \n",
    "#             print(\"mmd2_D before ReLU = \" + str(mmd2_D.item()))\n",
    "            mmd2_D_before_ReLU_list.append(mmd2_D.item())\n",
    "            mmd2_D = F.relu(mmd2_D)\n",
    "#             print(\"mmd2_D after ReLU = \" + str(mmd2_D.item()))\n",
    "            mmd2_D_after_ReLU_list.append(mmd2_D.item())\n",
    "\n",
    "            # compute rank hinge loss\n",
    "            #print('f_enc_X_D:', f_enc_X_D.size())\n",
    "            #print('f_enc_Y_D:', f_enc_Y_D.size())\n",
    "            one_side_errD = one_sided(f_enc_X_D.mean(0) - f_enc_Y_D.mean(0))\n",
    "#             print(\"one_side_errD = \" + str(one_side_errD.item()))\n",
    "            one_side_errD_list.append(one_side_errD.item())\n",
    "            \n",
    "            # compute L2-loss of AE\n",
    "            \"\"\"\n",
    "            These L2 losses are decreasing like a standard optimization\n",
    "            which means that the autoencoder is learning how to encode\n",
    "            and decode using 3D convolutions.\n",
    "            x = real cube (x batch_size)\n",
    "            y = cube generated by the Generator with noise input\n",
    "            f_dec_X_D = AE reconstructed real cube\n",
    "            f_dec_Y_D = AE reconstructed noise-input cube\n",
    "            \"\"\"\n",
    "            L2_AE_X_D = match(x.view(batch_size, -1), f_dec_X_D, dist_ae)\n",
    "            L2_AE_Y_D = match(y.view(batch_size, -1), f_dec_Y_D, dist_ae)\n",
    "            \n",
    "#             print(\"L2-loss of AE, L2_AE_X_D = \" + str(L2_AE_X_D.item()))\n",
    "#             print(\"L2-loss of AE, L2_AE_Y_D = \" + str(L2_AE_Y_D.item()))\n",
    "            L2_AE_X_D_list.append(L2_AE_X_D.item())\n",
    "            L2_AE_Y_D_list.append(L2_AE_Y_D.item())\n",
    "            \n",
    "\n",
    "\n",
    "#             print(\"lambda_rg = \" + str(lambda_rg))\n",
    "            errD = torch.sqrt(mmd2_D) + lambda_rg * one_side_errD - lambda_AE_X * L2_AE_X_D - lambda_AE_Y * L2_AE_Y_D\n",
    "#             print(\"errD shape = \" + str(errD.shape))\n",
    "#             print(\"errD = \" + str(errD.item()))\n",
    "            errD_list.append(errD.item())\n",
    "            errD.backward(mone)\n",
    "            optimizerD.step()\n",
    "            \n",
    "            time_2 = time.time()  \n",
    "            time_2 = time_2 - time_1\n",
    "            time_2_list.append(time_2)\n",
    "            print(np.mean(np.array(time_2_list)))\n",
    "            \n",
    "            \n",
    "            # Plotting Discriminator Plots\n",
    "            if j % 5 == 0 and plotted < 1:\n",
    "                try:\n",
    "                    plt.figure(1, figsize = (10,5))\n",
    "                    plt.title(\"mmd2_D_before_ReLU_list\")\n",
    "                    plt.plot(mmd2_D_before_ReLU_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'mmd2_D_before_ReLU_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "#                     plt.show() \n",
    "                    plt.figure(2, figsize = (10,5))\n",
    "                    plt.title(\"mmd2_D_after_ReLU_list\")\n",
    "                    plt.plot(mmd2_D_after_ReLU_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'mmd2_D_after_ReLU_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(3, figsize = (10,5))\n",
    "                    plt.title(\"one_side_errD_list\")\n",
    "                    plt.plot(one_side_errD_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'one_side_errD_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(4, figsize = (10,5))\n",
    "                    plt.title(\"L2_AE_X_D_list\")\n",
    "                    plt.plot(L2_AE_X_D_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'L2_AE_X_D_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(5, figsize = (10,5))\n",
    "                    plt.title(\"L2_AE_Y_D_list\")\n",
    "                    plt.plot(L2_AE_Y_D_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'L2_AE_Y_D_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(6, figsize = (10,5))\n",
    "                    plt.title(\"errD_list - D loss goes to 0: failure mode\")\n",
    "                    plt.plot(errD_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'errD_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "\n",
    "                    # plot output of the discriminator with real data input\n",
    "                    # and output of the discriminator with noise input\n",
    "                    # on the same histogram \n",
    "                    recon_plot = y[0].cpu().view(-1,1).detach().numpy()\n",
    "                    real_plot = x[0].cpu().view(-1,1).detach().numpy()\n",
    "                    print(\"max(x[0]) = \" + str(max(real_plot)))\n",
    "                    print(\"max(y[0]) = \" + str(max(recon_plot)))\n",
    "                    print(\"min(x[0]) = \" + str(min(real_plot)))\n",
    "                    print(\"min(y[0]) = \" + str(min(recon_plot)))\n",
    "                    recon_plot = recon_plot[np.nonzero(recon_plot)]\n",
    "    #                 recon_plot = recon_plot[np.greater(recon_plot, 0)]\n",
    "                    real_plot = real_plot[np.nonzero(real_plot)]\n",
    "    #                 print(\"max(x[0] - nonzero) = \" + str(max(real_plot)))\n",
    "    #                 print(\"max(y[0] - nonzero) = \" + str(max(recon_plot)))\n",
    "    #                 print(\"min(x[0] - nonzero) = \" + str(min(real_plot)))\n",
    "    #                 print(\"min(y[0] - nonzero) = \" + str(min(recon_plot)))\n",
    "    #                 recon_plot = recon_plot + 1\n",
    "    #                 real_plot = real_plot + 1\n",
    "\n",
    "\n",
    "                    print(\"len(real_plot) - nonzero elements = \" + str(len(real_plot)))\n",
    "                    print(\"len(recon_plot) - nonzero elements = \" + str(len(recon_plot)))\n",
    "    #                 log_nonzero_real_list.append(len(real_plot))\n",
    "    #                 log_nonzero_recon_list.append(len(recon_plot))\n",
    "\n",
    "                    log_nonzero_recon_over_real_list.append(len(recon_plot) / len(real_plot))\n",
    "                    print(\"max(real_plot) = \" + str(max(real_plot)))\n",
    "                    print(\"max(recon_plot) = \" + str(max(recon_plot)))\n",
    "                    print(\"min(real_plot) = \" + str(min(real_plot)))\n",
    "                    print(\"min(recon_plot) = \" + str(min(recon_plot)))\n",
    "                    \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"Histograms of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\")\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\")\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'hist_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "                    \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"PDFs of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'pdf_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "\n",
    "#                     plt.figure(figsize = (16,8))\n",
    "#                     plt.title(\"Nonzero in Reconstructed Subcubes / Nonzero in Real Subcubes\")\n",
    "#                     plt.ylim(-0.0001, 10)\n",
    "#                     plt.plot(log_nonzero_recon_over_real_list, \n",
    "#                              color = \"blue\", \n",
    "#                              label = \"Nonzero in Reconstructed Subcubes / Nonzero in Real Subcubes\")\n",
    "#                     plt.show()  \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    Plotting the log histograms & PDF\n",
    "                    \"\"\"\n",
    "                    recon_plot = np.log(recon_plot)\n",
    "                    real_plot = np.log(real_plot)\n",
    "        \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"Histograms of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\")\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\")\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'hist_log_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "                    \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"PDFs of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'pdf_log_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                plotted = plotted + 1\n",
    "                \n",
    "                \n",
    "                \n",
    "            if plotted_2 < 1:\n",
    "                \n",
    "                # selecting a random cube from the batch\n",
    "                random_batch = random.randint(0,batch_size-1)\n",
    "                real_ae_cube = f_dec_X_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "                noise_ae_cube = f_dec_Y_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "                noise_gen_cube = y[random_batch][0].cpu().detach().numpy()\n",
    "                real_cube = x[random_batch][0].cpu().detach().numpy()\n",
    "                \n",
    "                # transforming the inputs for visualization\n",
    "                # to [0,1] interval for better plotting\n",
    "                # using the whole cube's min and max!!!\n",
    "                # not the subcube's!!!\n",
    "                real_ae_cube = (real_ae_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                noise_ae_cube = (noise_ae_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                noise_gen_cube = (noise_gen_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                real_cube = (real_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                \n",
    "                print(\"real_ae_cube max = \" + str(real_ae_cube.max()) + \", min = \" + str(real_ae_cube.min()))\n",
    "                print(\"noise_ae_cube max = \" + str(noise_ae_cube.max()) + \", min = \" + str(noise_ae_cube.min()))\n",
    "                print(\"noise_gen_cube max = \" + str(noise_gen_cube.max()) + \", min = \" + str(noise_gen_cube.min()))\n",
    "                print(\"real_cube max = \" + str(real_cube.max()) + \", min = \" + str(real_cube.min()))\n",
    "\n",
    "                print(\"\\nReconstructed, AutoEncoder Generated Real Cube\")\n",
    "#                 recon_real_viz = \n",
    "                visualize_cube(cube=real_ae_cube,      ## array name\n",
    "                                         edge_dim=real_ae_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder + 'recon_ae_real_' + str(t) + '.png')\n",
    "                \n",
    "                print(\"\\nReconstructed, AutoEncoder Generated Noise-Input Cube\")\n",
    "#                 recon_fake_viz = \n",
    "                visualize_cube(cube=noise_ae_cube,      ## array name\n",
    "                                         edge_dim=noise_ae_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder + 'recon_ae_noisegen_' + str(t) + '.png')\n",
    "                \n",
    "                print(\"\\nNoise-Input Generated Cube\")\n",
    "#                 sample_viz = \n",
    "                visualize_cube(cube=noise_gen_cube,      ## array name\n",
    "                                         edge_dim=noise_gen_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder + 'noisegen_' + str(t) + '.png')\n",
    "                \n",
    "                print(\"\\nReal Cube\")\n",
    "#                 real_viz = \n",
    "                visualize_cube(cube=real_cube,      ## array name\n",
    "                                         edge_dim=real_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder +'real_' + str(t) + '.png')\n",
    "\n",
    "#             sample_viz.show()\n",
    "\n",
    "                plotted_2 = plotted_2 + 1 # to limit one 3d plotting per epoch\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "        print(\"\\n Finished optimizing over NetD \\n\")\n",
    "\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Optimize over NetG\n",
    "        # ---------------------------\n",
    "        \"\"\"\n",
    "        Because i is increased in each training loop for the\n",
    "        discriminitor, the below condition of if i == len(trn_loader)\n",
    "        is True in every epoch.\n",
    "        Should an i = 0 be added to the beginning of the netG optimization?\n",
    "        Look at paper to see how the training method is.\n",
    "        \"\"\"\n",
    "        print(\"Optimize over NetG\")\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        print(\"Giters = \" + str(Giters))\n",
    "        for j in range(Giters):\n",
    "            print(\"i = \" + str(i))\n",
    "            print(\"len(trn_loader) = \" + str(len(trn_loader)))\n",
    "            if i == len(trn_loader):\n",
    "                print(\"Breaking from the Generator training loop\")\n",
    "                break\n",
    "\n",
    "            print(\"j / Giter = \" + str(j+1) + \" / \" + str(Giters))\n",
    "            data = data_iter.next()\n",
    "            i += 1\n",
    "            netG.zero_grad()\n",
    "\n",
    "#             x_cpu, _ = data\n",
    "            x_cpu = data\n",
    "            x = Variable(x_cpu.cuda().float())\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            # output of discriminator with real input\n",
    "            f_enc_X, f_dec_X = netD(x)\n",
    "\n",
    "            noise = torch.cuda.FloatTensor(batch_size, \n",
    "                                           nz).normal_(0, 1)\n",
    "            noise = Variable(noise)\n",
    "            \n",
    "            # output of the generator with noise input\n",
    "            y = netG(noise)\n",
    "\n",
    "            # output of the discriminator with noise input\n",
    "            f_enc_Y, f_dec_Y = netD(y)\n",
    "\n",
    "            # compute biased MMD2 and use ReLU to prevent negative value\n",
    "            mmd2_G = mix_rbf_mmd2(f_enc_X, f_enc_Y, sigma_list)\n",
    "#             mmd2_G = poly_mmd2(f_enc_X, f_enc_Y)\n",
    "#             mmd2_G = linear_mmd2(f_enc_X, f_enc_Y)\n",
    "    \n",
    "            mmd2_G_before_ReLU_list.append(mmd2_G)\n",
    "            mmd2_G = F.relu(mmd2_G)\n",
    "            mmd2_G_after_ReLU_list.append(mmd2_G)\n",
    "\n",
    "            # compute rank hinge loss\n",
    "            one_side_errG = one_sided(f_enc_X.mean(0) - f_enc_Y.mean(0))\n",
    "            one_side_errG_list.append(one_side_errG)\n",
    "\n",
    "            errG = torch.sqrt(mmd2_G) + lambda_rg * one_side_errG\n",
    "            print(\"errG = \" + str(errG))\n",
    "#             print(\"one = \") + str(one)\n",
    "            errG_list.append(errG.item())\n",
    "            errG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "            \n",
    "            if plotted_3 < 1:\n",
    "                # plotting Generator plots\n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"mmd2_G_before_ReLU_list\")\n",
    "                plt.plot(mmd2_G_before_ReLU_list)\n",
    "                plt.savefig(redshift_fig_folder + 'mmd2_G_before_ReLU_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                    #                 plt.show() \n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"mmd2_G_after_ReLU_list\")\n",
    "                plt.plot(mmd2_G_after_ReLU_list)\n",
    "                plt.savefig(redshift_fig_folder + 'mmd2_G_after_ReLU_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                #                 plt.show() \n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"one_side_errG_list\")\n",
    "                plt.plot(one_side_errG_list)\n",
    "                plt.savefig(redshift_fig_folder + 'one_side_errG_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                #                 plt.show() \n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"errG_list\")\n",
    "                plt.plot(errG_list)\n",
    "                plt.savefig(redshift_fig_folder + 'errG_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                #                 plt.show()            \n",
    "            \n",
    "                plotted_3 = plotted_3 + 1\n",
    "\n",
    "        run_time = (timeit.default_timer() - time_loop) / 60.0\n",
    "        print(\"run_time = \" + str(run_time))\n",
    "        try:\n",
    "            print('[%3d/%3d][%3d/%3d] [%5d] (%.2f m) MMD2_D %.6f hinge %.6f L2_AE_X %.6f L2_AE_Y %.6f loss_D %.6f Loss_G %.6f f_X %.6f f_Y %.6f |gD| %.4f |gG| %.4f'\n",
    "    #                   % (t, max_iter, i, len(trn_loader), gen_iterations, run_time,\n",
    "    #                      mmd2_D.data[0], one_side_errD.data[0],\n",
    "    #                      L2_AE_X_D.data[0], L2_AE_Y_D.data[0],\n",
    "    #                      errD.data[0], errG.data[0],\n",
    "    #                      f_enc_X_D.mean().data[0], f_enc_Y_D.mean().data[0],\n",
    "    #                      grad_norm(netD), grad_norm(netG)))\n",
    "                % (t, max_iter, i, len(trn_loader), gen_iterations, run_time,\n",
    "                     mmd2_D.item(), one_side_errD.item(),\n",
    "                     L2_AE_X_D.item(), L2_AE_Y_D.item(),\n",
    "                     errD.item(), errG.item(),\n",
    "                     f_enc_X_D.mean().item(), f_enc_Y_D.mean().item(),\n",
    "                     grad_norm(netD), grad_norm(netG)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "#         if gen_iterations % 500 == 0:\n",
    "#             y_fixed = netG(fixed_noise)\n",
    "#             y_fixed.data = y_fixed.data.mul(0.5).add(0.5)\n",
    "#             f_dec_X_D = f_dec_X_D.view(f_dec_X_D.size(0), args.nc, args.image_size, args.image_size)\n",
    "#             f_dec_X_D.data = f_dec_X_D.data.mul(0.5).add(0.5)\n",
    "#             vutils.save_image(y_fixed.data, '{0}/fake_samples_{1}.png'.format(args.experiment, gen_iterations))\n",
    "#             vutils.save_image(f_dec_X_D.data, '{0}/decode_samples_{1}.png'.format(args.experiment, gen_iterations))\n",
    "\n",
    "        # plotting gradient norms for monitoring\n",
    "        grad_norm_D.append(grad_norm(netD))\n",
    "        grad_norm_G.append(grad_norm(netG))\n",
    "        \n",
    "        if plotted_4 < 1:\n",
    "            plt.figure(figsize = (10,5))\n",
    "            plt.title(\"grad_norms - if they are over 100 things are screwing up\")\n",
    "            plt.plot(grad_norm_D, \n",
    "                     color = \"red\", \n",
    "                     label = \"grad_norm_D\")\n",
    "            plt.plot(grad_norm_G, \n",
    "                     color = \"blue\", \n",
    "                     label = \"grad_norm_G\")\n",
    "            plt.legend()\n",
    "            plt.savefig(redshift_fig_folder + 'grad_norms_' + str(t) + '.png', \n",
    "                        bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            #             plt.show()\n",
    "            \n",
    "            plotted_4 = plotted_4 + 1\n",
    "\n",
    "\n",
    "    if t % save_model_every == 0:\n",
    "        torch.save(netG.state_dict(), \n",
    "                   '{0}/netG_iter_{1}.pth'.format(model_save_folder, t))\n",
    "        torch.save(netD.state_dict(), \n",
    "                   '{0}/netD_iter_{1}.pth'.format(model_save_folder, t))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_testing == False:\n",
    "    assert(False, \"Stopping here, because not in testing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The folder models were saved in: \" + str(experiment))\n",
    "model_files = [f for f in listdir(experiment) if isfile(join(experiment, f))]\n",
    "model_files\n",
    "\n",
    "netG_files = [f for f in model_files if \"netG\" in f]\n",
    "netG_files\n",
    "\n",
    "max_iter_netG = max(netG_files, key=lambda x: int(x[10:-4]))\n",
    "max_iter_netG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = nz\n",
    "G_decoder = Decoder(cube_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "\n",
    "netG_test = NetG(G_decoder)\n",
    "# print(\"netG:\", netG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_test.load_state_dict(torch.load(experiment + max_iter_netG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netG_test.eval()\n",
    "netG_test.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Cube with Trained Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.cuda.FloatTensor(1, \n",
    "                                nz, \n",
    "                                1, \n",
    "                                1,\n",
    "                                1).normal_(0, 1)\n",
    "noise.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = Variable(noise)\n",
    "\n",
    "    # output of the generator with noise input\n",
    "    y = netG_test(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_batch = random.randint(0,batch_size-1)\n",
    "noise_gen_cube = y[0][0].cpu().detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noise-Input Generated Cube\")\n",
    "#                 sample_viz = \n",
    "visualize_cube(cube=noise_gen_cube,      ## array name\n",
    "                         edge_dim=noise_gen_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                         start_cube_index_x=0,\n",
    "                         start_cube_index_y=0,\n",
    "                         start_cube_index_z=0,\n",
    "                         fig_size=(10,10),\n",
    "                         stdev_to_white=-2,\n",
    "                         norm_multiply=viz_multiplier,\n",
    "                         color_map=\"Blues\",\n",
    "                         plot_show = True,\n",
    "                         save_fig = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file = testing_folder + \"noise_gen_cube\",\n",
    "    arr = noise_gen_cube,\n",
    "    allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a real subcube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcd = define_test(s_test = 1024,\n",
    "                     s_train = 128)\n",
    "print(testcd)\n",
    "\n",
    "trial_sample = get_samples(s_sample = 128, \n",
    "                            nsamples = 1, \n",
    "#                             h5_filename = redshift_file, \n",
    "                            test_coords = testcd,\n",
    "                            f = f)\n",
    "trial_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Sampled Cube\")\n",
    "#                 sample_viz = \n",
    "visualize_cube(cube=trial_sample[0],      ## array name\n",
    "                         edge_dim=trial_sample[0].shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                         start_cube_index_x=0,\n",
    "                         start_cube_index_y=0,\n",
    "                         start_cube_index_z=0,\n",
    "                         fig_size=(10,10),\n",
    "                         stdev_to_white=-2,\n",
    "                         norm_multiply=viz_multiplier,\n",
    "                         color_map=\"Blues\",\n",
    "                         plot_show = True,\n",
    "                         save_fig = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file = testing_folder + \"real_cube\",\n",
    "    arr = trial_sample[0],\n",
    "    allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Generated vs. Real with Power Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pyfftw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd seda_pylians/Pylians\n",
    "# import Pk_library as PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
