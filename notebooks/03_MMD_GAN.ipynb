{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/OctoberChang/MMD-GAN - accompanying the paper MMD-GAN: Towards Deeper Understanding of Moment Matching Network.\n",
    "\n",
    "To check GPU usage, open new terminal inside Jupyter and nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import h5py\n",
    "import timeit\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle as pkl\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import colors\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "batch_size = 16       # BATCH_SIZE: batch size for training\n",
    "workers = 2          # WORKERS: number of threads to load data\n",
    "\n",
    "experiment = \"./mmd_gan/model/\"       # : output directory of saved models\n",
    "save_model_every = 10               # (every x epoch) frequency to save the model\n",
    "\n",
    "redshift_info_folder = \"./mmd_gan/redshift_info/\"   # save some info here as pickle to speed up processing\n",
    "redshift_file = \"minmax_scale_01_redshift0.h5\"    # redshift cube to be used\n",
    "root_dir = \"\"                                     # should be \"\" fo prince\n",
    "redshift_fig_folder = \"./mmd_gan/figures/\"        # folder to save mmd & related plots\n",
    "redshift_3dfig_folder = \"./mmd_gan/3d_figures/\"   # folder to save 3D plots\n",
    "testing_folder = \"./mmd_gan/testing/\"   # folder to save 3D plots\n",
    "\n",
    "\n",
    "gpu_device = 0        # GPU_DEVICE: gpu id (default 0)\n",
    "nc = 1                # NC: number of channels in images\n",
    "nz = 128                # NZ: hidden dimension in z and codespace\n",
    "cube_size = 128       # IMAGE_SIZE: image size of dataset - \n",
    "                        # for our dataset more like one edge of the subcube\n",
    "lr = 5e-7               # LR: learning rate (default 5e-5)\n",
    "max_iter = 150         # MAX_ITER: max iteration for training\n",
    "\n",
    "optimizer_choice = \"rmsprop\"     # adam or rmsprop\n",
    "dist_ae = 'L1'                  # \"L2\" or \"L1\" or \"cos\" -> Autoencoder reconstructruced cube loss choice\n",
    "manual_seed = 1126\n",
    "n_samples = batch_size * 128      # on prince, number of samples to get from the training cube\n",
    "in_testing = False              # True if doing testing\n",
    "\n",
    "viz_multiplier = 5e1    # the norm multiplier in the 3D visualization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n_samples / batch_size > 100, \"The gen_iterations wont work properly!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size = 16\n",
      "Redshift File Used = minmax_scale_01_redshift0.h5\n",
      "Number of Channels in Input = 1\n",
      "Hidden Dimension (codespace) = 128\n",
      "Length of Edge of a Sampled Subcube = 128\n",
      "Learning Rate = 5e-07\n",
      "Number of Epochs = 150\n",
      "Optimizer = rmsprop\n",
      "Autoencoder Reconstruction Loss  = L1\n",
      "Seed = 1126\n",
      "Number of Samples = 2048\n",
      "Visualization Multiplier = 50.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch Size = \" + str(batch_size))\n",
    "print(\"Redshift File Used = \" + str(redshift_file))\n",
    "print(\"Number of Channels in Input = \" + str(nc))\n",
    "print(\"Hidden Dimension (codespace) = \" + str(nz))\n",
    "print(\"Length of Edge of a Sampled Subcube = \" + str(cube_size))\n",
    "print(\"Learning Rate = \" + str(lr))\n",
    "print(\"Number of Epochs = \" + str(max_iter))\n",
    "print(\"Optimizer = \" + str(optimizer_choice))\n",
    "print(\"Autoencoder Reconstruction Loss  = \" + str(dist_ae))\n",
    "print(\"Seed = \" + str(manual_seed))\n",
    "print(\"Number of Samples = \" + str(n_samples))\n",
    "print(\"Visualization Multiplier = \" + str(viz_multiplier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_sample = 128\n",
    "edge_test = 1024\n",
    "\n",
    "print(\"one edge of the test partition of the whole cube = \" + str(edge_test))\n",
    "print(\"one edge of the sampled subcubes =  \" + str(edge_sample))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MMD Parameters\n",
    "\n",
    "errD = torch.sqrt(mmd2_D) + lambda_rg * one_side_errD \n",
    "       - lambda_AE_X * L2_AE_X_D - lambda_AE_Y * L2_AE_Y_D\n",
    "       \n",
    "errG = torch.sqrt(mmd2_G) + lambda_rg * one_side_errG\n",
    "\n",
    "The explanations can be found in Ratio Matching MMD Nets (2018) in \n",
    "Equation 3.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "lambda_MMD = 1.0   # not used anywhere\n",
    "lambda_AE_X = 8.0  # used in above calc only \n",
    "lambda_AE_Y = 8.0  # used in above calc only\n",
    "lambda_rg = 16.0   # used in both err calcs\n",
    "\n",
    "print(\"lambda_MMD = \" + str(lambda_MMD))\n",
    "print(\"lambda_AE_X = \" + str(lambda_AE_X))\n",
    "print(\"lambda_AE_Y = \" + str(lambda_AE_Y))\n",
    "print(\"lambda_rg = \" + str(lambda_rg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sigma for MMD\n",
    "\"\"\"\n",
    "base = 1.0\n",
    "sigma_list = [1, 2, 4, 8, 16]\n",
    "sigma_list = [sigma / base for sigma in sigma_list]\n",
    "print(\"sigma_list = \" + str(sigma_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax_scale_01_redshift0.h5\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(root_dir + redshift_file, 'r')\n",
    "print(f.filename)\n",
    "f = f['delta_HI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Info Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create redshift info folder if it doesn't exist\n",
    "if Path(redshift_info_folder).exists() == False:\n",
    "    os.mkdir(redshift_info_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_cube(f):\n",
    "    max_list = [np.max(f[i:i+1,:,:]) for i in range(f.shape[0])]\n",
    "    max_cube = max(max_list)\n",
    "    return max_cube\n",
    "\n",
    "def get_min_cube(f):\n",
    "    min_list = [np.min(f[i:i+1,:,:]) for i in range(f.shape[0])]\n",
    "    min_cube = min(min_list)\n",
    "    return min_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if redshift info (min & max exists) as pickle\n",
    "# if not saved, find the max and min and save them for later use\n",
    "min_cube_file = Path(redshift_info_folder + redshift_file + \"_min_cube\" + \".npy\")\n",
    "max_cube_file = Path(redshift_info_folder + redshift_file + \"_max_cube\" + \".npy\")\n",
    "\n",
    "\n",
    "if not min_cube_file.exists() or not max_cube_file.exists():\n",
    "    \n",
    "    f = h5py.File(root_dir + redshift_file, 'r')\n",
    "    f=f['delta_HI']\n",
    "    \n",
    "    # get the min and max\n",
    "    min_cube = get_min_cube(f=f)\n",
    "    print(min_cube)\n",
    "    max_cube = get_max_cube(f=f)\n",
    "    print(max_cube)\n",
    "    \n",
    "    np.save(file = redshift_info_folder + redshift_file + \"_min_cube\",\n",
    "        arr = min_cube,\n",
    "        allow_pickle = True)\n",
    "    np.save(file = redshift_info_folder + redshift_file + \"_max_cube\",\n",
    "        arr = max_cube,\n",
    "        allow_pickle = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of data = 0.0\n",
      "Max of data = 1.0\n"
     ]
    }
   ],
   "source": [
    "min_cube = np.load(file = redshift_info_folder + redshift_file + \"_min_cube\" + '.npy')\n",
    "max_cube = np.load(file = redshift_info_folder + redshift_file + \"_max_cube\" + '.npy')\n",
    "print(\"Min of data = \" + str(min_cube))\n",
    "print(\"Max of data = \" + str(max_cube))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figures folder if it doesn't exist\n",
    "if Path(redshift_fig_folder).exists() == False:\n",
    "    os.mkdir(redshift_fig_folder)\n",
    "if Path(redshift_3dfig_folder).exists() == False:\n",
    "    os.mkdir(redshift_3dfig_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    \"\"\"Function for dividing/truncating cmaps\"\"\"\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "def visualize_cube(cube=None,      # array name\n",
    "             edge_dim=None,        # edge dimension (128 for 128 x 128 x 128 cube)\n",
    "             start_cube_index_x=0,\n",
    "             start_cube_index_y=0,\n",
    "             start_cube_index_z=0,\n",
    "             fig_size=None,\n",
    "             stdev_to_white=1,\n",
    "             norm_multiply=viz_multiplier,\n",
    "             color_map=\"Blues\",\n",
    "             plot_show = False,\n",
    "             save_fig = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    The inputs should be in the interval [0,1]\n",
    "    All the transformations on the input\n",
    "    should be done before passing\n",
    "    into the function.\n",
    "    \"\"\"\n",
    "        \n",
    "    cube_size = edge_dim\n",
    "    edge = np.array([*range(cube_size)])\n",
    "    \n",
    "    end_x = start_cube_index_x + cube_size\n",
    "    end_y = start_cube_index_y + cube_size\n",
    "    end_z = start_cube_index_z + cube_size\n",
    "    \n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    data_value = cube[start_cube_index_x:end_x,\n",
    "                      start_cube_index_y:end_y,\n",
    "                      start_cube_index_z:end_z]\n",
    "    \n",
    "    x,y,z = edge,edge,edge\n",
    "    product = [*itertools.product(x,y,z)]\n",
    "    \n",
    "    X = np.array([product[k][0] for k in [*range(len(product))]])\n",
    "    Y = np.array([product[k][1] for k in [*range(len(product))]])\n",
    "    Z = np.array([product[k][2] for k in [*range(len(product))]])\n",
    "    \n",
    "    ## map data to 1d array that corresponds to the axis values in the product array\n",
    "    data_1dim = np.array([data_value[X[i]][Y[i]][Z[i]] for i in [*range(len(product))]])\n",
    "    \n",
    "    \n",
    "    initial_mean = np.mean(data_1dim) - stdev_to_white*np.std(data_1dim)\n",
    "    mask = data_1dim > initial_mean\n",
    "    mask = mask.astype(np.int)\n",
    "    \n",
    "    data_1dim = np.multiply(mask,data_1dim)\n",
    "    ## mask X,Y,Z to match the dimensions of the data\n",
    "    X, Y, Z, data_1dim = [axis[np.where(data_1dim>0)] for axis in [X,Y,Z,data_1dim]]\n",
    "\n",
    "    \n",
    "    \n",
    "#     if lognormal == False:\n",
    "    \"\"\"\n",
    "    norm_multiply = function argument\n",
    "    data_1dim = data in one dimension, flattened\n",
    "    nn.linalg.norm = return one of eight different matrix norms\n",
    "\n",
    "    The nn.linalg.norm should not be used due to the fact \n",
    "    that each subcube has different norms. Use the maximum of\n",
    "    the whole cube and mitigate with norm_multiply if \n",
    "    no points are seen in the 3D plot.\n",
    "    \"\"\"\n",
    "        \n",
    "#         s = norm_multiply*data_1dim/np.linalg.norm(data_1dim)\n",
    "    s = norm_multiply * data_1dim\n",
    "\n",
    "    # adding this for [-1,1] scaled input\n",
    "    # so that s is between [0,1]\n",
    "#         s = (s + 1.0) / 2.0 \n",
    "    \n",
    "#     else:\n",
    "#         s = np.log(norm_multiply*data_1dim/np.linalg.norm(data_1dim))\n",
    "    try:\n",
    "        # checking min, max , mean of s\n",
    "        print(\"Plotting s (= norm_multiply * data_1dim) stats:\")\n",
    "        print(\"s mean = \" + str(s.mean()))\n",
    "        print(\"s max = \" + str(s.max()))\n",
    "        print(\"s min = \" + str(s.min()))\n",
    "\n",
    "\n",
    "        cmap=plt.get_cmap(color_map)\n",
    "        new_cmap = truncate_colormap(cmap, 0.99, 1,n=10)\n",
    "\n",
    "        ## IGNORE BELOW 3D PLOT FORMATTING \n",
    "\n",
    "        ## plot cube\n",
    "\n",
    "        cube_definition = [(start_cube_index_x, start_cube_index_x, start_cube_index_x),\n",
    "                          (start_cube_index_x, start_cube_index_x+edge_dim, start_cube_index_x),\n",
    "                          (start_cube_index_x + edge_dim, start_cube_index_x, start_cube_index_x),\n",
    "                          (start_cube_index_x, start_cube_index_x, start_cube_index_x+edge_dim)]\n",
    "\n",
    "        cube_definition_array = [\n",
    "            np.array(list(item))\n",
    "            for item in cube_definition\n",
    "        ]\n",
    "\n",
    "        points = []\n",
    "        points += cube_definition_array\n",
    "        vectors = [\n",
    "            cube_definition_array[1] - cube_definition_array[0],\n",
    "            cube_definition_array[2] - cube_definition_array[0],\n",
    "            cube_definition_array[3] - cube_definition_array[0]\n",
    "        ]\n",
    "\n",
    "\n",
    "        points += [cube_definition_array[0] + vectors[0] + vectors[1]]\n",
    "        points += [cube_definition_array[0] + vectors[0] + vectors[2]]\n",
    "        points += [cube_definition_array[0] + vectors[1] + vectors[2]]\n",
    "        points += [cube_definition_array[0] + vectors[0] + vectors[1] + vectors[2]]\n",
    "\n",
    "        points = np.array(points)\n",
    "\n",
    "        edges = [\n",
    "            [points[0], points[3], points[5], points[1]],\n",
    "            [points[1], points[5], points[7], points[4]],\n",
    "            [points[4], points[2], points[6], points[7]],\n",
    "            [points[2], points[6], points[3], points[0]],\n",
    "            [points[0], points[2], points[4], points[1]],\n",
    "            [points[3], points[6], points[7], points[5]]\n",
    "        ]\n",
    "\n",
    "    #     ax.fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        faces = Poly3DCollection(edges, linewidths=1, edgecolors='k',)\n",
    "        faces.set_facecolor((0,0,1,0)) ## set transparent facecolor to the cube\n",
    "\n",
    "        ax.add_collection3d(faces)\n",
    "\n",
    "        ax.scatter(points[:,0], points[:,1], points[:,2], s=0)\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        ax.xaxis.pane.fill = False\n",
    "        ax.yaxis.pane.fill = False\n",
    "        ax.zaxis.pane.fill = False\n",
    "\n",
    "        ax.xaxis.pane.set_edgecolor('w')\n",
    "        ax.yaxis.pane.set_edgecolor('w')\n",
    "        ax.zaxis.pane.set_edgecolor('w')\n",
    "\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(edge_dim))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(edge_dim))\n",
    "        ax.zaxis.set_major_locator(MultipleLocator(edge_dim))\n",
    "\n",
    "        ax.grid(False)\n",
    "\n",
    "        ax.set_xlim3d(0,edge_dim)\n",
    "        ax.set_ylim3d(0,edge_dim)\n",
    "        ax.set_zlim3d(0,edge_dim)\n",
    "    #     ax.get_frame_on()\n",
    "\n",
    "        ax.xaxis._axinfo['tick']['inward_factor'] = 0\n",
    "        ax.xaxis._axinfo['tick']['outward_factor'] = 0\n",
    "        ax.yaxis._axinfo['tick']['inward_factor'] = 0\n",
    "        ax.yaxis._axinfo['tick']['outward_factor'] = 0\n",
    "        ax.zaxis._axinfo['tick']['inward_factor'] = 0\n",
    "        ax.zaxis._axinfo['tick']['outward_factor'] = 0\n",
    "\n",
    "        ax.scatter(X, Y, Z,       ## axis vals\n",
    "                   c=data_1dim,   ## data, mapped to 1-dim\n",
    "                   cmap=new_cmap,\n",
    "                   s=s,           ## sizes - dims multiplied by each data point's magnitude\n",
    "                   alpha=0.7,\n",
    "                   edgecolors=\"face\")\n",
    "\n",
    "        if plot_show:\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        if save_fig:\n",
    "            fig.savefig(save_fig,bbox_inches='tight')\n",
    "\n",
    "        plt.close(fig)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_test(s_test, s_train):\n",
    "    \"\"\"\n",
    "    s_test = one edge of the test partition of the whole cube\n",
    "    s_train = one edge of the sampled subcubes\n",
    "    \"\"\"\n",
    "    #2048/16=128\n",
    "    m = 8\n",
    "    x = random.randint(0,m) * s_train\n",
    "    y = random.randint(0,m) * s_train\n",
    "    z = random.randint(0,m) * s_train\n",
    "    #print(x,y,z)\n",
    "    return {'x':[x,x + s_test], 'y':[y,y + s_test], 'z':[z,z + s_test]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coords(test_coords, train_coords):\n",
    "    valid=True\n",
    "    for i in ['x','y','z']:\n",
    "        r=(max(test_coords[i][0], \n",
    "               train_coords[i][0]), \n",
    "           min(test_coords[i][1],\n",
    "               train_coords[i][1]))\n",
    "        if r[0]<=r[1]:\n",
    "            valid=False\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_2_list = []\n",
    "time_3_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(s_sample, \n",
    "                nsamples, \n",
    "#                 h5_filename,  \n",
    "                test_coords,\n",
    "                f):   # given as f[\"delta_HI\"]\n",
    "    #n is size of minibatch, get valid samples (not intersecting with test_coords)\n",
    "    sample_list=[]\n",
    "    m = 2048 - 128\n",
    "    \n",
    "    \n",
    "    for n in range(nsamples):\n",
    "        #print(\"Sample No = \" + str(n + 1) + \" / \" + str(nsamples))\n",
    "        sample_valid = False\n",
    "        while sample_valid == False:\n",
    "            x = random.randint(0,m)\n",
    "            y = random.randint(0,m)\n",
    "            z = random.randint(0,m)\n",
    "            sample_coords = {'x':[x,x+s_sample], \n",
    "                             'y':[y,y+s_sample], \n",
    "                             'z':[z,z+s_sample]}\n",
    "            \n",
    "            sample_valid = check_coords(test_coords, \n",
    "                                        sample_coords)\n",
    "        \n",
    "        sample_list.append(sample_coords)\n",
    "    \n",
    "#     print(\"Sampling subcube edges finished.\")\n",
    "        \n",
    "    #Load cube and get samples and convert them to np.arrays\n",
    "    sample_array=[]\n",
    "    \n",
    "\n",
    "#     time_1 = time.time()\n",
    "#     f = h5py.File(h5_filename, 'r') \n",
    "#     f=f_deltaHI\n",
    "    \n",
    "    counter = 0\n",
    "    for c in sample_list:\n",
    "#         print(\"Counter = \" + str(counter + 1) + \" / \" + str(len(sample_list)))\n",
    "        a = f[c['x'][0]:c['x'][1],\n",
    "              c['y'][0]:c['y'][1],\n",
    "              c['z'][0]:c['z'][1]]\n",
    "#         time_2 = time.time()\n",
    "        \n",
    "        a = np.array(a)\n",
    "        \n",
    "    \n",
    "        sample_array.append(a)\n",
    "    \n",
    "        counter = counter + 1\n",
    "    \n",
    "#     time_3 = time.time() - time_2\n",
    "#     time_2 = time_2 - time_1\n",
    "    \n",
    "#     print(\"time_2 = \" + str(time_2))\n",
    "#     print(\"time_3 = \" + str(time_3))\n",
    "#     time_2_list.append(time_2)\n",
    "#     time_3_list.append(time_3)\n",
    "#     print_count = random.randint(a=0,b=40)\n",
    "#     if print_count % 40 == 0:\n",
    "#         print(\"time_2 mean = \" + str(np.mean(np.array(time_2_list))))\n",
    "#         print(\"time_3 mean = \" + str(np.mean(np.array(time_3_list))))\n",
    "\n",
    "        \n",
    "#     f = 0\n",
    "    return sample_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [128, 1152], 'y': [640, 1664], 'z': [512, 1536]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcd = define_test(s_test = edge_test, s_train = edge_sample)\n",
    "testcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[3.20450298e-11, 4.67032281e-11, 2.72145978e-12, ...,\n",
       "          1.06594032e-10, 9.70450803e-11, 9.54710894e-11],\n",
       "         [1.99082157e-12, 1.58703935e-11, 4.03069158e-12, ...,\n",
       "          8.99718980e-11, 1.13415617e-10, 6.14033199e-11],\n",
       "         [1.65710397e-11, 4.67020519e-11, 3.83790638e-11, ...,\n",
       "          1.12921138e-10, 8.60633231e-11, 6.55772103e-11],\n",
       "         ...,\n",
       "         [1.58625836e-12, 1.02740811e-11, 5.16342307e-12, ...,\n",
       "          9.26015428e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.40510815e-11, 1.41158352e-11, 3.08180348e-12, ...,\n",
       "          2.46716666e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.60694285e-12, 2.24549806e-11, 4.90242612e-12, ...,\n",
       "          1.47826317e-11, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[5.70977883e-11, 5.78067802e-12, 7.97979911e-12, ...,\n",
       "          9.76613165e-11, 8.50037402e-11, 8.77765916e-11],\n",
       "         [2.91991396e-11, 1.23353576e-11, 2.01584151e-13, ...,\n",
       "          6.92149532e-11, 9.38182310e-11, 5.78484344e-11],\n",
       "         [3.75963601e-11, 2.84454179e-11, 4.51776776e-11, ...,\n",
       "          9.60797761e-11, 7.10049866e-11, 8.46378453e-11],\n",
       "         ...,\n",
       "         [1.13684062e-12, 1.26786255e-11, 6.27581190e-12, ...,\n",
       "          1.12013903e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.00701374e-11, 5.39243606e-12, 1.18642487e-12, ...,\n",
       "          9.65382115e-12, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.54821451e-11, 2.27187470e-11, 1.96914663e-12, ...,\n",
       "          4.77602550e-12, 1.08060548e-11, 2.80452376e-12]],\n",
       " \n",
       "        [[2.11484719e-11, 1.68232615e-11, 5.90015146e-12, ...,\n",
       "          8.42063225e-11, 1.11409090e-10, 9.33003536e-11],\n",
       "         [6.15193868e-11, 2.45985801e-11, 4.94289332e-12, ...,\n",
       "          7.29220850e-11, 5.93202154e-11, 3.99245394e-11],\n",
       "         [1.06477388e-11, 3.40652680e-12, 5.39393617e-12, ...,\n",
       "          4.42262858e-11, 1.07344550e-10, 5.35919677e-11],\n",
       "         ...,\n",
       "         [1.82922115e-11, 2.78352601e-11, 1.18988023e-11, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.64032728e-11, 1.01623386e-12, 6.87093991e-13, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.97462618e-12, 6.24512811e-12, 3.91775067e-12, ...,\n",
       "          2.71103973e-11, 4.73852554e-12, 3.85957894e-13]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[6.16936432e-11, 7.50296075e-11, 8.61649224e-11, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.83689192e-11, 3.58556310e-11, 1.27026334e-10, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [6.67487871e-11, 7.78268491e-11, 1.20407309e-10, ...,\n",
       "          6.77238051e-13, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.89218557e-10, 1.25371769e-10, 1.32017147e-10],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.69245742e-10, 1.82289156e-10, 1.31672118e-10],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.36600239e-10, 2.97203678e-10, 1.06855365e-10]],\n",
       " \n",
       "        [[8.66930694e-11, 1.49855767e-10, 9.17408927e-11, ...,\n",
       "          0.00000000e+00, 3.57609276e-12, 7.27403858e-12],\n",
       "         [1.02789340e-10, 1.27840016e-10, 1.23584087e-10, ...,\n",
       "          0.00000000e+00, 2.95369117e-13, 6.00802665e-13],\n",
       "         [1.32746258e-10, 1.85444840e-10, 2.67822098e-10, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.01616293e-10, 1.51975058e-10, 9.41626846e-11],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.31046321e-10, 1.12316302e-10, 1.93530955e-10],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.17511231e-10, 1.50691529e-10, 1.81470464e-10]],\n",
       " \n",
       "        [[1.00584222e-10, 1.26275587e-10, 1.19084104e-10, ...,\n",
       "          0.00000000e+00, 8.70192546e-12, 1.77003620e-11],\n",
       "         [1.13324884e-10, 3.43661599e-10, 2.06855921e-10, ...,\n",
       "          0.00000000e+00, 7.18739792e-13, 1.46196987e-12],\n",
       "         [2.23783908e-10, 4.82224538e-10, 5.33029121e-10, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.14284562e-10, 1.82555832e-10, 3.94553765e-11],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.01259787e-10, 1.19133897e-10, 1.04579553e-10],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.42683040e-10, 2.07449918e-10, 1.91329633e-10]]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_sample = get_samples(s_sample = edge_sample, \n",
    "                            nsamples = 1, \n",
    "#                             h5_filename = redshift_file, \n",
    "                            test_coords = testcd,\n",
    "                            f = f)\n",
    "trial_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097152,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_sample[0].reshape(-1,).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_plot = trial_sample[0].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [-1,1] -> [0,1] for plotting\n",
    "# trial_plot = (trial_plot + 1.0) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_plot.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0960252434015274"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_plot.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0026892851354763"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_plot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b33ca231358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "plt.title(\"Trial Sample\")\n",
    "plt.xlim((trial_plot.min(),\n",
    "         trial_plot.max()))\n",
    "bins = np.linspace(trial_plot.min(),\n",
    "                   trial_plot.max(), \n",
    "                   100)\n",
    "plt.hist(trial_plot, bins = bins, \n",
    "         color = \"blue\" ,\n",
    "         alpha = 0.3, \n",
    "         label = \"Trial\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n",
      "edge dim = 128\n",
      "(128, 128, 128)\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 25.128456268312977\n",
      "s max = 27.400631085038185\n",
      "s min = 25.005631530075334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b33ca5267f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial_visual = trial_sample[0]\n",
    "print(trial_visual.shape)\n",
    "trial_visual_edge = trial_visual.shape[0]\n",
    "print(\"edge dim = \" + str(trial_visual_edge))\n",
    "\n",
    "# from [-1,1] to [0,1]\n",
    "trial_visual = (trial_visual + 1.0) / 2.0\n",
    "print(trial_visual.shape)\n",
    "\n",
    "visualize_cube(cube=trial_visual,      ## array name\n",
    "             edge_dim=trial_visual_edge,        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "             start_cube_index_x=0,\n",
    "             start_cube_index_y=0,\n",
    "             start_cube_index_z=0,\n",
    "             fig_size=(10,10),\n",
    "             stdev_to_white=-2,\n",
    "             norm_multiply=viz_multiplier,\n",
    "             color_map=\"Blues\",\n",
    "             plot_show = True,\n",
    "             save_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Duplicates in Sampled Subcubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [640, 1664], 'y': [128, 1152], 'z': [0, 1024]}\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_sample = edge_sample \n",
    "nsamples = 10000\n",
    "\n",
    "testcd = define_test(s_test = edge_test,\n",
    "                     s_train = edge_sample)\n",
    "print(testcd)\n",
    "\n",
    "sample_list=[]\n",
    "m = 2048 - 128\n",
    "\n",
    "\n",
    "for n in range(nsamples):\n",
    "    #print(\"Sample No = \" + str(n + 1) + \" / \" + str(nsamples))\n",
    "    sample_valid = False\n",
    "    while sample_valid == False:\n",
    "        x = random.randint(0,m)\n",
    "        y = random.randint(0,m)\n",
    "        z = random.randint(0,m)\n",
    "        sample_coords = {'x':[x,x+s_sample], \n",
    "                         'y':[y,y+s_sample], \n",
    "                         'z':[z,z+s_sample]}\n",
    "\n",
    "        sample_valid = check_coords(testcd, \n",
    "                                    sample_coords)\n",
    "\n",
    "    sample_list.append(sample_coords)\n",
    "\n",
    "print(len(sample_list))\n",
    "# print(len(list(set(sample_list))))\n",
    "sample_df = pd.DataFrame.from_dict(sample_list)\n",
    "dropped_sample_df = sample_df.applymap(lambda x: x[0]).drop_duplicates()\n",
    "\n",
    "sample_df.shape[0] == dropped_sample_df.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydrogenDataset2(Dataset):\n",
    "    \"\"\"Hydrogen Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, h5_file, root_dir, s_test, s_train,\n",
    "                 s_sample, nsamples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h5_file (string): name of the h5 file with 32 sampled cubes.\n",
    "            root_dir (string): Directory with the .h5 file.\n",
    "        \"\"\"\n",
    "        file_size = os.path.getsize(root_dir + h5_file) / 1e6 # in MBs\n",
    "#         print(\"The whole file size is \" + str(int(file_size)) + \" MBs\")\n",
    "        \n",
    "        # self.subcubes = h5py.File('../data/sample_32.h5', 'r')\n",
    "#         self.f = f_deltaHI\n",
    "        self.h5_file = h5_file\n",
    "        self.root_dir = root_dir\n",
    "        self.s_test = s_test\n",
    "        self.s_train = s_train\n",
    "        self.t_coords = define_test(self.s_test,\n",
    "                                    self.s_train)\n",
    "        self.s_sample = s_sample\n",
    "        self.nsamples = nsamples\n",
    "        self.h5_filename = self.root_dir + self.h5_file\n",
    "        \n",
    "#         self.samples = get_samples(s_sample = self.s_sample,\n",
    "#                              nsamples = self.nsamples,\n",
    "#                              h5_filename = self.h5_filename,\n",
    "#                              test_coords = self.t_coords)\n",
    "#         print(\"Got self.samples\")\n",
    "        \n",
    "        self.min_val = min_cube\n",
    "#         print(\"min = \" + str(self.min_val))\n",
    "        self.max_val = max_cube\n",
    "#         print(\"max = \" + str(self.max_val))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Function called when len(self) is executed\n",
    "        \n",
    "        #print(len(self.subcubes))\n",
    "#         return len(self.nsamples)\n",
    "        return self.nsamples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This can be implemented in such a way that the whole h5 file read \n",
    "        using h5py.File() and get_sample() function is called to return\n",
    "        a random subcube. This won't increase memory usage because the\n",
    "        subcubes will be read in the same way and only the batch will\n",
    "        be read into memory.\n",
    "        \n",
    "        Here we have implemented it so that it can be used with data\n",
    "        generated by get_sample() function.\n",
    "        \n",
    "        The output of this function is one subcube with the dimensions\n",
    "        specified by get_sample() implementation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # default version -> error in training because of dimensions\n",
    "#         sample = self.subcubes[idx]\n",
    "        \n",
    "        # reshaped version to add another dimension\n",
    "#         sample = self.subcubes[idx].reshape((1,128,128,128))\n",
    "\n",
    "        # On prince using get_samples()\n",
    "#         print(\"nsamples = \" + str(self.nsamples))\n",
    "        sample = get_samples(s_sample = self.s_sample,\n",
    "                             nsamples = 1,\n",
    "#                              h5_filename = self.h5_filename,\n",
    "                             test_coords = self.t_coords,\n",
    "                            f = f)\n",
    "    \n",
    "#         sample = self.samples[idx].reshape((1,128,128,128))\n",
    "\n",
    "        sample = np.array(sample).reshape((1,self.s_sample,self.s_sample,self.s_sample))\n",
    "        \n",
    "        # added division by 1e6 for exploding variance\n",
    "        # and resulting in inf during reparametrization trick part\n",
    "#         sample = sample/1e6\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on prince\n",
    "sampled_subcubes = HydrogenDataset2(h5_file=redshift_file,\n",
    "                                    root_dir = root_dir,\n",
    "                                    s_test = edge_test, \n",
    "                                    s_train = edge_sample,\n",
    "                                    s_sample = edge_sample, \n",
    "                                    nsamples = n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "trn_loader = torch.utils.data.DataLoader(sampled_subcubes, \n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle=True, \n",
    "                                         num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used at:\n",
    "def _mmd2_and_ratio(K_XX, K_XY, K_YY, \n",
    "                    const_diagonal=False, \n",
    "                    biased=False):\n",
    "    mmd2, var_est = _mmd2_and_variance(K_XX, K_XY, K_YY, \n",
    "                                       const_diagonal=const_diagonal, \n",
    "                                       biased=biased)\n",
    "    loss = mmd2 / torch.sqrt(torch.clamp(var_est, min=min_var_est))\n",
    "    return loss, mmd2, var_est\n",
    "    \n",
    "torch.clamp(input, min, max, out=None)  Tensor\n",
    "    Clamp all elements in input into the range [ min, max ] \n",
    "    and return a resulting tensor\n",
    "\"\"\"\n",
    "\n",
    "# min_var_est = 1e-8\n",
    "min_var_est = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider linear time MMD with a linear kernel:\n",
    "# K(f(x), f(y)) = f(x)^Tf(y)\n",
    "# h(z_i, z_j) = k(x_i, x_j) + k(y_i, y_j) - k(x_i, y_j) - k(x_j, y_i)\n",
    "#             = [f(x_i) - f(y_i)]^T[f(x_j) - f(y_j)]\n",
    "#\n",
    "# f_of_X: batch_size * k\n",
    "# f_of_Y: batch_size * k\n",
    "def linear_mmd2(f_of_X, f_of_Y):\n",
    "    loss = 0.0\n",
    "    delta = f_of_X - f_of_Y\n",
    "    loss = torch.mean((delta[:-1] * delta[1:]).sum(1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider linear time MMD with a polynomial kernel:\n",
    "# K(f(x), f(y)) = (alpha*f(x)^Tf(y) + c)^d\n",
    "# f_of_X: batch_size * k\n",
    "# f_of_Y: batch_size * k\n",
    "def poly_mmd2(f_of_X, f_of_Y, d=2, alpha=1.0, c=2.0):\n",
    "    K_XX = (alpha * (f_of_X[:-1] * f_of_X[1:]).sum(1) + c)\n",
    "    K_XX_mean = torch.mean(K_XX.pow(d))\n",
    "\n",
    "    K_YY = (alpha * (f_of_Y[:-1] * f_of_Y[1:]).sum(1) + c)\n",
    "    K_YY_mean = torch.mean(K_YY.pow(d))\n",
    "\n",
    "    K_XY = (alpha * (f_of_X[:-1] * f_of_Y[1:]).sum(1) + c)\n",
    "    K_XY_mean = torch.mean(K_XY.pow(d))\n",
    "\n",
    "    K_YX = (alpha * (f_of_Y[:-1] * f_of_X[1:]).sum(1) + c)\n",
    "    K_YX_mean = torch.mean(K_YX.pow(d))\n",
    "\n",
    "    return K_XX_mean + K_YY_mean - K_XY_mean - K_YX_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mix_rbf_kernel(X, Y, sigma_list):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X -> f_enc_X_D ->\n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        Y -> f_enc_Y_D -> \n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        sigma_list -> \n",
    "            base = 1.0\n",
    "            sigma_list = [1, 2, 4, 8, 16]\n",
    "            sigma_list = [sigma / base for sigma in sigma_list] \n",
    "            \n",
    "    m = batch_size\n",
    "    torch.cat(seq, dim=0, out=None)  Tensor\n",
    "        Concatenates the given sequence of seq tensors \n",
    "        in the given dimension\n",
    "    Z size = [2 x batch_size, nz]\n",
    "    \n",
    "    torch.mm(mat1, mat2, out=None)  Tensor\n",
    "        Performs a matrix multiplication of the matrices mat1 and mat2\n",
    "    ZZT size = [2 x batch_size, 2 x batch_size]\n",
    "    \n",
    "    torch.diag(input, diagonal=0, out=None)  Tensor\n",
    "        If input is a matrix (2-D tensor), then returns a 1-D tensor \n",
    "        with the diagonal elements of input\n",
    "    torch.unsqueeze(input, dim, out=None)  Tensor\n",
    "        Returns a new tensor with a dimension of size \n",
    "        one inserted at the specified position\n",
    "    diag_ZZT = [2 x batch_size, 1]\n",
    "    \n",
    "    expand_as(other)  Tensor\n",
    "        Expand this tensor to the same size as other\n",
    "    Z_norm_sqr = [2 x batch_size, 2 x batch_size]\n",
    "    \n",
    "    torch.exp(tensor, out=None)  Tensor\n",
    "        Returns a new tensor with the exponential of the elements of input\n",
    "        y_i = e^(x_i)\n",
    "        \n",
    "    exponent size = [2 x batch_size, 2 x batch_size]\n",
    "    K size = [2 x batch_size, 2 x batch_size]\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(X.size(0) == Y.size(0))\n",
    "    m = X.size(0)\n",
    "\n",
    "    Z = torch.cat((X, Y), dim = 0)\n",
    "#     print(\"Z size = \" + str(Z.size()))\n",
    "    \n",
    "    ZZT = torch.mm(Z, Z.t())\n",
    "#     print(\"ZZT size = \" + str(ZZT.size()))\n",
    "    \n",
    "    diag_ZZT = torch.diag(ZZT).unsqueeze(1)\n",
    "#     print(\"diag_ZZT size = \" + str(diag_ZZT.size()))\n",
    "    \n",
    "    Z_norm_sqr = diag_ZZT.expand_as(ZZT)\n",
    "#     print(\"Z_norm_sqr size = \" + str(Z_norm_sqr.size()))\n",
    "    \n",
    "    exponent = Z_norm_sqr - 2 * ZZT + Z_norm_sqr.t()\n",
    "#     print(\"exponent size = \" + str(exponent.size()))\n",
    "#     print(\"exponent = \" + str(exponent))\n",
    "\n",
    "    K = 0.0\n",
    "    for sigma in sigma_list:\n",
    "        gamma = 1.0 / (2 * sigma**2)\n",
    "        K += torch.exp(-gamma * exponent)\n",
    "#     print(\"K size = \" + str(K.size()))\n",
    "\n",
    "    return K[:m, :m], K[:m, m:], K[m:, m:], len(sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_rbf_mmd2(X, Y, sigma_list, biased=True):\n",
    "    \"\"\"\n",
    "    How it is used in the training loop:\n",
    "        mmd2_D = mix_rbf_mmd2(f_enc_X_D,  f_enc_Y_D,  sigma_list)\n",
    "        X -> f_enc_X_D ->\n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        Y -> f_enc_Y_D -> \n",
    "            size = batch_size x nz \n",
    "                nz = hidden dimension of z\n",
    "        sigma_list -> \n",
    "            base = 1.0\n",
    "            sigma_list = [1, 2, 4, 8, 16]\n",
    "            sigma_list = [sigma / base for sigma in sigma_list]\n",
    "        \n",
    "    _mix_rbf_kernel's internal K has [2 x batch_size, 2 x batch_size] size\n",
    "    K_XX = K[:m, :m] (left upper quadrant) -> size = [batch_size, batch_size]\n",
    "    K_XY = K[:m, m:] (right upper and left lower quadrant) -> size = [batch_size, batch_size]\n",
    "    K_YY = K[m:, m:] (right lower quadrant) -> size = [batch_size, batch_size]\n",
    "    d = len(sigma_list)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    K_XX, K_XY, K_YY, d = _mix_rbf_kernel(X, Y, sigma_list)\n",
    "#     print(\"K_XX size = \" + str(K_XX.size()))\n",
    "#     print(\"K_XY size = \" + str(K_XY.size()))\n",
    "#     print(\"K_YY size = \" + str(K_YY.size()))\n",
    "    # return _mmd2(K_XX, K_XY, K_YY, const_diagonal=d, biased=biased)\n",
    "    return _mmd2(K_XX, K_XY, K_YY, const_diagonal=False, biased=biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_rbf_mmd2_and_ratio(X, Y, sigma_list, biased=True):\n",
    "    K_XX, K_XY, K_YY, d = _mix_rbf_kernel(X, Y, sigma_list)\n",
    "    # return _mmd2_and_ratio(K_XX, K_XY, K_YY, const_diagonal=d, biased=biased)\n",
    "    return _mmd2_and_ratio(K_XX, K_XY, K_YY, const_diagonal=False, biased=biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\tilde{K}_XX * e = K_XX * e - diag_X $\n",
    "* $ \\tilde{K}_YY * e = K_YY * e - diag_Y $ \n",
    "* $ K_{XY}^T * e $\n",
    "\n",
    "\n",
    "* $ e^T * \\tilde{K}_XX * e $\n",
    "* $ e^T * \\tilde{K}_YY * e $ \n",
    "* $ e^T * K_{XY} * e $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Helper functions to compute variances based on kernel matrices\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def _mmd2(K_XX, K_XY, K_YY, const_diagonal=False, biased=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        K_XX = K[:m, :m] size = [batch_size, batch_size]\n",
    "        K_XY = K[:m, m:] size = [batch_size, batch_size]\n",
    "        K_YY = K[m:, m:] size = [batch_size, batch_size]\n",
    "        \n",
    "    m = batch_size\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    m = K_XX.size(0)    # assume X, Y are same shape\n",
    "\n",
    "    # Get the various sums of kernels that we'll use\n",
    "    # Kts drop the diagonal, but we don't need to compute them explicitly\n",
    "    if const_diagonal is not False:\n",
    "        diag_X = diag_Y = const_diagonal\n",
    "        sum_diag_X = sum_diag_Y = m * const_diagonal\n",
    "    else:\n",
    "        diag_X = torch.diag(K_XX)                       # (m,)\n",
    "        diag_Y = torch.diag(K_YY)                       # (m,)\n",
    "        sum_diag_X = torch.sum(diag_X)\n",
    "        sum_diag_Y = torch.sum(diag_Y)\n",
    "\n",
    "    Kt_XX_sums = K_XX.sum(dim=1) - diag_X             # \\tilde{K}_XX * e = K_XX * e - diag_X\n",
    "    Kt_YY_sums = K_YY.sum(dim=1) - diag_Y             # \\tilde{K}_YY * e = K_YY * e - diag_Y\n",
    "    K_XY_sums_0 = K_XY.sum(dim=0)                     # K_{XY}^T * e\n",
    "\n",
    "    Kt_XX_sum = Kt_XX_sums.sum()                       # e^T * \\tilde{K}_XX * e\n",
    "    Kt_YY_sum = Kt_YY_sums.sum()                       # e^T * \\tilde{K}_YY * e\n",
    "    K_XY_sum = K_XY_sums_0.sum()                       # e^T * K_{XY} * e\n",
    "\n",
    "    if biased:\n",
    "        mmd2 = ((Kt_XX_sum + sum_diag_X) / (m * m)\n",
    "            + (Kt_YY_sum + sum_diag_Y) / (m * m)\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "    else:\n",
    "        mmd2 = (Kt_XX_sum / (m * (m - 1))\n",
    "            + Kt_YY_sum / (m * (m - 1))\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "\n",
    "    return mmd2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mmd2_and_ratio(K_XX, K_XY, K_YY, const_diagonal=False, biased=False):\n",
    "    mmd2, var_est = _mmd2_and_variance(K_XX, K_XY, K_YY, const_diagonal=const_diagonal, biased=biased)\n",
    "    loss = mmd2 / torch.sqrt(torch.clamp(var_est, min=min_var_est))\n",
    "    return loss, mmd2, var_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _mmd2_and_variance(K_XX, K_XY, K_YY, const_diagonal=False, biased=False):\n",
    "    m = K_XX.size(0)    # assume X, Y are same shape\n",
    "\n",
    "    # Get the various sums of kernels that we'll use\n",
    "    # Kts drop the diagonal, but we don't need to compute them explicitly\n",
    "    if const_diagonal is not False:\n",
    "        diag_X = diag_Y = const_diagonal\n",
    "        sum_diag_X = sum_diag_Y = m * const_diagonal\n",
    "        sum_diag2_X = sum_diag2_Y = m * const_diagonal**2\n",
    "    else:\n",
    "        diag_X = torch.diag(K_XX)                       # (m,)\n",
    "        diag_Y = torch.diag(K_YY)                       # (m,)\n",
    "        sum_diag_X = torch.sum(diag_X)\n",
    "        sum_diag_Y = torch.sum(diag_Y)\n",
    "        sum_diag2_X = diag_X.dot(diag_X)\n",
    "        sum_diag2_Y = diag_Y.dot(diag_Y)\n",
    "\n",
    "    Kt_XX_sums = K_XX.sum(dim=1) - diag_X             # \\tilde{K}_XX * e = K_XX * e - diag_X\n",
    "    Kt_YY_sums = K_YY.sum(dim=1) - diag_Y             # \\tilde{K}_YY * e = K_YY * e - diag_Y\n",
    "    K_XY_sums_0 = K_XY.sum(dim=0)                     # K_{XY}^T * e\n",
    "    K_XY_sums_1 = K_XY.sum(dim=1)                     # K_{XY} * e\n",
    "\n",
    "    Kt_XX_sum = Kt_XX_sums.sum()                       # e^T * \\tilde{K}_XX * e\n",
    "    Kt_YY_sum = Kt_YY_sums.sum()                       # e^T * \\tilde{K}_YY * e\n",
    "    K_XY_sum = K_XY_sums_0.sum()                       # e^T * K_{XY} * e\n",
    "\n",
    "    Kt_XX_2_sum = (K_XX ** 2).sum() - sum_diag2_X      # \\| \\tilde{K}_XX \\|_F^2\n",
    "    Kt_YY_2_sum = (K_YY ** 2).sum() - sum_diag2_Y      # \\| \\tilde{K}_YY \\|_F^2\n",
    "    K_XY_2_sum  = (K_XY ** 2).sum()                    # \\| K_{XY} \\|_F^2\n",
    "\n",
    "    if biased:\n",
    "        mmd2 = ((Kt_XX_sum + sum_diag_X) / (m * m)\n",
    "            + (Kt_YY_sum + sum_diag_Y) / (m * m)\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "    else:\n",
    "        mmd2 = (Kt_XX_sum / (m * (m - 1))\n",
    "            + Kt_YY_sum / (m * (m - 1))\n",
    "            - 2.0 * K_XY_sum / (m * m))\n",
    "\n",
    "    var_est = (\n",
    "        2.0 / (m**2 * (m - 1.0)**2) * (2 * Kt_XX_sums.dot(Kt_XX_sums) - Kt_XX_2_sum + 2 * Kt_YY_sums.dot(Kt_YY_sums) - Kt_YY_2_sum)\n",
    "        - (4.0*m - 6.0) / (m**3 * (m - 1.0)**3) * (Kt_XX_sum**2 + Kt_YY_sum**2)\n",
    "        + 4.0*(m - 2.0) / (m**3 * (m - 1.0)**2) * (K_XY_sums_1.dot(K_XY_sums_1) + K_XY_sums_0.dot(K_XY_sums_0))\n",
    "        - 4.0*(m - 3.0) / (m**3 * (m - 1.0)**2) * (K_XY_2_sum) - (8 * m - 12) / (m**5 * (m - 1)) * K_XY_sum**2\n",
    "        + 8.0 / (m**3 * (m - 1.0)) * (\n",
    "            1.0 / m * (Kt_XX_sum + Kt_YY_sum) * K_XY_sum\n",
    "            - Kt_XX_sums.dot(K_XY_sums_1)\n",
    "            - Kt_YY_sums.dot(K_XY_sums_0))\n",
    "        )\n",
    "    return mmd2, var_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, dim=1):\n",
    "    \"\"\"\n",
    "    used only in match() when dist == cos\n",
    "    \"\"\"\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "\n",
    "def match(x, y, dist):\n",
    "    '''\n",
    "    Computes distance between corresponding points points in `x` and `y`\n",
    "    using distance `dist`.\n",
    "    \n",
    "    # compute L2-loss of AE\n",
    "    L2_AE_X_D = match(x.view(batch_size, -1), f_dec_X_D, 'L2')\n",
    "    L2_AE_Y_D = match(y.view(batch_size, -1), f_dec_Y_D, 'L2')\n",
    "    \n",
    "    '''\n",
    "    if dist == 'L2':\n",
    "        return (x - y).pow(2).mean()\n",
    "    elif dist == 'L1':\n",
    "        return (x - y).abs().mean()\n",
    "    elif dist == 'cos':\n",
    "        x_n = normalize(x)\n",
    "        y_n = normalize(y)\n",
    "        return 2 - (x_n).mul(y_n).mean()\n",
    "    else:\n",
    "        assert dist == 'none', 'wtf ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm(m, norm_type=2):\n",
    "    total_norm = 0.0\n",
    "    for p in m.parameters():\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm ** norm_type\n",
    "    total_norm = total_norm ** (1. / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.1)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: batch_size * k * 1 * 1\n",
    "# output: batch_size * nc * image_size * image_size\n",
    "\n",
    "\"\"\"\n",
    "# construct encoder/decoder modules\n",
    "hidden_dim = nz\n",
    "G_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "D_encoder = Encoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ndf=16)\n",
    "D_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ngf=16)\n",
    "                    \n",
    "What is ngf?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, isize, nc, k=100, ngf=64):\n",
    "        super(Decoder, self).__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        cngf, tisize = ngf // 2, 4\n",
    "        print(\"cngf = \" + str(cngf))\n",
    "        print(\"tisize = \" + str(tisize))\n",
    "        \n",
    "        while tisize != isize:\n",
    "            cngf = cngf * 2\n",
    "            tisize = tisize * 2\n",
    "            \n",
    "        print(\"cngf = \" + str(cngf))\n",
    "        print(\"tisize = \" + str(tisize))\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        \n",
    "#         \"\"\"\n",
    "#         This part has been added to introduce FC layers to\n",
    "#         the decoder part of the GAN. We believe that these layers\n",
    "#         will be effective to learn the sparsity of the input data\n",
    "#         \"\"\"\n",
    "#         main.add_module(\"first_decoder_FC\",\n",
    "#                         nn.Linear(in_features = k,\n",
    "#                                   out_features = k * 2,\n",
    "#                                   bias = False))\n",
    "#         main.add_module(\"second_decoder_FC\",\n",
    "#                         nn.Linear(in_features = k * 2,\n",
    "#                                   out_features = k,\n",
    "#                                   bias = False))\n",
    "        \n",
    "        \n",
    "        main.add_module('initial_{0}-{1}_convt'.format(k, cngf), \n",
    "                        nn.ConvTranspose3d(in_channels = k,\n",
    "                                           out_channels = cngf,\n",
    "                                           kernel_size = 4, \n",
    "                                           stride = 1,\n",
    "                                           padding = 0, \n",
    "                                           bias=False))\n",
    "        main.add_module('initial_{0}_batchnorm'.format(cngf), \n",
    "                        nn.BatchNorm3d(num_features = cngf))\n",
    "#         main.add_module('initial_{0}_relu'.format(cngf), \n",
    "#                         nn.ReLU(True))\n",
    "        main.add_module('initial_{0}_leakyrelu'.format(cngf), \n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        csize = 4\n",
    "#         cize = 8\n",
    "        while csize < isize // 2:\n",
    "            main.add_module('pyramid_{0}-{1}_convt'.format(cngf, cngf // 2),\n",
    "                            nn.ConvTranspose3d(in_channels = cngf,\n",
    "                                               out_channels = cngf // 2,\n",
    "                                               kernel_size = 4,\n",
    "                                               stride = 2,\n",
    "                                               padding = 1,\n",
    "                                               bias=False))\n",
    "            main.add_module('pyramid_{0}_batchnorm'.format(cngf // 2),\n",
    "                            nn.BatchNorm3d(num_features = cngf // 2))\n",
    "#             main.add_module('pyramid_{0}_relu'.format(cngf // 2),\n",
    "#                             nn.ReLU(True))\n",
    "            main.add_module('initial_{0}_leakyrelu'.format(cngf // 2), \n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cngf = cngf // 2\n",
    "            csize = csize * 2\n",
    "\n",
    "        main.add_module('final_{0}-{1}_convt'.format(cngf, nc), \n",
    "                        nn.ConvTranspose3d(in_channels = cngf,\n",
    "                                           out_channels = nc,\n",
    "                                           kernel_size = 4,\n",
    "                                           stride = 2,\n",
    "                                           padding = 1,\n",
    "                                           bias=False))\n",
    "#         main.add_module('final_{0}_tanh'.format(nc),\n",
    "#                         nn.Tanh())\n",
    "#         main.add_module('final_{0}_sigmoid'.format(nc),\n",
    "#                 nn.Sigmoid())\n",
    "#         main.add_module('final_{0}_leakyrelu'.format(nc),\n",
    "#                 nn.LeakyReLU(negative_slope=0.0001,\n",
    "#                              inplace = True))\n",
    "        main.add_module('final_{0}_relu'.format(nc),\n",
    "                        nn.ReLU(False))\n",
    "#         main.add_module('final_{0}_linear'.format(nc),\n",
    "#                         nn.Linear(in_features = isize, \n",
    "#                                   out_features = isize))\n",
    "    \n",
    "        self.main = main\n",
    "        \n",
    "        # to print out the resulting structure\n",
    "#         print(main)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetG is a decoder\n",
    "# input: batch_size * nz * 1 * 1\n",
    "# output: batch_size * nc * image_size * image_size\n",
    "class NetG(nn.Module):\n",
    "    def __init__(self, decoder):\n",
    "        super(NetG, self).__init__()\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.decoder(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: batch_size * nc * 64 * 64\n",
    "# output: batch_size * k * 1 * 1\n",
    "\n",
    "\"\"\"\n",
    "# construct encoder/decoder modules\n",
    "hidden_dim = nz\n",
    "G_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "D_encoder = Encoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ndf=16)\n",
    "D_decoder = Decoder(image_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ngf=16)\n",
    "\"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, isize, nc, k=100, ndf=64):\n",
    "        \"\"\"\n",
    "        isize = image_size\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        # input is nc x isize x isize\n",
    "        main = nn.Sequential()\n",
    "        main.add_module('initial_conv_{0}-{1}'.format(nc, ndf),\n",
    "                        nn.Conv3d(in_channels = nc,\n",
    "                                  out_channels = ndf,\n",
    "                                  kernel_size = 4,\n",
    "                                  stride = 2,\n",
    "                                  padding = 1,\n",
    "                                  bias=False))\n",
    "        main.add_module('initial_relu_{0}'.format(ndf),\n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        \n",
    "        csize, cndf = isize / 2, ndf\n",
    "        print(\"csize = \" + str(csize))\n",
    "        print(\"cndf = \" + str(cndf))\n",
    "\n",
    "\n",
    "        while csize > 4:\n",
    "#         while csize > 8:\n",
    "            in_feat = cndf\n",
    "            out_feat = cndf * 2\n",
    "            main.add_module('pyramid_{0}-{1}_conv'.format(in_feat, out_feat),\n",
    "                            nn.Conv3d(in_channels = in_feat,\n",
    "                                      out_channels = out_feat,\n",
    "                                      kernel_size = 4,\n",
    "                                      stride = 2,\n",
    "                                      padding = 1,\n",
    "                                      bias=False))\n",
    "            main.add_module('pyramid_{0}_batchnorm'.format(out_feat),\n",
    "                            nn.BatchNorm3d(num_features = out_feat))\n",
    "            main.add_module('pyramid_{0}_relu'.format(out_feat),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cndf = cndf * 2\n",
    "            csize = csize / 2\n",
    "\n",
    "            \n",
    "        main.add_module('final_{0}-{1}_conv'.format(cndf, 1),\n",
    "                        nn.Conv3d(in_channels = cndf,\n",
    "                                  out_channels = k,\n",
    "                                  kernel_size = 4,\n",
    "                                  stride = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias=False))\n",
    "\n",
    "        self.main = main\n",
    "        \n",
    "        # to print out the resulting structure\n",
    "#         print(main)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetD is an encoder + decoder\n",
    "# input: batch_size * nc * image_size * image_size\n",
    "# f_enc_X: batch_size * k * 1 * 1\n",
    "# f_dec_X: batch_size * nc * image_size * image_size\n",
    "class NetD(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(NetD, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        \"\"\"\n",
    "        This part has been added to introduce FC layers to\n",
    "        the encoder part of the GAN. We believe that these layers\n",
    "        will be effective to learn the sparsity of the input data\n",
    "        \"\"\"\n",
    "#         # \"first_encoder_FC\"\n",
    "#         self.fc1 = nn.Linear(in_features = k,\n",
    "#                       out_features = k * 2,\n",
    "#                       bias = False)\n",
    "#         # \"second_encoder_FC\"\n",
    "#         self.fc2 = nn.Linear(in_features = k * 2,\n",
    "#                       out_features = k,\n",
    "#                       bias = False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        f_enc_X = self.encoder(input)\n",
    "#         print(\"f_enc_X outputted.\")\n",
    "        \n",
    "#         # The FC Layers\n",
    "#         f_enc_X = self.fc1(f_enc_X)\n",
    "#         f_enc_X = self.fc1(f_enc_X)\n",
    "        \n",
    "        \n",
    "        f_dec_X = self.decoder(f_enc_X)\n",
    "#         print(\"f_dec_X outputted.\")\n",
    "\n",
    "        f_enc_X = f_enc_X.view(input.size(0), -1)\n",
    "        f_dec_X = f_dec_X.view(input.size(0), -1)\n",
    "        return f_enc_X, f_dec_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONE_SIDED(nn.Module):\n",
    "    \"\"\"\n",
    "    rank hinge loss\n",
    "    one_side_errD = one_sided(f_enc_X_D.mean(0) - f_enc_Y_D.mean(0))\n",
    "        always 0!\n",
    "    one_side_errG = one_sided(f_enc_X.mean(0) - f_enc_Y.mean(0))\n",
    "        always 0!\n",
    "    \n",
    "    torch.mean(input, dim, keepdim=False, out=None)  Tensor\n",
    "        Returns the mean value of each row of the input tensor \n",
    "        in the given dimension dim\n",
    "        0 = dim -> rows\n",
    "        \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ONE_SIDED, self).__init__()\n",
    "\n",
    "        main = nn.ReLU()\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(-input)\n",
    "        output = -output.mean()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if args.experiment is None:\n",
    "#     args.experiment = 'samples'\n",
    "# os.system('mkdir {0}'.format(args.experiment))\n",
    "\n",
    "if experiment is None:\n",
    "    experiment = 'samples'\n",
    "os.system('mkdir {0}'.format(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "#     args.cuda = True\n",
    "    cuda = True\n",
    "#     torch.cuda.set_device(args.gpu_device)\n",
    "    torch.cuda.set_device(gpu_device)\n",
    "    print(\"Using GPU device\", torch.cuda.current_device())\n",
    "else:\n",
    "    raise EnvironmentError(\"GPU device not available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(seed=args.manual_seed)\n",
    "# random.seed(args.manual_seed)\n",
    "# torch.manual_seed(args.manual_seed)\n",
    "# torch.cuda.manual_seed(args.manual_seed)\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "np.random.seed(seed=manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed(manual_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cngf = 8\n",
      "tisize = 4\n",
      "cngf = 256\n",
      "tisize = 128\n",
      "csize = 64.0\n",
      "cndf = 16\n",
      "cngf = 8\n",
      "tisize = 4\n",
      "cngf = 256\n",
      "tisize = 128\n"
     ]
    }
   ],
   "source": [
    "# construct encoder/decoder modules\n",
    "\n",
    "\"\"\"\n",
    "ngf = \n",
    "ndf = \n",
    "\n",
    "\"\"\"\n",
    "hidden_dim = nz\n",
    "G_decoder = Decoder(cube_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "D_encoder = Encoder(cube_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ndf=16)\n",
    "D_decoder = Decoder(cube_size, \n",
    "                    nc, \n",
    "                    k=hidden_dim, \n",
    "                    ngf=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netD: NetD(\n",
      "  (encoder): Encoder(\n",
      "    (main): Sequential(\n",
      "      (initial_conv_1-16): Conv3d(1, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (initial_relu_16): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_16-32_conv): Conv3d(16, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_32_batchnorm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_32_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_32-64_conv): Conv3d(32, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_64_batchnorm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_64_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_64-128_conv): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_128_batchnorm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_128_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_128-256_conv): Conv3d(128, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_256_batchnorm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pyramid_256_relu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (final_256-1_conv): Conv3d(256, 128, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (main): Sequential(\n",
      "      (initial_128-256_convt): ConvTranspose3d(128, 256, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
      "      (initial_256_batchnorm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_256_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_256-128_convt): ConvTranspose3d(256, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_128_batchnorm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_128_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_128-64_convt): ConvTranspose3d(128, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_64_batchnorm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_64_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_64-32_convt): ConvTranspose3d(64, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_32_batchnorm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_32_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_32-16_convt): ConvTranspose3d(32, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_16_batchnorm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_16_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (final_16-1_convt): ConvTranspose3d(16, 1, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (final_1_relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = NetD(D_encoder, D_decoder)\n",
    "print(\"netD:\", netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netG: NetG(\n",
      "  (decoder): Decoder(\n",
      "    (main): Sequential(\n",
      "      (initial_128-256_convt): ConvTranspose3d(128, 256, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
      "      (initial_256_batchnorm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_256_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_256-128_convt): ConvTranspose3d(256, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_128_batchnorm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_128_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_128-64_convt): ConvTranspose3d(128, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_64_batchnorm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_64_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_64-32_convt): ConvTranspose3d(64, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_32_batchnorm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_32_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (pyramid_32-16_convt): ConvTranspose3d(32, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (pyramid_16_batchnorm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (initial_16_leakyrelu): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (final_16-1_convt): ConvTranspose3d(16, 1, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (final_1_relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = NetG(G_decoder)\n",
    "print(\"netG:\", netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " oneSide: ONE_SIDED(\n",
      "  (main): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "one_sided = ONE_SIDED()\n",
    "print(\"\\n \\n oneSide:\", one_sided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ONE_SIDED(\n",
       "  (main): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "one_sided.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put variable into cuda device\n",
    "fixed_noise = torch.cuda.FloatTensor(64, nz, 1, 1).normal_(0, 1)\n",
    "one = torch.tensor(1.0).cuda()\n",
    "#one = torch.cuda.FloatTensor([1])\n",
    "mone = one * -1\n",
    "if cuda:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    one_sided.cuda()\n",
    "fixed_noise = Variable(fixed_noise, \n",
    "                       requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_choice == \"rmsprop\":\n",
    "#     setup optimizer\n",
    "    optimizerG = torch.optim.RMSprop(netG.parameters(), \n",
    "                                     lr=lr)\n",
    "    optimizerD = torch.optim.RMSprop(netD.parameters(), \n",
    "                                     lr=lr)\n",
    "elif optimizer_choice == \"adam\":\n",
    "    # Why not try adam?\n",
    "    optimizerG = torch.optim.Adam(netG.parameters(), \n",
    "                                     lr=lr)\n",
    "    optimizerD = torch.optim.Adam(netD.parameters(), \n",
    "                                     lr=lr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 2620169.261826965\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch = 1 / 150\n",
      "----------------------------------------------- \n",
      "\n",
      "len(trn_loader) = 128\n",
      "Optimize over NetD\n",
      "gen_iterations = 0\n",
      "j / Diter = 1 / 100\n",
      "37.86641240119934\n",
      "max(x[0]) = [0.0050333]\n",
      "max(y[0]) = [0.95961446]\n",
      "min(x[0]) = [0.]\n",
      "min(y[0]) = [0.]\n",
      "len(real_plot) - nonzero elements = 896162\n",
      "len(recon_plot) - nonzero elements = 839873\n",
      "max(real_plot) = 0.0050332965\n",
      "max(recon_plot) = 0.95961446\n",
      "min(real_plot) = 2.8416213e-19\n",
      "min(recon_plot) = 2.59839e-07\n",
      "real_ae_cube max = 0.119734325, min = 0.0\n",
      "noise_ae_cube max = 0.97168213, min = 0.0\n",
      "noise_gen_cube max = 0.92777693, min = 0.0\n",
      "real_cube max = 0.00055495923, min = 0.0\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 1.7374974418065472\n",
      "s max = 5.986716225743294\n",
      "s min = 1.1469613760709763\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Noise-Input Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 14.318832823651956\n",
      "s max = 48.58410656452179\n",
      "s min = 9.8964124917984\n",
      "\n",
      "Noise-Input Generated Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 14.428188276452298\n",
      "s max = 46.38884663581848\n",
      "s min = 10.177744925022125\n",
      "\n",
      "Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.0063233874403778876\n",
      "s max = 0.027747961576096714\n",
      "s min = 0.00010565312322796672\n",
      "j / Diter = 2 / 100\n",
      "19.207703471183777\n",
      "j / Diter = 3 / 100\n",
      "13.027550061543783\n",
      "j / Diter = 4 / 100\n",
      "9.973521411418915\n",
      "j / Diter = 5 / 100\n",
      "8.136538076400758\n",
      "j / Diter = 6 / 100\n",
      "7.0424567858378095\n",
      "j / Diter = 7 / 100\n",
      "6.366876568113055\n",
      "j / Diter = 8 / 100\n",
      "5.797949910163879\n",
      "j / Diter = 9 / 100\n",
      "5.406904300053914\n",
      "j / Diter = 10 / 100\n",
      "4.950240635871888\n",
      "j / Diter = 11 / 100\n",
      "4.724169536070391\n",
      "j / Diter = 12 / 100\n",
      "4.395866135756175\n",
      "j / Diter = 13 / 100\n",
      "4.225455265778762\n",
      "j / Diter = 14 / 100\n",
      "3.9780409846987044\n",
      "j / Diter = 15 / 100\n",
      "3.903010447820028\n",
      "j / Diter = 16 / 100\n",
      "3.734912246465683\n",
      "j / Diter = 17 / 100\n",
      "3.613128662109375\n",
      "j / Diter = 18 / 100\n",
      "3.483333388964335\n",
      "j / Diter = 19 / 100\n",
      "3.3883307482066907\n",
      "j / Diter = 20 / 100\n",
      "3.310051965713501\n",
      "j / Diter = 21 / 100\n",
      "3.2155305544535318\n",
      "j / Diter = 22 / 100\n",
      "3.1746207692406396\n",
      "j / Diter = 23 / 100\n",
      "3.0684269096540366\n",
      "j / Diter = 24 / 100\n",
      "3.0418344736099243\n",
      "j / Diter = 25 / 100\n",
      "2.9546483039855955\n",
      "j / Diter = 26 / 100\n",
      "2.93741670021644\n",
      "j / Diter = 27 / 100\n",
      "2.8573471440209284\n",
      "j / Diter = 28 / 100\n",
      "2.8389972874096463\n",
      "j / Diter = 29 / 100\n",
      "2.767498287661322\n",
      "j / Diter = 30 / 100\n",
      "2.749330520629883\n",
      "j / Diter = 31 / 100\n",
      "2.6853394046906502\n",
      "j / Diter = 32 / 100\n",
      "2.669147677719593\n",
      "j / Diter = 33 / 100\n",
      "2.612130201224125\n",
      "j / Diter = 34 / 100\n",
      "2.600286792306339\n",
      "j / Diter = 35 / 100\n",
      "2.548811367579869\n",
      "j / Diter = 36 / 100\n",
      "2.5391085743904114\n",
      "j / Diter = 37 / 100\n",
      "2.490848799009581\n",
      "j / Diter = 38 / 100\n",
      "2.4819176385277197\n",
      "j / Diter = 39 / 100\n",
      "2.437704575367463\n",
      "j / Diter = 40 / 100\n",
      "2.431479799747467\n",
      "j / Diter = 41 / 100\n",
      "2.3906008150519393\n",
      "j / Diter = 42 / 100\n",
      "2.390323865981329\n",
      "j / Diter = 43 / 100\n",
      "2.3532952486082563\n",
      "j / Diter = 44 / 100\n",
      "2.349118509075858\n",
      "j / Diter = 45 / 100\n",
      "2.3140336672465005\n",
      "j / Diter = 46 / 100\n",
      "2.311741512754689\n",
      "j / Diter = 47 / 100\n",
      "2.2787074687633107\n",
      "j / Diter = 48 / 100\n",
      "2.286496803164482\n",
      "j / Diter = 49 / 100\n",
      "2.2555386241601436\n",
      "j / Diter = 50 / 100\n",
      "2.2547595071792603\n",
      "j / Diter = 51 / 100\n",
      "2.225981777789546\n",
      "j / Diter = 52 / 100\n",
      "2.224838233911074\n",
      "j / Diter = 53 / 100\n",
      "2.197462995097322\n",
      "j / Diter = 54 / 100\n",
      "2.19650638545001\n",
      "j / Diter = 55 / 100\n",
      "2.170482908595692\n",
      "j / Diter = 56 / 100\n",
      "2.1705017345292226\n",
      "j / Diter = 57 / 100\n",
      "2.1461162357999566\n",
      "j / Diter = 58 / 100\n",
      "2.1490032878415337\n",
      "j / Diter = 59 / 100\n",
      "2.125701112262273\n",
      "j / Diter = 60 / 100\n",
      "2.1275591333707173\n",
      "j / Diter = 61 / 100\n",
      "2.105755829420246\n",
      "j / Diter = 62 / 100\n",
      "2.1067525379119383\n",
      "j / Diter = 63 / 100\n",
      "2.085689650641547\n",
      "j / Diter = 64 / 100\n",
      "2.088254526257515\n",
      "j / Diter = 65 / 100\n",
      "2.0680278851435734\n",
      "j / Diter = 66 / 100\n",
      "2.0706454623829234\n",
      "j / Diter = 67 / 100\n",
      "2.051341900184973\n",
      "j / Diter = 68 / 100\n",
      "2.052977677653818\n",
      "j / Diter = 69 / 100\n",
      "2.0343169060306274\n",
      "j / Diter = 70 / 100\n",
      "2.0356216328484673\n",
      "j / Diter = 71 / 100\n",
      "2.0178606745222925\n",
      "j / Diter = 72 / 100\n",
      "2.020638565222422\n",
      "j / Diter = 73 / 100\n",
      "2.0034482283134984\n",
      "j / Diter = 74 / 100\n",
      "2.0050136720812\n",
      "j / Diter = 75 / 100\n",
      "1.988513209025065\n",
      "j / Diter = 76 / 100\n",
      "1.9907371182190745\n",
      "j / Diter = 77 / 100\n",
      "1.9751754271519648\n",
      "j / Diter = 78 / 100\n",
      "1.9768779705732296\n",
      "j / Diter = 79 / 100\n",
      "1.9613753693013252\n",
      "j / Diter = 80 / 100\n",
      "1.962302166223526\n",
      "j / Diter = 81 / 100\n",
      "1.9474661821200523\n",
      "j / Diter = 82 / 100\n",
      "1.9490298875948278\n",
      "j / Diter = 83 / 100\n",
      "1.9352453990154956\n",
      "j / Diter = 84 / 100\n",
      "1.9405671074276878\n",
      "j / Diter = 85 / 100\n",
      "1.9271069975460278\n",
      "j / Diter = 86 / 100\n",
      "1.9331560301226238\n",
      "j / Diter = 87 / 100\n",
      "1.920281766474932\n",
      "j / Diter = 88 / 100\n",
      "1.924928375265815\n",
      "j / Diter = 89 / 100\n",
      "1.9121800781635756\n",
      "j / Diter = 90 / 100\n",
      "1.9167792161305746\n",
      "j / Diter = 91 / 100\n",
      "1.9043812856569395\n",
      "j / Diter = 92 / 100\n",
      "1.9106570715489595\n",
      "j / Diter = 93 / 100\n",
      "1.898505062185308\n",
      "j / Diter = 94 / 100\n",
      "1.904690887065644\n",
      "j / Diter = 95 / 100\n",
      "1.8929562618857936\n",
      "j / Diter = 96 / 100\n",
      "1.8988362128535907\n",
      "j / Diter = 97 / 100\n",
      "1.8872970895668895\n",
      "j / Diter = 98 / 100\n",
      "1.8925953568244467\n",
      "j / Diter = 99 / 100\n",
      "1.8813043242753154\n",
      "j / Diter = 100 / 100\n",
      "1.8850241637229919\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 100\n",
      "len(trn_loader) = 128\n",
      "j / Giter = 1 / 1\n",
      "errG = tensor(0.0179, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "run_time = 4.247493422085729\n",
      "[  0/150][101/128] [    1] (4.25 m) MMD2_D 0.000547 hinge -0.000341 L2_AE_X 0.017124 L2_AE_Y 0.062161 loss_D -0.616333 Loss_G 0.017891 f_X -0.000000 f_Y -0.000664 |gD| 316.4661 |gG| 0.2118\n",
      "Optimize over NetD\n",
      "gen_iterations = 1\n",
      "j / Diter = 1 / 100\n",
      "1.8741226408741263\n",
      "j / Diter = 2 / 100\n",
      "1.8635756618836348\n",
      "j / Diter = 3 / 100\n",
      "1.870171412680913\n",
      "j / Diter = 4 / 100\n",
      "1.8597042056230397\n",
      "j / Diter = 5 / 100\n",
      "1.8665419328780402\n",
      "j / Diter = 6 / 100\n",
      "1.8567801781420439\n",
      "j / Diter = 7 / 100\n",
      "1.8622151267862765\n",
      "j / Diter = 8 / 100\n",
      "1.852528867898164\n",
      "j / Diter = 9 / 100\n",
      "1.8571496031699923\n",
      "j / Diter = 10 / 100\n",
      "1.8471822370182385\n",
      "j / Diter = 11 / 100\n",
      "1.8522842961388666\n",
      "j / Diter = 12 / 100\n",
      "1.8427981457539968\n",
      "j / Diter = 13 / 100\n",
      "1.8479859913344931\n",
      "j / Diter = 14 / 100\n",
      "1.8387478046249925\n",
      "j / Diter = 15 / 100\n",
      "1.8437456690746805\n",
      "j / Diter = 16 / 100\n",
      "1.8346046127122024\n",
      "j / Diter = 17 / 100\n",
      "1.8396699734223194\n",
      "j / Diter = 18 / 100\n",
      "1.8308925103333036\n",
      "j / Diter = 19 / 100\n",
      "1.836130001965691\n",
      "j / Diter = 20 / 100\n",
      "1.827407612403234\n",
      "j / Diter = 21 / 100\n",
      "1.8324615265712265\n",
      "j / Diter = 22 / 100\n",
      "1.8238256720245862\n",
      "j / Diter = 23 / 100\n",
      "1.8286419864592514\n",
      "j / Diter = 24 / 100\n",
      "1.820409918985059\n",
      "j / Diter = 25 / 100\n",
      "1.821224672317505\n",
      "j / Diter = 26 / 100\n",
      "1.8122772716340565\n",
      "j / Diter = 27 / 100\n",
      "1.8067883318803442\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 128\n",
      "len(trn_loader) = 128\n",
      "Breaking from the Generator training loop\n",
      "run_time = 4.944655864600403\n",
      "[  0/150][128/128] [    1] (4.94 m) MMD2_D 0.000538 hinge -0.000342 L2_AE_X 0.015391 L2_AE_Y 0.061789 loss_D -0.599722 Loss_G 0.017891 f_X -0.000000 f_Y -0.000743 |gD| 551.8553 |gG| 0.2118\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch = 2 / 150\n",
      "----------------------------------------------- \n",
      "\n",
      "len(trn_loader) = 128\n",
      "Optimize over NetD\n",
      "gen_iterations = 1\n",
      "j / Diter = 1 / 100\n",
      "1.818285807967186\n",
      "max(x[0]) = [0.02584181]\n",
      "max(y[0]) = [0.9528577]\n",
      "min(x[0]) = [0.]\n",
      "min(y[0]) = [0.]\n",
      "len(real_plot) - nonzero elements = 1012602\n",
      "len(recon_plot) - nonzero elements = 839954\n",
      "max(real_plot) = 0.025841812\n",
      "max(recon_plot) = 0.9528577\n",
      "min(real_plot) = 2.1088308e-18\n",
      "min(recon_plot) = 7.4505806e-08\n",
      "real_ae_cube max = 0.051691677, min = 0.0\n",
      "noise_ae_cube max = 0.9679605, min = 0.0\n",
      "noise_gen_cube max = 0.9669768, min = 0.0\n",
      "real_cube max = 0.060104012, min = 0.0\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.730995602719215\n",
      "s max = 2.5845838710665703\n",
      "s min = 0.4373823292553425\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Noise-Input Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 14.643234480390857\n",
      "s max = 48.39802384376526\n",
      "s min = 9.972970932722092\n",
      "\n",
      "Noise-Input Generated Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 14.656381169230196\n",
      "s max = 48.348841071128845\n",
      "s min = 10.307372361421585\n",
      "\n",
      "Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.13675088969951807\n",
      "s max = 3.0052006244659424\n",
      "s min = 0.0054763859225204214\n",
      "j / Diter = 2 / 100\n",
      "1.808521174645239\n",
      "j / Diter = 3 / 100\n",
      "1.8007052109791681\n",
      "j / Diter = 4 / 100\n",
      "1.792894454402778\n",
      "j / Diter = 5 / 100\n",
      "1.7853224367806406\n",
      "j / Diter = 6 / 100\n",
      "1.7817892992406859\n",
      "j / Diter = 7 / 100\n",
      "1.774585138505964\n",
      "j / Diter = 8 / 100\n",
      "1.780013833222566\n",
      "j / Diter = 9 / 100\n",
      "1.772743905291838\n",
      "j / Diter = 10 / 100\n",
      "1.7776002448840733\n",
      "j / Diter = 11 / 100\n",
      "1.7706487731657166\n",
      "j / Diter = 12 / 100\n",
      "1.7755948793973855\n",
      "j / Diter = 13 / 100\n",
      "1.76850631577628\n",
      "j / Diter = 14 / 100\n",
      "1.774011584883886\n",
      "j / Diter = 15 / 100\n",
      "1.7672959179945396\n",
      "j / Diter = 16 / 100\n",
      "1.7718047162035961\n",
      "j / Diter = 17 / 100\n",
      "1.764882140689426\n",
      "j / Diter = 18 / 100\n",
      "1.7697440690007704\n",
      "j / Diter = 19 / 100\n",
      "1.7631139624608707\n",
      "j / Diter = 20 / 100\n",
      "1.7689442748115176\n",
      "j / Diter = 21 / 100\n",
      "1.7622129917144775\n",
      "j / Diter = 22 / 100\n",
      "1.766525426967032\n",
      "j / Diter = 23 / 100\n",
      "1.7599028333028157\n",
      "j / Diter = 24 / 100\n",
      "1.7644643594097618\n",
      "j / Diter = 25 / 100\n",
      "1.758125458893023\n",
      "j / Diter = 26 / 100\n",
      "1.7628942595587835\n",
      "j / Diter = 27 / 100\n",
      "1.7565521342413766\n",
      "j / Diter = 28 / 100\n",
      "1.760393028874551\n",
      "j / Diter = 29 / 100\n",
      "1.7542996009190877\n",
      "j / Diter = 30 / 100\n",
      "1.7584532036143503\n",
      "j / Diter = 31 / 100\n",
      "1.752333268334594\n",
      "j / Diter = 32 / 100\n",
      "1.7565578169792704\n",
      "j / Diter = 33 / 100\n",
      "1.7504546508193015\n",
      "j / Diter = 34 / 100\n",
      "1.7549193808751076\n",
      "j / Diter = 35 / 100\n",
      "1.7490798985516582\n",
      "j / Diter = 36 / 100\n",
      "1.7533950264468514\n",
      "j / Diter = 37 / 100\n",
      "1.747409909236722\n",
      "j / Diter = 38 / 100\n",
      "1.7513428818095813\n",
      "j / Diter = 39 / 100\n",
      "1.7455660966505486\n",
      "j / Diter = 40 / 100\n",
      "1.7497031603030815\n",
      "j / Diter = 41 / 100\n",
      "1.7440636739844368\n",
      "j / Diter = 42 / 100\n",
      "1.7479123053466075\n",
      "j / Diter = 43 / 100\n",
      "1.7422344586428473\n",
      "j / Diter = 44 / 100\n",
      "1.74605433425011\n",
      "j / Diter = 45 / 100\n",
      "1.7405496572339259\n",
      "j / Diter = 46 / 100\n",
      "1.7445408719123443\n",
      "j / Diter = 47 / 100\n",
      "1.7390370930748424\n",
      "j / Diter = 48 / 100\n",
      "1.7432074914659772\n",
      "j / Diter = 49 / 100\n",
      "1.737691043452783\n",
      "j / Diter = 50 / 100\n",
      "1.7419889929604395\n",
      "j / Diter = 51 / 100\n",
      "1.7366700708196405\n",
      "j / Diter = 52 / 100\n",
      "1.7408256397566981\n",
      "j / Diter = 53 / 100\n",
      "1.7356071591377258\n",
      "j / Diter = 54 / 100\n",
      "1.7393336704422755\n",
      "j / Diter = 55 / 100\n",
      "1.7343143408115094\n",
      "j / Diter = 56 / 100\n",
      "1.7381461331101715\n",
      "j / Diter = 57 / 100\n",
      "1.7330721966598346\n",
      "j / Diter = 58 / 100\n",
      "1.7370312033472834\n",
      "j / Diter = 59 / 100\n",
      "1.732130399314306\n",
      "j / Diter = 60 / 100\n",
      "1.7357412940040629\n",
      "j / Diter = 61 / 100\n",
      "1.7308558048085962\n",
      "j / Diter = 62 / 100\n",
      "1.7346411117170222\n",
      "j / Diter = 63 / 100\n",
      "1.7296532066244827\n",
      "j / Diter = 64 / 100\n",
      "1.7333323568573797\n",
      "j / Diter = 65 / 100\n",
      "1.728508518387874\n",
      "j / Diter = 66 / 100\n",
      "1.7319488661276863\n",
      "j / Diter = 67 / 100\n",
      "1.7272603032515221\n",
      "j / Diter = 68 / 100\n",
      "1.7309950950818185\n",
      "j / Diter = 69 / 100\n",
      "1.7261860662577104\n",
      "j / Diter = 70 / 100\n",
      "1.7300198949533065\n",
      "j / Diter = 71 / 100\n",
      "1.725228195238595\n",
      "j / Diter = 72 / 100\n",
      "1.7286163862027115\n",
      "j / Diter = 73 / 100\n",
      "1.724228916168213\n",
      "j / Diter = 74 / 100\n",
      "1.7273069021120593\n",
      "j / Diter = 75 / 100\n",
      "1.723618756426443\n",
      "j / Diter = 76 / 100\n",
      "1.7260502030696776\n",
      "j / Diter = 77 / 100\n",
      "1.7223906330033845\n",
      "j / Diter = 78 / 100\n",
      "1.72464201857404\n",
      "j / Diter = 79 / 100\n",
      "1.721303262756866\n",
      "j / Diter = 80 / 100\n",
      "1.7234043291801415\n",
      "j / Diter = 81 / 100\n",
      "1.7201992605741208\n",
      "j / Diter = 82 / 100\n",
      "1.7222043201683812\n",
      "j / Diter = 83 / 100\n",
      "1.718941551163083\n",
      "j / Diter = 84 / 100\n",
      "1.7211297801320586\n",
      "j / Diter = 85 / 100\n",
      "1.7178502903794342\n",
      "j / Diter = 86 / 100\n",
      "1.7197723634925806\n",
      "j / Diter = 87 / 100\n",
      "1.71741618619901\n",
      "j / Diter = 88 / 100\n",
      "1.7190580057543376\n",
      "j / Diter = 89 / 100\n",
      "1.7160793002004977\n",
      "j / Diter = 90 / 100\n",
      "1.717918458622172\n",
      "j / Diter = 91 / 100\n",
      "1.7151719298931436\n",
      "j / Diter = 92 / 100\n",
      "1.7165831376428473\n",
      "j / Diter = 93 / 100\n",
      "1.7141602895476602\n",
      "j / Diter = 94 / 100\n",
      "1.71556901823881\n",
      "j / Diter = 95 / 100\n",
      "1.7134420678422257\n",
      "j / Diter = 96 / 100\n",
      "1.7149536534809746\n",
      "j / Diter = 97 / 100\n",
      "1.7127583378127642\n",
      "j / Diter = 98 / 100\n",
      "1.7142774528927274\n",
      "j / Diter = 99 / 100\n",
      "1.711750214078785\n",
      "j / Diter = 100 / 100\n",
      "1.7130543891553838\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 100\n",
      "len(trn_loader) = 128\n",
      "j / Giter = 1 / 1\n",
      "errG = tensor(0.0234, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/matplotlib-2.1.0-py3.6-linux-x86_64.egg/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_time = 8.640846341964789\n",
      "[  1/150][101/128] [    2] (8.64 m) MMD2_D 0.000782 hinge -0.000273 L2_AE_X 0.018470 L2_AE_Y 0.060732 loss_D -0.610015 Loss_G 0.023406 f_X -0.000000 f_Y -0.001122 |gD| 651.0886 |gG| 0.2397\n",
      "Optimize over NetD\n",
      "gen_iterations = 2\n",
      "j / Diter = 1 / 100\n",
      "1.708735938657794\n",
      "j / Diter = 2 / 100\n",
      "1.7047689856400137\n",
      "j / Diter = 3 / 100\n",
      "1.705521531727003\n",
      "j / Diter = 4 / 100\n",
      "1.7039488910080551\n",
      "j / Diter = 5 / 100\n",
      "1.7045979530646884\n",
      "j / Diter = 6 / 100\n",
      "1.7027384989251395\n",
      "j / Diter = 7 / 100\n",
      "1.7035414734457293\n",
      "j / Diter = 8 / 100\n",
      "1.702148953904497\n",
      "j / Diter = 9 / 100\n",
      "1.7026439329325143\n",
      "j / Diter = 10 / 100\n",
      "1.7013239468200296\n",
      "j / Diter = 11 / 100\n",
      "1.701752174802187\n",
      "j / Diter = 12 / 100\n",
      "1.7002821666925023\n",
      "j / Diter = 13 / 100\n",
      "1.7005798508723577\n",
      "j / Diter = 14 / 100\n",
      "1.6994148804439053\n",
      "j / Diter = 15 / 100\n",
      "1.6997815597155863\n",
      "j / Diter = 16 / 100\n",
      "1.6984089706169725\n",
      "j / Diter = 17 / 100\n",
      "1.6990018741029207\n",
      "j / Diter = 18 / 100\n",
      "1.697484606139514\n",
      "j / Diter = 19 / 100\n",
      "1.698248760487006\n",
      "j / Diter = 20 / 100\n",
      "1.6970554884628728\n",
      "j / Diter = 21 / 100\n",
      "1.697594807993981\n",
      "j / Diter = 22 / 100\n",
      "1.6968823800604027\n",
      "j / Diter = 23 / 100\n",
      "1.696800618171692\n",
      "j / Diter = 24 / 100\n",
      "1.6963369827346497\n",
      "j / Diter = 25 / 100\n",
      "1.6960001436490861\n",
      "j / Diter = 26 / 100\n",
      "1.6952647192204895\n",
      "j / Diter = 27 / 100\n",
      "1.6918264833960945\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 128\n",
      "len(trn_loader) = 128\n",
      "Breaking from the Generator training loop\n",
      "run_time = 9.337462612016436\n",
      "[  1/150][128/128] [    2] (9.34 m) MMD2_D 0.000864 hinge -0.000300 L2_AE_X 0.018980 L2_AE_Y 0.060453 loss_D -0.610861 Loss_G 0.023406 f_X -0.000000 f_Y -0.001132 |gD| 571.8016 |gG| 0.2397\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch = 3 / 150\n",
      "----------------------------------------------- \n",
      "\n",
      "len(trn_loader) = 128\n",
      "Optimize over NetD\n",
      "gen_iterations = 2\n",
      "j / Diter = 1 / 100\n",
      "1.6983710335750206\n",
      "max(x[0]) = [0.42455256]\n",
      "max(y[0]) = [1.0023339]\n",
      "min(x[0]) = [0.]\n",
      "min(y[0]) = [0.]\n",
      "len(real_plot) - nonzero elements = 1201656\n",
      "len(recon_plot) - nonzero elements = 838943\n",
      "max(real_plot) = 0.42455256\n",
      "max(recon_plot) = 1.0023339\n",
      "min(real_plot) = 1.9006673e-20\n",
      "min(recon_plot) = 8.009374e-08\n",
      "real_ae_cube max = 0.051021263, min = 0.0\n",
      "noise_ae_cube max = 0.85714996, min = 0.0\n",
      "noise_gen_cube max = 0.9337048, min = 0.0\n",
      "real_cube max = 0.01617502, min = 0.0\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.6793666020054444\n",
      "s max = 2.551063150167465\n",
      "s min = 0.3869627369567752\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Noise-Input Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 11.673289702324835\n",
      "s max = 42.85749793052673\n",
      "s min = 7.848275452852249\n",
      "\n",
      "Noise-Input Generated Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 13.337844276656345\n",
      "s max = 46.68523967266083\n",
      "s min = 9.400342404842377\n",
      "\n",
      "Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.1236379373879642\n",
      "s max = 0.8087510243058205\n",
      "s min = 0.002689475877559744\n",
      "j / Diter = 2 / 100\n",
      "1.6939653856679797\n",
      "j / Diter = 3 / 100\n",
      "1.6905169598323362\n",
      "j / Diter = 4 / 100\n",
      "1.687071404715841\n",
      "j / Diter = 5 / 100\n",
      "1.6836479906870132\n",
      "j / Diter = 6 / 100\n",
      "1.6814593186745277\n",
      "j / Diter = 7 / 100\n",
      "1.6785205936066492\n",
      "j / Diter = 8 / 100\n",
      "1.6808868992419643\n",
      "j / Diter = 9 / 100\n",
      "1.677954225032502\n",
      "j / Diter = 10 / 100\n",
      "1.6801643299333977\n",
      "j / Diter = 11 / 100\n",
      "1.6774668846490248\n",
      "j / Diter = 12 / 100\n",
      "1.6800643447646522\n",
      "j / Diter = 13 / 100\n",
      "1.6778748142585327\n",
      "j / Diter = 14 / 100\n",
      "1.6798397400485936\n",
      "j / Diter = 15 / 100\n",
      "1.6774760178916959\n",
      "j / Diter = 16 / 100\n",
      "1.679506833465011\n",
      "j / Diter = 17 / 100\n",
      "1.6771265800588686\n",
      "j / Diter = 18 / 100\n",
      "1.6798847335226395\n",
      "j / Diter = 19 / 100\n",
      "1.677476549323225\n",
      "j / Diter = 20 / 100\n",
      "1.6796516528094771\n",
      "j / Diter = 21 / 100\n",
      "1.6771304095875132\n",
      "j / Diter = 22 / 100\n",
      "1.6793635262959246\n",
      "j / Diter = 23 / 100\n",
      "1.6770404529915819\n",
      "j / Diter = 24 / 100\n",
      "1.678988360672546\n",
      "j / Diter = 25 / 100\n",
      "1.677389996880699\n",
      "j / Diter = 26 / 100\n",
      "1.6785822119031633\n",
      "j / Diter = 27 / 100\n",
      "1.677076161544094\n",
      "j / Diter = 28 / 100\n",
      "1.6783126710999943\n",
      "j / Diter = 29 / 100\n",
      "1.677223418710931\n",
      "j / Diter = 30 / 100\n",
      "1.678396788281454\n",
      "j / Diter = 31 / 100\n",
      "1.6770880690792151\n",
      "j / Diter = 32 / 100\n",
      "1.6780784621938958\n",
      "j / Diter = 33 / 100\n",
      "1.6767243632871516\n",
      "j / Diter = 34 / 100\n",
      "1.6778089818027284\n",
      "j / Diter = 35 / 100\n",
      "1.6765478309050563\n",
      "j / Diter = 36 / 100\n",
      "1.6778468921266754\n",
      "j / Diter = 37 / 100\n",
      "1.676342214505697\n",
      "j / Diter = 38 / 100\n",
      "1.6774439958676899\n",
      "j / Diter = 39 / 100\n",
      "1.6761196717467324\n",
      "j / Diter = 40 / 100\n",
      "1.6769260435688251\n",
      "j / Diter = 41 / 100\n",
      "1.6756282862970384\n",
      "j / Diter = 42 / 100\n",
      "1.6766251019529395\n",
      "j / Diter = 43 / 100\n",
      "1.6754966328039715\n",
      "j / Diter = 44 / 100\n",
      "1.6764256658170047\n",
      "j / Diter = 45 / 100\n",
      "1.6751517021536428\n",
      "j / Diter = 46 / 100\n",
      "1.6761056319872538\n",
      "j / Diter = 47 / 100\n",
      "1.6750005020255663\n",
      "j / Diter = 48 / 100\n",
      "1.676044905422539\n",
      "j / Diter = 49 / 100\n",
      "1.6746302870633971\n",
      "j / Diter = 50 / 100\n",
      "1.675746611858669\n",
      "j / Diter = 51 / 100\n",
      "1.6740694913707796\n",
      "j / Diter = 52 / 100\n",
      "1.6754340922910405\n",
      "j / Diter = 53 / 100\n",
      "1.6743820668820062\n",
      "j / Diter = 54 / 100\n",
      "1.675485621025036\n",
      "j / Diter = 55 / 100\n",
      "1.6743172272123565\n",
      "j / Diter = 56 / 100\n",
      "1.6753400202720397\n",
      "j / Diter = 57 / 100\n",
      "1.6739695401820338\n",
      "j / Diter = 58 / 100\n",
      "1.6749879282254438\n",
      "j / Diter = 59 / 100\n",
      "1.6736381381464462\n",
      "j / Diter = 60 / 100\n",
      "1.674708108233798\n",
      "j / Diter = 61 / 100\n",
      "1.673335121548365\n",
      "j / Diter = 62 / 100\n",
      "1.6742497969277297\n",
      "j / Diter = 63 / 100\n",
      "1.673316689319791\n",
      "j / Diter = 64 / 100\n",
      "1.6741378809670981\n",
      "j / Diter = 65 / 100\n",
      "1.673047744368311\n",
      "j / Diter = 66 / 100\n",
      "1.673889648169279\n",
      "j / Diter = 67 / 100\n",
      "1.6727636722018042\n",
      "j / Diter = 68 / 100\n",
      "1.673628890736503\n",
      "j / Diter = 69 / 100\n",
      "1.672451794332026\n",
      "j / Diter = 70 / 100\n",
      "1.6736151443587408\n",
      "j / Diter = 71 / 100\n",
      "1.6723438050196722\n",
      "j / Diter = 72 / 100\n",
      "1.6734578784989433\n",
      "j / Diter = 73 / 100\n",
      "1.6719990177621171\n",
      "j / Diter = 74 / 100\n",
      "1.6730863132127902\n",
      "j / Diter = 75 / 100\n",
      "1.6718179737543262\n",
      "j / Diter = 76 / 100\n",
      "1.6728586615938128\n",
      "j / Diter = 77 / 100\n",
      "1.6714738596602148\n",
      "j / Diter = 78 / 100\n",
      "1.6729013819292367\n",
      "j / Diter = 79 / 100\n",
      "1.6715398221402555\n",
      "j / Diter = 80 / 100\n",
      "1.6728510414055007\n",
      "j / Diter = 81 / 100\n",
      "1.671381845758922\n",
      "j / Diter = 82 / 100\n",
      "1.6725756149916422\n",
      "j / Diter = 83 / 100\n",
      "1.6710577393144104\n",
      "j / Diter = 84 / 100\n",
      "1.6724786010719614\n",
      "j / Diter = 85 / 100\n",
      "1.6709180349445625\n",
      "j / Diter = 86 / 100\n",
      "1.6722225806292366\n",
      "j / Diter = 87 / 100\n",
      "1.6708224840527754\n",
      "j / Diter = 88 / 100\n",
      "1.67242207443505\n",
      "j / Diter = 89 / 100\n",
      "1.6709471527411013\n",
      "j / Diter = 90 / 100\n",
      "1.6723997301833575\n",
      "j / Diter = 91 / 100\n",
      "1.6708172611568286\n",
      "j / Diter = 92 / 100\n",
      "1.6721338219725328\n",
      "j / Diter = 93 / 100\n",
      "1.67065377262896\n",
      "j / Diter = 94 / 100\n",
      "1.671999255131031\n",
      "j / Diter = 95 / 100\n",
      "1.6704826293497168\n",
      "j / Diter = 96 / 100\n",
      "1.6719184977667672\n",
      "j / Diter = 97 / 100\n",
      "1.6704295483070222\n",
      "j / Diter = 98 / 100\n",
      "1.67161725461483\n",
      "j / Diter = 99 / 100\n",
      "1.670200489735806\n",
      "j / Diter = 100 / 100\n",
      "1.6713562308058227\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 100\n",
      "len(trn_loader) = 128\n",
      "j / Giter = 1 / 1\n",
      "errG = tensor(0.0291, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "run_time = 13.126873668034872\n",
      "[  2/150][101/128] [    3] (13.13 m) MMD2_D 0.001123 hinge -0.000245 L2_AE_X 0.012300 L2_AE_Y 0.059435 loss_D -0.544282 Loss_G 0.029139 f_X 0.000000 f_Y -0.001472 |gD| 352.5367 |gG| 0.2717\n",
      "Optimize over NetD\n",
      "gen_iterations = 3\n",
      "j / Diter = 1 / 100\n",
      "1.6685106599834603\n",
      "j / Diter = 2 / 100\n",
      "1.666046879934461\n",
      "j / Diter = 3 / 100\n",
      "1.6666053303149568\n",
      "j / Diter = 4 / 100\n",
      "1.6650496301704278\n",
      "j / Diter = 5 / 100\n",
      "1.6656184760972983\n",
      "j / Diter = 6 / 100\n",
      "1.6640592899587419\n",
      "j / Diter = 7 / 100\n",
      "1.6648265701251677\n",
      "j / Diter = 8 / 100\n",
      "1.66318315761524\n",
      "j / Diter = 9 / 100\n",
      "1.6639059719632152\n",
      "j / Diter = 10 / 100\n",
      "1.6620530892204453\n",
      "j / Diter = 11 / 100\n",
      "1.6630814617627288\n",
      "j / Diter = 12 / 100\n",
      "1.6610099455046523\n",
      "j / Diter = 13 / 100\n",
      "1.6621172330684817\n",
      "j / Diter = 14 / 100\n",
      "1.6601426232120264\n",
      "j / Diter = 15 / 100\n",
      "1.6613283293034002\n",
      "j / Diter = 16 / 100\n",
      "1.659109193569905\n",
      "j / Diter = 17 / 100\n",
      "1.660546044455063\n",
      "j / Diter = 18 / 100\n",
      "1.6585564786388027\n",
      "j / Diter = 19 / 100\n",
      "1.6599502499557373\n",
      "j / Diter = 20 / 100\n",
      "1.6580440532714926\n",
      "j / Diter = 21 / 100\n",
      "1.659471711476644\n",
      "j / Diter = 22 / 100\n",
      "1.6575064468891063\n",
      "j / Diter = 23 / 100\n",
      "1.6589703433393483\n",
      "j / Diter = 24 / 100\n",
      "1.656881745530184\n",
      "j / Diter = 25 / 100\n",
      "1.6587436060792224\n",
      "j / Diter = 26 / 100\n",
      "1.6563964065752532\n",
      "j / Diter = 27 / 100\n",
      "1.655299784317417\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 128\n",
      "len(trn_loader) = 128\n",
      "Breaking from the Generator training loop\n",
      "run_time = 13.790405834846508\n",
      "[  2/150][128/128] [    3] (13.79 m) MMD2_D 0.001015 hinge -0.000223 L2_AE_X 0.032475 L2_AE_Y 0.059094 loss_D -0.704266 Loss_G 0.029139 f_X -0.000000 f_Y -0.001408 |gD| 1443.4861 |gG| 0.2717\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch = 4 / 150\n",
      "----------------------------------------------- \n",
      "\n",
      "len(trn_loader) = 128\n",
      "Optimize over NetD\n",
      "gen_iterations = 3\n",
      "j / Diter = 1 / 100\n",
      "1.660111037224375\n",
      "max(x[0]) = [0.10859764]\n",
      "max(y[0]) = [0.92332596]\n",
      "min(x[0]) = [0.]\n",
      "min(y[0]) = [0.]\n",
      "len(real_plot) - nonzero elements = 1838865\n",
      "len(recon_plot) - nonzero elements = 839574\n",
      "max(real_plot) = 0.10859764\n",
      "max(recon_plot) = 0.92332596\n",
      "min(real_plot) = 4.062938e-20\n",
      "min(recon_plot) = 1.9744039e-07\n",
      "real_ae_cube max = 0.09599002, min = 0.0\n",
      "noise_ae_cube max = 0.90451837, min = 0.0\n",
      "noise_gen_cube max = 0.92332596, min = 0.0\n",
      "real_cube max = 0.10859764, min = 0.0\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 1.4124759207974045\n",
      "s max = 4.7995008528232574\n",
      "s min = 0.9232519194483757\n",
      "\n",
      "Reconstructed, AutoEncoder Generated Noise-Input Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 12.840149502240726\n",
      "s max = 45.22591829299927\n",
      "s min = 8.55785682797432\n",
      "\n",
      "Noise-Input Generated Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 14.156392043971703\n",
      "s max = 46.16629779338837\n",
      "s min = 9.952503442764282\n",
      "\n",
      "Real Cube\n",
      "Plotting s (= norm_multiply * data_1dim) stats:\n",
      "s mean = 0.375486174849304\n",
      "s max = 5.429882183670998\n",
      "s min = 0.024345832935068756\n",
      "j / Diter = 2 / 100\n",
      "1.6573080263312119\n",
      "j / Diter = 3 / 100\n",
      "1.6551015960673492\n",
      "j / Diter = 4 / 100\n",
      "1.6528818378200778\n",
      "j / Diter = 5 / 100\n",
      "1.6507469576257499\n",
      "j / Diter = 6 / 100\n",
      "1.6496983221335004\n",
      "j / Diter = 7 / 100\n",
      "1.6484271515276014\n",
      "j / Diter = 8 / 100\n",
      "1.6494955648799787\n",
      "j / Diter = 9 / 100\n",
      "1.6484673041563767\n",
      "j / Diter = 10 / 100\n",
      "1.6491909344178026\n",
      "j / Diter = 11 / 100\n",
      "1.648302075206017\n",
      "j / Diter = 12 / 100\n",
      "1.6489362589275565\n",
      "j / Diter = 13 / 100\n",
      "1.6482089546126157\n",
      "j / Diter = 14 / 100\n",
      "1.6489478171626224\n",
      "j / Diter = 15 / 100\n",
      "1.6480385426319006\n",
      "j / Diter = 16 / 100\n",
      "1.6483902925207874\n",
      "j / Diter = 17 / 100\n",
      "1.6475657637993895\n",
      "j / Diter = 18 / 100\n",
      "1.6481337929728037\n",
      "j / Diter = 19 / 100\n",
      "1.6476516669988632\n",
      "j / Diter = 20 / 100\n",
      "1.647887097927103\n",
      "j / Diter = 21 / 100\n",
      "1.6475392817264765\n",
      "j / Diter = 22 / 100\n",
      "1.6475750335097017\n",
      "j / Diter = 23 / 100\n",
      "1.6475697490248349\n",
      "j / Diter = 24 / 100\n",
      "1.6472051950148594\n",
      "j / Diter = 25 / 100\n",
      "1.6473327469943193\n",
      "j / Diter = 26 / 100\n",
      "1.6468940917631332\n",
      "j / Diter = 27 / 100\n",
      "1.6468847434894711\n",
      "j / Diter = 28 / 100\n",
      "1.6466782378684046\n",
      "j / Diter = 29 / 100\n",
      "1.6467900107546551\n",
      "j / Diter = 30 / 100\n",
      "1.6461264826085447\n",
      "j / Diter = 31 / 100\n",
      "1.646521571770455\n",
      "j / Diter = 32 / 100\n",
      "1.645780326667767\n",
      "j / Diter = 33 / 100\n",
      "1.6463006579357644\n",
      "j / Diter = 34 / 100\n",
      "1.6457027136561382\n",
      "j / Diter = 35 / 100\n",
      "1.6462032410960932\n",
      "j / Diter = 36 / 100\n",
      "1.645883839765041\n",
      "j / Diter = 37 / 100\n",
      "1.6469149948877582\n",
      "j / Diter = 38 / 100\n",
      "1.646436030654179\n",
      "j / Diter = 39 / 100\n",
      "1.6470908914293563\n",
      "j / Diter = 40 / 100\n",
      "1.6465735248601918\n",
      "j / Diter = 41 / 100\n",
      "1.6473739683910569\n",
      "j / Diter = 42 / 100\n",
      "1.6467429458672274\n",
      "j / Diter = 43 / 100\n",
      "1.6475250906539414\n",
      "j / Diter = 44 / 100\n",
      "1.6467847784827738\n",
      "j / Diter = 45 / 100\n",
      "1.647677263743441\n",
      "j / Diter = 46 / 100\n",
      "1.6468451547957694\n",
      "j / Diter = 47 / 100\n",
      "1.6478581322687809\n",
      "j / Diter = 48 / 100\n",
      "1.6468990960599104\n",
      "j / Diter = 49 / 100\n",
      "1.647768102135769\n",
      "j / Diter = 50 / 100\n",
      "1.6469265280632852\n",
      "j / Diter = 51 / 100\n",
      "1.6478140199625935\n",
      "j / Diter = 52 / 100\n",
      "1.6471555486287035\n",
      "j / Diter = 53 / 100\n",
      "1.648088345879234\n",
      "j / Diter = 54 / 100\n",
      "1.6470707498747728\n",
      "j / Diter = 55 / 100\n",
      "1.647967861879856\n",
      "j / Diter = 56 / 100\n",
      "1.6470729611831072\n",
      "j / Diter = 57 / 100\n",
      "1.6479556146822019\n",
      "j / Diter = 58 / 100\n",
      "1.6469269629763037\n",
      "j / Diter = 59 / 100\n",
      "1.64805253256451\n",
      "j / Diter = 60 / 100\n",
      "1.6470027770044582\n",
      "j / Diter = 61 / 100\n",
      "1.6482307986436386\n",
      "j / Diter = 62 / 100\n",
      "1.6471135783141677\n",
      "j / Diter = 63 / 100\n",
      "1.6483507365793795\n",
      "j / Diter = 64 / 100\n",
      "1.647511717442716\n",
      "j / Diter = 65 / 100\n",
      "1.6483228126448901\n",
      "j / Diter = 66 / 100\n",
      "1.647371680411183\n",
      "j / Diter = 67 / 100\n",
      "1.64825917248215\n",
      "j / Diter = 68 / 100\n",
      "1.6473395017313799\n",
      "j / Diter = 69 / 100\n",
      "1.6483065440919664\n",
      "j / Diter = 70 / 100\n",
      "1.6472786963646797\n",
      "j / Diter = 71 / 100\n",
      "1.6483511022761859\n",
      "j / Diter = 72 / 100\n",
      "1.6472766188859413\n",
      "j / Diter = 73 / 100\n",
      "1.6482306839611036\n",
      "j / Diter = 74 / 100\n",
      "1.6470789217686914\n",
      "j / Diter = 75 / 100\n",
      "1.6480407986724586\n",
      "j / Diter = 76 / 100\n",
      "1.6470170026274165\n",
      "j / Diter = 77 / 100\n",
      "1.647991706190151\n",
      "j / Diter = 78 / 100\n",
      "1.6468896133447783\n",
      "j / Diter = 79 / 100\n",
      "1.6480002123376598\n",
      "j / Diter = 80 / 100\n",
      "1.6468337001097177\n",
      "j / Diter = 81 / 100\n",
      "1.6477895273274674\n",
      "j / Diter = 82 / 100\n",
      "1.6467038931135998\n",
      "j / Diter = 83 / 100\n",
      "1.6475487449045838\n",
      "j / Diter = 84 / 100\n",
      "1.646416906131211\n",
      "j / Diter = 85 / 100\n",
      "1.6475501546532298\n",
      "j / Diter = 86 / 100\n",
      "1.6461941210565016\n",
      "j / Diter = 87 / 100\n",
      "1.6476720581706772\n",
      "j / Diter = 88 / 100\n",
      "1.646334463091039\n",
      "j / Diter = 89 / 100\n",
      "1.6474034177496077\n",
      "j / Diter = 90 / 100\n",
      "1.6462987825875577\n",
      "j / Diter = 91 / 100\n",
      "1.6472694262609644\n",
      "j / Diter = 92 / 100\n",
      "1.6461260787528362\n",
      "j / Diter = 93 / 100\n",
      "1.647088222362824\n",
      "j / Diter = 94 / 100\n",
      "1.6460851769698293\n",
      "j / Diter = 95 / 100\n",
      "1.6470354755385583\n",
      "j / Diter = 96 / 100\n",
      "1.6459189820839424\n",
      "j / Diter = 97 / 100\n",
      "1.6469025217838367\n",
      "j / Diter = 98 / 100\n",
      "1.6457821411976983\n",
      "j / Diter = 99 / 100\n",
      "1.6466845239202181\n",
      "j / Diter = 100 / 100\n",
      "1.645592688027142\n",
      "\n",
      " Finished optimizing over NetD \n",
      "\n",
      "Optimize over NetG\n",
      "Giters = 1\n",
      "i = 100\n",
      "len(trn_loader) = 128\n",
      "j / Giter = 1 / 1\n",
      "errG = tensor(0.0333, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "run_time = 17.56284516218584\n",
      "[  3/150][101/128] [    4] (17.56 m) MMD2_D 0.001401 hinge -0.000248 L2_AE_X 0.011113 L2_AE_Y 0.058128 loss_D -0.520464 Loss_G 0.033323 f_X -0.000000 f_Y -0.001713 |gD| 119.3462 |gG| 0.3000\n",
      "Optimize over NetD\n",
      "gen_iterations = 4\n",
      "j / Diter = 1 / 100\n",
      "1.6436202585449853\n",
      "j / Diter = 2 / 100\n",
      "1.6419327955068268\n",
      "j / Diter = 3 / 100\n",
      "1.6411793281224147\n",
      "j / Diter = 4 / 100\n",
      "1.6417212874619003\n",
      "j / Diter = 5 / 100\n",
      "1.6409314959137529\n",
      "j / Diter = 6 / 100\n",
      "1.6415410374713875\n",
      "j / Diter = 7 / 100\n"
     ]
    }
   ],
   "source": [
    "time_loop = timeit.default_timer()\n",
    "print(\"time = \" + str(time_loop))\n",
    "\n",
    "gen_iterations = 0  # the code default is = 0\n",
    "\n",
    "# lists for tracking - Discriminator side\n",
    "mmd2_D_before_ReLU_list = []\n",
    "mmd2_D_after_ReLU_list = []\n",
    "one_side_errD_list = []\n",
    "L2_AE_X_D_list = []\n",
    "L2_AE_Y_D_list = []\n",
    "errD_list = []\n",
    "\n",
    "# lists for tracking - Generator side\n",
    "mmd2_G_before_ReLU_list = []\n",
    "mmd2_G_after_ReLU_list = []\n",
    "one_side_errG_list = []\n",
    "errG_list = []\n",
    "# errG = torch.Tensor(np.array(0.0))\n",
    "# print(errG.item())\n",
    "\n",
    "# lists for tracking count of nonzero voxels\n",
    "log_nonzero_recon_over_real_list = []\n",
    "\n",
    "# list for tracking gradient norms for generator and discriminator\n",
    "grad_norm_D = []\n",
    "grad_norm_G = []\n",
    "\n",
    "\n",
    "for t in range(max_iter):\n",
    "    print(\"\\n-----------------------------------------------\")\n",
    "    print(\"Epoch = \" + str(t+1) + \" / \" + str(max_iter))\n",
    "    print(\"----------------------------------------------- \\n\")\n",
    "    \n",
    "    data_iter = iter(trn_loader)\n",
    "    print(\"len(trn_loader) = \" + str(len(trn_loader)))\n",
    "    i = 0\n",
    "    plotted = 0\n",
    "    plotted_2 = 0\n",
    "    plotted_3 = 0\n",
    "    plotted_4 = 0   # grad norm plotting controller\n",
    "    \n",
    "    while (i < len(trn_loader)):\n",
    "        \n",
    "        # ---------------------------\n",
    "        #        Optimize over NetD\n",
    "        # ---------------------------\n",
    "        print(\"Optimize over NetD\")\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        What does the below if-else do?\n",
    "        Trains the discriminator for a lot more when the training\n",
    "        is starting, then switches to a more frequent generator\n",
    "        training regime.\n",
    "        \"\"\"\n",
    "        print(\"gen_iterations = \" + str(gen_iterations))\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "#         if gen_iterations < 5 or gen_iterations % 500 == 0:\n",
    "            Diters = 100\n",
    "            Giters = 1\n",
    "        else:\n",
    "            Diters = 5\n",
    "            Giters = 1\n",
    "\n",
    "        for j in range(Diters):\n",
    "            if i == len(trn_loader):\n",
    "                break\n",
    "\n",
    "            time_1 = time.time()\n",
    "            print(\"j / Diter = \" + str(j+1) + \" / \" + str(Diters))\n",
    "            # clamp parameters of NetD encoder to a cube\n",
    "            # do not clamp parameters of NetD decoder!!!\n",
    "            # exactly like numpy.clip()\n",
    "            \"\"\"\n",
    "            Given an interval, values outside the interval are clipped to the interval edges. \n",
    "            For example, if an interval of [0, 1] is specified, values smaller than 0 become 0, \n",
    "            and values larger than 1 become 1.\n",
    "            \n",
    "            Below code clamps the encoder parameters of the \n",
    "            dsicriminator between -0.01 and 0.01\n",
    "            \"\"\"\n",
    "            for p in netD.encoder.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            data = data_iter.next()\n",
    "#             print(\"data shape = \" + str(data.shape))\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            netD.zero_grad()\n",
    "\n",
    "#             x_cpu, _ = data\n",
    "            x_cpu = data\n",
    "            x = Variable(x_cpu.cuda().float())\n",
    "            batch_size = x.size(0)\n",
    "#             print(\"batch_size = \" + str(batch_size))\n",
    "\n",
    "            # output of the discriminator with real data input\n",
    "            \"\"\"\n",
    "            2097152^(1/3) = 128 (= one side of our cube so the\n",
    "            reconstructed cube is the same size as the original one)\n",
    "            This one just acts like an autoencoder\n",
    "            \"\"\"\n",
    "            f_enc_X_D, f_dec_X_D = netD(x)\n",
    "#             print(\"netD(x) outputs:\")\n",
    "#             print(\"f_enc_X_D size = \" + str(f_enc_X_D.size()))\n",
    "#             print(\"f_dec_X_D size = \" + str(f_dec_X_D.size()))\n",
    "#             print(\"f_dec_X_D min = \" + str(f_dec_X_D.min().item()))\n",
    "#             print(\"f_dec_X_D max = \" + str(f_dec_X_D.max().item()))\n",
    "#             print(\"f_dec_X_D mean = \" + str(f_dec_X_D.mean().item()))\n",
    "            \n",
    "\n",
    "            noise = torch.cuda.FloatTensor(batch_size, \n",
    "                                            nz, \n",
    "                                            1, \n",
    "                                            1,\n",
    "                                            1).normal_(0, 1)\n",
    "            with torch.no_grad():\n",
    "                #noise = Variable(noise, volatile=True)  # total freeze netG\n",
    "                noise = Variable(noise)\n",
    "#             print(\"noise shape = \" + str(noise.shape))\n",
    "\n",
    "            # output of the generator with noise input\n",
    "#             y = Variable(netG(noise).data)\n",
    "            y = Variable(netG(noise))\n",
    "#             print(\"y shape = \" + str(y.shape))\n",
    "#             print(\"y[0] shape = \" + str(y[0].shape))\n",
    "#             print(\"y[0][0] shape = \" + str(y[0][0].shape))\n",
    "#             sample_cube_viz = y[0][0].cpu().detach().numpy()\n",
    "#             print(\"sample_cube_viz shape = \" + str(sample_cube_viz.shape))\n",
    "        \n",
    "\n",
    "\n",
    "            # output of the discriminator with noise input\n",
    "            # this tests discriminator \n",
    "            f_enc_Y_D, f_dec_Y_D = netD(y)\n",
    "#             print(\"netD(y) outputs:\")\n",
    "#             print(\"f_enc_Y_D size = \" + str(f_enc_Y_D.size()))\n",
    "#             print(\"f_dec_Y_D size = \" + str(f_dec_Y_D.size()))\n",
    "#             print(\"f_dec_Y_D min = \" + str(f_dec_Y_D.min().item()))\n",
    "#             print(\"f_dec_Y_D max = \" + str(f_dec_Y_D.max().item()))\n",
    "#             print(\"f_dec_Y_D mean = \" + str(f_dec_Y_D.mean().item()))\n",
    "\n",
    "            # compute biased MMD2 and use ReLU to prevent negative value\n",
    "            mmd2_D = mix_rbf_mmd2(f_enc_X_D, \n",
    "                                  f_enc_Y_D, \n",
    "                                  sigma_list)\n",
    "#             mmd2_D = poly_mmd2(f_enc_X_D, f_enc_Y_D)\n",
    "#             mmd2_D = linear_mmd2(f_enc_X_D, f_enc_Y_D)\n",
    "            \n",
    "#             print(\"mmd2_D before ReLU = \" + str(mmd2_D.item()))\n",
    "            mmd2_D_before_ReLU_list.append(mmd2_D.item())\n",
    "            mmd2_D = F.relu(mmd2_D)\n",
    "#             print(\"mmd2_D after ReLU = \" + str(mmd2_D.item()))\n",
    "            mmd2_D_after_ReLU_list.append(mmd2_D.item())\n",
    "\n",
    "            # compute rank hinge loss\n",
    "            #print('f_enc_X_D:', f_enc_X_D.size())\n",
    "            #print('f_enc_Y_D:', f_enc_Y_D.size())\n",
    "            one_side_errD = one_sided(f_enc_X_D.mean(0) - f_enc_Y_D.mean(0))\n",
    "#             print(\"one_side_errD = \" + str(one_side_errD.item()))\n",
    "            one_side_errD_list.append(one_side_errD.item())\n",
    "            \n",
    "            # compute L2-loss of AE\n",
    "            \"\"\"\n",
    "            These L2 losses are decreasing like a standard optimization\n",
    "            which means that the autoencoder is learning how to encode\n",
    "            and decode using 3D convolutions.\n",
    "            x = real cube (x batch_size)\n",
    "            y = cube generated by the Generator with noise input\n",
    "            f_dec_X_D = AE reconstructed real cube\n",
    "            f_dec_Y_D = AE reconstructed noise-input cube\n",
    "            \"\"\"\n",
    "            L2_AE_X_D = match(x.view(batch_size, -1), f_dec_X_D, dist_ae)\n",
    "            L2_AE_Y_D = match(y.view(batch_size, -1), f_dec_Y_D, dist_ae)\n",
    "            \n",
    "#             print(\"L2-loss of AE, L2_AE_X_D = \" + str(L2_AE_X_D.item()))\n",
    "#             print(\"L2-loss of AE, L2_AE_Y_D = \" + str(L2_AE_Y_D.item()))\n",
    "            L2_AE_X_D_list.append(L2_AE_X_D.item())\n",
    "            L2_AE_Y_D_list.append(L2_AE_Y_D.item())\n",
    "            \n",
    "\n",
    "\n",
    "#             print(\"lambda_rg = \" + str(lambda_rg))\n",
    "            errD = torch.sqrt(mmd2_D) + lambda_rg * one_side_errD - lambda_AE_X * L2_AE_X_D - lambda_AE_Y * L2_AE_Y_D\n",
    "#             print(\"errD shape = \" + str(errD.shape))\n",
    "#             print(\"errD = \" + str(errD.item()))\n",
    "            errD_list.append(errD.item())\n",
    "            errD.backward(mone)\n",
    "            optimizerD.step()\n",
    "            \n",
    "            time_2 = time.time()  \n",
    "            time_2 = time_2 - time_1\n",
    "            time_2_list.append(time_2)\n",
    "            print(np.mean(np.array(time_2_list)))\n",
    "            \n",
    "            \n",
    "            # Plotting Discriminator Plots\n",
    "            if j % 5 == 0 and plotted < 1:\n",
    "                try:\n",
    "                    plt.figure(1, figsize = (10,5))\n",
    "                    plt.title(\"mmd2_D_before_ReLU_list\")\n",
    "                    plt.plot(mmd2_D_before_ReLU_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'mmd2_D_before_ReLU_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "#                     plt.show() \n",
    "                    plt.figure(2, figsize = (10,5))\n",
    "                    plt.title(\"mmd2_D_after_ReLU_list\")\n",
    "                    plt.plot(mmd2_D_after_ReLU_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'mmd2_D_after_ReLU_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(3, figsize = (10,5))\n",
    "                    plt.title(\"one_side_errD_list\")\n",
    "                    plt.plot(one_side_errD_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'one_side_errD_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(4, figsize = (10,5))\n",
    "                    plt.title(\"L2_AE_X_D_list\")\n",
    "                    plt.plot(L2_AE_X_D_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'L2_AE_X_D_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(5, figsize = (10,5))\n",
    "                    plt.title(\"L2_AE_Y_D_list\")\n",
    "                    plt.plot(L2_AE_Y_D_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'L2_AE_Y_D_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "                    plt.figure(6, figsize = (10,5))\n",
    "                    plt.title(\"errD_list - D loss goes to 0: failure mode\")\n",
    "                    plt.plot(errD_list)\n",
    "                    plt.savefig(redshift_fig_folder + 'errD_list_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show() \n",
    "\n",
    "                    # plot output of the discriminator with real data input\n",
    "                    # and output of the discriminator with noise input\n",
    "                    # on the same histogram \n",
    "                    recon_plot = y[0].cpu().view(-1,1).detach().numpy()\n",
    "                    real_plot = x[0].cpu().view(-1,1).detach().numpy()\n",
    "                    print(\"max(x[0]) = \" + str(max(real_plot)))\n",
    "                    print(\"max(y[0]) = \" + str(max(recon_plot)))\n",
    "                    print(\"min(x[0]) = \" + str(min(real_plot)))\n",
    "                    print(\"min(y[0]) = \" + str(min(recon_plot)))\n",
    "                    recon_plot = recon_plot[np.nonzero(recon_plot)]\n",
    "    #                 recon_plot = recon_plot[np.greater(recon_plot, 0)]\n",
    "                    real_plot = real_plot[np.nonzero(real_plot)]\n",
    "    #                 print(\"max(x[0] - nonzero) = \" + str(max(real_plot)))\n",
    "    #                 print(\"max(y[0] - nonzero) = \" + str(max(recon_plot)))\n",
    "    #                 print(\"min(x[0] - nonzero) = \" + str(min(real_plot)))\n",
    "    #                 print(\"min(y[0] - nonzero) = \" + str(min(recon_plot)))\n",
    "    #                 recon_plot = recon_plot + 1\n",
    "    #                 real_plot = real_plot + 1\n",
    "\n",
    "\n",
    "                    print(\"len(real_plot) - nonzero elements = \" + str(len(real_plot)))\n",
    "                    print(\"len(recon_plot) - nonzero elements = \" + str(len(recon_plot)))\n",
    "    #                 log_nonzero_real_list.append(len(real_plot))\n",
    "    #                 log_nonzero_recon_list.append(len(recon_plot))\n",
    "\n",
    "                    log_nonzero_recon_over_real_list.append(len(recon_plot) / len(real_plot))\n",
    "                    print(\"max(real_plot) = \" + str(max(real_plot)))\n",
    "                    print(\"max(recon_plot) = \" + str(max(recon_plot)))\n",
    "                    print(\"min(real_plot) = \" + str(min(real_plot)))\n",
    "                    print(\"min(recon_plot) = \" + str(min(recon_plot)))\n",
    "                    \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"Histograms of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\")\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\")\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'hist_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "                    \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"PDFs of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'pdf_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "\n",
    "#                     plt.figure(figsize = (16,8))\n",
    "#                     plt.title(\"Nonzero in Reconstructed Subcubes / Nonzero in Real Subcubes\")\n",
    "#                     plt.ylim(-0.0001, 10)\n",
    "#                     plt.plot(log_nonzero_recon_over_real_list, \n",
    "#                              color = \"blue\", \n",
    "#                              label = \"Nonzero in Reconstructed Subcubes / Nonzero in Real Subcubes\")\n",
    "#                     plt.show()  \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    Plotting the log histograms & PDF\n",
    "                    \"\"\"\n",
    "                    recon_plot = np.log(recon_plot)\n",
    "                    real_plot = np.log(real_plot)\n",
    "        \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"Histograms of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\")\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\")\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'hist_log_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "                    \n",
    "                    plt.figure(figsize = (16,8))\n",
    "                    plt.title(\"PDFs of Hydrogen\")\n",
    "                    plt.xlim(min(recon_plot.min(),real_plot.min()),\n",
    "                            max(recon_plot.max(),real_plot.max()))\n",
    "                    bins = np.linspace(min(recon_plot.min(),real_plot.min()),\n",
    "                                       max(recon_plot.max(),real_plot.max()), \n",
    "                                       100)\n",
    "                    plt.hist(recon_plot, bins = bins, \n",
    "                             color = \"red\" ,\n",
    "                             alpha= 0.5, \n",
    "                             label = \"Generator(Noise) Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.hist(real_plot, bins = bins, \n",
    "                             color = \"blue\" ,\n",
    "                             alpha = 0.3, \n",
    "                             label = \"Real Sample Subcube - Only Nonzero\",\n",
    "                             density = True)\n",
    "                    plt.legend()\n",
    "                    plt.savefig(redshift_fig_folder + 'pdf_log_' + str(t) + '.png', \n",
    "                                bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    #                     plt.show()\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                plotted = plotted + 1\n",
    "                \n",
    "                \n",
    "                \n",
    "            if plotted_2 < 1:\n",
    "                \n",
    "                # selecting a random cube from the batch\n",
    "                random_batch = random.randint(0,batch_size-1)\n",
    "                real_ae_cube = f_dec_X_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "                noise_ae_cube = f_dec_Y_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "                noise_gen_cube = y[random_batch][0].cpu().detach().numpy()\n",
    "                real_cube = x[random_batch][0].cpu().detach().numpy()\n",
    "                \n",
    "                # transforming the inputs for visualization\n",
    "                # to [0,1] interval for better plotting\n",
    "                # using the whole cube's min and max!!!\n",
    "                # not the subcube's!!!\n",
    "                real_ae_cube = (real_ae_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                noise_ae_cube = (noise_ae_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                noise_gen_cube = (noise_gen_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                real_cube = (real_cube - sampled_subcubes.min_val) / sampled_subcubes.max_val\n",
    "                \n",
    "                print(\"real_ae_cube max = \" + str(real_ae_cube.max()) + \", min = \" + str(real_ae_cube.min()))\n",
    "                print(\"noise_ae_cube max = \" + str(noise_ae_cube.max()) + \", min = \" + str(noise_ae_cube.min()))\n",
    "                print(\"noise_gen_cube max = \" + str(noise_gen_cube.max()) + \", min = \" + str(noise_gen_cube.min()))\n",
    "                print(\"real_cube max = \" + str(real_cube.max()) + \", min = \" + str(real_cube.min()))\n",
    "\n",
    "                print(\"\\nReconstructed, AutoEncoder Generated Real Cube\")\n",
    "#                 recon_real_viz = \n",
    "                visualize_cube(cube=real_ae_cube,      ## array name\n",
    "                                         edge_dim=real_ae_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder + 'recon_ae_real_' + str(t) + '.png')\n",
    "                \n",
    "                print(\"\\nReconstructed, AutoEncoder Generated Noise-Input Cube\")\n",
    "#                 recon_fake_viz = \n",
    "                visualize_cube(cube=noise_ae_cube,      ## array name\n",
    "                                         edge_dim=noise_ae_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder + 'recon_ae_noisegen_' + str(t) + '.png')\n",
    "                \n",
    "                print(\"\\nNoise-Input Generated Cube\")\n",
    "#                 sample_viz = \n",
    "                visualize_cube(cube=noise_gen_cube,      ## array name\n",
    "                                         edge_dim=noise_gen_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder + 'noisegen_' + str(t) + '.png')\n",
    "                \n",
    "                print(\"\\nReal Cube\")\n",
    "#                 real_viz = \n",
    "                visualize_cube(cube=real_cube,      ## array name\n",
    "                                         edge_dim=real_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = False,\n",
    "                                         save_fig = redshift_3dfig_folder +'real_' + str(t) + '.png')\n",
    "\n",
    "#             sample_viz.show()\n",
    "\n",
    "                plotted_2 = plotted_2 + 1 # to limit one 3d plotting per epoch\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "        print(\"\\n Finished optimizing over NetD \\n\")\n",
    "\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Optimize over NetG\n",
    "        # ---------------------------\n",
    "        \"\"\"\n",
    "        Because i is increased in each training loop for the\n",
    "        discriminitor, the below condition of if i == len(trn_loader)\n",
    "        is True in every epoch.\n",
    "        Should an i = 0 be added to the beginning of the netG optimization?\n",
    "        Look at paper to see how the training method is.\n",
    "        \"\"\"\n",
    "        print(\"Optimize over NetG\")\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        print(\"Giters = \" + str(Giters))\n",
    "        for j in range(Giters):\n",
    "            print(\"i = \" + str(i))\n",
    "            print(\"len(trn_loader) = \" + str(len(trn_loader)))\n",
    "            if i == len(trn_loader):\n",
    "                print(\"Breaking from the Generator training loop\")\n",
    "                break\n",
    "\n",
    "            print(\"j / Giter = \" + str(j+1) + \" / \" + str(Giters))\n",
    "            data = data_iter.next()\n",
    "            i += 1\n",
    "            netG.zero_grad()\n",
    "\n",
    "#             x_cpu, _ = data\n",
    "            x_cpu = data\n",
    "            x = Variable(x_cpu.cuda().float())\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            # output of discriminator with real input\n",
    "            f_enc_X, f_dec_X = netD(x)\n",
    "\n",
    "            noise = torch.cuda.FloatTensor(batch_size, \n",
    "                                           nz, \n",
    "                                           1,\n",
    "                                           1,\n",
    "                                           1).normal_(0, 1)\n",
    "            noise = Variable(noise)\n",
    "            \n",
    "            # output of the generator with noise input\n",
    "            y = netG(noise)\n",
    "\n",
    "            # output of the discriminator with noise input\n",
    "            f_enc_Y, f_dec_Y = netD(y)\n",
    "\n",
    "            # compute biased MMD2 and use ReLU to prevent negative value\n",
    "            mmd2_G = mix_rbf_mmd2(f_enc_X, f_enc_Y, sigma_list)\n",
    "#             mmd2_G = poly_mmd2(f_enc_X, f_enc_Y)\n",
    "#             mmd2_G = linear_mmd2(f_enc_X, f_enc_Y)\n",
    "    \n",
    "            mmd2_G_before_ReLU_list.append(mmd2_G)\n",
    "            mmd2_G = F.relu(mmd2_G)\n",
    "            mmd2_G_after_ReLU_list.append(mmd2_G)\n",
    "\n",
    "            # compute rank hinge loss\n",
    "            one_side_errG = one_sided(f_enc_X.mean(0) - f_enc_Y.mean(0))\n",
    "            one_side_errG_list.append(one_side_errG)\n",
    "\n",
    "            errG = torch.sqrt(mmd2_G) + lambda_rg * one_side_errG\n",
    "            print(\"errG = \" + str(errG))\n",
    "#             print(\"one = \") + str(one)\n",
    "            errG_list.append(errG.item())\n",
    "            errG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "            \n",
    "            if plotted_3 < 1:\n",
    "                # plotting Generator plots\n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"mmd2_G_before_ReLU_list\")\n",
    "                plt.plot(mmd2_G_before_ReLU_list)\n",
    "                plt.savefig(redshift_fig_folder + 'mmd2_G_before_ReLU_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                    #                 plt.show() \n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"mmd2_G_after_ReLU_list\")\n",
    "                plt.plot(mmd2_G_after_ReLU_list)\n",
    "                plt.savefig(redshift_fig_folder + 'mmd2_G_after_ReLU_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                #                 plt.show() \n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"one_side_errG_list\")\n",
    "                plt.plot(one_side_errG_list)\n",
    "                plt.savefig(redshift_fig_folder + 'one_side_errG_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                #                 plt.show() \n",
    "                plt.figure(figsize = (10,5))\n",
    "                plt.title(\"errG_list\")\n",
    "                plt.plot(errG_list)\n",
    "                plt.savefig(redshift_fig_folder + 'errG_list_' + str(t) + '.png', \n",
    "                            bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                #                 plt.show()            \n",
    "            \n",
    "                plotted_3 = plotted_3 + 1\n",
    "\n",
    "        run_time = (timeit.default_timer() - time_loop) / 60.0\n",
    "        print(\"run_time = \" + str(run_time))\n",
    "        try:\n",
    "            print('[%3d/%3d][%3d/%3d] [%5d] (%.2f m) MMD2_D %.6f hinge %.6f L2_AE_X %.6f L2_AE_Y %.6f loss_D %.6f Loss_G %.6f f_X %.6f f_Y %.6f |gD| %.4f |gG| %.4f'\n",
    "    #                   % (t, max_iter, i, len(trn_loader), gen_iterations, run_time,\n",
    "    #                      mmd2_D.data[0], one_side_errD.data[0],\n",
    "    #                      L2_AE_X_D.data[0], L2_AE_Y_D.data[0],\n",
    "    #                      errD.data[0], errG.data[0],\n",
    "    #                      f_enc_X_D.mean().data[0], f_enc_Y_D.mean().data[0],\n",
    "    #                      grad_norm(netD), grad_norm(netG)))\n",
    "                % (t, max_iter, i, len(trn_loader), gen_iterations, run_time,\n",
    "                     mmd2_D.item(), one_side_errD.item(),\n",
    "                     L2_AE_X_D.item(), L2_AE_Y_D.item(),\n",
    "                     errD.item(), errG.item(),\n",
    "                     f_enc_X_D.mean().item(), f_enc_Y_D.mean().item(),\n",
    "                     grad_norm(netD), grad_norm(netG)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "#         if gen_iterations % 500 == 0:\n",
    "#             y_fixed = netG(fixed_noise)\n",
    "#             y_fixed.data = y_fixed.data.mul(0.5).add(0.5)\n",
    "#             f_dec_X_D = f_dec_X_D.view(f_dec_X_D.size(0), args.nc, args.image_size, args.image_size)\n",
    "#             f_dec_X_D.data = f_dec_X_D.data.mul(0.5).add(0.5)\n",
    "#             vutils.save_image(y_fixed.data, '{0}/fake_samples_{1}.png'.format(args.experiment, gen_iterations))\n",
    "#             vutils.save_image(f_dec_X_D.data, '{0}/decode_samples_{1}.png'.format(args.experiment, gen_iterations))\n",
    "\n",
    "        # plotting gradient norms for monitoring\n",
    "        grad_norm_D.append(grad_norm(netD))\n",
    "        grad_norm_G.append(grad_norm(netG))\n",
    "        \n",
    "        if plotted_4 < 1:\n",
    "            plt.figure(figsize = (10,5))\n",
    "            plt.title(\"grad_norms - if they are over 100 things are screwing up\")\n",
    "            plt.plot(grad_norm_D, \n",
    "                     color = \"red\", \n",
    "                     label = \"grad_norm_D\")\n",
    "            plt.plot(grad_norm_G, \n",
    "                     color = \"blue\", \n",
    "                     label = \"grad_norm_G\")\n",
    "            plt.legend()\n",
    "            plt.savefig(redshift_fig_folder + 'grad_norms_' + str(t) + '.png', \n",
    "                        bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            #             plt.show()\n",
    "            \n",
    "            plotted_4 = plotted_4 + 1\n",
    "\n",
    "\n",
    "    if t % save_model_every == 0:\n",
    "        torch.save(netG.state_dict(), \n",
    "                   '{0}/netG_iter_{1}.pth'.format(experiment, t))\n",
    "        torch.save(netD.state_dict(), \n",
    "                   '{0}/netD_iter_{1}.pth'.format(experiment, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_testing == False:\n",
    "    assert(False, \"Stopping here, because not in testing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The folder models were saved in: \" + str(experiment))\n",
    "model_files = [f for f in listdir(experiment) if isfile(join(experiment, f))]\n",
    "model_files\n",
    "\n",
    "netG_files = [f for f in model_files if \"netG\" in f]\n",
    "netG_files\n",
    "\n",
    "max_iter_netG = max(netG_files, key=lambda x: int(x[10:-4]))\n",
    "max_iter_netG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = nz\n",
    "G_decoder = Decoder(cube_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "\n",
    "netG_test = NetG(G_decoder)\n",
    "# print(\"netG:\", netG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_test.load_state_dict(torch.load(experiment + max_iter_netG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netG_test.eval()\n",
    "netG_test.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Cube with Trained Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.cuda.FloatTensor(1, \n",
    "                                nz, \n",
    "                                1, \n",
    "                                1,\n",
    "                                1).normal_(0, 1)\n",
    "noise.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = Variable(noise)\n",
    "\n",
    "    # output of the generator with noise input\n",
    "    y = netG_test(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_batch = random.randint(0,batch_size-1)\n",
    "noise_gen_cube = y[0][0].cpu().detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noise-Input Generated Cube\")\n",
    "#                 sample_viz = \n",
    "visualize_cube(cube=noise_gen_cube,      ## array name\n",
    "                         edge_dim=noise_gen_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                         start_cube_index_x=0,\n",
    "                         start_cube_index_y=0,\n",
    "                         start_cube_index_z=0,\n",
    "                         fig_size=(10,10),\n",
    "                         stdev_to_white=-2,\n",
    "                         norm_multiply=viz_multiplier,\n",
    "                         color_map=\"Blues\",\n",
    "                         plot_show = True,\n",
    "                         save_fig = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file = testing_folder + \"noise_gen_cube\",\n",
    "    arr = noise_gen_cube,\n",
    "    allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a real subcube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcd = define_test(s_test = 1024,\n",
    "                     s_train = 128)\n",
    "print(testcd)\n",
    "\n",
    "trial_sample = get_samples(s_sample = 128, \n",
    "                            nsamples = 1, \n",
    "#                             h5_filename = redshift_file, \n",
    "                            test_coords = testcd,\n",
    "                            f = f)\n",
    "trial_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Sampled Cube\")\n",
    "#                 sample_viz = \n",
    "visualize_cube(cube=trial_sample[0],      ## array name\n",
    "                         edge_dim=trial_sample[0].shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                         start_cube_index_x=0,\n",
    "                         start_cube_index_y=0,\n",
    "                         start_cube_index_z=0,\n",
    "                         fig_size=(10,10),\n",
    "                         stdev_to_white=-2,\n",
    "                         norm_multiply=viz_multiplier,\n",
    "                         color_map=\"Blues\",\n",
    "                         plot_show = True,\n",
    "                         save_fig = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file = testing_folder + \"real_cube\",\n",
    "    arr = trial_sample[0],\n",
    "    allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Generated vs. Real with Power Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pyfftw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd seda_pylians/Pylians\n",
    "# import Pk_library as PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
