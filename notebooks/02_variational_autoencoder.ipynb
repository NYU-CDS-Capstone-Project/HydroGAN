{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from: https://github.com/pytorch/examples/tree/master/vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify to accept hard coded arguments\n",
    "batch_size = 8\n",
    "epochs = 20\n",
    "no_cuda = False\n",
    "log_interval = 1\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "# cuda = False\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_test(s_test, s_train):\n",
    "    #2048/16=128\n",
    "    m=8\n",
    "    x=random.randint(0,m)*s_train\n",
    "    y=random.randint(0,m)*s_train\n",
    "    z=random.randint(0,m)*s_train\n",
    "    #print(x,y,z)\n",
    "    return {'x':[x,x+s_test], 'y':[y,y+s_test], 'z':[z,z+s_test]}\n",
    "\n",
    "def check_coords(test_coords, train_coords):\n",
    "    valid=True\n",
    "    for i in ['x','y','z']:\n",
    "        r=(max(test_coords[i][0], \n",
    "               train_coords[i][0]), \n",
    "           min(test_coords[i][1],\n",
    "               train_coords[i][1]))\n",
    "        if r[0]<=r[1]:\n",
    "            valid=False\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # getting the max of the whole cube\n",
    "# f = h5py.File('fields_z=1.0.hdf5', 'r')\n",
    "# f=f['delta_HI']\n",
    "# #print(f.shape)\n",
    "# max_list = []\n",
    "# for i in range(f.shape[0]):\n",
    "#     #print(np.max(f[i:i+1,:,:]))\n",
    "#     max_list.append(np.max(f[i:i+1,:,:]))\n",
    "# max(max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samples(s_sample, nsamples, redshift, test_coords):\n",
    "    #n is size of minibatch, get valid samples (not intersecting with test_coords)\n",
    "    sample_list=[]\n",
    "    m=2048-128\n",
    "    for n in range(nsamples):\n",
    "        #print(\"Sample No = \" + str(n + 1) + \" / \" + str(nsamples))\n",
    "        sample_valid=False\n",
    "        while sample_valid==False:\n",
    "            x = random.randint(0,m)\n",
    "            y = random.randint(0,m)\n",
    "            z = random.randint(0,m)\n",
    "            sample_coords = {'x':[x,x+s_sample], \n",
    "                             'y':[y,y+s_sample], \n",
    "                             'z':[z,z+s_sample]}\n",
    "            \n",
    "            sample_valid = check_coords(test_coords, \n",
    "                                        sample_coords)\n",
    "        \n",
    "        sample_list.append(sample_coords)\n",
    "    \n",
    "    print(\"Sampling finished.\")\n",
    "        \n",
    "    #Load cube and get samples and convert them to np.arrays\n",
    "    sample_array=[]\n",
    "    datapath=''\n",
    "    f = h5py.File(datapath+'fields_z='+redshift+'.hdf5', 'r')\n",
    "    f=f['delta_HI']\n",
    "    \n",
    "    # getting the max of the whole cube\n",
    "    #print(f.shape)\n",
    "    max_list = []\n",
    "    for i in range(f.shape[0]):\n",
    "        #print(np.max(f[i:i+1,:,:]))\n",
    "        max_list.append(np.max(f[i:i+1,:,:]))\n",
    "    max_cube = max(max_list)\n",
    "    #f.close()\n",
    "    \n",
    "    print(\"Getting max value finished.\")\n",
    "    \n",
    "    counter = 0\n",
    "    for c in sample_list:\n",
    "        print(\"Counter = \" + str(counter + 1) + \" / \" + str(len(sample_list)))\n",
    "        a = f[c['x'][0]:c['x'][1],\n",
    "              c['y'][0]:c['y'][1],\n",
    "              c['z'][0]:c['z'][1]]\n",
    "        \n",
    "        # a = np.array(a)\n",
    "        a = np.array(a) / max_cube\n",
    "        sample_array.append(a)\n",
    "    \n",
    "        counter = counter + 1\n",
    "        \n",
    "    f=0\n",
    "    return sample_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_coords=define_test(1024,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=get_samples(128,1,'1.0',t_coords)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# a=get_samples(128,1,'1.0',t_coords)\n",
    "# len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HydrogenDataset2(Dataset):\n",
    "    \"\"\"Hydrogen Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, h5_file, root_dir, s_test, s_train,\n",
    "                 s_sample, nsamples, redshift):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h5_file (string): name of the h5 file with 32 sampled cubes.\n",
    "            root_dir (string): Directory with the .h5 file.\n",
    "        \"\"\"\n",
    "        file_size = os.path.getsize(root_dir + h5_file) / 1e6 # in MBs\n",
    "        print(\"The whole file size is \" + str(int(file_size)) + \" MBs\")\n",
    "        \n",
    "        # self.subcubes = h5py.File('../data/sample_32.h5', 'r')\n",
    "        self.subcubes = h5py.File(root_dir + h5_file, 'r')[\"delta_HI\"]\n",
    "        self.h5_file = h5_file\n",
    "        self.root_dir = root_dir\n",
    "        self.s_test = s_test\n",
    "        self.s_train = s_train\n",
    "        self.t_coords = define_test(self.s_test,\n",
    "                                    self.s_train)\n",
    "        self.s_sample = s_sample\n",
    "        self.nsamples = nsamples\n",
    "        self.redshift = redshift\n",
    "        \n",
    "        self.samples = get_samples(s_sample = self.s_sample,\n",
    "                             nsamples = self.nsamples,\n",
    "                             redshift = self.redshift,\n",
    "                             test_coords = self.t_coords)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Function called when len(self) is executed\n",
    "        \n",
    "        #print(len(self.subcubes))\n",
    "#         return len(self.nsamples)\n",
    "        return self.nsamples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This can be implemented in such a way that the whole h5 file read \n",
    "        using h5py.File() and get_sample() function is called to return\n",
    "        a random subcube. This won't increase memory usage because the\n",
    "        subcubes will be read in the same way and only the batch will\n",
    "        be read into memory.\n",
    "        \n",
    "        Here we have implemented it so that it can be used with data\n",
    "        generated by get_sample() function.\n",
    "        \n",
    "        The output of this function is one subcube with the dimensions\n",
    "        specified by get_sample() implementation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # default version -> error in training because of dimensions\n",
    "#         sample = self.subcubes[idx]\n",
    "        \n",
    "        # reshaped version to add another dimension\n",
    "#         sample = self.subcubes[idx].reshape((1,128,128,128))\n",
    "\n",
    "        # On prince using get_samples()\n",
    "#         print(\"nsamples = \" + str(self.nsamples))\n",
    "#         sample = get_samples(s_sample = self.s_sample,\n",
    "#                              nsamples = self.nsamples,\n",
    "#                              redshift = self.redshift,\n",
    "#                              test_coords = self.t_coords)\n",
    "    \n",
    "        sample = self.samples[idx].reshape((1,128,128,128))\n",
    "        \n",
    "        # added division by 1e6 for exploding variance\n",
    "        # and resulting in inf during reparametrization trick part\n",
    "        sample = sample/1e6\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HydrogenDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, h5_file, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h5_file (string): name of the h5 file with 32 sampled cubes.\n",
    "            root_dir (string): Directory with the .h5 file.\n",
    "        \"\"\"\n",
    "        file_size = os.path.getsize(root_dir + h5_file) / 1e6 # in MBs\n",
    "        print(\"The file size is \" + str(int(file_size)) + \" MBs\")\n",
    "        \n",
    "        # self.subcubes = h5py.File('../data/sample_32.h5', 'r')\n",
    "        self.subcubes = h5py.File(root_dir + h5_file, 'r')['sample32']\n",
    "        self.h5_file = h5_file\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        # Function called when len(self) is executed\n",
    "        \n",
    "        #print(len(self.subcubes))\n",
    "        return len(self.subcubes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This can be implemented in such a way that the whole h5 file read \n",
    "        using h5py.File() and get_sample() function is called to return\n",
    "        a random subcube. This won't increase memory usage because the\n",
    "        subcubes will be read in the same way and only the batch will\n",
    "        be read into memory.\n",
    "        \n",
    "        Here we have implemented it so that it can be used with data\n",
    "        generated by get_sample() function.\n",
    "        \n",
    "        The output of this function is one subcube with the dimensions\n",
    "        specified by get_sample() implementation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # default version -> error in training because of dimensions\n",
    "        #sample = self.subcubes[idx]\n",
    "        \n",
    "        # reshaped version to add another dimension\n",
    "        sample = self.subcubes[idx].reshape((1,128,128,128))\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled_subcubes = HydrogenDataset2(h5_file=\"fields_z=1.0.hdf5\",\n",
    "                                    root_dir = \"\",\n",
    "                                    s_test = 1024, \n",
    "                                    s_train = 128,\n",
    "                                    s_sample = 128, \n",
    "                                    nsamples = 256, \n",
    "                                    redshift = \"1.0\")\n",
    "# print(type(sampled_subcubes))\n",
    "# print(len(sampled_subcubes))\n",
    "# print(len(sampled_subcubes[0]))\n",
    "#print(len(sampled_subcubes[1]))\n",
    "# print(len(sampled_subcubes[0][0]))\n",
    "# print(len(sampled_subcubes[0][0][0]))\n",
    "#print(len(sampled_subcubes[1][0]))\n",
    "#sampled_subcubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file size is 268 MBs\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.HydrogenDataset at 0x11a0f0f28>"
      ]
     },
     "execution_count": 1515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_subcubes = HydrogenDataset(h5_file=\"sample_32.h5\",\n",
    "                                    root_dir = \"../data/\")\n",
    "print(len(sampled_subcubes))\n",
    "sampled_subcubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "train_loader = DataLoader(\n",
    "        dataset=sampled_subcubes,\n",
    "        #batch_size=args.batch_size, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        **kwargs)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        dataset=sampled_subcubes,\n",
    "        #batch_size=args.batch_size, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The Encoding Layers\n",
    "        nn.Conv3d \n",
    "        nn.MaxPool3d \n",
    "        \n",
    "        out_channels is the number of different filters we convolute \n",
    "        over the whole sampled subcube.\n",
    "        \n",
    "        So the first convolutional layer's in_channel should be 0 (?)\n",
    "        \n",
    "        In addition, the next layer's in_channel should be equal to\n",
    "        the previous layer's out_channels (all examples show that\n",
    "        this is the case)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convolutional Layer 1\n",
    "        self.encode_conv1 = nn.Conv3d(in_channels=1, \n",
    "                                      out_channels=8, \n",
    "                                      kernel_size=(4,4,4), # == 4\n",
    "                                      stride = (2,2,2), # == 2\n",
    "                                      padding=(1,1,1)) # == 1\n",
    "        nn.init.xavier_uniform_(self.encode_conv1.weight) #Xaviers Initialisation\n",
    "        \n",
    "        self.encode_relu1 = nn.ReLU()\n",
    "        self.encode_maxpool1 = nn.MaxPool3d(kernel_size=(2, 2, 2), \n",
    "                                             stride=(2, 2, 2),\n",
    "                                            return_indices = True)\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        self.encode_conv2 = nn.Conv3d(in_channels=8, \n",
    "                                      out_channels=16, \n",
    "                                      kernel_size=(4,4,4), # == 4 \n",
    "                                      stride = (2,2,2),\n",
    "                                      padding=(1,1,1))\n",
    "        nn.init.xavier_uniform_(self.encode_conv2.weight) #Xaviers Initialisation\n",
    "        \n",
    "        self.encode_relu2 = nn.ReLU()\n",
    "        self.encode_maxpool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), \n",
    "                                             stride=(2, 2, 2),\n",
    "                                            return_indices = True)\n",
    "\n",
    "        # Convolutional Layer 3\n",
    "        self.encode_conv3 = nn.Conv3d(in_channels=16, \n",
    "                                      out_channels=32, \n",
    "                                      kernel_size=(4,4,4), # == 4 \n",
    "                                      stride = (2,2,2),\n",
    "                                      padding=(1,1,1))\n",
    "        nn.init.xavier_uniform_(self.encode_conv3.weight) #Xaviers Initialisation\n",
    "        \n",
    "        self.encode_relu3 = nn.ReLU()\n",
    "#         self.encode_maxpool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), \n",
    "#                                              stride=(2, 2, 2),\n",
    "#                                             return_indices = True)\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Fully Connected Layers after 3D Convolutional Layers\n",
    "        First FC layer's input should be equal to \n",
    "        last convolutional layer's output\n",
    "        8192 = 8^3 * 16 \n",
    "            8^3 = (output of 2nd convolutional layer)\n",
    "            16 = number of out_channels\n",
    "        \"\"\"\n",
    "        \n",
    "#         self.encode_fc1 = nn.Sequential(\n",
    "#             nn.Linear(in_features=2048, \n",
    "#                       out_features=5096), \n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5))\n",
    "        \n",
    "        self.encode_fc1_linear = nn.Linear(in_features=2048, \n",
    "                                           out_features=128)\n",
    "        self.encode_fc1_relu = nn.ReLU()\n",
    "        self.encode_fc1_dropout = nn.Dropout(0.5)\n",
    "        nn.init.xavier_uniform_(self.encode_fc1_linear.weight) #Xaviers Initialisation\n",
    "\n",
    "        \n",
    "#         self.encode_fc2 = nn.Sequential(\n",
    "#             nn.Linear(in_features = 5096,\n",
    "#                       out_features = 5096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5))\n",
    "\n",
    "        self.encode_fc2_linear = nn.Linear(in_features=128, \n",
    "                                           out_features=128)\n",
    "        self.encode_fc2_relu = nn.ReLU()\n",
    "        self.encode_fc2_dropout = nn.Dropout(0.5)\n",
    "        nn.init.xavier_uniform_(self.encode_fc2_linear.weight) #Xaviers Initialisation\n",
    "        \n",
    "        \"\"\"\n",
    "        The last fully connected layer's output is the dimensions\n",
    "        of the embeddings?\n",
    "        \n",
    "        PyTorch VAE example uses output of 20 dimensions for mu &\n",
    "        logvariance\n",
    "        \"\"\"\n",
    "#         self.encode_fc31 = nn.Sequential(\n",
    "#             nn.Linear(in_features=5096,\n",
    "#                       out_features=20))\n",
    "        \n",
    "        self.encode_fc31_linear = nn.Linear(in_features=128, \n",
    "                                           out_features=10)\n",
    "        self.encode_fc31_relu = nn.ReLU()\n",
    "        self.encode_fc31_dropout = nn.Dropout(0.5)\n",
    "        nn.init.xavier_uniform_(self.encode_fc31_linear.weight) #Xaviers Initialisation\n",
    "\n",
    "        \n",
    "#         self.encode_fc32 = nn.Sequential(\n",
    "#             nn.Linear(in_features=5096,\n",
    "#                       out_features=20))\n",
    "\n",
    "        self.encode_fc32_linear = nn.Linear(in_features=128, \n",
    "                                           out_features=10)\n",
    "        self.encode_fc32_relu = nn.ReLU()\n",
    "        self.encode_fc32_dropout = nn.Dropout(0.5)\n",
    "        nn.init.xavier_uniform_(self.encode_fc32_linear.weight) #Xaviers Initialisation\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        The Decoding Layers\n",
    "        nn.Conv3d -> nn.ConvTranspose3d\n",
    "        nn.MaxPool3d -> nn.MaxUnpool3d\n",
    "        \"\"\"\n",
    "        \n",
    "        self.decode_fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=10,\n",
    "                      out_features=128))\n",
    "        \n",
    "        self.decode_fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=128, \n",
    "                      out_features=128), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #init.xavier_normal(self.fc1.state_dict()['weight'])\n",
    "        \n",
    "        self.decode_fc3 = nn.Sequential(\n",
    "            nn.Linear(in_features = 128,\n",
    "                      out_features = 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #init.xavier_normal(self.fc2.state_dict()['weight'])\n",
    "        \n",
    "        \n",
    "        self.decode_conv1 = nn.ConvTranspose3d(in_channels=32, \n",
    "                                              out_channels=16, \n",
    "                                              kernel_size=(4,4,4),\n",
    "                                              stride = (2,2,2),\n",
    "                                              padding=(1,1,1))\n",
    "        self.decode_relu1 = nn.ReLU()\n",
    "        self.decode_maxunpool1 = nn.MaxUnpool3d(kernel_size=(2, 2, 2), \n",
    "                                                     stride=(2, 2, 2))\n",
    "        #init.xavier_normal(self.group1.state_dict()['weight'])\n",
    "        \n",
    "        self.decode_conv2 = nn.ConvTranspose3d(in_channels=16, \n",
    "                                              out_channels=8, \n",
    "                                              kernel_size=(4,4,4),\n",
    "                                              stride = (2,2,2),\n",
    "                                              padding=(1,1,1))\n",
    "        self.decode_relu2 = nn.ReLU()\n",
    "        self.decode_maxunpool2 = nn.MaxUnpool3d(kernel_size=(2, 2, 2), \n",
    "                                                     stride=(2, 2, 2))\n",
    "        \n",
    "        self.decode_conv3 = nn.ConvTranspose3d(in_channels=8, \n",
    "                                              out_channels=1, \n",
    "                                              kernel_size=(4,4,4),\n",
    "                                              stride = (2,2,2),\n",
    "                                              padding=(1,1,1))\n",
    "        self.decode_relu3 = nn.ReLU()\n",
    "        self.decode_maxunpool3 = nn.MaxUnpool3d(kernel_size=(2, 2, 2), \n",
    "                                                     stride=(2, 2, 2))\n",
    "        \n",
    "        \n",
    "    # Encoding part of VAE\n",
    "    def encode(self, x):\n",
    "#         h1 = F.relu(self.fc1(x))\n",
    "#         return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "        print(\"Starting Encoding\")\n",
    "#         print(\"----------------------------\")\n",
    "        \n",
    "        out = self.encode_conv1(x)\n",
    "#         print(\"First Conv output shape = \" + str(out.shape))\n",
    "        #print(out.shape)\n",
    "        out = self.encode_relu1(out)\n",
    "#         print(\"First ReLU Layer output shape = \" + str(out.shape))\n",
    "        size1 = out.size()\n",
    "        out, ind1 = self.encode_maxpool1(out)\n",
    "#         print(\"First MaxPooling output shape = \" + str(out.shape))\n",
    "#         print(\"Ind1 shape = \" + str(ind1.shape))\n",
    "#         #print(\"Size1 = \" + str(size1))\n",
    "#         print(\"----------------------------\")\n",
    "        \n",
    "        out = self.encode_conv2(out)\n",
    "#         print(\"Second Conv output shape = \" + str(out.shape))\n",
    "        out = self.encode_relu2(out)\n",
    "#         print(\"Second ReLU Layer output shape = \" + str(out.shape))\n",
    "        size2 = out.size()\n",
    "        out, ind2 = self.encode_maxpool2(out)\n",
    "#         print(\"Second MaxPooling output shape = \" + str(out.shape))\n",
    "#         print(\"Ind2 shape = \" + str(ind2.shape))\n",
    "        #print(\"Size2 = \" + str(size2))\n",
    "#          print(\"----------------------------\")\n",
    "        \n",
    "        out = self.encode_conv3(out)\n",
    "#         print(\"Last Conv output shape = \" + str(out.shape))\n",
    "        out = self.encode_relu3(out)\n",
    "#         print(\"Last ReLU output shape = \" + str(out.shape))\n",
    "        size3 = out.size()\n",
    "#         out, ind3 = self.encode_maxpool3(out)\n",
    "#         print(\"Last Conv Layer output shape = \" + str(out.shape))\n",
    "#         print(\"Ind3 shape = \" + str(ind3.shape))\n",
    "        #print(\"Size3 = \" + str(size3))\n",
    "#         print(\"----------------------------\")\n",
    "\n",
    "        \"\"\"\n",
    "        From here on, the convolutional layers' output is flattened\n",
    "        into a rank 1 tensor of size x & put into a fully connected \n",
    "        network to output ??????\n",
    "        \n",
    "        https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "        PyTorch's own example uses just 2 fully-connected layers\n",
    "        to output mu and logvar predictions, below we use 3.\n",
    "        \"\"\"\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        \n",
    "        \n",
    "        # batch_size = 1 - WORKS\n",
    "#         out = out.view(1, -1)\n",
    "        # batch_size != 1\n",
    "        out = out.view(batch_size, -1)\n",
    "        print(out.shape)\n",
    "        \n",
    "#         print(\"Last Conv Layer output shape after reshaping \\n \\\n",
    "#                 (Input to first FC layer) = \" + str(out.shape))\n",
    "        \n",
    "#         out = self.encode_fc1(out)\n",
    "    \n",
    "        out = self.encode_fc1_linear(out)\n",
    "        out = self.encode_fc1_relu(out)\n",
    "        out = self.encode_fc1_dropout(out)\n",
    "        \n",
    "#         out = self.encode_fc2(out)\n",
    "\n",
    "        out = self.encode_fc2_linear(out)\n",
    "        out = self.encode_fc2_relu(out)\n",
    "        out = self.encode_fc2_dropout(out)\n",
    "        \n",
    "        \n",
    "#         out_mu = self.encode_fc31(out)\n",
    "        \n",
    "        out_mu = self.encode_fc31_linear(out)\n",
    "        out_mu = self.encode_fc31_relu(out_mu)\n",
    "        out_mu = self.encode_fc31_dropout(out_mu)\n",
    "        \n",
    "#         out_logvar = self.encode_fc32(out)\n",
    "\n",
    "        out_logvar = self.encode_fc32_linear(out)\n",
    "        out_logvar = self.encode_fc32_relu(out_logvar)\n",
    "        out_logvar = self.encode_fc32_dropout(out_logvar)\n",
    "        \n",
    "        print(\"Encode - Forward Pass Finished\")\n",
    "        print(out_mu.shape)\n",
    "        print(out_logvar.shape)\n",
    "#         print(\"----------------------------\")\n",
    "        \n",
    "#         return out_mu, out_logvar, [ind1,ind2,ind3], [size1,size2,size3]\n",
    "        return out_mu, out_logvar, [ind1,ind2], [size1,size2]\n",
    "    \n",
    "\n",
    "    # Reparametrization Trick\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        torch.exp = returns a new tensor with the exponential of \n",
    "                    the elements of input\n",
    "        rand_like = returns a tensor with the same size as input\n",
    "                    that is filled with random numbers from a normal\n",
    "                    distribution with mean 0 and variance 1\n",
    "        \n",
    "        \"\"\"\n",
    "#         print(\"Reparametrization...\")\n",
    "#         print(\"logvar (in reparametrization) = \\n\" + str(logvar))\n",
    "#         print(\"logvar (in reparametrization) = \\n\" + str(logvar*1e6))\n",
    "#         print(\"mu * 1e6 (in reparametrization) = \\n\" + str(mu))\n",
    "#         print(\"mu * 1e6 (in reparametrization) = \\n\" + str(mu*1e6))\n",
    "        \n",
    "        std = torch.exp(0.5*logvar)\n",
    "#         std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "#         print(\"0.5*logvar (in reparametrization) = \\n\" + str(0.5*logvar))\n",
    "#         print(\"std (in reparametrization) = \\n\" + str(std))\n",
    "#         print(\"eps (in reparametrization) = \\n\" + str(eps))\n",
    "         \n",
    "#         print(\"eps.mul(std).add_(mu) \\n \\\n",
    "#                 [This is the output from reparameterize()] =\\\n",
    "#                     \\n\" + str(eps.mul(std).add_(mu)))\n",
    "        \n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    \n",
    "    # Decoding part of VAE\n",
    "    def decode(self, z, indices_list, size_list):\n",
    "#         h3 = F.relu(self.fc3(z))\n",
    "#         return torch.sigmoid(self.fc4(h3))\n",
    "#         print(\"----------------------------\")\n",
    "        print(\"Starting Decoding\")\n",
    "#         print(\"z shape = \" + str(z.shape))\n",
    "        \n",
    "        out = self.decode_fc1(z)\n",
    "#         print(\"1st FC output shape = \" + str(out.shape))\n",
    "        out = self.decode_fc2(out)\n",
    "#         print(\"2nd FC output shape = \" + str(out.shape))\n",
    "        out = self.decode_fc3(out)\n",
    "#         print(\"Last FC output shape = \" + str(out.shape))\n",
    "        \n",
    "        # batch_size = 1 - WORKS\n",
    "#         out = out.view(1, 32, 4, 4, 4)\n",
    "        # batch_size != 1 \n",
    "        out = out.view(batch_size, 32, 4, 4, 4)        \n",
    "        \n",
    "        \n",
    "#         print(\"First Deconv input shape = \" + str(out.shape))\n",
    "#         print(\"After last convolution (encoding stage) output shape = \" +\\\n",
    "#                   str(indices_list[1].shape))\n",
    "        out = self.decode_conv1(out)\n",
    "#         print(\"First Deconv output shape = \" + str(out.shape))\n",
    "        out = self.decode_relu1(out)\n",
    "#         print(\"First ReLU output shape = \" + str(out.shape))\n",
    "        # maxunpooling needs indices\n",
    "\n",
    "#         out = self.decode_maxunpool1(out,\n",
    "#                              indices = indices_list[1])\n",
    "        out = self.decode_maxunpool1(out,\n",
    "                                     indices = indices_list[1],\n",
    "                                     output_size = size_list[1])\n",
    "#         print(\"2nd MaxUnpool ouput shape = \" + str(out.shape))\n",
    "        \n",
    "        out = self.decode_conv2(out)\n",
    "#         print(\"2nd Deconv output shape = \" + str(out.shape))\n",
    "        out = self.decode_relu2(out)\n",
    "#         print(\"2nd ReLU output shape = \" + str(out.shape))\n",
    "        out = self.decode_maxunpool1(out,\n",
    "                     indices = indices_list[0])\n",
    "#         out = self.decode_maxunpool2(out,\n",
    "#                                      indices= indices_list[1],\n",
    "#                                      output_size = size_list[1])\n",
    "        \n",
    "        out = self.decode_conv3(out)\n",
    "        out = self.decode_relu3(out)\n",
    "#         print(\"Last ReLU output shape = \" + str(out.shape))\n",
    "#         out = self.decode_maxunpool1(out,\n",
    "#                              indices = indices_list[0])\n",
    "        # there is no last maxunpool in https://github.com/pgtgrly/Convolution-Deconvolution-Network-Pytorch/blob/master/Neural_Network_Class.py\n",
    "#         out = self.decode_maxunpool2(out,\n",
    "#                                      indices= indices_list[0],\n",
    "#                                      output_size = size_list[0])\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "    # Forward Pass\n",
    "    def forward(self, x):\n",
    "#         mu, logvar = self.encode(x.view(-1, 784))\n",
    "        mu, logvar, indices_list, size_list = self.encode(x)\n",
    "#         print(\"logvar (after encoding) = \\n\" + str(logvar))\n",
    "#         print(\"mu (after encoding) = \\n\" + str(mu))\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "#         print(\"z = \")\n",
    "#         print(z)\n",
    "        reconstructed_x = self.decode(z, indices_list, size_list)\n",
    "    \n",
    "        return reconstructed_x , mu, logvar\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     print(param.name)\n",
    "#     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "#     print(\"--------------------------------------\")\n",
    "#     print(\"Calculating Loss...\")\n",
    "#     print(\"recon_x shape = \" + str(recon_x.shape))\n",
    "    \n",
    "#     BCE = F.binary_cross_entropy(recon_x, \n",
    "#                                  x.view(-1, 1, 128, 128, 128), \n",
    "#                                  reduction='sum')\n",
    "#     print(\"BCE Loss = \" + str(BCE))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    https://towardsdatascience.com/teaching-a-variational-autoencoder-vae-to-draw-mnist-characters-978675c95776\n",
    "    This article is about reconstructing MNIST dataset (2D images with 1 channels)\n",
    "    And it uses squared difference for the reconstruction loss, thus\n",
    "    it is safe to say that for 3D reconstruction we might use the same thing too.\n",
    "    \n",
    "    But the MSE loss seems to be around 1e20 magnitude, thus suggesting some\n",
    "    bug might exist in it.\n",
    "    \"\"\"\n",
    "    MSE = F.mse_loss(recon_x, \n",
    "                     x.view(-1, 1, 128, 128, 128), \n",
    "                     reduction='sum') # / 1e18\n",
    "    \n",
    "    print(\"MSE Loss = \" + str(MSE))\n",
    "\n",
    "    \"\"\"\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    \n",
    "    # https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/\n",
    "    # normalises the KLD loss by batch_size\n",
    "    \"\"\"\n",
    "#     print(\"logvar (KLD Loss) = \\n\" + str(logvar))\n",
    "#     print(\"mu (KLD Loss) = \\n\" + str(mu))\n",
    "#     print(\"logvar.exp() (KLD Loss) = \\n\" + str(logvar.exp()))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    KLD = KLD / float(batch_size)\n",
    "    print(\"KLD Loss = \" + str(KLD))\n",
    "\n",
    "    \n",
    "#     return MSE\n",
    "#     return BCE\n",
    "#     return BCE + KLD\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128, 128])"
      ]
     },
     "execution_count": 1511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(train_loader))[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "#     for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "#         print(data)\n",
    "        \n",
    "        #print(\"Batch size = \" + str(data.shape))\n",
    "        \n",
    "        data = data.to(device)\n",
    "        print(\"Data transfer to device completed.\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "#         print(\"Reconstructed Input = \\n \" + str(recon_batch))\n",
    "#         print(\"Real Input = \\n \" + str(data))\n",
    "#         print(\"Reconstructed Input Shape = \\n \" + str(recon_batch.shape))\n",
    "#         print(\"Real Input Shape = \\n \" + str(data.shape))\n",
    "\n",
    "#         print(\"logvar = \\n\" + str(logvar))\n",
    "#         print(\"mu = \\n\" + str(mu))\n",
    "        \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if batch_idx % args.log_interval == 0:\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.12f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.12f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "#         for i, (data, _) in enumerate(test_loader):\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            \n",
    "            \n",
    "            \n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n], \n",
    "                                        recon_batch.view(batch_size, 1, 128, 128, 128)[:n]])\n",
    "                                      #recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "#                                         recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "#                 save_image(comparison.cpu(),\n",
    "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.12f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0.0000e+00, 0.0000e+00, 4.5429e+06, 4.0098e+05, 3.9971e+06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9019e+05, 0.0000e+00, 1.4348e+06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6227e+06, 5.0755e+06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[4.8991e+06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.5237e+06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7581e+06, 0.0000e+00, 0.0000e+00, 1.2391e+06,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0.0000e+00, 0.0000e+00, 4.5429e+06, 4.0098e+05, 3.9971e+06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9019e+05, 0.0000e+00, 1.4348e+06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6227e+06, 5.0755e+06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[4.8991e+06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.5237e+06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.7581e+06, 0.0000e+00, 0.0000e+00, 1.2391e+06,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0.0000e+00, 0.0000e+00, 2.2715e+06, 2.0049e+05, 1.9985e+06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4509e+05, 0.0000e+00, 7.1740e+05,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1136e+05, 2.5378e+06, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1.0000, 1.0000,    inf,    inf,    inf, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "            inf, 1.0000,    inf, 1.0000, 1.0000, 1.0000,    inf,    inf, 1.0000,\n",
      "         1.0000, 1.0000]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.7261,  1.1456, -0.3825, -0.4785,  0.9009, -0.0952,  2.1472,  1.5053,\n",
      "         -0.6261,  1.2031, -0.2690,  1.3064, -0.6834,  0.5597,  0.9461,  0.1690,\n",
      "         -0.1202,  0.9094, -0.1968, -1.7940]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(inf, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [0/32 (0%)]\tLoss: inf\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0.0067, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0332, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0272, 0.0165, 0.0000, 0.0000, 0.0180, 0.0000, 0.0000, 0.0000, 0.0158,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0.0067, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0332, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0272, 0.0165, 0.0000, 0.0000, 0.0180, 0.0000, 0.0000, 0.0000, 0.0158,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0.0034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1.0034, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6317,  0.3267,  0.7348, -0.2910,  0.2520, -0.4122, -0.1374,  1.3288,\n",
      "          0.1197,  0.4881,  0.8917,  0.3181, -1.0064,  0.4353,  0.0532,  0.7743,\n",
      "         -1.0202,  0.1599, -0.2468, -2.3120]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [1/32 (3%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0130, 0.0013, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0130, 0.0013, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0065, 0.0007, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0065, 1.0007, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0211,  0.3217, -1.8052,  0.1765, -1.4409, -1.3088,  0.6238, -0.0994,\n",
      "         -0.1341,  1.2435,  0.3451,  1.0443, -1.4033,  0.6435, -0.2536, -0.9305,\n",
      "          1.1877, -0.4275,  0.9791, -1.7073]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(0.0001, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [2/32 (6%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0.0000, 0.0000, 0.0021, 0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0.0000, 0.0000, 0.0021, 0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5361,  0.3941, -0.3976, -1.9831, -1.0168, -1.1205,  0.4651, -0.8740,\n",
      "          0.8145, -0.5798, -0.4902, -1.0462,  2.1096, -0.8703,  0.1195, -1.1309,\n",
      "          1.0069, -0.0815, -0.1380, -0.3435]])\n",
      "----------------------------\n",
      "Starting Decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(4.9472e-06, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [3/32 (9%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1890, -1.0221, -0.8348,  0.7948,  0.7083,  0.7714,  0.1178,  1.3044,\n",
      "          0.0223,  0.4428, -1.2414,  0.8905, -0.1100, -0.3048,  0.8278, -0.4714,\n",
      "         -1.6581, -0.7537, -1.0330, -0.6892]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [4/32 (12%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.2232,  1.4984,  0.7458, -0.9689, -1.2568, -1.1356,  0.4701, -1.4626,\n",
      "         -0.2925,  1.1495, -0.4704, -0.7191,  0.8309,  0.2804, -1.3414, -0.5050,\n",
      "         -0.9411, -0.5919,  1.0600,  0.2341]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [5/32 (16%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.8701,  0.3890,  0.8505, -0.5402,  1.0202,  0.7216,  0.2618, -0.1743,\n",
      "         -0.9862,  1.6491,  1.1155,  0.6326,  2.5036, -0.4502,  0.8001, -1.7061,\n",
      "         -0.1163, -0.7745, -0.3665,  0.2783]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [6/32 (19%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.1644, -0.6142,  2.3279, -1.9563,  0.2576,  0.8899,  0.3845,  1.9257,\n",
      "         -0.0346, -2.0502,  0.9642,  0.3439,  0.6153, -0.2046,  0.1352, -0.8213,\n",
      "          0.1374, -0.4857, -0.8255,  0.6143]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [7/32 (22%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.8052, -0.9453, -0.4172,  1.1577,  0.1760, -1.4790,  0.3572, -0.6024,\n",
      "         -0.0915,  0.1395,  2.1156,  0.2492,  0.9990,  0.5430,  1.8689, -0.1424,\n",
      "          0.2493, -2.2260,  0.5922, -0.2003]])\n",
      "----------------------------\n",
      "Starting Decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [8/32 (25%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.7193,  1.7187, -1.4380,  1.1109, -1.1618,  0.3730,  0.2692,  1.1777,\n",
      "         -0.0223,  0.3605,  0.5255, -0.1656, -1.9777,  2.0941,  0.8578,  0.2379,\n",
      "          0.9121,  0.1345,  0.3505, -0.1133]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [9/32 (28%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 2.4396, -0.6600, -0.3355, -0.2461,  0.1081,  2.0281,  1.0096,  0.2315,\n",
      "         -0.3979,  0.4998, -0.4613, -0.5120, -1.1508, -0.6711,  1.0364, -1.3204,\n",
      "          1.3193,  1.5102, -0.3474, -0.2588]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [10/32 (31%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1763,  0.7602, -0.4941, -0.6676,  0.7326,  0.1603, -0.1139, -2.5305,\n",
      "          1.3467, -0.0039,  0.9097, -2.0763,  0.7837, -1.1525,  1.2200, -0.1281,\n",
      "         -0.3424,  0.2246,  0.1051, -0.6152]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [11/32 (34%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3485,  1.2315,  0.4248, -0.0218, -0.0066, -0.1553, -2.2527,  0.9871,\n",
      "          1.9014, -1.7233,  0.8084, -0.1127, -0.5265,  0.2509,  1.6951, -0.2501,\n",
      "         -1.2873, -0.1041, -1.2079, -1.4654]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [12/32 (38%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.0879,  1.2670, -0.9327, -0.6465,  0.1554,  0.3939, -1.7179,  0.6574,\n",
      "         -2.2662, -0.1657, -0.4805,  0.7541, -1.3019,  0.2895, -0.2243,  0.4825,\n",
      "         -0.4362,  0.6446,  1.4023, -0.8413]])\n",
      "----------------------------\n",
      "Starting Decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [13/32 (41%)]\tLoss: 40561705228284461056.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4855,  1.1372, -1.6411,  0.2387,  1.3799,  0.2720, -1.0857, -0.9818,\n",
      "          0.1284,  0.1108,  0.9303, -0.7335, -0.8265, -0.5553, -0.3681, -0.1383,\n",
      "         -1.7915,  1.1120,  1.6440,  1.4232]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [14/32 (44%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.9677, -1.2020, -1.2131,  0.5749, -1.2141,  0.4661,  0.4505,  2.3019,\n",
      "          0.2494,  0.9443,  0.1950, -0.0974, -0.8213, -1.1662, -0.8307,  1.0728,\n",
      "         -1.1486,  0.0960,  0.6645, -0.6010]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [15/32 (47%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0023, -0.8530, -0.0827, -1.4775, -0.6060, -0.8640, -0.5145,  0.2599,\n",
      "         -0.6300, -1.7710, -0.5382,  1.1978,  1.8005,  0.5808, -0.3302, -0.6693,\n",
      "         -0.0721,  1.0936, -1.3106,  0.1338]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [16/32 (50%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0076,  0.4691,  1.7383,  0.5391,  0.2288, -0.4859,  0.0570,  0.6152,\n",
      "         -1.0679,  0.7829, -0.5749, -0.4282,  3.0715, -0.6055,  0.4668,  1.0462,\n",
      "         -1.4508,  0.6149,  1.2283, -0.2772]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [17/32 (53%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6437, -0.4349,  0.1722, -0.3630, -1.7066, -0.4421, -0.0319,  0.8159,\n",
      "          0.3642,  1.4164, -0.1530, -0.0366, -1.2453,  2.2242, -0.9553,  0.7260,\n",
      "          1.8197, -0.0834,  0.9328,  0.4595]])\n",
      "----------------------------\n",
      "Starting Decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [18/32 (56%)]\tLoss: 1386609781829009408.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1357, -0.1122,  0.0555,  1.4310,  0.0726, -1.4282,  0.4771,  1.6662,\n",
      "          1.5873,  0.4230, -0.1015,  1.5657, -0.8068, -0.1820, -0.7660,  1.1191,\n",
      "         -0.7234,  0.4104, -1.4624, -0.5798]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [19/32 (59%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7902, -0.2972, -0.4363, -0.7988, -1.5548,  1.0854,  0.4981,  0.7885,\n",
      "          1.2516,  0.2437, -1.8613, -0.5913,  0.1838,  0.1268, -2.2471, -2.4012,\n",
      "          0.3341,  0.4050, -1.0703, -0.3630]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [20/32 (62%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-2.0943,  1.7245,  0.4051, -0.1913, -0.3012,  0.9792,  0.5047,  1.1783,\n",
      "          1.4215, -1.6933, -0.1336,  0.1226, -0.4944,  0.7109, -0.6893, -1.1758,\n",
      "         -0.2850, -1.1253, -0.0890,  0.3801]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [21/32 (66%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.3986,  0.2291, -0.2830,  0.9492,  0.4759, -0.0861,  0.8566, -1.3752,\n",
      "         -0.1730, -1.2255,  2.9108,  0.1029,  0.4251,  0.9415,  2.2225,  0.1620,\n",
      "         -0.8476,  2.2929, -2.0565,  1.1089]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [22/32 (69%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1044,  0.1785, -0.5489,  0.9457, -0.1977,  0.3057, -0.3507, -0.6456,\n",
      "          0.3666, -0.4732,  0.4755, -0.6530,  0.3969, -0.7348, -2.0986, -1.3783,\n",
      "         -0.0473, -0.8989,  0.3479, -1.0896]])\n",
      "----------------------------\n",
      "Starting Decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [23/32 (72%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4839, -0.2305, -0.4565, -1.4066, -0.0562,  0.4986,  1.5097,  0.4709,\n",
      "          1.7145,  0.5850,  0.7549,  0.4037, -0.1911, -0.0926,  0.5221,  0.1281,\n",
      "          0.5137, -0.7257, -0.3726,  0.4873]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [24/32 (75%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2197,  0.9022, -0.5884, -1.3467, -0.4417, -0.4659, -0.4880, -0.1610,\n",
      "         -0.4674, -0.3763, -2.4246, -0.4526, -0.1276,  1.1165, -0.0089,  0.2696,\n",
      "         -0.8072,  0.3545,  0.8504, -0.5946]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [25/32 (78%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.5494,  1.0085,  0.8853, -0.4840, -1.0697, -0.4426, -1.2093, -0.4258,\n",
      "          0.0735,  1.0757,  0.0973,  0.3657,  0.3303,  1.6644, -0.0897, -1.1678,\n",
      "          0.4231,  2.1314,  0.5944,  0.0185]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [26/32 (81%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.9933, -0.6304, -1.3468, -0.5711,  0.1500, -0.5942,  1.3605,  2.4105,\n",
      "          0.6230, -1.3635, -0.2658,  0.8162, -0.6301, -0.8528,  0.0553,  1.0694,\n",
      "          0.8686, -0.7626, -1.0811,  0.7256]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [27/32 (84%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3013,  0.2595, -0.2500, -0.5018, -0.6079, -0.3113,  1.6161,  2.1701,\n",
      "          0.2658, -0.8569, -0.3414,  0.7859, -0.7619,  0.9699, -1.0123,  1.3861,\n",
      "          0.9582,  1.9976,  0.8523, -0.4553]])\n",
      "----------------------------\n",
      "Starting Decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [28/32 (88%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6980, -0.1507, -2.2080,  1.4952, -1.7708,  1.1263, -0.4340, -1.4798,\n",
      "          2.1170,  3.1820, -0.5613,  0.3653, -0.4623,  0.3154,  1.7985,  0.0628,\n",
      "          0.4606, -0.5810,  0.7212, -0.8812]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [29/32 (91%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.9099,  1.1079,  1.3015, -0.5672, -0.4474,  0.1087,  1.5610,  0.0187,\n",
      "          1.0401, -1.4730,  0.0240, -0.4312,  0.1342, -0.1666,  1.6433, -0.7963,\n",
      "          0.1538, -0.9897,  1.0777, -0.6039]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [30/32 (94%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1208, -0.4303, -1.4554,  1.4086,  0.0396, -0.1150,  1.8842,  0.1923,\n",
      "          0.8054,  0.2651, -0.2264,  0.5825,  1.5130,  1.3421,  1.6423, -1.6758,\n",
      "          0.5723, -1.1711,  0.0387,  0.6653]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1 [31/32 (97%)]\tLoss: 201689698293369536512.000000\n",
      "====> Epoch: 1 Average loss: inf\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHdCAYAAAAZ2vQJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e3bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.7342,  2.0704,  0.8731,  1.1279,  0.1502, -0.0579, -0.0626,  1.2011,\n",
      "          1.2139,  0.8060, -0.6187, -0.4719, -0.0028, -0.8656, -0.1620, -0.5534,\n",
      "          0.2011,  0.4010, -0.5165, -0.3158]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [0/32 (0%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2928,  0.1431, -1.0469,  0.6894, -0.5105,  0.3671, -0.8669,  0.2990,\n",
      "          0.4499,  0.3753, -1.5653,  0.3374, -1.5407,  0.6840, -0.8306,  1.4479,\n",
      "         -0.8432, -0.5083, -0.8407,  0.5071]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [1/32 (3%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.3261, -1.1965, -2.9508,  0.4698,  1.6150,  0.8145,  0.9552, -0.6198,\n",
      "         -0.1259,  0.1889,  1.9768,  0.7426, -0.8687, -0.0637,  0.6842, -0.5279,\n",
      "          0.5268, -0.1736, -0.5617,  0.0307]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [2/32 (6%)]\tLoss: 40561705228284461056.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.8886, -0.4215,  0.2636,  0.7197,  0.8503, -2.1728, -1.4677,  0.8017,\n",
      "          0.0943, -1.8477,  0.4429, -0.6851,  1.2190,  1.3482, -2.2806, -0.4215,\n",
      "          0.7573, -0.4977, -0.2932, -0.2869]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [3/32 (9%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.2286,  0.3056, -2.7427,  0.6314, -1.1239, -1.8803,  1.6893,  0.1750,\n",
      "         -0.2040, -0.0943,  0.4746,  0.4157, -1.6473,  1.1748,  0.2049,  1.9361,\n",
      "         -0.7556,  0.5470,  1.0436, -0.1026]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [4/32 (12%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1239,  1.5114,  0.5456, -0.0758, -0.2394,  1.0999,  0.6829, -1.9241,\n",
      "          0.0173, -1.2745, -0.0352, -0.5432, -0.1984, -0.1429,  1.0128,  2.0784,\n",
      "         -0.0203,  1.3464,  0.5385, -0.6794]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [5/32 (16%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.0566,  0.5321,  1.7237,  1.7510,  0.6977,  0.1877,  1.2508, -0.8857,\n",
      "          1.9533,  1.3233, -0.6280, -1.0704, -0.1677,  0.6132, -0.0582,  1.2116,\n",
      "          0.5735,  0.0955, -0.4578,  0.8051]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [6/32 (19%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.0897, -1.6953, -0.7529,  1.6410,  0.3449, -0.0447, -2.6846, -0.8018,\n",
      "          0.6026,  1.1077,  0.7770, -0.3251,  1.5439,  0.7351, -0.4827,  0.7892,\n",
      "         -0.0867, -0.4222, -1.5149, -0.3875]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [7/32 (22%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1526, -0.6437, -1.0407,  1.3286,  0.5037,  0.9469,  1.5723,  0.9573,\n",
      "         -0.4595,  1.6939,  0.2635, -2.6523,  0.1673,  0.8155,  0.2191, -0.6782,\n",
      "          0.5273,  0.4851,  0.2439,  1.5970]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [8/32 (25%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2379,  0.2824, -1.6246, -2.4495, -0.4836,  1.1549, -1.7241, -1.1493,\n",
      "          0.6683, -0.9381,  0.5548, -0.1829, -0.5854,  0.8263,  1.2455, -0.9755,\n",
      "          0.8487,  0.3930, -0.4664, -1.7372]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [9/32 (28%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1163, -1.6849,  1.0695, -0.0189, -0.6518, -0.5402,  0.0601, -0.5607,\n",
      "          0.1419,  1.2750,  0.9009,  0.2152, -0.1218,  0.9179,  0.1632,  0.7699,\n",
      "         -0.0569, -0.7099,  0.1026,  0.3996]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [10/32 (31%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-2.2289,  0.5297,  0.3977, -1.0385, -0.7708, -0.2360, -0.0825,  1.0988,\n",
      "         -0.4202,  0.2297, -1.1203,  0.0891, -0.7983, -0.5710,  0.3933,  0.4570,\n",
      "         -1.6345,  0.0084,  0.3598,  0.7820]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [11/32 (34%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.8373,  0.0143,  0.0762, -0.4113,  0.5876, -0.0134, -0.4110,  1.1927,\n",
      "         -1.4105, -0.8476,  0.2347,  2.9605, -0.5577, -2.2584, -1.5342,  0.0551,\n",
      "         -0.5625,  0.4384,  1.0086,  0.1044]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [12/32 (38%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.5583,  0.7371, -0.1775,  0.1332,  1.0089, -0.4088, -0.7235,  0.6146,\n",
      "         -1.0310,  0.3560,  0.5226, -0.9495,  0.5179, -1.8630, -1.6558,  0.0587,\n",
      "         -0.2996,  0.2203, -0.9125,  0.8195]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [13/32 (41%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.4088, -0.0468, -0.0485, -2.6827, -0.9803,  1.2195, -1.4084,  1.2280,\n",
      "         -0.6599,  0.0561,  0.7253, -0.3229,  0.1405,  0.3951, -1.0131,  0.7042,\n",
      "          1.3949, -0.3314, -2.2818, -0.4850]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [14/32 (44%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.4427, -0.2686, -0.6776,  0.4182,  2.1258,  0.2747,  1.5179,  0.3460,\n",
      "          0.2698,  1.5677, -0.8709, -1.7591, -0.3835, -1.9792,  0.5788, -1.6680,\n",
      "          0.6875, -3.6589,  1.2755,  0.0385]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [15/32 (47%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.3576, -0.2145, -0.9159,  0.8974, -0.3018,  1.7983,  0.3062, -0.6325,\n",
      "          1.1306, -0.4614, -0.6458,  0.7780, -0.4690, -0.7878, -0.5754,  0.6811,\n",
      "          0.1589,  0.4883, -0.5312, -0.5138]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [16/32 (50%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.4979,  0.1143,  0.2583,  0.0483, -1.0875,  0.3645,  1.9736,  0.3238,\n",
      "         -1.4407, -0.6677, -0.3168,  1.7874, -1.4844,  0.7940,  1.9756,  1.6242,\n",
      "         -0.0426,  0.5616,  1.2957, -0.4719]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [17/32 (53%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.7451, -0.0047, -0.7232,  1.4535,  0.6581, -0.0879,  0.1439, -0.8507,\n",
      "          0.5057,  1.6197, -0.2711,  1.1656,  0.0846, -0.4523, -2.3755,  0.0186,\n",
      "          1.6229,  0.5108, -0.1021, -1.3538]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [18/32 (56%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4817,  1.9455,  0.1348, -0.2438,  1.5483, -1.3597, -0.1924, -0.4038,\n",
      "         -0.4617, -0.5580, -1.3244,  0.8250, -0.7629,  0.9709, -0.1050, -0.9762,\n",
      "          1.0242,  0.1294,  0.7232, -0.8757]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [19/32 (59%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.3415,  0.1465,  1.1626, -0.3543,  0.0925,  1.0350,  1.6450,  2.2989,\n",
      "          0.6155, -1.3643,  0.0245, -0.6646,  0.8122,  0.8399,  1.2412, -1.4544,\n",
      "         -1.3127,  0.3433,  0.8346, -0.3470]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [20/32 (62%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.7401,  0.9119,  0.0353, -0.4813, -3.1791,  1.7006,  1.2538,  0.9903,\n",
      "         -0.5301, -0.1803,  1.8465, -0.4357, -0.6508, -0.6260,  0.7473,  1.0020,\n",
      "         -0.7360, -1.6086,  0.3836,  0.3535]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [21/32 (66%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.2518, -0.2384, -0.3564,  0.4346,  0.3544, -1.5849,  1.5000,  1.1503,\n",
      "          1.2742,  0.1671,  1.6871, -0.7555, -1.2552,  1.4169,  0.0321,  0.6047,\n",
      "          0.6304,  1.3457, -0.5678, -0.4649]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [22/32 (69%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.5361,  1.6597, -0.6260, -0.7315,  1.5435, -1.2773, -0.4842, -0.9815,\n",
      "          0.9417,  1.3806, -1.1545, -1.7586,  1.4067, -1.3911, -0.9786,  1.2939,\n",
      "          0.3642,  0.0659, -1.2255, -0.2373]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [23/32 (72%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0014,  0.1359, -0.4730, -0.0583,  0.9311,  0.0508, -0.7656,  0.7161,\n",
      "         -1.1319, -0.7369,  1.9783,  0.3927,  0.4861, -1.3071, -0.1040, -0.5174,\n",
      "         -0.7287,  0.5413,  2.2238, -1.3798]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [24/32 (75%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.6352,  1.1892,  0.8011, -0.0777, -0.8995, -2.8855, -2.6790, -1.8624,\n",
      "          1.2510,  1.6864, -0.4606,  0.4808,  0.1821,  2.6816, -0.0359,  1.5286,\n",
      "          0.0276, -1.7678, -0.7848,  0.2715]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [25/32 (78%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4971, -0.6326,  1.1653,  0.0357,  0.9162, -1.7040, -0.7497,  1.8111,\n",
      "          0.0782,  0.6628,  0.5226,  0.5762,  0.9967,  0.8469,  0.9606, -1.9010,\n",
      "          0.0089, -0.4300, -0.5270,  1.3689]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [26/32 (81%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 2.7356, -0.6059, -1.1923, -0.5009,  1.0782, -0.7696, -0.8531, -0.2802,\n",
      "         -1.2257, -0.7626,  0.6936, -0.3043, -0.7267, -1.2255,  0.4762,  0.6344,\n",
      "          0.4225,  0.3298,  0.9068, -1.5280]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [27/32 (84%)]\tLoss: 201689698293369536512.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2718,  1.1032,  0.0550, -0.5084,  0.2561, -1.2289,  0.7128, -0.4685,\n",
      "          0.8235,  0.7991, -0.1648, -0.7848,  2.1453,  0.9545,  0.7228, -0.1926,\n",
      "          0.1842, -0.0960, -2.0028,  1.7697]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [28/32 (88%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.0382,  1.0263,  0.9228,  0.1629, -1.0906,  1.8546,  1.0350, -2.1227,\n",
      "          0.1306, -0.6702, -0.5354,  1.4832, -0.8782,  0.5899, -0.3198, -1.0668,\n",
      "          0.0175, -1.2601, -0.9476,  0.9972]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [29/32 (91%)]\tLoss: 7129966218999496704.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.9133, -2.1354, -0.8735, -1.1703,  0.4540, -0.0659, -0.6146, -0.3362,\n",
      "          0.1191,  0.1557, -1.3093,  0.3969,  0.8538, -1.3008,  0.8969, -0.7738,\n",
      "          0.1847, -0.0868, -0.7647, -0.4188]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [30/32 (94%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.6793,  0.7049, -0.6798,  0.4279,  0.8250, -0.4590,  1.0961,  0.8257,\n",
      "          0.4742,  0.2428,  0.8344, -0.4521, -0.1721,  0.4100,  0.4838,  0.2949,\n",
      "         -0.5187, -1.3771, -0.8650,  0.2154]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2 [31/32 (97%)]\tLoss: 1386609781829009408.000000\n",
      "====> Epoch: 2 Average loss: 29516452548412735488.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHdCAYAAAAZ2vQJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nioiIiIiIiC8pYRURERERERFf+hv615AWPi07vgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1195426a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1605,  2.2147, -0.7131,  0.3080, -0.1802,  1.3009, -0.4135, -0.9198,\n",
      "          1.2148,  0.4052, -0.4318,  1.1912,  0.6507, -1.1108,  0.9709, -0.2531,\n",
      "         -0.1745,  2.4618, -1.0450, -1.3258]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [0/32 (0%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.8043, -0.7599,  0.0591,  0.4626,  0.8741,  1.2909, -1.5699,  0.4354,\n",
      "          0.8113, -0.1739, -1.4924,  1.4987,  2.1173,  1.0435,  1.2581,  0.4348,\n",
      "          0.1977,  0.7131,  1.2801, -0.0672]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [1/32 (3%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.9507, -1.0764, -0.4292, -0.7794, -0.2342, -0.1498,  0.6999, -0.5836,\n",
      "          1.1598, -0.9312,  0.7845,  0.0825,  0.3688, -0.3230,  0.1290,  1.3888,\n",
      "         -0.9980,  0.3197, -1.1490, -0.5303]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [2/32 (6%)]\tLoss: 7129966218999496704.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7423, -0.2869, -1.2364, -0.3153, -0.0256, -0.1927, -3.0575,  1.5793,\n",
      "         -0.5058, -0.5026, -0.3570,  0.7841,  2.1671, -1.0584, -0.6613, -0.3840,\n",
      "         -0.0821,  1.4170,  0.2479,  1.4633]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [3/32 (9%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4502,  0.0979,  0.3554,  1.2900,  0.2153,  0.7187, -0.7440, -0.1024,\n",
      "         -0.2100,  0.3905, -1.1420, -0.6964, -0.4138, -0.0137,  0.8551,  0.4532,\n",
      "         -0.8205, -0.3145, -1.8929, -0.0202]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [4/32 (12%)]\tLoss: 201689698293369536512.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1801, -0.4030, -1.0350, -0.0200, -2.0261, -0.8398,  0.2597, -0.2154,\n",
      "         -0.0531, -0.9703,  1.7741, -1.1909, -0.0406,  1.0171,  0.7971,  0.3080,\n",
      "          0.2326,  0.1735,  1.4303, -1.4514]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [5/32 (16%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-2.0224,  0.2802, -1.1569, -0.6817, -0.7170,  1.2681, -0.4965,  0.1368,\n",
      "         -0.1951, -0.9256,  0.4275, -1.7659,  0.1434,  0.0210,  0.2202, -1.8600,\n",
      "          0.4652, -0.3131, -1.1186,  0.9150]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [6/32 (19%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.5980, -1.1449,  0.7398, -0.1701, -0.4225,  1.8845, -0.4301, -0.1599,\n",
      "         -1.4398,  0.8177, -1.8292, -1.8625,  0.1330,  0.4513, -1.1547, -0.9380,\n",
      "          0.4298,  2.2121, -0.0778,  0.1541]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [7/32 (22%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4283, -0.8992,  0.8751,  0.6483, -1.0007,  0.5942,  1.1628, -1.4118,\n",
      "         -0.1540, -2.4758, -0.8718,  0.1759, -0.2405, -0.0034,  0.3188,  1.0557,\n",
      "         -2.0276,  2.5769, -0.7915, -1.1915]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [8/32 (25%)]\tLoss: 1386609781829009408.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.5864, -0.8126, -1.2407, -0.6544, -0.1743, -1.0748,  0.5380,  0.8861,\n",
      "          0.9677, -0.6077, -1.4524, -0.8981, -1.0173, -1.6999, -0.1665, -1.0904,\n",
      "          0.2005,  1.6716,  0.9010,  0.2573]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [9/32 (28%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1160, -0.6880, -0.8121,  1.3584,  0.1156, -1.3295, -1.3001,  0.6163,\n",
      "          1.1170, -0.1456, -0.4656, -0.1339, -1.1880, -0.9490,  0.1275,  0.4124,\n",
      "          0.2899,  0.5731, -0.7232, -0.4601]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [10/32 (31%)]\tLoss: 40561705228284461056.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1126,  0.0974,  1.6649,  0.7161, -0.4226, -0.5483,  0.9963,  1.0365,\n",
      "         -1.6611,  0.4909,  0.7489,  0.9595, -0.1053, -0.4737,  1.5693, -0.1864,\n",
      "          2.1603, -0.2055,  2.8179, -0.5449]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [11/32 (34%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.9810,  0.0073,  0.3655,  1.4969, -0.1258, -1.4731, -1.3565,  0.6658,\n",
      "          0.3716,  0.1377,  0.7722, -1.9304, -1.0209,  0.1127, -0.4275, -0.1520,\n",
      "          0.0523, -1.3804,  0.2721, -0.7500]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [12/32 (38%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7610,  1.7666, -0.9595,  0.9977,  0.2293,  1.0601, -0.3861, -1.3137,\n",
      "         -0.7176, -0.5464, -0.7259, -0.3198, -1.1410,  0.5399,  0.9109,  1.8163,\n",
      "         -0.1166, -1.6806, -1.0177,  0.7409]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [13/32 (41%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4405,  2.0726, -1.6046,  1.5080,  0.6517,  1.3479,  3.1615, -1.2878,\n",
      "         -0.2332, -0.2778, -1.2467,  0.1305,  1.0294, -0.9793, -1.0528,  0.2500,\n",
      "          0.2186, -0.2377,  1.7061,  2.1607]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [14/32 (44%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0417, -1.9646, -0.9288,  0.0058,  0.8943, -1.6034,  1.7818,  0.5023,\n",
      "          0.7484, -0.1908,  0.0707, -1.1499, -0.6205, -0.4765, -1.2933, -0.4210,\n",
      "          0.0017,  0.6932,  1.1962, -0.7768]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [15/32 (47%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3544,  0.0009, -0.4966, -0.0160, -1.5983,  0.4837, -0.7382,  0.4717,\n",
      "         -0.0369,  0.7811,  0.4465, -0.0147,  1.2225, -0.4880,  1.4330,  0.3332,\n",
      "          0.2035, -0.2161,  0.6199,  0.6298]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [16/32 (50%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.2481, -1.3211, -1.2456, -1.3697,  0.9943,  0.5878,  0.0471, -0.1909,\n",
      "          0.5705,  0.1537,  1.2057, -0.5142,  1.3762, -0.2380, -0.3535, -0.1128,\n",
      "          1.3221, -1.2671, -0.9999, -0.2803]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [17/32 (53%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3958,  0.2161,  0.8239,  0.3878, -1.8268,  0.1094,  0.9173, -0.1078,\n",
      "          0.9859,  0.1679,  0.2600, -1.3711, -0.3190, -0.8091, -0.2270, -0.0170,\n",
      "         -1.3097,  1.2611,  0.8857,  0.1904]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [18/32 (56%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2902,  0.8472,  0.0146, -1.6286, -0.0620,  1.0684,  0.0101,  0.7811,\n",
      "          0.7097, -0.3368, -0.9205, -0.2280, -0.6153, -0.3539,  0.1755, -0.1557,\n",
      "         -0.3721, -0.1029,  2.3891, -0.5807]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [19/32 (59%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7684, -0.2853, -2.8508, -1.4475, -1.1300,  0.8521, -0.7743, -1.0429,\n",
      "         -0.5566,  1.1076, -0.1071,  2.2346, -0.8342,  1.3986, -1.7651, -0.6359,\n",
      "          0.8286,  1.4805, -0.2090,  2.0746]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [20/32 (62%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-2.7214,  1.5092,  0.7486, -0.9273, -0.2688, -0.0682, -1.0955,  0.8388,\n",
      "          1.4766, -0.6864,  0.3530, -1.8730, -0.2051,  1.3411, -2.4971,  0.5767,\n",
      "          0.7021, -0.8761,  0.5593, -1.3416]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [21/32 (66%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.6291,  1.2273, -0.0649,  0.2293,  0.4523,  1.0724, -0.3997, -0.9142,\n",
      "          0.6857,  1.3785,  1.9379, -0.1694, -0.1393, -0.3982, -0.5689,  1.1984,\n",
      "          1.1381,  1.6965,  0.1367, -0.6222]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [22/32 (69%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.2443,  0.9884, -0.5920,  2.1877,  0.0058, -1.3178,  0.6791, -1.0081,\n",
      "          1.1348, -0.1330, -0.0815, -0.0488, -1.4251, -0.0719, -0.2056, -0.6349,\n",
      "          0.2717, -0.5887, -1.7912,  0.2242]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [23/32 (72%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1901, -0.9365, -0.4325, -0.2780,  0.1521,  0.9121,  0.7182, -0.4586,\n",
      "          2.5589, -0.6879,  0.7440,  1.3338,  0.8867,  0.2555, -0.5326,  0.8105,\n",
      "         -0.8444, -0.1778,  1.5175,  1.7334]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [24/32 (75%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.4622, -0.5844,  2.0177,  0.0100, -0.1283,  0.8887, -0.7357,  0.2944,\n",
      "          1.1508, -1.5673,  0.0044,  1.9981, -0.1453, -1.0171, -1.1424,  0.7522,\n",
      "          1.9450,  0.4766,  0.9816,  0.7041]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [25/32 (78%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7109,  0.1180,  1.0140,  0.1170, -0.5673, -2.0610, -0.8950,  0.5232,\n",
      "          0.5509,  0.6165, -0.7170,  0.7243,  0.9413,  0.2103, -0.0270,  1.2323,\n",
      "          1.1058, -0.0452,  1.0016, -1.2249]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [26/32 (81%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4501, -0.1030,  0.2784,  0.6048,  1.5365,  1.1934,  1.5410, -0.1474,\n",
      "         -0.0377,  0.3868, -0.0452, -0.3051, -0.8082, -0.9308,  0.4494,  1.7314,\n",
      "          0.3381,  1.5753, -0.3481, -0.6279]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [27/32 (84%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2895,  0.5357,  1.4973, -1.0754,  1.4006, -0.4190,  0.7189,  0.5110,\n",
      "         -0.4524,  1.7437,  1.4414, -0.2607, -2.0486, -0.8078, -0.5280,  0.0909,\n",
      "          0.7744, -0.0109,  1.7215,  1.5526]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [28/32 (88%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0131, -0.2926,  0.0480,  0.5315, -0.3094,  0.2834,  0.5173, -0.9148,\n",
      "          0.4296,  0.5425,  0.9155,  1.3970,  0.2589,  0.3551, -0.3887,  1.5777,\n",
      "          0.5930,  1.1173, -2.2737,  1.3601]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [29/32 (91%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6168,  1.2710, -0.9317, -0.5436,  0.1779,  0.8415, -0.5686,  1.2224,\n",
      "         -0.3013,  2.0830, -1.9769, -0.5663, -0.2387,  0.4118, -0.2158, -0.0256,\n",
      "          0.9485,  1.0333,  2.3767,  0.8797]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [30/32 (94%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0534, -0.6318,  0.2079,  0.8301,  0.0928,  0.4500,  0.4431, -0.0127,\n",
      "          0.4744, -0.0103, -0.4722, -0.7520, -0.1076,  1.2577,  0.4247,  0.6639,\n",
      "         -0.7208,  0.9985, -0.8959, -0.6467]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3 [31/32 (97%)]\tLoss: 3682479121067147264.000000\n",
      "====> Epoch: 3 Average loss: 29516452548412735488.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHdCAYAAAAZ2vQJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQQQgghhFeSgFUIIYQQQgghhFf6///nybxooG2QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e55198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2266, -1.5942, -0.1541, -0.8899, -1.8308,  0.2310, -1.0186,  0.0474,\n",
      "         -0.1291,  0.6669, -0.0990,  0.3174,  0.3886, -0.4885,  0.6059, -0.4315,\n",
      "         -0.8666,  0.6080, -1.3493,  0.8139]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [0/32 (0%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1046,  1.3039, -1.9842,  0.1336,  0.1296,  0.9234, -0.1266,  0.7457,\n",
      "         -0.0844,  1.2281, -0.7472, -1.1577, -1.8503, -0.9693,  1.0586,  0.8572,\n",
      "          0.2972, -0.7891, -0.4077, -0.9456]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [1/32 (3%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.8394, -0.6031, -0.3794, -0.7629, -0.2041, -0.0040, -0.6758,  1.3131,\n",
      "         -0.4572, -0.0775,  2.4777,  0.3197,  1.0438,  0.4706,  1.8112,  0.7097,\n",
      "         -1.1310,  0.4103,  1.0798, -0.6805]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [2/32 (6%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.6483,  1.0252,  0.6751, -0.9360, -0.5511,  0.8949, -0.2503, -0.0268,\n",
      "          0.4151, -0.4319,  0.5684,  0.6592,  0.5134, -0.5145,  0.7546,  0.5538,\n",
      "         -1.3924, -1.2108, -1.5772, -0.0126]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [3/32 (9%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-3.4116,  0.3097, -0.9521, -0.3601, -0.1367,  0.4302, -2.7053, -0.3564,\n",
      "         -0.6674, -0.7547, -2.0762,  0.8825,  0.8879, -1.0081, -0.9868,  0.5208,\n",
      "         -1.8237,  0.6878, -0.2283,  1.3413]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [4/32 (12%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0552, -0.7533,  1.6851, -1.9903,  1.1741, -0.9913, -0.9880,  2.1400,\n",
      "         -0.1001, -0.4537,  2.4071, -0.4098, -0.2991, -1.4207,  0.1579,  1.9779,\n",
      "         -1.1010,  0.6516, -0.1848,  0.6668]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [5/32 (16%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.6220,  0.3231, -0.3872,  1.0517, -0.8052,  0.5412, -1.1826, -0.1115,\n",
      "         -1.2770, -0.5754, -0.1722, -2.1444, -1.6262,  1.3246,  0.9250,  0.9841,\n",
      "          0.0372, -0.1531, -0.7823, -1.6365]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [6/32 (19%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.8676, -0.2177,  1.2232, -0.3461,  1.9785,  2.1864, -1.7063, -1.2166,\n",
      "          0.5798,  1.1778,  1.8070,  0.6288,  0.5367,  0.4416, -0.8231,  0.9254,\n",
      "         -1.2830,  0.0916,  1.5236,  1.0718]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [7/32 (22%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.0632,  1.2234, -0.1779,  0.9873, -0.9142, -0.3874, -1.2944,  0.3854,\n",
      "          0.5294,  0.8002, -1.5248,  0.3676, -1.2754,  0.3368,  0.4620, -0.9711,\n",
      "         -0.4686,  0.7865, -2.2486, -0.3679]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [8/32 (25%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.9345, -0.7487,  0.7814, -0.5784, -0.7281,  0.3927, -0.2947, -0.3152,\n",
      "          0.1193,  1.1422, -1.2355,  0.8380,  1.7692, -1.8345, -1.1366, -0.5497,\n",
      "          1.1984, -1.5372,  0.0284, -0.7259]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [9/32 (28%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5912, -1.4036, -1.0526, -0.5394,  0.5053,  1.4775, -0.7651, -0.1414,\n",
      "          1.0974, -1.0419, -0.1885,  0.0024,  0.7029,  0.6877, -0.4336, -0.1557,\n",
      "          0.2183, -0.6669, -1.2329,  1.1469]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [10/32 (31%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3164, -1.2263, -0.1977, -0.8083,  0.7889,  1.4378,  1.0199,  1.2445,\n",
      "          2.2274,  0.6727, -1.6966,  0.9764, -1.5061, -0.1632, -0.2355,  0.5709,\n",
      "         -0.8506,  0.4495, -0.0610, -0.7730]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [11/32 (34%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.9035, -0.3221, -1.4659,  0.3750,  1.0276,  0.0834,  0.5455, -1.2519,\n",
      "          0.0916,  0.5986, -0.8216,  1.0409, -0.1546,  0.6716, -0.2048,  1.5740,\n",
      "          0.3720,  0.9914,  0.0751,  2.3653]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [12/32 (38%)]\tLoss: 1386609781829009408.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7257,  1.3059,  2.5764, -0.4949,  0.0786,  0.7964, -0.4937,  0.0257,\n",
      "         -1.2397, -0.5760,  1.7019, -0.8722,  0.9883, -0.9714, -1.2992,  0.4352,\n",
      "          0.8632,  0.0539,  0.2919, -0.7491]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [13/32 (41%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.5259, -0.8640, -0.4857, -1.2175, -0.5768, -0.3966,  0.5489, -0.1641,\n",
      "          0.7707, -1.0957,  0.4268,  1.0912,  0.3246, -0.7441, -0.4191,  1.6295,\n",
      "         -1.3118, -0.4360,  1.3987, -0.0211]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [14/32 (44%)]\tLoss: 201689698293369536512.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.5023, -0.8046, -0.5587,  0.3246, -0.2644,  0.1655,  1.9527,  2.2979,\n",
      "          0.3190, -0.0558,  1.2838, -0.6920,  1.4589, -0.6589,  0.0655, -1.7643,\n",
      "          0.1564,  0.8710, -0.3905,  0.0410]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [15/32 (47%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4738, -0.1281,  0.1043, -1.0483,  0.9483, -0.2132,  0.6649, -0.1783,\n",
      "          0.2704, -0.3344,  1.8263, -0.4650, -0.1707, -1.0233,  0.2335,  0.5444,\n",
      "         -0.6830, -0.7524,  0.3275,  0.2725]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [16/32 (50%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.6086,  1.9923,  0.8082, -0.5514, -0.4815, -0.1911, -0.0232,  0.5049,\n",
      "         -1.6826, -1.0450,  0.9174, -0.4224, -0.3078,  0.1296,  0.7005, -0.7701,\n",
      "          0.4174, -1.3581,  0.1674, -0.2872]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [17/32 (53%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7893, -1.2863, -0.1153, -0.3183,  1.3153,  1.3441,  0.5254,  0.0711,\n",
      "         -0.1555, -0.6653,  1.7686, -2.7827,  1.1620,  0.7034,  0.2474,  0.5883,\n",
      "         -1.0183,  0.3735,  0.8776, -0.3520]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [18/32 (56%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.5854,  0.1732, -1.0130, -1.2401, -0.0456, -0.4325, -0.0359, -0.1521,\n",
      "         -0.0534, -0.7683,  1.2925,  2.2624,  0.4428, -0.7507, -0.1451, -0.5217,\n",
      "          0.9860,  0.8732,  0.9025,  0.3637]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [19/32 (59%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1003,  0.7517, -0.4364,  0.1266,  1.3024, -0.1955,  0.3335, -1.1141,\n",
      "         -1.9340, -0.8481,  0.1129,  1.2946,  0.5629,  1.8669, -0.9879,  1.1685,\n",
      "         -0.2688, -0.3595, -1.4230,  1.2693]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [20/32 (62%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3275,  0.0627,  0.0945, -1.1205, -0.7748, -1.1711,  0.5145, -0.0559,\n",
      "         -0.0105, -0.0953,  0.2247,  0.8933, -0.7926, -0.5611,  0.7817, -1.2571,\n",
      "         -0.4842, -0.1201,  2.1643, -0.4241]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [21/32 (66%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1846, -0.4871,  0.4115, -0.7741,  1.2210,  0.0239, -0.4012,  0.6655,\n",
      "         -0.3084,  0.3207, -0.3981,  0.0413, -0.3842,  0.3316, -1.3609, -0.5006,\n",
      "         -0.4334,  0.0689,  0.4262,  1.7366]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [22/32 (69%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1333, -0.7138,  0.0987,  2.0352, -0.5751,  0.3471, -1.1050,  0.7201,\n",
      "         -0.2845,  1.7535, -0.8413, -0.2904, -1.1164,  0.2361, -0.0159,  0.5921,\n",
      "          0.4828,  0.2647,  0.2866, -0.8372]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [23/32 (72%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.7461, -0.3668, -0.3699, -0.8127,  0.9484,  1.6554, -0.6772,  0.0738,\n",
      "          1.4872, -0.3995,  0.5849, -1.0379,  1.5933, -0.1527,  0.0254, -0.9491,\n",
      "          0.2010, -0.6328,  2.4482,  0.7850]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [24/32 (75%)]\tLoss: 40561705228284461056.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.1360,  0.0507,  0.2389, -0.5280, -0.1152, -0.7633, -2.6209, -0.0952,\n",
      "          0.4739,  0.1833,  1.7188,  0.0739,  0.1605,  0.8847, -0.5131, -0.1329,\n",
      "         -1.7007, -0.3032, -0.2024,  1.2031]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [25/32 (78%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.4215, -0.1545,  1.1696, -0.2504,  0.1621,  1.8410,  1.8646, -1.2612,\n",
      "          1.1582,  1.6570,  1.4512,  1.1965,  0.1246, -0.6851, -0.0925, -0.4221,\n",
      "          1.5849, -1.4552,  0.0997,  0.6504]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [26/32 (81%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.7128,  0.9501, -1.5148,  0.7728, -0.1601,  0.0516,  1.6187,  1.9708,\n",
      "         -0.0003, -0.4649, -0.6885, -0.3601, -0.6504,  2.1125, -0.7014, -0.5167,\n",
      "         -0.9736,  1.5939, -0.4157,  0.1823]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [27/32 (84%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 2.8489, -0.9877,  1.3935,  0.3713, -0.6406, -0.4026, -1.2354, -0.8811,\n",
      "         -0.3937,  0.9161, -0.7705,  0.1262,  0.1150, -1.2846, -0.7082,  0.2999,\n",
      "          0.1849,  0.0947, -2.2034, -1.2927]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [28/32 (88%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3700, -0.4658,  0.4315,  0.9137, -1.0198,  1.0651, -1.1672,  2.2359,\n",
      "         -0.2376, -0.4075,  0.1746, -0.9458,  1.0888,  0.6724, -0.6769,  0.1176,\n",
      "          1.7455, -0.7267, -0.2841, -0.9768]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [29/32 (91%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2238,  0.2303,  1.0034, -0.3669, -0.7747, -0.4262, -0.8426,  0.8041,\n",
      "          0.9795, -0.6769, -0.7100, -2.1668, -0.7842, -1.4511, -0.4969, -0.6695,\n",
      "         -1.3376, -0.0995, -0.5523,  0.6714]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [30/32 (94%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1361,  1.2001, -1.2185, -0.3352,  0.2144, -0.4658, -0.0177,  0.1569,\n",
      "          0.1069, -0.6422,  0.1842,  2.3397,  1.1996,  0.0133, -1.2983, -0.3787,\n",
      "          0.8016, -0.8503, -0.3696,  0.0651]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4 [31/32 (97%)]\tLoss: 7129966218999496704.000000\n",
      "====> Epoch: 4 Average loss: 29516452548412735488.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHdCAYAAAAZ2vQJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQQQgghhIxI/w/4uwazT6ubvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119ed38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3882,  0.4830,  0.5825,  0.5953, -0.3691, -0.1812,  0.0447,  0.1409,\n",
      "          0.3532, -1.0627, -1.7135, -0.4754, -1.8716, -1.1728, -1.2219,  0.6986,\n",
      "          1.2570,  0.2743,  0.2331,  0.7022]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [0/32 (0%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4335,  0.1449,  0.6336, -0.2265,  0.6585, -0.2531,  1.5582,  0.6755,\n",
      "          0.5669,  0.9556, -0.1268, -0.8696,  0.4738,  0.2474, -0.1647, -0.2070,\n",
      "         -0.1063,  0.2197, -0.6809,  0.7085]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [1/32 (3%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0158, -0.2747,  0.1672, -0.1206, -0.3566,  0.4352, -0.3956, -1.4412,\n",
      "         -2.1006, -0.0939,  0.9946,  0.9055,  0.5948,  0.9931,  0.4170,  0.5588,\n",
      "          0.9351,  0.9883, -0.0497, -0.2874]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [2/32 (6%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6282,  0.0150, -0.0119, -0.6618, -0.5519, -1.3995,  0.2737,  1.1427,\n",
      "          0.2077,  0.0508, -0.4810,  0.5982,  0.4341,  0.1525, -0.2329,  1.7957,\n",
      "         -0.4358, -1.3348,  0.4062,  0.2518]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [3/32 (9%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5456, -2.0996, -0.1353, -0.9031,  0.5840, -0.1794, -0.5424,  1.5975,\n",
      "         -0.8481, -0.4963, -0.9779, -0.2898, -0.0254,  0.9845,  0.9443,  0.3158,\n",
      "         -1.6217,  0.7100,  1.7996,  1.0662]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [4/32 (12%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.5426,  0.3783,  0.9848,  1.2758, -0.5390,  1.3992, -0.4116, -0.1786,\n",
      "          0.0471, -0.9428, -0.1698, -1.0923,  0.0949, -1.5204, -2.0183, -0.9907,\n",
      "          2.0416, -0.0008, -0.6734, -1.5325]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [5/32 (16%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.2751, -1.0393,  0.7249,  1.5025,  0.5375, -1.4346, -1.2850, -0.5983,\n",
      "          0.6945, -0.2348, -0.2114,  0.6811,  1.4899,  0.2938,  0.7800, -0.5063,\n",
      "          1.2463, -0.9564,  0.5672,  1.2720]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [6/32 (19%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.3897, -1.3373,  0.9450, -1.7237, -1.4115,  0.2820,  1.7426, -0.0903,\n",
      "         -0.8389, -1.3713,  1.0001, -0.2730, -0.3072,  1.9030, -0.7320,  1.2088,\n",
      "          0.3209, -2.1941, -0.0862,  0.9495]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [7/32 (22%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.8541, -0.0606, -1.0616, -0.1968,  0.4179,  0.2289,  1.7073,  0.6674,\n",
      "          0.1475,  1.9432, -0.0947,  1.4908, -0.0933, -0.3656, -1.4171,  0.1537,\n",
      "         -1.3222,  0.0110,  0.4895,  0.1300]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [8/32 (25%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.5458, -0.7429, -0.0041, -1.2258, -0.3313, -0.8386,  3.1006, -1.3015,\n",
      "         -0.4544,  0.7969, -0.6563, -0.7271,  1.9062, -0.7823,  0.2328, -2.2919,\n",
      "          0.4788, -1.0844,  0.5984,  0.8718]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [9/32 (28%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.5095,  1.0468,  0.9410, -1.4076,  1.1106,  0.7403,  0.1944,  0.0945,\n",
      "          0.6920,  0.7926,  1.4483,  0.3363,  0.8104,  1.4260, -0.5956,  1.7784,\n",
      "          1.1324, -1.4631, -0.2454, -0.4879]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [10/32 (31%)]\tLoss: 40561705228284461056.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7129, -0.3259, -0.8342,  1.5831,  0.5113,  0.7841, -1.0093,  3.1324,\n",
      "          0.9238, -0.3743, -0.0468,  0.3230, -1.2703,  0.9686, -0.4170,  1.5885,\n",
      "         -1.7219, -0.5837, -1.7636, -3.0306]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [11/32 (34%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6320, -1.3612,  1.3197,  1.6028, -1.4640,  1.1870,  0.8564,  1.3077,\n",
      "         -1.5834,  0.1658, -0.1423, -0.2316, -0.2041,  0.1071,  0.7556,  0.5765,\n",
      "         -0.0418,  1.3711, -1.2697,  0.0154]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [12/32 (38%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-2.0706,  0.8435,  0.2329, -0.2444, -0.9386,  1.4792, -0.9686,  0.2770,\n",
      "         -0.2448, -0.6617,  0.0228,  0.0905,  1.0997,  0.2056,  1.2213, -0.5312,\n",
      "          0.4169, -1.2764, -0.5883, -0.2234]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [13/32 (41%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4117, -0.3411,  0.3037, -0.5001, -1.5292, -0.2253,  1.4999, -0.6654,\n",
      "         -1.3061,  0.5391, -0.5241,  0.2532,  1.9403, -1.1589, -0.3433,  1.0562,\n",
      "          0.1544, -2.0714,  0.1739,  0.4540]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [14/32 (44%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.6958, -0.9556, -1.8439, -0.5699, -0.8455, -0.0191, -0.7133, -1.6212,\n",
      "         -0.0274,  0.1638,  0.4447, -2.5895,  0.2866, -0.4945, -0.5829, -2.1120,\n",
      "         -0.5504, -0.6849, -0.2738,  1.1413]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [15/32 (47%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7825, -1.2197, -1.6108, -1.2149,  0.0059,  2.0373,  0.3893, -0.4031,\n",
      "         -0.5988,  0.0839, -1.1877,  0.9183, -0.0638,  0.2097,  0.1369,  0.4783,\n",
      "         -0.5711, -0.1256, -1.3897, -1.0080]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [16/32 (50%)]\tLoss: 1386609781829009408.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6839,  0.6406, -0.5903,  0.8892, -0.1425,  0.2612, -0.9040, -0.4304,\n",
      "         -1.3389,  0.8097,  1.7056,  0.3033,  0.9433,  1.6936, -0.5275, -0.7260,\n",
      "         -0.8925, -0.2540, -0.5554, -0.5205]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [17/32 (53%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.0520,  0.7044, -1.4365, -1.3189,  1.1017,  0.6752, -1.4581,  0.7594,\n",
      "         -0.3303, -0.7782,  0.9783, -0.7828,  1.0604,  1.1053,  0.7565, -0.0358,\n",
      "          0.4504, -1.0190, -1.2461, -0.7692]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [18/32 (56%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.3521, -1.7939, -1.6410, -0.1660, -0.1359, -0.6888,  0.9448, -3.7745,\n",
      "          0.2712,  0.8539, -0.7373, -0.6623,  1.6345, -1.0676, -0.8848, -0.5953,\n",
      "         -0.8170,  0.0195, -1.4451, -1.0912]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [19/32 (59%)]\tLoss: 201689698293369536512.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4474, -0.0782, -1.0751,  0.3769,  0.4106,  1.5339,  0.4257,  0.2266,\n",
      "         -1.2057,  0.1710,  0.1832,  1.8820, -1.0512, -0.1329, -0.5331,  0.4592,\n",
      "         -1.1222, -0.1103,  0.9715,  1.3007]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [20/32 (62%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5209,  1.2259, -1.3341,  0.5914,  1.9163, -1.6604,  1.9784, -2.2517,\n",
      "          0.5771, -0.6024, -0.2023,  1.0130, -1.6754, -0.3646, -1.5835, -1.9840,\n",
      "          0.3737,  1.4626, -0.5865,  1.8980]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [21/32 (66%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2320, -0.5441, -0.4074,  0.2609,  0.3699,  0.0041, -0.0858,  1.2618,\n",
      "         -0.7000,  0.0786,  0.2723,  0.4158,  2.4876, -0.3332, -1.7643,  0.4596,\n",
      "         -0.5185,  0.6229, -0.1902, -2.1135]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [22/32 (69%)]\tLoss: 7129966218999496704.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.9591, -0.6720, -1.5325,  0.9543, -0.1136, -0.8206,  1.0935, -0.6537,\n",
      "          0.0400, -0.7401,  0.2589,  0.9453,  0.7687, -0.2922, -0.9409,  0.0939,\n",
      "         -0.1366,  0.4109,  0.0804,  0.6330]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [23/32 (72%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4332,  0.7610,  0.6811, -0.8703, -0.3281,  1.0910,  1.9284, -0.2684,\n",
      "         -2.4954,  1.9449, -0.3324,  1.1966, -0.5207, -1.7002,  0.1861, -1.5683,\n",
      "         -0.1365, -0.8651,  2.0830, -1.7940]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [24/32 (75%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.2450,  0.4010,  1.2832, -0.0119,  1.7137,  0.6602, -1.3557, -0.4349,\n",
      "          1.1195,  0.1226,  1.6754,  1.0191,  0.1540, -1.4221, -0.8358,  1.4719,\n",
      "         -1.4586,  0.4448,  0.9770, -2.0809]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [25/32 (78%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4840, -0.5957, -0.6776,  1.0104, -0.3094,  0.9498, -1.0799,  1.5068,\n",
      "          0.3395,  0.4044,  1.0143,  1.5370, -0.0927,  0.7892, -1.4690, -0.9445,\n",
      "         -0.7764, -0.4118, -0.2191, -0.6688]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [26/32 (81%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5841,  0.9148, -0.5205, -1.8456, -0.2065, -1.5986, -0.1131, -0.2480,\n",
      "          0.1624,  0.2024,  0.8116,  0.5607,  1.1502,  0.5777, -0.2332, -1.6214,\n",
      "         -0.3268, -0.7652,  0.3454,  0.6159]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [27/32 (84%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4239,  1.7419,  0.5997,  0.0511, -0.1702,  2.0838,  0.0601,  0.4226,\n",
      "          1.0988,  0.5400, -1.4468,  0.1432, -0.8805, -1.0084,  1.0468,  1.3371,\n",
      "          0.2975,  1.0406,  0.5082, -0.4373]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [28/32 (88%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.6513, -0.0580,  1.0484,  0.6719,  1.9486, -0.3816,  0.0219, -0.2479,\n",
      "         -1.3855, -0.7264, -0.7881,  1.3839, -0.5436, -0.6001,  0.6488,  0.3370,\n",
      "          0.6009,  0.2928, -1.2347, -1.8899]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [29/32 (91%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2862,  1.2478,  0.0812,  0.0180,  0.0691, -0.3734,  0.2616,  0.7167,\n",
      "          0.4929, -0.2228,  0.3795,  1.2595, -1.3350,  0.7396, -0.7635,  0.3317,\n",
      "         -0.6981,  0.1348, -0.0883, -0.1297]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [30/32 (94%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2486, -0.3791, -0.1174, -0.6927, -0.0516, -2.0837, -0.2702,  0.2725,\n",
      "          0.1945,  0.2278, -1.5487,  0.4151, -0.7447,  2.9242, -0.9663, -0.0775,\n",
      "         -0.3532,  2.3167, -0.3618, -0.3919]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5 [31/32 (97%)]\tLoss: 171314803644563456.000000\n",
      "====> Epoch: 5 Average loss: 29516452548412735488.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHdCAYAAAAZ2vQJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXMICVgaDwWAwGAwGg8FgxCX/P8mNzkKaDrNiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1184a8588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.9740,  0.7197,  0.9311,  0.6431,  1.0928,  1.3084,  0.3617,  0.7300,\n",
      "         -1.8857,  0.1613,  1.3585, -0.0144, -0.4877, -0.0860, -1.8713,  0.1067,\n",
      "         -0.1824, -1.0241, -0.4508,  0.1876]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [0/32 (0%)]\tLoss: 40561705228284461056.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.9480,  0.2122, -1.2355,  0.5803,  1.6231,  0.9631,  1.0019, -0.6097,\n",
      "         -1.1774,  1.5144,  1.7730,  0.9239,  0.0556,  0.0042,  0.6407, -2.0584,\n",
      "         -2.0491,  0.2854, -1.3554, -0.2506]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [1/32 (3%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.3842,  0.1814,  1.6526, -0.7673,  0.0922, -0.1852,  1.0140,  0.8432,\n",
      "         -2.0542, -0.1999,  0.6397,  0.3282, -0.8599,  0.8105, -0.2786, -0.7773,\n",
      "         -0.6297,  0.2514,  1.3193,  0.1432]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [2/32 (6%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1062, -0.1196,  0.0256,  1.8400,  0.7943,  1.9468, -0.8765,  0.0068,\n",
      "          1.3815,  0.5425, -0.2554,  0.2932,  0.3216,  0.4107,  0.6479, -0.7834,\n",
      "         -0.5956,  0.3606,  0.0729, -0.9785]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [3/32 (9%)]\tLoss: 7129966218999496704.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.6106,  0.4819,  0.1625, -0.2047,  0.2891,  0.2478, -1.3762, -0.3403,\n",
      "          0.9480,  2.8362, -0.5465, -0.8600,  0.5562, -1.1755,  0.7297,  0.3374,\n",
      "         -0.5939, -0.6338,  2.6433, -1.1947]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [4/32 (12%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.5416,  1.3101, -0.0621,  0.1974, -0.2928,  0.2162,  2.2663,  0.5303,\n",
      "         -0.7036, -0.2146,  1.1669,  0.4332,  0.2205, -0.8924, -0.3437, -0.6981,\n",
      "          0.6153, -1.1372,  0.5469, -0.4228]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [5/32 (16%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.6066, -0.2554, -0.4514, -0.6658,  1.5930,  0.7870, -0.3413,  0.3458,\n",
      "          0.3848,  1.3159, -0.4813,  1.8399, -0.6065,  1.1556,  0.4603,  1.2204,\n",
      "          3.1310,  2.3910,  0.0370,  0.1338]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [6/32 (19%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3020,  0.6684,  1.0616,  0.9830,  0.1462,  0.3641, -0.6041,  0.5151,\n",
      "          0.4201,  0.6927,  1.5265,  1.6111,  0.7270,  1.2475, -1.0568, -0.7430,\n",
      "          0.4592,  0.1645,  0.8278, -0.4270]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [7/32 (22%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6790,  0.3437, -0.3546, -1.3784, -0.2525,  0.5287,  0.2342, -0.3666,\n",
      "          0.3983,  1.3563, -1.2814, -1.4612, -1.7755,  1.4774,  0.2331,  0.2069,\n",
      "         -1.3051, -0.3370, -0.5472,  0.8083]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [8/32 (25%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1629, -0.6549, -0.2070, -1.1137,  0.1093,  0.3214, -0.0627, -1.2997,\n",
      "          0.2948, -0.7744, -1.6332, -1.0232,  2.1447, -1.2424, -1.3668, -0.3885,\n",
      "         -1.9865, -1.9808,  2.0986,  0.3429]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [9/32 (28%)]\tLoss: 201689698293369536512.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1865,  0.8853,  1.1209, -0.3476, -1.5268,  0.2928, -1.0974, -0.4285,\n",
      "         -0.8287, -1.6538,  1.4470,  0.1566,  0.9103,  0.0654, -0.6099,  0.7649,\n",
      "         -0.5421, -0.4952,  1.1740, -0.0508]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [10/32 (31%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.7094, -0.4578,  0.5484,  0.5274,  1.1078, -0.5175, -0.2433, -0.9063,\n",
      "          0.8095, -0.0835,  1.4137,  1.3978,  0.3806,  1.7985, -0.3043, -0.2599,\n",
      "         -0.2006, -0.2556, -0.8120, -0.4862]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [11/32 (34%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0774,  0.4704,  1.3348,  1.7907,  0.5302, -0.5963,  0.7087, -1.0219,\n",
      "         -1.0430, -0.1392, -0.4620, -1.2997,  0.1744, -1.1766,  2.2860,  0.9628,\n",
      "          0.1875,  0.2127, -0.2325, -0.5181]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [12/32 (38%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.6365,  1.1752, -0.5243, -0.5549, -0.7984, -1.5051,  0.3621, -0.4296,\n",
      "          0.8384,  0.7406, -0.4088, -0.0558,  0.5550, -0.1601,  0.8766, -0.4528,\n",
      "          2.0451, -0.3192,  0.9776,  1.3055]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [13/32 (41%)]\tLoss: 1386609781829009408.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.5950, -1.0192, -0.3883,  0.0077, -1.1667, -0.2815, -1.0008,  1.7195,\n",
      "         -0.7057, -0.5215,  0.8302, -0.3611, -0.3225, -2.1282,  1.3060,  1.3679,\n",
      "         -0.5778, -1.6329, -1.2127,  1.0675]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [14/32 (44%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0001,  0.9956,  0.6381,  0.6725,  0.2336, -0.7271, -0.3432,  0.7540,\n",
      "         -1.1462,  0.4964,  0.6683, -1.2240,  1.1069,  0.2372, -1.0655, -1.6104,\n",
      "         -0.1793,  0.5748, -0.3267,  0.8796]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [15/32 (47%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4406, -0.3897,  0.5626,  0.6707, -0.0159,  1.1561, -1.8338,  0.2296,\n",
      "         -0.7502,  0.4732, -0.4092,  1.6636, -0.4772, -0.2452, -0.1149,  0.2135,\n",
      "          0.2389,  0.2780, -0.2059,  0.2779]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [16/32 (50%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4541,  0.3812, -1.0060,  1.9662, -0.8613,  0.2356,  0.4688,  0.3226,\n",
      "          0.3694, -0.7447, -1.5124, -1.0314, -1.1254, -0.0166, -0.4232,  0.1689,\n",
      "         -1.0160,  2.8450, -0.1666,  1.6097]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [17/32 (53%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.0062,  0.2192,  1.4753, -0.6772,  0.3315,  1.2310,  0.5322,  1.3630,\n",
      "         -1.4536, -0.1959,  1.7960, -1.2396,  0.0724, -0.5796,  0.5480,  0.8260,\n",
      "         -0.4108, -1.4960, -2.0733,  0.3542]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [18/32 (56%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1424,  0.7586,  1.6888,  1.7874,  1.5914, -0.1832, -1.1013,  0.2257,\n",
      "         -0.2429,  0.0972,  0.9946,  0.5366, -0.6746,  0.5601,  0.7242,  1.4597,\n",
      "         -2.4226, -0.3069, -0.0699,  0.3082]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [19/32 (59%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1394,  0.4676,  0.0435,  1.0467, -1.3377,  1.3630, -0.4062,  0.1128,\n",
      "          1.3196,  1.7982, -1.1297,  0.0873, -0.0369,  0.6195,  0.5650, -1.4821,\n",
      "         -1.0558, -1.3575,  1.1476,  0.7352]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [20/32 (62%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.8094, -0.2058,  0.3656,  0.2186, -0.1939,  1.3583,  0.8404,  0.3135,\n",
      "          0.1959,  0.3653, -1.5602, -0.2795, -0.9816,  1.1085,  1.4289,  1.3833,\n",
      "          0.0733, -1.6156, -1.0486,  0.3634]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [21/32 (66%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1025,  1.8067, -0.5618, -0.6204,  1.1287, -0.0999,  1.1553, -1.0918,\n",
      "         -0.1139,  0.5620, -1.3962,  1.4659, -0.1886,  0.0438,  0.0849, -0.1201,\n",
      "         -0.4158,  0.7248, -1.7526, -0.4398]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [22/32 (69%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1820, -1.8080,  0.7146, -0.7364,  1.5514,  1.2290, -0.1639,  0.2868,\n",
      "          0.6920,  0.1709, -0.4532,  1.4786,  0.1174, -0.8152, -1.1045, -1.6294,\n",
      "         -0.1798, -1.2512, -0.1710, -3.2272]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [23/32 (72%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0470,  1.7486, -0.3275, -1.9322,  1.6713, -1.2634, -1.0711,  0.7951,\n",
      "         -1.0518,  0.2054,  1.7363,  1.5015, -0.0773, -0.0393, -0.1652,  0.9556,\n",
      "         -2.1081,  0.2358,  1.1353, -0.3314]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [24/32 (75%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1032, -0.1585, -1.7137, -1.5054, -0.4983,  0.3642, -1.2395, -0.3123,\n",
      "         -0.4906,  1.0202, -0.1006, -0.6518,  0.2391, -0.5519, -2.0490,  0.2098,\n",
      "          1.5429, -0.6244, -0.8893, -0.1352]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [25/32 (78%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.4277, -1.0862,  1.1398,  1.9023, -0.7553, -1.7560, -0.4463, -0.2897,\n",
      "         -0.0288, -1.0383,  1.4250,  0.5248,  0.2589, -2.0236,  0.3891,  0.0651,\n",
      "         -0.6905,  0.4012, -1.3248,  0.5157]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [26/32 (81%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.7103, -0.0934, -0.5690, -0.1820,  0.4936, -1.0954, -0.8173,  0.2115,\n",
      "          1.0009, -1.8453, -1.1993, -0.3315,  2.2167, -1.1527, -0.6321, -0.3728,\n",
      "          0.5586,  0.2001, -0.1661,  0.0385]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [27/32 (84%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.7856,  1.4860,  1.0224,  0.7956, -0.9651, -0.2566,  0.1025,  0.0349,\n",
      "         -0.3397,  1.3720, -0.5772,  1.2194,  0.2776,  0.4195,  1.2594,  0.0950,\n",
      "         -0.5047,  1.7148,  1.1463, -2.0382]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [28/32 (88%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-2.1897,  1.6919,  1.2183,  0.0049, -0.6511,  0.7193, -0.1629,  1.0045,\n",
      "         -0.9187,  0.5801, -0.0886,  0.8327, -1.4936, -1.8916,  0.4120,  0.3247,\n",
      "         -1.1749,  0.2078,  0.6556, -0.5110]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [29/32 (91%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3814,  0.8361,  1.2445, -0.1381, -0.5155, -1.1402,  0.2438, -1.4463,\n",
      "          1.0308,  1.3245,  1.2202,  0.5820, -0.4237,  1.3668,  0.0665,  0.0635,\n",
      "          0.8093, -1.4000,  0.7768, -1.0014]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [30/32 (94%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.5317,  0.4314,  1.0874, -0.6625, -0.6242,  0.9480,  1.3239,  1.4586,\n",
      "          0.4526,  1.1085,  0.0118,  0.0980, -1.6359,  0.3926, -0.6176,  1.0681,\n",
      "          0.0010,  0.2127, -0.6499, -0.4958]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6 [31/32 (97%)]\tLoss: 6439071595012030464.000000\n",
      "====> Epoch: 6 Average loss: 29516452548412735488.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAHdCAYAAAAkSJVvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRpFCxgJUmSJEmj8APXKY53siI2PAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a18e6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1362,  1.0826, -0.1759,  0.8621, -0.7693,  0.9093, -0.5669, -0.6569,\n",
      "         -0.9125,  0.9865,  2.2446, -0.3767,  0.0125, -0.4255, -0.5383, -0.5457,\n",
      "          1.1664,  0.5916, -0.9411, -0.1707]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [0/32 (0%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.6675, -1.1463,  0.0341, -1.2465, -0.1282, -0.1467, -1.8585,  0.2390,\n",
      "          0.8253, -0.9576,  1.6564, -1.4885, -0.0933,  1.6891, -0.7630,  0.2375,\n",
      "         -2.3159,  0.1038, -0.6962,  0.8462]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [1/32 (3%)]\tLoss: 40561705228284461056.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3995, -0.7066,  1.1112,  0.7184,  1.8891,  0.2326,  0.7842,  0.2148,\n",
      "         -0.4613, -2.6894, -0.6134, -0.6348, -0.7304, -1.3466,  0.8712,  2.3298,\n",
      "          1.0079,  1.7885, -0.1436, -0.0636]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [2/32 (6%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.9164,  1.1727, -0.0748,  0.1799, -1.8705, -0.9868,  0.1562,  1.0441,\n",
      "         -1.0509, -0.4908,  0.5808,  2.0593, -0.1059, -0.5929,  0.1952,  0.8351,\n",
      "          0.0476,  0.4091, -0.0733, -0.0197]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [3/32 (9%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3477, -1.5407, -0.0464,  0.6337,  0.2410,  0.1686, -0.9328,  0.1785,\n",
      "         -0.3279,  0.2101, -0.6028,  0.7253, -1.8069,  0.9134,  0.2563, -1.6374,\n",
      "         -1.0925, -1.1155,  2.0546, -1.0531]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [4/32 (12%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0156,  1.0639, -1.0741,  1.2374, -0.5852,  0.1301,  0.1846,  0.5336,\n",
      "          0.4152, -1.2753, -0.4759, -1.3805,  0.6063, -0.3249,  0.6357, -1.1067,\n",
      "          0.9271, -0.0708, -2.0354,  0.4573]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [5/32 (16%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.8909,  0.7708,  1.0435,  2.1339,  1.1577, -0.3410,  0.4631,  1.8905,\n",
      "          1.2312, -0.5996, -1.9829,  0.6271, -1.4488,  0.2226,  2.1666, -1.6717,\n",
      "         -0.3436, -0.6069, -1.0716, -1.1787]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [6/32 (19%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3244,  0.4998,  0.3429, -0.9557, -0.7615, -0.2534, -0.1482,  0.2400,\n",
      "          1.0834,  1.1203, -0.4099,  0.9141,  0.1849, -0.3840,  0.1427,  0.0746,\n",
      "         -0.2304,  0.6740, -0.0395, -0.7148]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [7/32 (22%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.0206, -0.4406, -0.7731,  0.1667,  0.0644,  0.6243, -1.6854,  1.8906,\n",
      "         -0.0086,  0.3597, -0.7501, -1.2129, -0.3452, -1.7830, -0.5608, -0.4488,\n",
      "          1.7268, -0.5698, -0.5298,  0.3082]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [8/32 (25%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.8377, -1.1171, -0.4264, -0.2278, -0.1883, -2.1157,  0.6855,  0.9876,\n",
      "         -0.7671, -0.1835, -0.5455,  0.6158,  0.2453,  1.0448, -1.4455, -0.7444,\n",
      "          0.9536,  1.9186, -0.2863,  0.5900]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [9/32 (28%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1511, -0.1759, -0.4299, -0.1120,  0.1158,  0.2789,  1.3563,  0.1541,\n",
      "          0.4504, -0.8212, -0.8815, -0.7202, -0.7582,  1.2638, -1.3355,  0.5042,\n",
      "          0.7075, -0.3880,  1.1478, -0.7658]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [10/32 (31%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3291, -0.6105,  1.9912, -0.5904, -0.0683,  0.9094,  0.3716,  1.5266,\n",
      "          0.0893,  0.8467,  0.5690,  0.4841,  0.6378,  0.6143,  0.9630, -0.3534,\n",
      "          1.1066,  0.5429,  1.2939,  0.2626]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [11/32 (34%)]\tLoss: 201689698293369536512.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0953, -1.3328,  0.7212,  1.2424, -1.4432, -0.9977,  0.5921,  0.7786,\n",
      "         -0.1326, -0.9061,  0.0230,  0.9148,  1.3961,  2.7926,  0.6175, -1.4041,\n",
      "         -0.3579, -0.2793,  0.1498,  0.9627]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [12/32 (38%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3853, -2.1014,  0.9124, -1.4130,  0.7435,  0.0275, -0.9872,  0.9652,\n",
      "          0.5976, -2.1212, -0.7100,  0.0533,  0.3159, -0.6142,  0.1443,  0.8056,\n",
      "          0.8041,  0.5241,  0.0006,  0.1939]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [13/32 (41%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.5096, -0.3161, -0.8746,  0.0110,  0.6938,  1.0397, -0.2947,  0.4066,\n",
      "         -0.3959,  1.0818, -0.2393,  0.3662,  0.9462, -0.0869,  1.5749,  0.1112,\n",
      "          0.6361,  0.6117, -0.5615, -0.3405]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [14/32 (44%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.5657, -0.3190, -0.0190,  0.6179, -0.4939,  1.0200, -0.7079, -0.3563,\n",
      "          0.6836, -0.8104, -1.2718, -0.9515, -1.7325, -2.0767, -0.7787, -0.3046,\n",
      "          1.0990,  0.2866, -0.4989, -0.8736]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [15/32 (47%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.8288,  0.7210, -0.4880, -1.8115, -0.0022, -0.7358, -1.8988, -0.2207,\n",
      "         -0.7831,  0.8346,  1.2668, -0.7146,  0.3511, -0.9761,  0.7555, -0.4940,\n",
      "         -1.0014, -0.2694,  1.4494, -1.6951]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [16/32 (50%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.8175, -2.6723, -1.7325,  0.6975,  1.8989,  0.7260, -1.5166, -0.4012,\n",
      "          0.0191,  0.5456,  0.7518, -0.7195, -0.7435,  1.0138,  1.1972,  0.6880,\n",
      "         -0.5988,  0.2180, -0.2060,  2.0743]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [17/32 (53%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3320,  0.5826,  2.2981, -1.3867, -0.7854,  0.0952, -2.0107,  0.3783,\n",
      "         -0.3158, -1.9258, -1.1363,  0.2747, -1.1759, -1.0245,  0.9875,  0.7492,\n",
      "         -1.1038, -0.2480,  0.4022,  0.7154]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [18/32 (56%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.9497,  1.0573,  0.5207, -2.1269,  1.0431, -0.2136,  2.2287,  1.1668,\n",
      "         -0.3341, -0.2366, -1.6888, -0.4268,  0.7594, -0.7464, -0.1160, -1.2718,\n",
      "          1.0623, -1.1817,  0.7619, -0.7880]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [19/32 (59%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.5181, -1.1828,  1.5242,  0.2756, -0.0977, -0.0815, -2.2180,  0.6097,\n",
      "         -0.0899, -1.5498,  0.1217, -1.5883, -0.5512, -0.0701,  0.7190, -0.3305,\n",
      "          1.8332,  1.7202,  1.2041, -1.1805]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [20/32 (62%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.8315, -0.0912, -0.9484, -0.5941, -1.3322,  0.9756, -1.3597,  0.2334,\n",
      "          0.4870,  1.0366,  1.5886,  0.2478, -0.8027,  0.3985, -1.0024, -0.0222,\n",
      "         -0.9066, -1.1295, -0.5313,  0.7837]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [21/32 (66%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1770, -0.1808,  0.4746,  0.0676, -0.2726, -1.3844, -0.4458, -0.8853,\n",
      "         -1.5717, -0.8793,  0.2826,  0.8955, -0.9831,  0.3074, -0.8049,  0.0356,\n",
      "          1.3621,  0.3335, -0.4094,  1.3272]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [22/32 (69%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.3052, -1.4239,  0.0812, -1.8754, -0.4018,  0.0424, -0.7283, -0.9730,\n",
      "          0.3863,  0.2053, -0.1091,  0.0715, -1.1345, -1.6867,  1.1604, -1.4161,\n",
      "         -1.8525, -1.2461,  2.0376,  2.0603]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [23/32 (72%)]\tLoss: 1386609781829009408.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.9346, -0.6219,  0.5588,  0.1401,  0.5741, -0.5784,  0.9937, -0.9105,\n",
      "         -1.4035, -0.7304, -0.2522,  0.4079,  1.5239,  0.9614, -0.6086, -0.3903,\n",
      "          0.9672,  0.5486, -0.1368, -1.5992]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [24/32 (75%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.9547,  0.7241, -0.6021, -0.8442, -1.0209,  0.8236,  0.2756, -0.9161,\n",
      "          0.1987, -1.9360, -0.0732, -0.7789,  0.2185,  1.0594, -1.0399,  0.2562,\n",
      "         -0.5973, -0.5928,  1.1776,  0.0925]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [25/32 (78%)]\tLoss: 7129966218999496704.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.6799, -0.4939, -0.5884,  0.3962,  0.5308,  0.5757, -1.2801, -0.0352,\n",
      "          2.1500, -0.6093, -1.9631,  0.5600,  1.1682, -1.0241, -0.2990, -1.4250,\n",
      "          1.3098, -0.7034,  0.9149,  0.3991]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [26/32 (81%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3911,  0.2896, -0.5905, -0.3389, -0.7817,  0.3488, -0.0536, -0.2327,\n",
      "          0.0104, -2.4524,  1.3053, -0.8415, -0.5344,  2.0994,  0.3201, -0.4830,\n",
      "         -0.0240, -0.1092, -0.7603,  1.1602]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [27/32 (84%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2113,  0.2580,  0.8226, -0.9810, -0.1175, -1.9897, -0.8422,  0.7515,\n",
      "          0.6875,  0.5468, -0.9624,  0.0874, -0.5776,  2.0675,  1.0473,  0.0793,\n",
      "          0.9480,  1.7233,  0.0304,  1.0368]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [28/32 (88%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.7420,  0.6284, -0.3553, -0.3633,  1.0262,  0.4293, -0.0875,  1.4047,\n",
      "         -1.2006,  0.0555,  1.0374,  0.2831, -0.2945,  0.6011, -0.1418,  1.2623,\n",
      "         -0.7457,  0.8611,  0.1213,  1.7319]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [29/32 (91%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.8062, -0.5904, -1.0426,  0.9593,  0.6558, -1.3998, -0.2847, -1.4528,\n",
      "         -0.5163, -1.4099, -0.8952,  2.3167,  1.5605, -0.8127,  0.0832, -0.2056,\n",
      "         -0.6546, -1.1836, -0.0326, -1.4181]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [30/32 (94%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.6655,  0.2960,  0.5757,  0.9252,  1.1793, -0.4305, -0.1558,  1.6533,\n",
      "         -0.0484,  0.8200,  1.2952,  0.0056, -0.1802, -0.1558, -1.4844,  1.7989,\n",
      "          1.1873,  0.6832, -0.0370,  0.4943]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7 [31/32 (97%)]\tLoss: 13218407953960271872.000000\n",
      "====> Epoch: 7 Average loss: 29516452548412735488.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHdCAYAAAAZ2vQJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVkmSJElSJ/0X+mleQFmoTU4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a5029e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.4469,  0.4701,  0.7911, -0.8873, -0.7071,  0.3363,  0.4707,  0.1802,\n",
      "          0.8139, -1.0633, -1.1406, -0.5907,  0.0144, -1.5719, -0.2261, -0.1242,\n",
      "         -0.0052,  0.2921, -1.0422,  1.2389]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(58316856488122908672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [0/32 (0%)]\tLoss: 58316856488122908672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1257,  0.0817,  1.2714,  1.5039, -0.0809, -0.8758,  1.2656, -0.7241,\n",
      "          1.0921,  1.3545,  0.3431, -1.4492, -0.2405,  0.9158,  2.4874,  0.5117,\n",
      "          0.6891,  0.7108,  2.9198, -0.4141]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(4799747036998008832., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [1/32 (3%)]\tLoss: 4799747036998008832.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5679, -0.5521,  0.0242,  1.2073, -0.5411,  1.1564,  0.4470,  1.5120,\n",
      "         -1.7335,  1.2523, -1.0730, -0.0875, -0.6316,  0.6087, -0.1669,  1.3564,\n",
      "         -1.4343, -0.2529,  0.8777, -0.4216]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1024848.2500, grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [2/32 (6%)]\tLoss: 1024848.250000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.2488,  0.6876,  0.0986,  0.7110,  0.9717, -1.1186, -0.7936, -0.7430,\n",
      "          1.9243,  1.6063, -0.2271, -0.5677,  0.9292, -0.5262, -0.4645, -1.7545,\n",
      "          0.0337,  0.5932, -0.6714, -0.3241]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(431491278052524032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [3/32 (9%)]\tLoss: 431491278052524032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.6715, -1.4414,  1.3393, -1.4804, -0.4679, -0.8777, -1.3615, -1.1486,\n",
      "         -1.2396,  0.4925, -0.8988,  0.1075, -1.5169,  1.6200,  0.5097, -0.7476,\n",
      "          0.6592, -2.7009, -0.1145,  0.1918]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(10166051525068062720., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [4/32 (12%)]\tLoss: 10166051525068062720.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2026, -0.2080, -0.2918,  0.1244, -0.9510,  0.6423, -0.4074, -0.6683,\n",
      "         -0.6758,  0.8074, -0.3178, -0.1300, -1.2612,  1.6664,  0.2231, -0.8986,\n",
      "         -1.3203,  1.0209,  0.6291,  1.0124]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [5/32 (16%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.9397,  0.2060,  1.3960, -0.9912, -0.3220, -0.8792, -1.5111, -1.0755,\n",
      "         -0.1519, -0.4734, -0.7337,  0.6700,  1.2319, -0.2439,  1.2739, -0.7086,\n",
      "          0.5215,  0.2657,  1.6444, -0.4044]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(201689698293369536512., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [6/32 (19%)]\tLoss: 201689698293369536512.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5047, -0.0071, -0.6951, -0.4451, -0.2388,  0.1015, -0.0689, -2.2004,\n",
      "         -0.7141, -0.1309, -0.0215, -0.1184,  1.0464, -0.4123,  1.4730, -0.3376,\n",
      "          0.5643, -0.1982, -0.4867,  1.4395]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1386609781829009408., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [7/32 (22%)]\tLoss: 1386609781829009408.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4809,  0.5690, -0.2209, -1.3688, -0.2422,  2.0805, -1.8787,  1.9047,\n",
      "          0.3906,  0.1989, -0.5318,  0.8597, -0.4941,  0.6043, -0.0498, -0.0148,\n",
      "         -0.1825,  0.9022, -2.0721, -0.1904]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(30881037509344624640., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [8/32 (25%)]\tLoss: 30881037509344624640.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.5163,  0.4090, -1.0201, -1.5733,  0.7195, -0.9918,  1.5899,  1.1647,\n",
      "         -0.9542, -1.9762, -1.1512, -0.2060, -0.9543,  0.7229,  0.4011,  0.2775,\n",
      "          0.2197, -0.4524, -0.8290, -0.1241]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [9/32 (28%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1297, -0.5124,  0.3641,  1.0399, -0.8762, -0.8413, -1.9013,  0.1459,\n",
      "          0.9517, -0.1141, -2.5149, -1.3453, -0.6919,  0.6160,  0.7313,  0.7716,\n",
      "         -0.2389, -0.3951, -0.1010, -0.3203]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [10/32 (31%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.5304,  1.2249, -1.1239,  0.2139,  0.5216,  0.2794, -0.3123, -0.4876,\n",
      "         -0.6426, -0.5725,  0.2770,  1.8965, -1.2414,  0.5815,  2.1483,  0.2832,\n",
      "         -1.0409,  0.2258,  0.2311,  0.9914]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(50599472333693386752., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [11/32 (34%)]\tLoss: 50599472333693386752.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.0738,  1.7935,  1.6954, -0.0645, -0.1211,  0.4527,  0.6917,  0.0216,\n",
      "         -0.0730, -1.0201, -1.3418,  0.3618,  0.9815, -0.2368, -0.6419, -0.5136,\n",
      "          0.4557, -0.0579, -2.0068, -1.0331]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(56907392532476854272., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [12/32 (38%)]\tLoss: 56907392532476854272.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0312,  0.4954,  1.5741, -1.1793, -0.4542, -0.8619, -0.6362,  0.0938,\n",
      "          1.3855,  0.6677, -1.3524, -0.0598,  0.8265,  0.3176,  0.2831, -0.5901,\n",
      "          1.1486, -0.6283,  1.5302, -0.1632]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5961383270766608384., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [13/32 (41%)]\tLoss: 5961383270766608384.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7452, -1.3570, -0.6303,  1.4985,  0.7091,  0.8701, -0.5074,  0.0482,\n",
      "         -0.3002,  0.0033, -1.7491, -1.6790, -1.5802, -0.6356, -0.3009,  1.3200,\n",
      "          0.6272, -0.1849, -2.9085,  0.5073]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [14/32 (44%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2922, -0.1269,  0.5171, -1.5403, -0.3812,  0.8096,  0.4444, -0.9114,\n",
      "         -1.1527, -1.7351,  0.1867, -1.4591,  0.0118,  1.2904,  0.2244, -0.7250,\n",
      "         -1.4755, -0.8861,  0.2896,  0.4730]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [15/32 (47%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.2608,  0.0728, -1.0284, -0.1350,  0.1801, -0.2382,  2.5510,  1.1397,\n",
      "         -0.5692, -0.0469, -0.2310,  1.7812, -0.5223, -0.2908,  1.8025, -0.3116,\n",
      "          2.1307,  0.0509, -1.6034, -0.1521]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(15249034406648610816., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [16/32 (50%)]\tLoss: 15249034406648610816.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.0943, -0.9136, -0.2306,  1.0922, -1.0282, -0.5295, -0.8633, -1.0247,\n",
      "         -0.5189, -1.0795,  0.7491,  0.3061,  0.1229,  0.3353, -0.5494, -0.7933,\n",
      "          0.8052, -1.7265,  0.9650,  0.3847]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [17/32 (53%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.1856,  0.4908,  0.0276,  0.3857, -1.3615,  1.6559, -0.4635, -0.4885,\n",
      "         -1.9468,  0.1323,  0.6401, -0.9752, -0.0962,  1.2545,  1.0196,  0.8882,\n",
      "         -0.6722, -1.2857, -0.1033,  0.0024]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [18/32 (56%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-2.4293, -0.6603, -0.7831, -0.0589, -1.7302,  0.1573,  0.3827,  0.4418,\n",
      "          1.4220, -0.3642,  0.7771, -1.8648,  0.5278, -2.4275,  1.2288, -0.0709,\n",
      "         -1.4626,  1.3261,  0.5212, -0.7029]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(92985538641920., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [19/32 (59%)]\tLoss: 92985538641920.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3789, -0.0767, -0.7122, -1.6342, -0.6145, -0.2121, -0.4200,  0.6204,\n",
      "         -0.7156,  1.1969,  0.5991,  0.5705,  0.3289, -0.7695, -0.3574,  1.1500,\n",
      "          1.0108, -2.1552,  0.6786,  0.8428]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [20/32 (62%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3869, -0.0937,  1.1909,  0.3499, -1.0489,  1.1553,  0.3505, -0.8007,\n",
      "          0.0079, -0.3757, -1.7554, -1.8782, -1.5114, -0.7924, -1.5017,  2.1327,\n",
      "         -0.0759, -1.5116,  0.4808,  0.4805]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(7129966218999496704., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [21/32 (66%)]\tLoss: 7129966218999496704.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7997,  0.3391,  1.3768, -1.0010,  0.3611, -1.4684,  0.6936, -0.9971,\n",
      "         -1.5750,  1.0597,  0.3892, -0.2825,  0.3053, -0.0140,  0.7673,  0.5881,\n",
      "         -0.7682,  0.1308, -0.0994,  0.1782]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [22/32 (69%)]\tLoss: 129342009107569180672.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.9014, -1.2797, -2.4286,  0.2217,  0.8010,  0.8363,  0.2905, -0.7279,\n",
      "         -0.7307, -0.1485, -1.6706, -0.9130,  2.3797,  0.1080, -0.9411, -1.0795,\n",
      "         -1.1606, -0.0824,  1.2808,  0.6017]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [23/32 (72%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1570,  0.6966,  1.6515,  3.2174, -0.3273, -0.4771, -0.3313, -0.0960,\n",
      "         -0.6491,  1.3312, -0.2863,  1.6974, -0.3289, -0.1226,  0.6284, -1.0173,\n",
      "          0.7591,  2.2932,  0.3254,  1.2299]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(5458832239838101504., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [24/32 (75%)]\tLoss: 5458832239838101504.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.0802, -0.4413,  0.5049, -1.0328, -0.5042, -0.3312, -0.9320, -0.2639,\n",
      "          0.5430,  2.3875,  1.4807, -0.9269, -0.5936,  0.7538, -0.1518, -0.1962,\n",
      "          1.0869, -0.3296, -0.0611,  0.2810]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [25/32 (78%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.0643,  0.4763,  0.6545,  1.5813, -0.5602,  1.3951, -0.1798,  0.1696,\n",
      "          0.8056, -0.1857, -1.9547,  0.4157,  0.8227,  1.4250,  0.8907,  0.2519,\n",
      "         -0.1117,  0.3254, -0.8715,  0.4553]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(9442163477708800., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [26/32 (81%)]\tLoss: 9442163477708800.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.8391, -0.2825,  0.0465, -0.7032, -0.2240,  0.5071,  0.8944,  1.0800,\n",
      "         -1.5395,  0.5099,  0.7998, -1.1496,  1.1552,  1.4607,  1.1929, -0.0732,\n",
      "          0.4480,  0.7402,  0.9859,  2.4282]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [27/32 (84%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2772, -0.6770,  0.6731,  0.3667,  0.1339, -1.3777,  0.7435,  0.1189,\n",
      "         -1.7502,  1.2137,  0.7567, -1.7531,  0.8862,  0.2552, -0.3253, -1.2270,\n",
      "          0.0592, -0.1109, -0.7478,  0.9392]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [28/32 (88%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.9360,  0.2525,  0.4732, -1.3011, -0.1850, -0.0234,  2.0107, -0.4161,\n",
      "         -0.5247,  0.5138,  1.1663,  0.9165,  0.3388, -0.6021,  0.3653,  0.0193,\n",
      "         -0.2707, -0.0937,  0.7939, -0.4924]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [29/32 (91%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1501, -1.6293,  0.9594,  0.5556,  0.6275,  1.2931, -0.4477,  1.8076,\n",
      "          0.2436,  0.2717,  0.2159, -0.3967,  0.2629,  0.3297,  0.1963, -0.4890,\n",
      "          0.0842,  2.0394,  1.4500, -0.8160]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [30/32 (94%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.4516,  0.5794,  0.8313,  0.8315,  0.3034, -0.9881, -1.7124, -0.5775,\n",
      "         -1.0578, -0.7559,  0.9157, -0.7735,  1.1005,  0.6669, -0.9320,  1.0927,\n",
      "         -0.2731,  0.4847, -0.5060, -1.5575]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(40561705228284461056., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8 [31/32 (97%)]\tLoss: 40561705228284461056.000000\n",
      "====> Epoch: 8 Average loss: 29516452548412735488.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHdCAYAAAAZ2vQJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvX3sNelZ33fdM+f8nl2zXhPqNY0wWyOw2rqhOOnKRZQU\nE1XUoLYoUqti0QRFICsIqlSNkGgaAQqRWgFqJQSEOolFUBKj0uCAisF1kImdAInXBIwNGK/XBu/G\nsLtee1+e3ed5fmfuu3/MXHNfM2fm/Oblfp35fqRH5/zOOc+ZOfNy3/f19r2UMYYAAAAAAAAAAIDU\nKGLvAAAAAAAAAAAAMAQMVgAAAAAAAAAASQKDFQAAAAAAAABAksBgBQAAAAAAAACQJDBYAQAAAAAA\nAAAkCQxWAAAAAAAAAABJkqzBqpR6h1LqKaXURyZ89n9WSv2uUurDSqlfUUr9e+K9b1NKfbz5921+\n9xoAAAAAAAAAgCtUqn1YlVL/ORG9SEQ/bYz5Mzd89uuJ6F8ZY15SSn0nEb3ZGPPfK6W+iIgeJaJH\niMgQ0YeI6D8xxnzO8+4DAAAAAAAAAFhJshFWY8z7iehZ+ZpS6suVUr+slPqQUuoDSqn/oPns+4wx\nLzUf+w0iem3z/L8kovcaY55tjNT3EtFbAv0EAAAAAAAAAAArOMTegZm8nYj+qjHm40qp/5SIfoKI\n/kLvM99ORL/UPP8SIvq0eO+J5jUAAAAAAAAAAImTjcGqlHqAiL6GiH5WKcUv3+p95n+gOv3368Lu\nHQAAAAAAAAAA12RjsFKdvvx5Y8wbh95USv0XRPS/EtHXGWPuNi8/SURvFh97LRH9qsd9BAAAAAAA\nAADgiGRrWPsYY54nok8qpf47IiJV81XN8z9LRP8XEf03xpinxH97DxF9g1LqTyml/hQRfUPzGgAA\nAAAAAACAxEnWYFVKvZOIfp2I/n2l1BNKqW8nom8lom9XSv02EX2UiL65+fgPE9EDVKcL/5ZS6heI\niIwxzxLRDxLRB5t/f6t5DQAAAAAAAABA4iTb1gYAAAAAAAAAwL5JNsIKAAAAAAAAAGDfwGAFAAAA\nAAAAAJAkSaoEv/rVrzave93rYu8GAAAAAAAAAADHfOhDH3rGGPPQlM8mabC+7nWvo0cffTT2bgAA\nAAAAAAAAcIxS6g+nfhYpwQAAAAAAAAAAkgQGKwAAAAAAAACAJIHBCgAAAAAAAAAgSWCwAgAAAAAA\nAABIEhisAAAAAAAAAACSBAYrAAAAAAAAAIAkgcEKAAAAAAAAACBJYLACAAAAAAAAAEgSGKwAAAAA\nAAAAAJIEBisAAAAAAAAAgCSBwQoAAAAAAAAAIElgsAIAAAAAAAAASBIYrAAAAAAAAAAAkgQGKwAA\nAAAAAACAJIHBCgAAAAAAAAAgSWCwAgAAAAAAAABIEhisAAAAAAAAAACS5EaDVSn1pUqp9ymlflcp\n9VGl1F8b+IxSSv2oUuoxpdSHlVJ/Trz3FqXUx5r3vtf1DwD74m/+09+hv/5//3bs3dg0n3rmNn3l\nD7yHPv3sS8G2+XO/+QT9hR/51WDbA3nwsT9+gb7yB95Dn3nu5di7Ahxy91TR1/xvv0Lv/d0/ib0r\nyfE9P/vb9Dfe9TuxdwNM5MW7J3rkb7+Xfv0Tn429K5vjO/7BB+lH3vOx2LsBEmFKhPVERH/dGPMG\nIvpqIvoupdQbep/5RiJ6ffPvbUT0d4iIlFIlEf148/4biOitA/8XgMk8/vRt+uQzL8bejU3zxOde\nphfunOjJz4czEj71zG16/JnbZIwJtk2QPn/07Ev1tfg5GKxb4uV7Ff3b5+7QH372duxdSY5PPP0i\nffJpHJdc+Nzte/TMi/dwLXvgE0/fpk/iuIKGGw1WY8xnjDG/2Tx/gYh+j4i+pPexbyainzY1v0FE\nX6iU+tNE9CYieswY87gx5h4R/UzzWQAWoY0hDZvGK7oxGnVA45HPKc4tkFTNBXHvpCPvCXAJn1f4\np87RJuzYC9ZhMHd5QxsDJzZomVXDqpR6HRH9WSL6V723voSIPi3+fqJ5bex1ABahDWEA8wwvlkIe\n5hhGMkgfvh7uwmDdFLy4r3C/n1Ev0mPvBZgK5i5/VNqQxtAPGiYbrEqpB4jonxDR/2SMed71jiil\n3qaUelQp9ejTTz/t+uvBRjCIsHrHeoxjRFhxcoGFI3EwWLeFwSJ/lDqLCMclF6rWwYtz5hpj4NQC\nlkkGq1LqSLWx+o+MMT838JEniehLxd+vbV4be/0MY8zbjTGPGGMeeeihh6bsFtghlTbtIhb4gY9v\nyMPceqlhlwABXxf3KlwYW4LHFqxFz9EahnxOsKGKdYl7kBIMJFNUghUR/X0i+j1jzP8x8rFfIKK/\n3KgFfzURPWeM+QwRfZCIXq+U+jKl1BURfUvzWQAWgfoe/1jjMWCEVSPiAs5pI6zXVeQ9AS6JMcbk\ngjaGKhyWbID+gj+gWQIkhwmf+c+I6C8R0e8opX6ree1vENHDRETGmJ8koncT0TcR0WNE9BIR/ZXm\nvZNS6ruJ6D1EVBLRO4wxH3X6C8CuMKjv8U6M9FykBIMhWtElRFg3RYwsjlxAVCkvUMPqDwQogORG\ng9UY8y+ISN3wGUNE3zXy3rupNmgBWA0GMP/Y+rJw29QRtgnSh291qARvixh18rlQadSw5gSXseCc\nuQeaJUAySyUYgNhAkMI/MaKdbCQjsgAkLLgB0aVtoXG/j2IMavlzAs5Wf6ArBJDAYAVZUQ9gsfdi\n28RYTKIOCAyBPqzbBIv8cSo4ZbMC2QL+QLYBkMBgBVlhMJl7J8ZiEnVAYIhWJRgG66ZAH9Zx0Ic1\nLyAg5g9t0IcVWGCwgqyAapx/0IcVpILtwwqV4C0BB9U4aGuTF8gW8IeBZgkQwGAFWQHRJf/EmIBt\nDWu4bYL0QUrwNtG430eBTkNewNnqD2QbAAkMVpAVGMD8wxNw2BpWRFzAOW1KMNrabIpWWRVhqTMw\nx+VFDFX9vQDnDZDAYAVZgRQR/8QwHiG6BIZgO/XuNQzWLYE0ynEqpARnRTt34WJ2DjLqgAQGK8gK\neNz803qMA9oIEK4AQ/B1cRcR1k0BZdVx0HsyL7hsAdeye4wxVOGwggYYrCArILrknzh9WLuPABBZ\nBwZqWLcF+rCOg7Y2eYGUYH+gDyuQwGAFWaE1onC+iSGIghpWMAS3PbkLg3VTVFjkj6I1alhzAqJL\n/kAfViCBwQqyAinB/okxAaMvIxjCRljR1mZLcNQE9/s5qNvLC5Sz+CFGaRJIGxisICuQEuwfnnhD\nLiZ5m0j/ARK+BpESvC1iKJHngjamrYsE6QMBMT8gcg36wGAFWQHvs39iTMCY9MEQrUowDNZNwQ4q\nRE/OqdMgY+8FmAoExPyAXs2gDwxWkBUGPeq8gz6sIBU0IqybBNGTcQyEZrICc5cfcFxBHxisICsQ\nYfWPiVCTY3vZBdskyABOjbyHtjabAhkV40CnIS/gfPEDItegDwxWkBWYzP0TYzFp4E0FA7DBevca\nBuuWQFubcSroNGQFnC9+QEow6AODFWSFRn2Pd2KqBGNyAhI2aBBh3RaISg3DJS84LvkQIyNpD7Cz\nEvcCYGCwgqxAfY9/0IcVpAJUgrcJolLDwHGXH3C++MEe17j7AdIBBivICrS18U+M2hFM+mAIqxKM\nPqxbAn1Yh4HjLj/gfPEDyoRAHxisICsguuSftuVElBrWcNsE6cPX4nVlkHK3IdgRgWyZLkiDzI/2\nnGF8cooVYsRxBTUwWEFW6KbGBwsdf8SpYYUICzhHRuBQx7od2qgUTmkHm90Sdz/AdKBm6wdErkEf\nGKwgK3hOwNzgjxjGIy9cMTkBifSu30Ud62ZAut8wFRx32QHDyg9Ijwd9YLCCrOAJHbVP/oiRnovJ\nCQzRibDCYN0MEFQZBsZPfvC5wprELcg2AH1gsIKsgGHjnxgpwUirAkNUnQgrhJe2AkoAhjFtpgmO\nSy7gWvYDj/04roCBwQqygXvU1c/j7suWieHlR00bGEIjwrpJIC40jE0JxkI9FwzmLi8gOAH6wGAF\n2SDHLQxi/ohRR1VhcgIDyEUgRJe2A9L9hpHjH4bCPEBLNj9gjAB9YLCCbJATAgYxf/BhrgIeZEz6\nYAhZF3b3GgbrVkD0ZBgpMoaayDzAtewHHFfQBwYryAaNCGsQYvZhxWkFErmAR4R1O8BBNQzmuPyA\ngJgf+HjiNgAMDFaQDZ10KaxdvWEnivB9WLFIAxKoBG8T1KwPUyElODvQoskPWBOAPjBYQTaghjUM\nMSYK9GEFQ1TakFL1c6gEbwcN0aVBZEYBjk0e8DkLWUKzB+AIAH1gsIJs6NawYhDzBfqwglTQxtAr\njiURIcK6JZDuNwx0GvKjwrXsBaRagz4wWEE2YDIPQ8w+rGjlACSVNnT/VW2w3oXBuhngoBoGNaz5\ngUigH9rWV1jsgQYYrCAb5LgFw8YfthF6+G1ibgISrYnuO8Jg3RpY5A8DnYb84HOGlGC3wKkF+sBg\nBdlgEGENQowIKyYnMIQ2hu5HSvDm4DGmwu3eATWs+YH0dj+gDyvoA4MVZAPSpcIQI/qByQkMURmb\nEgyDdTtwNAqZMl0wx+UHnK1+6GQb4NgCgsEKMqKC9zkIMdJzbRoyziuwaG0jrEgJ3g5Y5A/TneMi\n7giYjHW24oS5pOu8ibcfIB1gsIJs6KQEY+3qjTh9WPkRMxOwVMa0NayIsG6HdpGPU9oBUaX8aNva\n4HQ5BV0hQB8YrCAbkC4Vhjb6EXAxGWObIH0qTXQsCzoUiu5V6MO6FRBhHQZK+PkRw8G7BwwMVtAD\nBivIBnjcwhAjxYk3VeG8AoHWhsqC6OpQ0N1reDO2AoRqhoFTNj/gfPFDJYZ7HFpABIMVZAS8z2GI\nUcMKERYwRGUMlYWiq0NB9yoYrFsBi/xhoNOQHzxnYXhyCwIUoM/hpg8opd5BRP8VET1ljPkzA+9/\nDxF9q/i+/5CIHjLGPKuU+hQRvUBEFRGdjDGPuNpxsD/kmAXDxh8xjEf0YQVDaG1IKUW3DgVqWDcE\n1/1hIdpFjrk4NHmAlGA/IEAB+kyJsP4UEb1l7E1jzA8bY95ojHkjEf0vRPTPjTHPio98ffM+jFWw\nCgxgYYiRngvRJTBEZQyVqo6wQiV4O9j7Pe5+pIY8HhUOThYgW8AP8nDi2AKiCQarMeb9RPTsTZ9r\neCsRvXPVHgEwAup7whAj2mkQYQUDaE4JLhFh3RJY5A+DlOD8qNqUYJwvl3QUszH0A3JYw6qUegXV\nkdh/Il42RPTPlFIfUkq9zdW2wD5BTUMYYiwm0YcVDKE1UaEU3TqUiLBuCAODdRCDLKLs4FOGS9kt\nnWwDHFxAE2pYZ/BfE9G/7KUDf60x5kml1GuI6L1Kqd9vIrZnNAbt24iIHn74YYe7BbYC6nvCELUP\nK1ZpQFBJleAT2tpsBXu/x92P1Kg6cxzGwhxAPbYfEKAAfVyqBH8L9dKBjTFPNo9PEdG7iOhNY//Z\nGPN2Y8wjxphHHnroIYe7BbYCUoLD0EY/YvRhxWkFgo5KMCKsm6FCRsUg3Tku3n6A6aAe2w8a6fGg\nhxODVSn1KiL6OiL6efHaFyilXsnPiegbiOgjLrYH9glEl8IQQwApRu9XkD5amyYlGG1ttgQcVMNg\nkZ4ffJ5Qw+oWeThxKwCiaW1t3klEbyaiVyulniCi7yeiIxGRMeYnm4/9RSL6/4wxt8V//WIiepdS\nirfzj40xv+xu18HekBE/TOb+iLGYtDWs4bYJ0ocjrLcOBX32RRisWwEOqmGQBpkfBtkCXsC9APrc\naLAaY9464TM/RXX7G/na40T0VUt3DIA+HdU4DGDeiFPDijogcE7VRFivEGHdFLbuL/KOJIaM0mEo\nzAOkBPsBAmSgj8saVgC8Io0ZrF39EUPBE5M+GMKmBJeoYd0Q6Ls8DHQa8qNNCcb5ckrnXsDCABAM\nVpARmMzDELcPK84rsGhDtUpwCZXgLYGMimEQVcqPGBlJe6CbURdxR0AywGAF2YCahjBwrXCMCCsm\nfSCpjKECKsGbozVYYZV1qDDHZYeJ4ODdAwhQgD4wWEE2oA9rGGIIIFmlxXDbBOmjtaGSVYJhsG4G\niKwN01VGxcHJAagE+8HAeQN6wGAF2QCPWxhCK3gaY6AaCgaRfVjvwmDdDKhhHabb1ibijoDJVBEy\nkvZAhXsB9IDBCrIBk3kYqjbFKcxBRlQBDMGODFYJPmmDFNKNgDTKYTplLzg4WWCQLeAFrAtAHxis\nIBsQYQ1DaNGlbm1ymG2C9GEPe92HtSQiQmubjcDnFuN4F0SV8gMCYn7odIXAsQUEgxVkRLeGFQOY\nL9p0vUArJohpgSF4kcIpwUREd69hsG4BK7IWdz9Sw8Apmx18LaOG1S2dGlYM+4BgsIKM6Pblircf\nWyd0i5nuIi3IJkEG8D2uFFmDtUJrmy2A3pXDQCU4PyAg5gdk1IE+MFhBNiASF4aYKcGInAOmjbA2\nKsFEBKXgjQCRtWFQHpEfuJb9gD6soA8MVpANmMzDwJGtUMYjPKlgCC1SgtlghVLwNpBRKTipLBgL\n8wPZAn7AvQD6wGAF2SDHLCxy/AHRJZACXENdKEVXJSKsW0LW+2Eot+jOccGByQE4X/zQ7QqB4wpg\nsIKMgGEThuB9WIUNgokJMB2V4CMM1i0BcaFhum1tIu4ImEy3/Uq8/dgaWO+BPjBYQTZIrzzSb/wR\nt4Y1zDZB+vA9XhSKrsq6rQ1SgrcBFqPDVIgqZYeMqmJd4g70YQV9YLCCbMAAFgab4oS2NiAeHGEq\nlW1rgwjrNsA9PwwU0/MDtZZ+MHBqgR4wWEE2GCxyghA6JRgTPhjC9mElqxKMtjabAGmUw1SdbBMc\nmBxAhpAf4NQCfWCwgmxAH9YwhE4J7qRU4byCho7oEqsEX+MC2QIa5R2DIFU6P5DG7Qc4skEfGKwg\nG+BxC4OOGGFFVAEw1YDBeg8ejU2AsXwYKKPmhzxNFbwMzkDkGvSBwQqyAQNYGKRMf8jt9Z+DfYM+\nrNul46TCKW1BVCk/EBX3QycLAwcWEAxWkBFohRAGnihCHeNuSlWQTYIM4OuvKERKMAzWTQAn1TBw\nyuZH95zhpLkCzhvQBwYryAZ4MsMQOiUYjggwRCVUgm81bW2gErwNcM8Pg5Tg/JBrEUQC3QHnDegD\ngxVkAzxuYWhFlwLZBpiYwBC8+CsLoltHtLXZEnA+DtOd4+LtB5gO2q/4Aes90AcGK8gGpN6EIbzo\nEqIK4Jw2JVgpuio5JRhtbbaAjERhLLdIxWQN6ycLIBroBzgCQB8YrCAbMICFgY9znD6sQTYJMsBG\nWBUVhaJDoRBh3QgG9/wgcN7lhzxPaNHkDtwLoA8MVpANSBEJQ8w+rDivgOHFX1EoIiK6dShgsG4E\nLPKH0RCgyw44XP2AyDXoA4MVZAPqnsLAxzbUJIGJCQzBi/dC1Qbr1aGASvBG0Eh9HQRO2fwwuJa9\ngPUe6AODFWRDx/uMEcwboSOs3cVrmG2C9GlTgoXBigjrNug6qeLtR2qgtjc/IBroByhmgz4wWEE2\nwPscBj60EF0CMeH7vWhmqVuHEqJLGwH3/DDQacgP6WRFers7kGoN+sBgBdmAFJEw2LY2MfqwBtkk\nyAC+DjsR1goR1i0Ag3UYbYiakm0cl0zAtewHdIUAfWCwgmxAhDUMfGxDHWJMTGAIqRJMRHRVIiV4\nK8ioFJxUlsoYOjQpBTgueYD5yw8G6z3QAwYryAaDiSEI4fuw2udIqQLMmUrwEaJLWwGL/GGMMXQo\nVfscpE9n/sLw5IyOkjiOKyAYrCAjkBIcBtuHNcz2cF7BELovulTCYN0KKAMYptKmzShAVCkPtDF0\nwDlzDlKtQR8YrCAbkBIchtARVkTOwRBnKcFQCd4MlbGGWQWLtUUbomOJlOCcMIbaqDjWJe5AuzvQ\nBwYryAZE4sIQuoa16tSz4cSCGr4WuA9rrRIMg3ULICo1jEaENTu0rDvG8OSMblubiDsCkgEGK8gG\nA4+bd4wxcdvaYMIHDezIsG1tCrqHtjabwBhqDVYM5RZtDB1xXLJCGzgZfKCNgWI26ACDFWQDGkn7\nJ0baNWpVwBBoa7NdsMgfpjJEJaeXIqyUBVoTsgU8oA1BMRt0gMEKsoEHrUOhMIB5gifckMfYiPOK\n+R4wbUowqwQfCrp7DYN1C2hj6NDWauKmZ+oIKxbpOSGVnXHO3CGdWsioA0QwWEFGyAUsFjl+aKNa\nRTgvv9wmzitgqr5KMCKsm0FrMcbglm8xUowKY2EWdCOBOGeu6IhZYZAABIMVZIQxhpSqF7CYF/wg\no51EYSbgbuQcJxbUnKkEl1AJ3grdWk3c80ylDRVKUaFwXHJBywgrDCtnaGOgmA06wGAF2VAZO5mj\nFYIfziKsAQ5zN8Lqf3sgD85Sgo/ow7oVtDG2VhP3fIs29fVeKDjvcqGreB15ZzaENoQ6d9DhRoNV\nKfUOpdRTSqmPjLz/ZqXUc0qp32r+fZ947y1KqY8ppR5TSn2vyx0H+0ObOrqKlGB/tNHOgPVlHEk4\nlAWiCqCFs3/blOCypEobOKs2gEyjxPm0aF0ro9YGa+y9AVNASrAftDZQEgcdpkRYf4qI3nLDZz5g\njHlj8+9vEREppUoi+nEi+kYiegMRvVUp9YY1Owv2jW5SggukBHujH2ENcZy5lQ0irEBStRHW+u+r\nQ/0EacH5Y4xcjOKmZ1hoRikYP7kAxWs/yOOKem5ANMFgNca8n4ieXfDdbyKix4wxjxtj7hHRzxDR\nNy/4HgCIqDaeOCUYE4MfTGMLhK1hlcrEOK+gRvdEl241Butd9GLNnkobiC4NUBkipRScshmhtaEj\n0tud0021xoEF7mpYv0Yp9WGl1C8ppf6j5rUvIaJPi8880bwGwCK66VIYwHxwXsMaTnQJEVYg4VTR\nQqgEEyHCugW0ISGogpueMcZQqah2ymIwzAJjwqrq7wVZw4ohAhARHRx8x28S0cPGmBeVUt9ERP+U\niF4/90uUUm8jorcRET388MMOdgtsDd1EWBXqe7who5313/63aWSEFScWNPRFl67aCCsM1txBGuUw\nuhUWxByXC3UkEM4X1xipEoybAZCDCKsx5nljzIvN83cT0VEp9WoiepKIvlR89LXNa2Pf83ZjzCPG\nmEceeuihtbsFNoitYUXdky9ktJMozHHuRlhxXkFNP9p/CwbrZjCGIKgyQKUNFahhzQot+4XilDmj\nqxIceWdAEqw2WJVS/65Sdc6WUupNzXd+log+SESvV0p9mVLqioi+hYh+Ye32wH4xxljJf6xZvWCj\nneH6n2mxTSzSANNXCb6FlODNgAjrMHUWUZ1VAKdsHuBa9gOOK+hzY0qwUuqdRPRmInq1UuoJIvp+\nIjoSERljfpKI/lsi+k6l1ImIXiaibzH1SHtSSn03Eb2HiEoieocx5qNefgXYBZwSDNElf/QjrCFF\nl8pC0TX0dECDTQmu/25rWCsYrLlTaYOo1ABaGzocCqQEZ4TMFkDqqjtsCRgy6kDNjQarMeatN7z/\nY0T0YyPvvZuI3r1s1wDoUtf3EGpYPcLy8XYxGc5gPZaKXrqHEwtqWHTJRlhLIiK6C69G9hj0YR2E\no0pwyuaDNkb0LY+8MxsCPYlBH1cqwQB4R7PkfwGPmy/YQxyyvozTuw9lgYkJtLQGa090CRHW/NHG\ntgLBWG7htjZwyuaDvJbhZHCHFSDDcQU1MFhBNhiDtja+4cN6CNhyQqYE47wChkXWFLe1KVHDuhW6\n9WmRdyYhZFsbGPJ5UIsDQSXYNVDMBn1gsIJswADmnzhtbajdJuZ7wFTatD1YiYhuHaESvBW0IbQC\nGYCv+VIppEpnQD8jCdeyO7Sp9QsKBQEyUAODFWRDpW0RPiYGP/RbiYQQkUCEFQyhja1fJUKEdSuY\n/hiDe76lXqQjJTgXzhy8GJqcYZASDHrAYN0oP/3rn6LPPPdy7N1wSt3Wpl7E+hzAtDb0E7/6GL1w\n59rbNlJFi2hn/Xe4PqyHAYPVGEN/7wOP02dfvOt9P0Ba6OZ+Z67Q1mYTVAvr5O9cV/Tj73uMrhOo\nYTbG0E/+80/Q527fc/69dVsbpATnQDt3NTWs1U7O2dMv3KW//y8+6fUatV0hFCVwy0fn1x57hj7w\n8adj70ZUYLBukBfuXNP3/fxH6Rc//JnYu+KUTkqwxwHs40+9SD/0yx+j9//BM/42kig2+hG+D2tZ\nnIsu/fHzd+hv/+Lv0Xt/90/87whIikqbToT1FVe1qP3te6dYuwQc0F/kT3WK/cbjn6Uffs/H6Hee\nfM7Xrk3m8Wdu0//+S79Pv/L7Tzn93kqzSjCyTXKgn5G0FyfDez76x/SD/+/v0tMeHclWwwARViKi\nH3vfY/Sjv/Lx2LsRFRisG+RU1Tf31tQ0ZV8unwMYe/BPO8zviRFhNSKtqj/h87V8Qn7c7qi0oaKw\nBusr76sN1hfuwGDNGd1zik2t1eSxIIXazs+/VGffVI7niHqRDp2GXLD6C/tqa3Nq1kg+70Xd1HMX\nA+uCPXKqzO7XQTBYNwhf1FW1rYubPW6+J3M+fnv06rWLyYAtJ/hcluX5eeUJMYVFKgiLVJIlIjqW\nBb3iqqTnXt5fqv6WMD2n2NQhhtMtTwnMa8/fYYPV7feGcsoCN5yLFO7jnPEt6NVgNYQ+rILKmCCa\nIikDg3WD8CByvbGL23BNg+f6Hus99LaJZImhEiy32Z/weZEKg3V/9FOCiYhedf+RnofBmjXt/T4z\nJVgn5Ejka9B1zaJu29pAMT0H+g7evRgUOoAjGX1Yu1Ta7KZGegwYrBuEU1ldpyvFRgfqw9pGWHcy\n+Uj4sIZU8NRim/0JMKVFKghLLbrUNVgfvO/YRrdAnlQLnWIpOa+eb9LSXc8R3NYGi/Q8OC+hibgz\nAQlxL0Ixu4s2ZpdBFAkM1g3Cg8jW8t3Z4+Z7AKt2bCTFkOnv1rD296d+3Nq1DG5mKML64P0HpARn\njmnGlEM5rw9rWx6QwLjcRlgdj0umWaRDdCkP7Ny1r57CIdZIrWK22o+Y1SW0Mbs/DjBYNwgv7lOo\n9XGJNtRtaeqJAAAgAElEQVQIUoQRXUphYRQaG+0MNwF3VYJ7KcGoYd0tdd/l7msP3nek51+G6FLO\n9J1iUxdh/P9SyHxhg9X1+FhHWAlRpUzoR1j3Mk/ZednfNjpdIXa4FutT6f1cX2PAYN0gW13kW4+b\n3/qe1nu4seM3hfPFZIhtUrvN/sTEf2/tWgY3YwZSgl91P1KCc6ffCmRySnCzOE4h28KKLnmoYS0U\nokqZYOux66X0Xk5ZiDWm7MOawC0fHY0aVhisW4Qjqyk0WHeJHcB8R1j3aySZs8Wk/2PAx/kAlWAg\nqHoqwURED0J0KXuWts7SCTkSn/MmukRoa5MRfO0eZwqI5U6b7eDx92qNPqwSqATDYN0kW13ks+iS\n8pwiYmulvG0iWdjHEXICNu2kX5xFFaoAEyNIk8Ea1vsO9MLd0+4n7pxZ2oe1FXpJYCzgtHTX12Gt\nEgzRpVxgjQd2rKVwbYYghE4KpwSXA9oWewQRVhism4RVgq83ZnF1a1j9bYeP3x4Xxf0UpzBtberH\nsjiPKugAEyNIk0GV4PuPZAzRC3dRx5or/ajU5D6sCTli/fVhRQ1rTsQooUmBYCrBAbpC5EIdYY29\nF3GBwbpB7MS+ratba1nD6m8A45TqPXqzlgqiuNrmmOjSHp0He2dYJfhIRIS04IxZnBKcUD27r5Tg\nShtSbVQp/u8Elzlz8CZwbYYgRLs5dlgqlcY9H5tKm90fBxisG+S00agUC1IM9et0SUqe/NCc92H1\nv03eBotpyYVaSr0XQVgqTYN9WIkIrW0yhhe75cwsjpTG5VYl2ENbGxZdSuF3gsvEmC9TgDMLfF6j\nRoguwXeDlGAiGKybpK0v2FxKcO199p0udd1Epvfo4e5HWEMsmqT6c/23fK9+3JrzBdxM7aDqvvYq\njrBCKThb+J6eG2FNpT+2MYaev1OnpPuIsIbQaQBuaOux1b5qWEO0mNLG9mHFvVA7Q/a4JpXAYN0g\n242wUjuA+bxxQ/QYS5V+H9ZQKcGs/sx/M6ksUkF46sV7PyX4QESEXqwZw4v6cmbZgU0J9rNfU3np\nXuWtVIHTIH3rNAA3SP2FPbUissKU/kWXUMNaUxmkBMNg3SBcu3raWA2r6Qxg/rZzjRpWEf0Isc0m\n9Wdgm0gJ3i+8YJFwSjBqWPPlvBXItP93CrBInoJMR3ftFJaL9L0YPznD17LamThQiKAIi2xCgKxG\no4YVBusWOW20j2ioPqzVjlWCY/RhrVO960m/v02tt3ktg5vhmnXJq16BlODcsWMM17BOjLDyWBA5\nxCqvPdfjkjbUtLXBIj0H+FpmJ0Ps6H8oQvREtiKb+4lcX6IyZvdjAgzWDcKT6PXGRk9r2CDC6gsO\nyh+C9mG1Ez7/zaQktALCMqQS/MDVgZRChDVn2jTK5txOXfS2Qi+RhwKZju56fLRtbVAGkQNSMFDt\nyLAK09YmTEZdLkAlGAbrJjltdJEvI6whalj3GGHVvQhriPlXelKJuo6Ctm5tJwsBYNGaqOjNUEWh\n6JW3DlAJzhjdRqVoVq0mjwGxx2V57bmcY40xZAz3GsciPQfktVwOtGXbKmHa2sgxYh/H9RJQCYbB\nuklaleCNzXhSTdbnALZVg38KS3skrt2mjLB2RZf4cX/nYu9UAynBRHUvVlZpBfnB9zL3G52dEhx5\n0Saj+y7Hx70K+OQMZyTVQln7SQm2EVZ/27B9WOG8IWpSgnd+IGCwbpC2ID527pRjQqWInJpROPbC\nKAbn9WX+tylTvYmIjJgEIbq0X4ZUgonq1jZICc4X2btyzmI0lbGAa1hvHQqn+8LfFcIpC9xgI6xq\nV2ncIVSCbakQnDdEtXNkj2tSCQzWDWJVgrd1cWvNqnG+RZfSSD2LQYwIqxGtHPrbDJF6BNJkSHSJ\nqFYKhuhSvvRTgie3tUkk84VTgr/wFUenEab2uLAhv5NoXc70U4L3YljZFlP+LlKu595TqvUlqqZk\nYC/X2BAwWDeIjbBua8azjaSV19pKFl3aob06UMPq/yBUInIu90E+31q2ALiZIdEloroXK2pY80UK\n1cyJJKYiwPb8yyd64NaBrg6F45RgqTgLJ10OnF/LcfcnFCF61XNGHZw3NTwe7OUaGwIG6wZJZWJ3\njUwRCdHWZo/pF/H6sNJwH1ZEWHdLpU2bJi6pU4JRw5or570rp/2/VnQpdg3rnWt68L4DlUo5nWOl\nerJvpyxwQ/da3s+agQ1Vv21tWIBsP8d1DBZkI9reun4OMFg3CEejrjfmlqqMoaLwX99zveuU4MZg\nLef1SFyDaSOs9u/+/mwtvR3cjDFE5cAMhZTgvOFxdW7dX0opwQ/ef6SiUE4X0laMqlbHjm2Yg5vp\n92HdS7pmCPX+bkbdPo7rGHLM2/O4AIN1g7QR1o2lUdbiPP5TRPi4xV4YxeC8D2uYbXZTgu17UAne\nL5dUgl+6V22uz/ReOEujnNqHNRXRpcZgLWfs+xSs4B2LUWHMS53zaznu/oQiRCcF9GG1SMdA7PEv\nJjBYN0hbw7qxC9uYOl2q9Ox9bgfjHS4Y+inBITyb1pPa3QeidNIAQXj0BZVgIoJScKZYcaGZfVgT\ncV49f+dED953pLLwkxJcKEUlUoKzwGYL7CslOES2gzYsQIb5Xw90TtgjMFg3yGZVgoP1Ya2P3x5T\ngmXLCaIwi0NtqI2c13+L9JeNtmgCNzMeYT0QEaEXa6ZIcaFc+7A+eP/B+TxU7dT4yRmeHtvMr52c\nM986KTbVel6d+1apBtZEewQG6wbZtkqw/0bSNsLqbxupYiOs4fqwGlGbXP9t34Po0n4ZVQm+r46w\nQik4T/hWnjuWt9kWsSOsL1/Tq+53H2FtF+nFPPVkEA9pWNVtbSLvUCB8Zz51U6333cqFqOsYiJ1h\nEhMYrDN5/OkX6dFPPRt7Ny7CF/TmIqxCNa4/gBlj6NPPvuRkO2zox14YxaBVqgzYh9XWqti/5XtE\n+xqkT5WmJz7n5lp2gav7ai5am1Y5WoKU4HM+d/teNkJUq/uwRly8VtrQC3frlOBadMnhd4vIc4hW\nHp9+9qXdGwJraQ2rpo+4i3nqqRfu0J3ravX3+MR3SrA+i7Dmf50+f+eaPv/SvUX/V65F95x5AYN1\nJn/3A5+kv/oPfzP2blxkuzWsZjRF5AMff4a+7offR5957uXV29lzVC9ODeu46NIeDdb3fPRP6Ot/\n5FfpqRfuxN4V+r3PPE9//ofeRx/9t88F33ZlxvqwNgZrJgZaCP7Hd/4b+oGf/2js3ZiEVcOd2Yc1\ngbHgxSYNvRZdcuvU7La18Tv2fuqZ2/Tnf+h99Ogffs7bNvaAD8PqL/74r9Hfff/jq7/HJ+296C3C\naseIrfRh/Zvv+gj9tZ/5rUX/t1sm5WqP8gMG60wOhWprRFOljbBuLiV4vA/rs7fvkTZEn39p/SL2\nescqwVKpkihUH1ZDStXtHPhvphVa2ZHz4NmX7tF1Zej3P/NC7F2hZ2/XHuHP3Q5vHFaaBiOsSAk+\n57O379Fnby/z3odG1snP6sOaQFsbvuZ8pATr1pD3X7f3uSbS88wLd/1tZAfIeuzCUUrwZ2/fTf5e\n5mvVVxYaL7HH1ns58uzte+18OpdODesGjsVSYLDOxPUk5QMWqNFmW2mtuql1VAPtBFwuZvYdYa0f\nbVsb/8fA9COsAz3HNuZ7uQj//seeejHynshsjfAngDMq+tiUYIguMZXW2YxXMio1qw9rAmMBR/Uf\nvK8WXXLpSNPCWei7DyvPcdcbWh/EoGOwOjKstE7fWc7Xva8svn7kOpOh7SInrRef145KcOLXhk9g\nsM4kB8UyGQHeUmSK1WSHBrB2AnawmuHF+R4Hhn5KcKgIK09M/W1aR8R+LFZeBHw8AYNVR3TejKkE\n33cs6FgqpAQLTtpko6S9uA9rAo5Erpt+sImwunQIW5XgcMKC16f9jKs+6EYC3QQzTlonv27jZZa3\nCKtw3sxREk+ZNY4IRFhrYLDOpCzSN2Sk1yuXRcwUbA3r+U3r0uPHx2xDh24yVnSpHhrC9WEdFl1K\nIQ0wNLwI+EQCBqttEB9+29VIH1alFD143xGiS4JKm+QXuYytT1vWhzWmNsNZSrDTCGv9yAI+Psde\n7dDBu2e61/J6J4MxJovMON8CaN12Qdsw0iqzfIzuiC4lfm345EaDVSn1DqXUU0qpj4y8/61KqQ8r\npX5HKfVrSqmvEu99qnn9t5RSj7rc8ViURZH8wkBe0DFS+XzRGjbF+cRg63ZdeDj91mekjOlHWGP3\nYW3l873vRjLw+PLY0/EN1pgRbq2HI6xEdYQLNayWU2WyGa94P+1YPi8lOObvbFOC7z/Oig5P4bz3\npL/feYLB6oROtkCx3snA35e6YKbNQvPz/Vvsw3rSy8douabfgvG+lCkR1p8iordceP+TRPR1xpiv\nJKIfJKK3997/emPMG40xjyzbxbRAhDUeLLo05HHTbYQVKcFrkKk49d/+tykj5/Xf9j3bomk/Cyv+\nzc/evkeffTGuKIo1WCNseyQlmKg2GJ6/gxpWJq8Ia/3IoktTdzuFbAuum37wvoPzCKtsa+N7kc7H\n8N6G1gcxsL1zyUlNc5v2nvjag3cvVB/WLRhpesUYLf/fnn1MNxqsxpj3E9Fo41FjzK8ZY1gb/TeI\n6LWO9i1JSkd1Cj7pRljT3tc5sJrs0CKHDXMnEdY2JXg7x24qPBjaGlb/x4BTP4d6v7YNync0SMv7\nN7bwku/2BZfQmgZTgolqgwEpwZbKmOTnJabfh3W26FLMGtY711QoogduNaJLDsclWQ/pOw3SpebD\nnjmrx155yqyDNu172bfzaIt9WNfoDCAluMZ1Deu3E9Evib8NEf0zpdSHlFJvc7ytKBQBUyWX0omw\nbmilr7WtdewvWnhAcyO6lIeX0wet6FLJNawhtsl1WwN9WHccYSWKnxZctdkG4Y9/HWEdfu/B+1HD\nKql0fgbr7D6sCYzLz718TQ/efySlFJWF6z6s3UW6z7EXoktu6Dtf1qYEx3QQzsG7wartGLGVPqxa\nm8WGN0SXag6uvkgp9fVUG6xfK17+WmPMk0qp1xDRe5VSv99EbIf+/9uI6G1ERA8//LCr3XIOR54q\nY6igYe9/bOTicmspwWWhqBxY5KCtjRvaGtaAbW1YJXioDyufzj0FAjiT4P5jSR//k9gGa/cx7LYN\nlSMR1lfdf4RKsOBULW+ZEBq+veeq4aYQfXr+5eu2D7B70SVbjuE7DRIRVjf0nS9r78EUnDJTsC2m\nwqQEhxB/9I2rtjZ7XJcyTiKsSqn/mIj+HhF9szHms/y6MebJ5vEpInoXEb1p7DuMMW83xjxijHnk\noYcecrFbXuAIa8qLA2mkpryfc+GFvGq8z3IQ44WDi75ybQ3rdg7dZPjwhWxr0+/D2jmvO3QeVNrQ\noVD05Q89QJ9IJMIaegElPexD1CrBp00sZFxQrfDeh8a2b5kXlbICbDFTgk9tH2DXokuyrc0cMapF\n23I4X+4Z0zGs1p8znYBTZgptgMBbDSs7b7YjuqTN8rFrqHPCHlltsCqlHiainyOiv2SM+QPx+hco\npV7Jz4noG4hoUGk4J9jjn/JFs1WV4HPDxr5XtTWsDlKCqzy8nD44F10KF2EdTAk27s5rLlSNOu5X\nvOaB+DWskVqJ9K/DPg/ef6B7laY71/u5Li5x0ib5RS5j0yjnRaVSEF2qU4LrxDS/bW18iy7V9w1S\ngtfRSQku1jt4cylH8q3Y3YlcF9twWFcrxmioBNfcmBKslHonEb2ZiF6tlHqCiL6fiI5ERMaYnySi\n7yOif4eIfqLxhp8aReAvJqJ3Na8diOgfG2N+2cNvCEopUoJTpVvDmu5+zsUaNuJv6p4PJ31YE1gY\nxaJV8GTjMcAxqCPnog/rgMDAnk4Fp8J+xWseoHf9myfphTvX9MomDTH8vnC2QdgTUN1gsHKU6/k7\n13T/VRlsv1KlWtEyITRGGmYDLcrG4IyXuCrB1/SaVz5ARO4FGM/EqDz+TnbKIiV4HX3RpbW1/trh\nOsYnvp1HS8sGUmaNzgBUgmtuNFiNMW+94f3vIKLvGHj9cSL6qvP/kTdFwIX8UjoR1g3ltco+rPXf\n4j1OpXGiEqzb7e0NcyHa6QttqKlhHY+w7sl5UBlDRRNhJSL6xNO36Y1f+oVx9iWSx18qpg7BdYTP\nv3xNX/zgfaF2K1nWNKUPzWKV4AQcic/fubYpwYXblGD+rtJReunFbTXfjbY267CRQHJbw5r4vRwq\nJdiVmFUKrHEqQiW4xrVK8OZhMZqULxqZBpy6p24O2rBqHP8tbmKnfVjjL4xiwU6BoWPsC2Os+jP/\nzaSQBhga3aQEv74xWGOmBfO9EHocsRHW4fcfbIyG56AUTFobMiaf1k/9qNTsPqwRF6+sEkzURFg9\npASrAFGlViV4z+EaB7ROhpnZAmPkMt9ZMURfBmv96Ko2OAVOekUfVqQEExEM1tmwxz/lAaUbYd3G\nhGQ6HrfzGtZ2YY0+rKuoo52qdQyE8GzyNouBdPtWpXZH5+LUiC49/EWvoKuyiGqw+q5VGkMK0Awh\nU4L3jnUq5DHWV52o1Pw+rLGym+6eKrpzrenB++rEtKJw3Ie1F1Ui8jf+QiXYDa7VbFNQwp5CK0zp\naT/5ezlynfjhmIQ2rlKCN3AwFgKDdSa51LBeNaGJ1Ae+qfQnhvo14XVyuGjLRVreB6zETBRuouBt\n2vPafY+oPidbSAuaAke5D2VBr3v1K+ixp16Iti9ttkHgYy8jF0Ow0fD8y6dg+5QqNioTeUcmwvdx\n2UYSp11bsSOsL9yprzV2lpSOxWC6bW38lmTAYHXDWUqwoz6sqa89eJnlK9pnAxTbibCuqWGVy9qU\nbQ/fwGCdSS4qwbcORft8C/SbqsvXiOxi7dpFhJVbeWzj0M2ClZiJ5kU/1iCjuvXfw+kvezkfrBJM\nRPT617wyboQ1UoraTaJLDyLC2mLHqzxuEL6m2Pk4XXQprmH+fJN+3kkJdnhf2KjSsFPWJbyte6c8\nrplUOTOsVl6b2bS1CdSHte1JnPjxmELdemxZFH4oOLNHYLDOpG33kbBj8lQZunWslTO34kGVMueX\nxHnWpgTrZlAh2o6xPwetTbtYCqXO1xd6Gqph7T/fMpW2x+LLX/MA/dGzL9Gd6yrKvsSq55ZGzRAs\nuvTcSzBYc6l7Y85rWGdGWCNNvlwvzdeea9ElIxbpQ847l+SWRp4q/cyvteerjbAm7nzyndXRbRe0\njZTgNR0Pqh067oeAwToTNlhTHuinRlg//9I9+sDHnw61W6swvYmhfs3+NltTse68SM9m6pPGEj78\nxOfpDz97e/R9jnYShVPna9Wf27Y23feGnm+ZSutW3O0rXvMAaUP0yWfGz5lPYkVY5UJwiKtDQfcf\ny01GWD/z3Mv06Keenfz53EoYWudjMU9ZNbZh/nyTEuxLdMnWbQ/rNLhkjynBz96+R//ysWecfmc/\n82vtHNXqZyR8L+sAa6RugCKvuf9Xfu9P6KV756Uq1QonEVSCa2CwzsS2VEn3ojlpTfcd61N7KUX2\n//nQE/Rt7/jX0aI3cxhOCbbvtynBK29mOZhscWD4np/9MP2f7/2D0ffPa1gDGKya0+CGUr2lU2J7\n52OIytjSg4e/6BVERPTk516Osi+xIqw3qQQTEX3BrQO9eHd7Nax/9/2fpO/8R785+fO5CLUwdiyf\np6zKi7ZYP/N2c609cKuuny4LX31Yw6UEX+8oJfhnPvhH9G3v+NeOz1n9qJSiolh/bebQxq0y/ufk\nboBiupJ4bJ5+4S59+z94lH7xw585e8/WJ8//XqgE18BgnYmtYY28IxeoI6xl+3yMl+9VpE0eCx2p\nGnpRdGnlidl6hPXl64pu3xt3UJimByhRWNGlmxwR9fPtnY8htLbn4FhyRkec397WKkUSXRqLsBIR\nHRwbDKnw8nU1y4kYSxhrKW192kxlVd91czfB0Ui+JwuvBqtf0SW+Zu6lvJBxzJ17FZ20cZod1+9e\nsDolOIP0/o7x5K2GVR7XfNZiPG7fOXWvMSMUgpeM02NO/L0Bg3Um7PFP+aI5aUO3jqwSPD44twud\nDJqHtymChW1/0kmTaPuwuknJIUr7HC+l0obuncaviapJzyWiYKk4bUpwc2/JBewexQYqbVrH2KGI\nK55WRUpR4+2NiS7xezk42+ZSaT3reGebEjyzZUXb4irS7+Rx89gsAnz1Ya1rWPk1TwbBDlOC10S4\nxug7GdaerhwirCGMp36dey4Ga3v+evdV1wk//7dUI2VSewMG60zKyAvIKVTa0H1NhPWSCFHsNgFz\nGOrDOjQIrBVdYgN/q9GbmwzWuoa1fh4qFUeb8VYOe0wJPmmrEtw6yCLdo7GiWjepBBMRHUq3ojep\nUOl5xzu3CGtfj2BuH9ZY4zIf59ZgLerx0VWd/1DZi/FkT552aLD6EJrqiy6tvTZz6AHfEUL0nLKu\nVDjxRxfYa6y7w2vFI9GHtQYG60xiLyCnMDfCmrKAFNOfGOrXzm/itb+Fv+fWochmkJzDSZuLaWBG\nRFjLIlAN61kf1pEIa8L3nEu0kQYrO8ji3KOxUtSmpASXChFW/jxRbQjmYMDbcztvMRrbwcrlJiyI\n1vZkd3TMw7a1qX+LizZwucDZIj4irKpVs12ZEpxDhFVG+7zVsMrIdfe1lLF19m4NVogu1cBgnQkv\noFK+aDoR1gv7yZNWBvZqx/s8JPnfpgSvjbA2///qUCR9jpeizQ0RVtFSJVTtCPd+HTyvO4ywVqKG\nNXbNfCyDdUqENZRDJTSVmWeUdeq8MzgeVW8xOnUh2i4GY6UEV+cRViJ3x1y2tWnb53kzWOvHS3PB\n1rBlQw4jrB1tDQcpwZHT3qfQEab0phJcP45lXqXKaIR1peMdoks1MFhn4nsiccGp0m2E9dLAx5NW\nHhFW6X0+l/x31XCb//+tQ5n0OV7KqdI3pASH78PaF13qnNcd1rBqY6gJ4lBZssEaOcIa+F6QImtj\nlIVa7aBKkUrrWdHS3JTNeRdtDeu0fY4lAMac+qJLvJB2dGvKtjZDvcZdwuNJDnO/K3yMZV3Dav39\nl0OENUR6arfOvftayrTXWG9eqlZqo3QzzRbu3AaAwToT12lAPpAR1kspPzlFWPt1T0TDkbi1NTm8\nKLk6FFkMkHPR5vIx0sYulgoVxkg868PaMVLt51K+51xSadOKLaUSYQ3tLODzfiHAut0I68yFdW7e\nd9M4qNj5OLsPayQnBTsz23vTcXnQsEqwpwir4fky/evFFT6yRWTml4vxaCylNCVCzMnyXhjKvEqV\nsbF7rZEPleAaGKwzKTNICZY1rJciM3nVsNqJwa/oEkdYt5kSfNKa7l6IsNZtbern8fqw2vdC9HxL\njZO258A6yOJGWEMfe77u9qkSPG9hLY9BDseDHVREdd3f1CGmFV2KtHA9a2vjeC3QznFFyD6s6c/9\nrvBjsNaPqjGs1n71WEppSoSIsMoABc8BGdiro33LV4suQSWYiGCwziaXCOutQ31qL0dY0/fmMVJ0\naUjy33Vbm6tGdCmHQv85VDeILnUWk4FSgm3EpdmHkcE9h+vUBVpb0aVD5PHGtoIIu/1KLN7HKDes\n5C0fp36eKI+0eW2W1cnH7lF5XWk6FDbi05YHOTNY68cyRB/WZp7bUx9WH9cPz11EbjQfYl/jU9AB\n5uR+H1aitI8Jo0fWoWuVlaESXAODdSa8gEpV3MIYQydt6L5jnRJ86eLOwZvH8CCplKx1PL+J10aL\n+f9fNQZ/BodmFtPa2oTuwzqeBrfHVBjZC5fHm1j3aKyWKXy/c0bLEOWMdNKcmDsu59Y7mlXBiaY7\nxYwx7ediOa5OlWkVgonciy51a1jr13w5IGxKMAzWNZw7eNd9d+zWTVNYGy2csw01si5IldNI3/KO\n6NKSlOAAxzwHYLDOhBdQqXqyebdYyfB0YULKwZvHdGtYz73PrWdrZUowH4urMv1+u3PhRd9Nokty\nMRlijtBNGvJNfVi3dC4uobVpI6v8GGuydiVmNhc+13tMCeZzPXWOGco0SRmtzWynmDwUsc75dWXo\nWNglU+F4LdC28iiGhQVdYrOr9jOu+hA06mYLrO8LncOarKt462cbdr3nX4DMJWMOh47oElSCFwOD\ndSZl5IjHTXCE8FAqOpaXF3Q5DI6Mre8ZVo1jQ3VthPVapAT3t5E7fJ4v92EN39ZGm/Heg5Uw3nK4\nTl1w0rIPaxoR1mgpwTeoBKfqOFyDHcsmRlgzc+poY6/rqU4x/l3Hsv58jFKN60rT8WCXTK4jrLLs\nhe1iX+OvvGb2EmX1kS3i2sGbQ5mWFveiL/0TqWGQUx/W0RrWgbXqHLprooU7twFgsM7Edd2Ka/hG\nOTS93C63tcnQYJWqcQOF6K4irLcON6dU54YcTMd+l2xrE76G9TzVWxvTZgvkED1yQSUiULHHGx1p\njOB7e88R1uk1rLm1tZGL/KkRVl4kx8t8OWndOs+I3AswypRg32mQcjzZSx1rmy3iUBm57+BdO0fF\nErmbA//Gq7Lw1mGi47zJKcI6Upq2NkKKCGsNDNaZuPaquoYHurIo6FgUF0WX+KbKZZFDdDkSR0R0\nvfK3XDfH5NaGI6xE4151WZMTroa139ZGvmdVOXO4Tl2gjYiwqjQirKGPfdV62Mc/s9W2NnMjQXIB\nnoHge2+RP+0c2ghrPOfVdWWdZ0S2vtzVMZcqwb7TIDvK0jtpbdNmi7iMsGrr4HUxHvF1bUz6QZEr\nj50Ucu3D6ksleKxMam/AYJ2Jayl713Cu/KFQVJbqYjuMHLx5DO9iKWTOu7VbzePK1QMfv9ZgzWAB\nOBW5yBtrbcPpuUSc4uT/2uCI4tB51drQ1Qaj3ZeoREpwvXiNGGGN1EqEf++llOBDoTa52G6j2hN/\n21oFytDILA6l1KQUtzaqE3Fcvq506zwj8t2HtX7N1/g7xXm5NXzU48saVhdtbXQG97J0HvnaRyPu\nhQIov4UAACAASURBVCz7sF4wWJf8jjEhyr0Bg3UmsUVQbsJGWBUdiuJixDFWfdoSbu7DWk+66/uw\ndlWCU500liAXwGPCS9JjXItI+N8vY2pP6lBUoTKGrsq00/BdIw1WotpJEy3COqJ66Bu5eB8DEdbu\n54nWO+xC0E15n2aU8b3PYngxeofXKsHnokvu+rDWjyHa2sh9viTCtyV8rHfO0ttXfncO9ejSYPU1\nJw+lBOcw1I8FgeS5XLJGza11mS9gsM6kFUFJ1LMva1gPhbropc8qwtrMqWqsD2vz/lpvMR+L1mDN\n4NhMRS6Ax+qWUkgJ7rcrYqGTHK5TF1TGdNq5lIWK5jjxoaw5abvC8TbGVmtYrZd+2liWmyCHNjad\ndn5KsNs03DlwH1ZmKCNkDbaVh/80yF1GWI379U6tcG/1Bly1tek/Twner6tD4W387dZzd7ebMmPz\nZaeP6ooaVhd10jkDg3UmRfIR1nryKRvRpesJKcE53ABDEdaOOI8j45sdEezJT/U8L2GKV10uJusJ\n2P9+acNqgCMpwTsTXdLangOixmCN5CCLJcw2LcLqz8MfE3vMp30+tz6sLLJGNF3Yje/9uDWsunVk\nErkXXeL5rCz8p0HKCPUlnYstwfeJ6whr6TAluBOJS/Re5nHpWPpTae9qluQjulSN6MJI5+MSZxtH\n8g9FkYVT0hcwWGdiJ6nIOzJCG2Ft2tpcmkzb1LMMJiyet8dU43gBsz4leMMR1kkGa3cxGaKGlQfj\nsfPKaXg5XKcuqHRCEVYPQiXTtls/XoywqnQXdWuwmS/TJpncFCSXZHHodpEcUyXYdCKs7FRypxLc\nfK9S7f3v63TKS2svEdZ2jeC4htVqPjSvrfj+HFI/O6JL3mpY68eyEBl1iR4PCd9K5wareL4wwlo2\n7a5yGON9AYN1JoVjoQXXSJXgm1LmsoywFsMTw9xF3hhVqxK8PaGfKWlgfZn+EIMjb3Ms1ZtrWHO4\nTl1w0obKsmewRroOY5UNTFMJ9qdSGRP+7VOHso7iawbHQ3fGmIl9WHuiSzHO+3WlOzWspeMoaCeL\nyHsfVntx7aWtjY/1jswWcHE95BBhlS2mfKsEF8o6LXOY/lstlQs1rEt0Bqom9bxU8dYCKQCDdSaH\ngqM9aQ7ysob1WBZ0urCfsVpWLEGmiAyK8/DCemUUjtOjrjbY1kYOouMqwV0FzzApwaaX6t19zyqD\nbudcXEKmmRE1ariRDdbQx36KSnBZ5DF2zYXHsOkR1sz6sOoFfVh7oksxnFenyvRUgt2nBLP4nO+2\nNpUotbjeiehSa7A6zNTRWjhfivXnTF7Xqc53HdElT/fhkOhSDg7r8QirOfvMHHQbYYXBCmbQpgQn\nes1w5IxrWC9d3GP59inSHcDq531xHqL1Xkn+nls7TglWgSOsZ31Ye5HzY7kz0SXdVQmu1ZrjGqyh\nFwvTRJf8paTFhO+5qfeevC9ycLDJPsPFxIhBu0g+xFMMr9vaDPRhdSW6JFKlfbfPq4yhW8f9jatE\nbseyroPXvrb4++Tcl+i93GY7BIiw1g6c7mspM1rDOrBWnfe9dk2fw3HwBQzWmbSpOokO8h2V4LK4\nKKgw5g1KEduXa9iT2SoArox8s8FvI6yrvi4pOgbrqEqwTbmequC5Fq4DGvKkamMN1r0M1HVroUQi\nrI5qw5dud5cR1pnZImub0odGpgSrmSnBMWtYryvTZlgRudez0MZ+p+8+rKfK0H3HuuxldynB3mpY\nXaQE2+epdqLgte+xrDOwfFyjsg/rkMhmqoz3YRWiSwt+BztGkBIMZtGmASV683T7sG47wipvfP7d\nl/rOTkEKCvS3kTtTIqym5+X33T5COiKsJ9W+r7XZpADWJU7a0EGkHhZF/Ahr6PugTQm+EGE9FJdL\nHnKFf/vUOSYHoRaJ7F1ZThQRsYvkiCnBWndSgls9C0fHvJsq7T8l+P7GYN1dSrDDg2qMaa+D0sE5\nW2vYhKC/RvIxLw+lBGcwtFlnY2/h1HFELPgh3D4pVJlWqsBgnYnruhXX2AhrLbp0SQEwzxpWGpT8\n145+Cx+T/aYEy+iH/0lTTkzcY7eT6m1srdVuUtdMQhFWR6n2c+HNlRcirFNbouTG3HE5N9GlrrDb\nxD6sSYgumU5KsA/RJV5f+E6DrIwwWBON5LnGR0/pvuI1v7aUasAJnxrWYG2EKT1co7n2YdUj19ha\npyKrBJdFHk5JX8BgnYnr3muu4TSSsri5rU2WKsGdFBH7vpyM1qSO8PHbpMEqjsu9qhr8jIx+TFXw\nXINUA+Rtdh0RtD/RJW066rhJtLUJfOzblOALM9ShVKtVwVNkbk/pTkpwBmN5pecLu7WL5KgpwbqT\n+eDaeV3priFP5NFg1Ybua2pYd9PWxlNK8Nk5W/H98lSkOt/Z9Hz+ve630WZeyZ7EGVymY87GtWUb\nHGEtVby1QArAYJ1JNhHWUlFZFBcXPVaNMs3fIuHBaiwluNuyZc2EUW+Ia5Vy8OpNRaYbXZ+Gf1dn\nAg7Q80uqPxOx0JN9vzJWmXMvA3VlBvqwRoqCxHJq8WLtUoS1LPynrMfgNNNJ0BFdymEs75Qd1K/d\n5GS0fVjjzb+nytBReFAKx+VB/R7YRP5aeaCG1Q3d9Pb1qaudNU2i892Z88jDft5UApYqY5l+1crz\navuwxisPSgEYrDPhtMVUbx6OOJSFomNxOQJhZd7Tn7D4eJfFsIJit3/Z8t9zrWsDKXXHxBKkiMPd\n0T6sZjTa6QMjJiYijrh0z2tMoZXQaG3ImFoBl4mphtt6jEOLLola/DFKtc0Iayt0NfF6H+pHnTKD\nUakbdrsvuhRj/r2udKtSTCRSgl3VsDZRFCL/aZDaGLr/ilOCt3cPDeFPJdjdOZNzdLKiSwEE0Do9\niT07b1xia1j7EdZ1rcekSnCqjowQwGBdwE1iRjGRKsFloS4Oem0abZo/pYOMxA0tcipt6NDMGGsi\nxtxSxHXLghTopARf7MMqjUe/+9RPCS5FGvKZ0Eqi95xLKuGYYWKq4bY1OaEjrCIlbIxa4j8P9cg5\nzE3DPmVmsEqhmqmL/L7QS4ysoOtKd1WCHTs1+2Nv/ZqTrz7jpA3dd9in6JLLa6fuw1o/Vw4cGJ1y\nmETHtarNdvAvuqSUsp05Ej0ektEIq5bPl6YEQyUYBusCpvaOi4FUCT6Wl1OCbYpM+hOWjMTxAGZ6\ngzvXna7xTF5Xmo5F4bxlQQpMEl3S3fRc38aAFVcQKcE9T/ieVILb4yEMtbLw1+/uJliFN/R90EZY\nb0gJlp/dAsaY2Qvrjvc+h0XdgGF20znkxSqnIcZIiztp01UJdi66RE6jdZeQNaw5lAS5YG6q/RTk\ntewiJbibKZbmeeHj53Ne7nYPyCd4MFbDKq+5Jb+jkxKcwXHwBQzWBZRZRFiLG/cz1mJ0CUMpIv0I\n662mJmdNq4tKGyrLvLx6U5mmEtxPCfa7T9aTer5Nm3q0PcNkjDb1XdawqpgR1voxtFPLRponGKwb\nukflaZ469uQWYa3Mee/Km34q/66Y2RanytChHIqwuvn+uv9y/dx378lK25TgvdSwtr3anRqsbp0M\nnR7kid7LrSO59GdIDolsJno4OowpUa8dozuiSzkcCE/AYF1Aykpd/T6sl+pTcoqwXirCN8aQNlbZ\nd82EVDeHV87rk1KgY7BeUAnuRDu917B2DRNZH86X5VXpTz4/NeT9yxxiRlgj9Wpu+7DuLMLaibBM\nzBTptEzI4B6RdfLlRMfgmcEa+HcaY+hepbttbbgPq0PRJb6mreKsk68+o9KGbrUpwelfMy5gR7bL\nOV2mt7uIBEqtgFTHtRDOI162Fko5bx/lk2pEyLQjurTUYG0jrOv2MWdgsC4gZaUuq3Kr6HBDWxub\nvhBk11ZxqQ8r/0YXKcGV1m10mmhbRtIUJWVtqLNoChVhtcrEqjViW6GVw/acB2PoAYO1iFnD2owN\noTdvr4vxzxw2brBOHXtOC4zcmGihgj01rbZdJB/8GnI3bl/el46dmrKtje8+rCet6epwc6/2LcGn\nyW2EVTp411+baw2bELSZTx5Tgq2GgYhcJ3o8JGMRVilsukx0qUkJVnkcB1/caLAqpd6hlHpKKfWR\nkfeVUupHlVKPKaU+rJT6c+K9tyilPta8970udzwmh4SVumQf1pva2uQUYbU1Ded9WPu1jtcrfs9J\nd0WXUp00ljA1Jbjbh9Xv7x/uw1o/78vnp1rT45IhddxDVJVg3XkMxRSV4CG18Nw5LVCTXFsfFRrd\nMczmqQTbsSDs9chjz3BKsJtjLqN1LuohL6G17dW+F4OVrxmX94gW6e1TswUuft8Ch1Vo+vOyjzFH\nrvd8C5C5ZKx1kvQjLmtrUzvzoRJ8Mz9FRG+58P43EtHrm39vI6K/Q0SklCqJ6Meb999ARG9VSr1h\nzc6mQpFDDWtZT0aX6jmrXiQrZS6lBPPahVOc1kQZTlXT1iajNJSpSIPv7ojBakwKfVj5vDbXcuE2\nkpEylZiomaJQUYx1TrUnCh/RYseJUuMG62GDtc3yOE/9Xexkq/+Pj71yS9cpVj/e3Ie165QMPS5z\nnacUXXKdhVMNROt8OQxPWlOpamHG3dSwNj/TZRbCUO9cVzWsqTpobbaDP0fy0HovBzX4McE8GRRa\nso6pywXSFnwNwY0GqzHm/UT07IWPfDMR/bSp+Q0i+kKl1J8mojcR0WPGmMeNMfeI6Geaz2ZPyoXP\nsgauvLDQ5X6P8v+kzCXRJfacWtXDlaJLhRLRm8VflRxyIp0iuhSirY1Uf+5vUwrvXLqWt0TVM9L5\neQxjfUl6qsttX1IIJkKEVX6OyyHycD4OpFHeFGHtRXVCj8ts5BwHIqzu+rCSSJW2r7mGHVFloeiq\nLHYXYXV5j0gHr4saVjnHpeqgbUuwPCp2d9Z7nrMNXNK2JOtdA/IWW7KO4fmwhErwar6EiD4t/n6i\neW3s9eyp1Xdj78UwUiX4WBaj3sQcBkYJ76JS6qy+x2WE9boR1uDUrE0this7CYx51fuLSd/XxnlK\nsL0e+VGp/aTCDLW1KVQcY72tIW5q4UN6uKtGFfESLvoup8aSCMtJG9tiItWJSaANze7DahXD46gE\nc6bSQUZYldvrT0ae23Y/Hu45mW5/LItdiC7JbBGXJVDSwVtOdL5c/D7pJEx0XOtrS/i4RuV6z3eL\nJ5e0EdbeONzpr7tUdAkqwemILiml3qaUelQp9ejTTz8de3cukrKXox9hHbu4c+j3JZF9ufrpUv0a\nVhcRVltDlP6xmQofp1dcHejeaUQlWA+n5/riTHRJ2XurE2ENYDynAF+6MroYO8Jqa5XCbVtPibBu\nvM586jmvtLaRxwwOxVAf1pt+K6//YvVktinBdslUOJ4j6rY23QirDydRp5NAqVZpPuRCJ1vE4c+t\nnQwO29pkYLDyverTeSSVxHPqwzpWw8rBAqWW1rByH9bw5Tkp4cJgfZKIvlT8/drmtbHXBzHGvN0Y\n84gx5pGHHnrIwW75I+X0xI5KcDE+GZ1W5tSH5lJfLpcqwde67rXHi+VUJ40l8G+571iOpgTLiSKI\nSrC2A3l/m20kQO0oJbjX5oefhxaZIRIGawQjodKXBZeItq8SPDnCWtkIax5jOc1PCe5HWAMvXm1K\n8HmE1dX1N9jWxmOE9dCmBKd/zaylq77rMsJKZ4bVmutBG5EtkaiBxgb/sU0J9rGNoXpu99txDZ+z\nsbY2x6JY5DBpI6w7yTQbw4XB+gtE9JcbteCvJqLnjDGfIaIPEtHrlVJfppS6IqJvaT6bPSlLS3f7\nsBZkzPC+5hZhlX25+p5MaYgRrfs9dVsb5dx7ngJ8nF5xVV5sayNbK/jvw1o/ym1yVKF9rxmoU73n\nXMKLqb7BGsMoi2mwylS7MbbeemrqvZfDIleypA+rFV2KI8B2ah3B5xFWV/dF1clu8de+RzrF6pTg\n7YdsvEVYhWHF49GaW/CkjajTTvNelqUi8m+XdJ1a/Fqax0PCa8/zGlYtsh7nX4BaU9PWZt8pwYeb\nPqCUeicRvZmIXq2UeoKIvp+IjkRExpifJKJ3E9E3EdFjRPQSEf2V5r2TUuq7ieg9RFQS0TuMMR/1\n8BuCE2sBOQVuXMx9WImaQbC3+ssh9UTS6cvVE7votzxYIyJxqkybgiq3uwX4PN9/IcKqRWuFuq2N\n332S55W32XdElAXtxrPIl263rU2c335msIasYdXmxgir67YiKdBxJE6MfOWwyJUMpgTfcG21yqSR\nfue9U3f7ROS8bMQ0SqBEfvuwVqL13fGwj7Y23fWO6xpWtynBV4eC6G6693JtpBOVBd+L7q8f01uH\nEOUhusRr0nOVYFmmN/97K2Po2Pz/HNSSfXGjwWqMeesN7xsi+q6R995NtUG7KQqV7uK5G2Flg1XT\nVS+YnpvBOtSHlXebB4lbx/WLmZM2dN+xyKpNxFT42rj/qqS7o6JLoWtY7Xm126zfky1eUnYSuaQV\nXeq1takipO2dK7OGjrDuOyV46hzTUQnO4FgMRRJv+qnRU4L1QFsbx0rynbY2DqJ1Y7Q9ZYv9tLXx\npXiujT1XLgwrbYyNXCZ6L1em69T3cfl0nVr2tdThe4szG2WmXtlkBy75HZwinbLtEYJkRJdy4lCm\nu3jmyAQrqxINp8ieMjNYpTjPWEowL9rW1OTUPQ2LsyjuFuDfcinCel7D6ttgrR+VWKj1+7Dy5JjD\ndboW/u1JRFgjKrNyzc4lttjWZkmtnaxhzeFYyEjiZJXgiOnpRHZOOXREl5p9cyW6FCgN0ma1NCnB\nezNYHV47nfnSgQOtjbCu/B6f6GaN6bOTwlCdew6RRblelGvsNnNvoeOd69vrlGAnu5olMFgXkPLi\nWTaR54XmUGpZzB6LS5DtT1TPk3lqDVauYV2TEqzpWFijOIdjMxU+Tq+4KsdVgnvpet5Fl8R5rR9t\nGnJba6WWp9Lkhox+MEWk6DKPGzGid1P6sB4Sj0QsQY7VU6/3Shs6FEWQjAgXLOrD2iv7iNXW5ihr\ny12LLumus5DITxqkHGN2I7rkyWAdcjKsMay0Ftd4ovdy2xPUY9mUbPGUU7Zbp12k6T6vDdZiZR/W\nbQVR5gKDdQEyCpQaLBpERCLCen6nn0Y8QakiI3H9iYHPhQuV4LatzQajN3yc7rsqR9PAuup8/r2a\nwynB3ch5q463Az33oT6sh0gGK5+HVFWC+ZrJYfyaipxXJkdYhaBHDsdCLvKnpvv1W2mEnn/ZqDse\nzmtYfagE+0yDtJkrBR3LndSwGj/rHSkO58LJcNJaqO+meS+ftFWsJfIzL5hA2Qau0SPXmR2jl53X\nSkMlmAgG6yLyibA2C7rBCGtebW2G+rCepQQfuQ/r8t9zXdUTxhZVgvk6uJwSPNxixhd8GQ6lIdv3\neKD2uy8p0KYEyxpWFccQ4W3GEF2S4l9jsGLrpu7RTiRo2v+pDLXpYjmM5TJ6YtVwL++3FV2K40i8\nFu3iGKWUUyX1bk9Pf2mQVueiTnHeQ4RVroFc3iNS84Gv6VUpwUY43hO9l9v0VI8q7dIRkFMf1k6G\nTC9bpi1tWvA7bA1sHmO8L2CwLiBlAZg6PYwjrOOREbkYSnVglPBNerkPa5MSvMJjvOUIKw+U9x3H\nFyk8MBLV13lo0SWZhmzbL6TdSsolNsJqXztEaunT1g1G8PhPSQnmY7QmoyI1dMdgnTaOcVZNyvOS\nRLYCmZ4SXD/Gqu+zfVi7SyaXzmutyWm0bgzbOqtoUoK3H2Edi3ytpdOiyYGTQWdQw8pjcyt652H8\nzb0Pa/+5bo5ZsXAub9eliLCCuaS8MGDRICISKsHn+3rKLMLKu1g0Xu36tV6ElUWXVvyeU2Pw2wjr\n4q9KDl7YXpWX2trYdFQVwEg04rzWj+ep3oWqewqvqU3OBb6WZb/HWKme/QhryH2oJoguHS445HKl\nE2GduDCRrbhyWMxoY9NpZ/dhjVTDykZd32AtHC4gZUqwz/pAtk9rleB9pASP1RaupVOP7WDNUGkT\nrXXTVFgQrxW98xJhlerLdrup02lLJtYrnPm4VEDRNMcj5ezOEMBgXUDKXo6qshHWtg/rwITUvbHS\n/C0SHqxUce5x43PRtrVZ2Yf1UNr6jByM+alw7cnVobjYh1Wm6/m+zIf7sDbvtalrqhEe8rsvKSB7\nzzIhIt2X9uWqyVwIqhI8IcLKxyjVsXgJ3QjrtN9V6WbMKvNIF5NjzOQ+rJHb2rBRdyi712TpMEVP\ntrVRrSHv5Ks78EK6UI1K8MhcsCU66q0OI4JDoktrrs2OSnCi45oVAPK3Rup3KyDKI3gwJu4l06gX\niS41x6Mo/K/JUgYG6wJSziOXNayXI6x+PI6+kJG41uPW/Ia2D2urErwuwloWhU0JzuDYTEU30eOr\nQ917byh1qS92EColeKj3a2u8Nep4uxBd6qVIE8WLsPb7sIYcJ6b0YfXZuD4W/VYIU6jEmJWD87E7\nxkxL92trWA9xBGnalOBeYbVL9XI9eFz8pFsSNRHWQ0H3NpRSP4bPCOtZPfYag9WY5EWX2npM7zWs\n/gXIXFONjN+8Ll/q4GInQaHSjbyHAAbrApKOsGrdeoE5Ze6mtjY51IDJ9ifjNawu+rBqOpZ+e4zF\nggfNq+b6GFIK7qse+v75MtWbqDZc+Zi3xlsjB5/BZboaGVVmysarGnoB07YSOYyLt3nbtqYJKcH5\ntDuYypJ2YydtqFRpq9dLumOMfe3i/2GDtYxzztuU4EP3mnTp1Ou2takffcw/rSOwVLupYfWVUTbs\nfFn+/bKGNVXnEwvi+eyDHcp545p+VLV9rlf2YdVQCSaCwbqIslDJGnkywlpySvBQW5tq/sIoJhdr\nWNu2Npy6uEJ0qbINmonS9XIugQdNnhCH0oL7fVh9XxtS/ZkfeZN8GmvP5LbOxRjVkMEaKdofO8Ja\n3jA72QXTdhbcS/pFyghrDg62IUGVm3a7TQmOFFVnXYTDYITVkcEqalj9ii7ZzJW91LD66sNa6YHU\n1RWHszKm7fWb6nx3lhLsKcJ6Hrl2vhnnjDlGTlq3x2zJ8aqgEkxEMFgXUap0PdlSJZgn9yFPneyx\nmMMix6aO2nYCbOzYWrv1Edbrpg/aFlOCWVCKDZCh46RNNz3Xfx9WarZlF2p9RwS3tdmT6FLHYI3U\nyqN/X4Xtw3pzDeshUrTNJ6eFBqtVCfa1Z+6Qgipz+7DGijKcWtGlXg2rw32ptDlrkeJjnXFqjW/V\ntLXJ4KJZSUe91eE41hVdOt/WXE5VHUk7RCoDmQIL4rUlZx6CN/3SJKJMUoJHrjOZRr2ohlXHG/tS\nAgbrAnJRCS4vDCh809wqi2QHRkmbKsktV0T0Ty7y1xo2LB9eJO7lXAJHNlhEpx9hPY92hkgJto4I\nu836NdvKqBEe2v66yrbykTWskVos9Q3WkOMEK1Feghc0W3Jk6AUL65M2VJZssKZ/LAYFVW74rVVP\nQTe0jcVz6KGvEuww4mGMvdd9pkHKsoNj04c1h3TLNfiKsJqOg9dBSrCx7U9SNUxYC8Nnr3oZubbC\nbM4345xKmzYg0On9a2zm3qKU4CbjaOn/3wowWBdQ1wrF3othZIT1cCEywwubq0ORhVE2HInj96zH\neG269knLPrbpThpL4GtjLCX4/BiHE12SAgv92uQ99R+zfVi7NaxEMVOCawdHSA/3pAirxwVTLNgp\ncCynL0w6fVgzOBSdqNTUlGAtnJURanXvXYqwOkwJlmrp9WtOvrrDSYyrV23ZUAYXzgracdWxaI0s\nXXBxzlrF74RTP0+N49s6Ut1vQzoseSrMwakiVZ77vX85QrooJVikYad6XYQABusCDslHWLsqwdcX\nalhvHTKJsPYicaqjJlu/VhaKjitSaSptyBhbpxTDk++TStu2NkRE96qq874UtiKqPZvG+J0opPoz\nP7ap3p2U4Dyu07VI5wvTGqyBrZHYKcE3RVgvZZDkiuw3OivCWtQKkjksZjqCKlP7sApjLoaGxJhK\ncOGwzr8yplOOQeQvekVkI6xEtPm0YDmWuXT8dZ0v3W2t+b6UU4JZC8NFCvQYMiW4nf8SPR6SSptW\n/LOjTN0p21gWYUVKMAzWRaQclmdvO5E1vIYWunIAz2GRY5oifNUxbOr3KtFX7lAWg31np8CphRyZ\nLoo8vHpTqUy3hvXuWYSVnQL9FCd/+9Q3kkuRvcDHfk+iS7wwli1dWjXcSBHWY4QaWk6Nu4RP0Y9Y\nnBYsrNn7figy0SPQ81uByIh7iMyPPiet2z6IEpcRD5kS7DMN0ra1KazBekr/ullDtcARNIWO5oOD\n8ah1PiUcSeP0fL5WfeynVBLPLiW4dfDa9VUrurQ0JbiJatclCM52NztgsC6g7gmZ5t1zqkSE9ZJK\nMNewHsosasCkV56IOtGEToS1VK2i41zaOqVOrVSa53kJbVubpjXDeQ1r/RhS7ICPrxQbGYqcp1w3\n7hItjHTG9hsNvUi3WRiht8+15JdoI6wbui60NFgnpwTXNaxLm9KHRjoj5vRhZYMgxlhwr9KtcSdx\nmYYt6/aI/Ine8TVSFLav7VCLsy1hHfSl4xrW83rsNaeMdSZSjrDyPvocf4ci1zkED04dg9W+rvW6\ndUzrJCi25aCdCwzWBaQclucaCCJreN2kEpzouNhBetyIujWslYzEFWpx6qSs7SGipIUPltC2tSmH\nRZdknQ+R9Bj72ydrJPPj+XnlyXEPBqs00hleJ4dewMgxgihshLeOXFz+TBth3dB1IR2J81WC81jM\naENn9WlTUoJLabAGVwk2gwaryzTsvtCYFKBziYywcg3rXlKCbznuitBJb3eREqytoFGq97JujSef\nEdbzTK9Uj4dEGyG6JAJBbHAWCx1cWlMbYd3SmnQuMFgXkHIvJKkSfBhQK2s/V9nFaC4RViVWsDIS\nJ1UPD0UxWLM7Bdu6wKosp3qel8DXxlj7nyEBJPm6D/rblFEFeV5TdhK5pOodDyIbYQ19Lcr0BH8f\n3wAAIABJREFUVKKwNbTSQBmDo3SpRiKWUBk5Lt/8u4wx7X2dS0aI7LE4Nd1PpgTHGJdPlW4dwRKn\nokva9LKI/Ig7SgfvXmpYO6n2Tg3WAcXrFfOUTLdN9V7u92H1U8M6dFydb8Y5p0rTreN5RhKLLh0W\njl2VUAn2rSuSMjBYF5B6uoatYR1f0Mmajgzs1c4ARlR76PmmbSOjqk4JXirI0e+BuTVvVp1mSRdE\nl+rHfn2Z3xrW+lEec5sSbM9ryk4il1TNwrErulQ/Bo+wtmNEHZEPeS9MUQmO1Z/WJ3z+63H55t/F\nH2FBjxyiEFJQZU6EtU0JVuHn33ujEVZ3c4Q23XZW0inrEq6tKwvVOrW3brC22SKua1i1OathXZ0S\nXCzv1xkCret0cr6HfYy/nHZMFMZx7gptSERY7f62kfOFY9eZkyDRa8M3MFgXkHJBvFQJthf3hRrW\nYy4R1nHvs20qv87jLRuq8za2NI9XHGEth9vaSJEjIrt4ChFhlREXvhzbaGORtpPIJexr6ba1iVvD\n2sr0B65hvUkl+LDByZvP/9QI60kYHzHUc5dQDUVPbvitHdGlSBHW48D16DLaWwklZKKusKBLpFaD\nTQlO/7pZwxIxsykscb5cIof2Jbae0m9KcCHWYUR+HeeuOGk9OF+2rYCK+cfLrm/9RrVzAAbrAsqE\nI28dleALkxEbsXVNR7j9W4qsFSHqKkX2U5yWeov7zeGXDC4pU0+G1gA5VwmuH0N6NtlIHur92g7U\nqqn92NC5GEOmQTOlR0/2lH05RujVOEUlmK+ZLTkyZH/sKedbZoXkkhEinY9W6fny/6k0dRyxwWtY\ntWnnBYnLfTE9p6wvo0X35kuiHURYhcHq0qkjnS/tOL3wejDG1FH2IhPRpZW/9xLdVOvmtUSPh0Tr\nWtiL6EJbm5nHq13fNplmvJ09AoN1ASkLwHT7sI5HZqzHsRyMwKaGrHsiaiJxzc+Si7ZDuXygb9va\niAhjDgvAqdTp4kWr+tqPsPZbzISoHekbyZ12RZ22NnmkO65FTk5MrDSgswhr6JTgiRHWHBYyU2G7\nYao4jBXQSTsqwxhjOlGpqU6xTh/WCPV9tUrw+fXossVd3ylbpwQ7+eoOUlxwLwZrO5aVhdNxTKaq\nr22/IstjUhddYmEopfzMS93IdUY1rFq3GWzdGlbdRKXnt5FsxTAbYT0iRFjBDFKuFerUsF5QAPTV\nl8wXxpxHWDk6J2sdD8WKCCsv/to+rOme5yWwEcCLlH4rg/M+rPXrPgv8z4zkwg7G0phd44jIiX4d\ntXwe+j7l8xCjrY1MCRtji21t2gjrxHFZXi85CJMZcU/Lx5vGmL7oUnDnzYW2Nq7miPO2Nn5Vgjtz\nwcb7sHYirC5rWI3UfKgfl86XnfT+hEWXZOtEX/vZ7cNqX0sZjpAPzZc8n5Vq/nzFP5uzaPrfvSdg\nsC4g5YL4ejBpVIIvLHQrMYDncPFfmsw7EdY1Naz9PqwZRCzmwLUnVyMR1rPF5MR0vTXwd9s+rPa8\nyvTY3YguDRis7X0ceMK2AkDnKU7et92kr19CKdVJId8Cc2vtZN19ypk/zNIsDhlxj2OwmmGVYKcR\n1n5bG1+iS/aa4Z7cu4mwHuZHuC4h07jXOhY50S31Nm6dHqmenGR1Rp1dEyiVvjKubJ0k/+bnHJWe\ne14rMWZusZXbHGCwLiBlaemuSvC5WhlzEjdXqsa35KLoUivO00TiFvdh5ZTgpoZVuWsKnwKcLm7b\n2lxOCVYBvHlmYAHbpgSLyHnKTiKX9HvhElnHQejUfSkARBR2kuzf72Ns7bqoVUfrOvp5EdY82tpU\nYqwmmi5UIw1WX5HHS1w35RR9aqemm20Mt7XxZ7AWO0oJntsuaira2PKNtSnBvI+pO586ziNPjuQ6\nPd7+7avFk0vkNUbUXXfLut+597RdEwihqwRtjxDAYF1AytLSJ23adg9tW5tB0SVrsOZw8fdTBAsh\niCQ9xsdyRR9WXvzJlOAEz/FSqqaOYkwl+LyetP47TErwgOiSUAneWrR7DE6Fkj2HbaZE2H2RAkBE\ngUWX9M0qwUTbuy5OTerr1EwRGWHNQZiMh5LZfVh7kazQv/P6ZGvTJC7TsLXpZlYoT4v0U2++JNqB\nwdr8vlsT20VNZUgcaOl82a1VTNcRV8kWU4WfTgp9AbJCpV+3KbMW6791572ljgiZadYGERI/Fr6A\nwbqAlKWlpUqwLYofb2tzLPOIsJ71YRWeqlPPA7V0McP/79h40gtPggKxYKVNFg85M1ib39rvw+o1\nJVikQfHjUKr31gSwxjgNRHKsGm7gCGuzuSiiSxNUgoni9OT0CaftTxXzqSqRXZJBzX2rUDvTKab7\nKcGBf+ZJ68GUYJdOgqonLCh1GlzSrWFt5oItpRINMLdd1BRYQEyJuYto+ZrBZhSlrZOiRT25z7R1\n6byJkVUxF6kLU/9t3ztp2193aUowr4OIoBIMZpB8hFXc6MeioOvBGlZWLatTMFOPUkzpw1rXsBaL\ne8qxl1mmnm3JSGJnhlJ1WvDd6oYa1gBiB+d9WO1gbGs3FJU7EV2qI4vd13ihHHqSkgJA9d8BDVZ9\ns+gSUdqK7UuoGkGTqRFWmUZYJByVYc6zOKbNpWzIE/E5D3szXFcjbW0cLthNz0lT1+07+eoOstSC\nI6ynrUdYZbsoZ+erfpzbommMMwdtoveyvBcPZeHFkapNN8vIV09il7RZi8fzCCsrKy/JyJDt/aAS\nDGYTqy/iFGQNK9H4go6jbbEEXeZS1zTIdKmBPqyq9hgvnXzb1OJyo6JLIs3yVlmMt7VpRgWbrufv\nGLSTvqiJ4ahCZ6DekehSP7IYK8IqW0HwvoVCG0MD9sEZmzNYOcI60fisesqiqd8jfQfV9D6sIiU4\nwmL+utJ0NSS65DLCelbD6mfs3WNbmzZbxGFXhHPNh+7rS7+vLIqkxzWtuw4nfynB9u9CpR9UsRHW\nc5FCjhgvaYMlI6y2D2vax8IXMFgX0KqnJjjG1xFWe1oPpRppa6Nbr3z9d9o3QL8Pq/S4sVDJ0pQL\nZkglOHVDfg7SmXE8XDBYz1pO+NunIdVQPn182ebSssMFsj6IafuNBv79PCkeD+HHiCHDfYiyyKOk\nYSq8sJma3numEpz4PWJ6JQBTF/laRHVq/QJvuzjIqRoWXXLehzVADSunVyslW5ylfd2spRNh1cZJ\nqnWbLVD058uVKcFF2o64eoyqn5eFH+OpH6DIQnTprIa1a7ByydrSPqwsPtn/7j0Bg3UB7GhNcXHQ\nj7COpZadxMKI/1/KmLMBzC5yTmJx60J06dDWsKY7aSxB1gVelef9avmn9vuw+jSUqr6RXJxHzoum\npieH1PW19O9fItFvNPCi8tTsS5u2GXC8my66tK1rQopzTMkU4WuCnTopOlEl1YCDimhBH9bgKsHD\nNayuDIu+WjpRPRb6qGGV8yVnT1yfEr9wVnJej7/+O8+yBdrMu2Xf11eDTdWH0EnP91Q2JcWsiLoZ\ndanSVwk+a2tT1uvtpX1YOSAjt7U3YLAuoIyQIjcFY8xZsfqhHK7plAsjovRvgP4A1hHnEVGpQ7Gi\nrU0z08iU4MQPyywq0fD76mKElZrHAKJLrZHMj9aTymlBSlmxgdSv07X0718imTYZ9rfzfdWOEQFX\nUFNFlw4bjLDOEY+TZQwp170xNu2xG5W6abe1tqUKMaLqdUrwQITVkfEsjZX2u721tdHt8T/upA8r\nR1iPDtdu/RrWtSnBnRrWCHXaU5ECaL46KZzVsBbKa7cCF/C689aFtjbFAjEt2eoOKcFgNqnWsMr2\nLsxhZODj1OEYi9ElnNewdkWX+JyMGehTOPWOXw4LwDlIQa6rQ0H3RvuwupmAp2B62yyUfa3qTYz8\n2pYZ6j/atqcK/NurqnFqRXAWDBnuQ6SsprmETvuDGSnBvBhK3Xi3Ual5WRzdqE74BdupMsMRVkd1\nw/wV58qoq7/6jErbMWU3Naym56B3cGD72QJK1V0ZFqcE92oVUz0lMkLvK9thuCuE8804hcewwQir\nsXPpKpXglcJeuXOIvQM5kqpSV7+PKFHteR9axNTRNspIdGlc8l9OwGMG+hRstKJJCS7SPy5zkHVg\nV0OiS736Mv6s1z6soj6Dt92JnCt7Xom2b7AOGWqxjHWOcnJ7rJBGgmwXcYmU+xUuodJ1H+2pEVa+\nVw5FUadHJz5enUelpi3AOqJLEer7RlWCHS3Y++ml/NxXhFVmJBFtv4a1bSvi0PnWd/ASrUuR7XY7\nSDvCKvuw+hh/QwmQuWRMpJAzHwthbBpjJs1vRF3xSV4abH0dNAYirAtINSw/HGEtBlNka49PkU3k\n6ryRtBTnERNwuTwlmL3MbR/bDFQ358A1iUS1F/BuQinB3T6szXvCeMsldX0t/bZURPGMdTaeiML3\nO61mqARv6R5lJ8FUT3ynhjWDjJDzMaZ+vLEPqxRd8pQqe4mT1nQciPi7aj3T70/Lz338TDkPqEZZ\nf+sRVt0vgXJgoLOAWL/9ytJbsA04zCgJiIEs1/ClTK574oO+BMhcIh0O8vy12RNqmWbMoErwxtdB\nY8BgXQCnBqU2oFi5entax9va5CW6JKXUiboeN5kutkZ0SdaQ8OOWDCTp5RuKsPajH1PT9dbQRhba\nVjp24K90N/JKlJ6TyDV6wGC1bW0iGKyRhG4mqwQrFbzdj0/YYVGnOk8TIyJqaliLIvn7o1+rObkP\na6fsI0KE9aTb9FlJWThKLw1YwyqNf6J6ztx6H1ZOY3Xp+Ow7X4jWRcXba0Dc/ykis4B8GdZDIpvJ\n17CKgJGMPHfH6PnXX1+MS762N2CwLiDWAvImxmpYh7ynZwqgif2WPv2UYOlxq4Qxu2YAvRYDC9H2\nIqxSgfZiDWu/D6vHtcy5kWwXadLLyucktXvONZWhM0ONf3voa7G/MAm1fS0WbjdR3+++9ygc7LCY\n6kg8yT6sRfr3h1S8lI+TUoJFhDW4wap9pwTXj92okqc+rNW5wbpU9yEXtEi1J3LT07ovIEa0bs1g\n0/vZ4ElzYJPzsk+nynkNa9rXaMfhoGxKtzQ4iwVrKv4s9+cm2n6m2RgwWBcQS7XzJuTihRnzRrNS\nYKrR4j59MRrpcdPCEDsWiq6rZX3WqjYluL4tNh1hPQy1teE6ql5UM0CEVaYIWkeEEa/vJ8LaN9TK\nSA6yjsEaMCW4TYGaWMOaaq3XElgMryimnXPZo8+VYq1PVqUER4r2E9UK8scB0SVXTk1bp9b7bg8/\ns18nfyzPnZdbox9hdZPGXT/KlOA1kVFp8LhKNffBWeaNl5Tg82yD1C9RGTA6CEdq1XFEdF+b9L2t\nY8TOiVtfB40Bg3UBeakEF23kUMJe1lSjxX206RricqCUdX+HFbL1bUqHiLCmPkjOoRNhHRJdGkkJ\n9rk2HK5hPU/1Licu4HPnpPVoH9bgbW2kwVqGi7DKhdtNpNyvcAl1hNWO4Teq58q6qQwyQobu9/r1\nCSnBwnkScu6ttCFtaCQl2K3oUmeR7qnHsBxXiYiuSrX5PqycBu0ywjrUO3dNVFzWMR8SjbAaU98L\nMkPCx/h7JrLpqSexS1rV6EJRWYoIayVTvYvOa5O+FynBLTBYF5CqUJEU4GDG1OZ4AOdoYmq/pc95\nI+l+6mj9+hrD5qytTQaD5Bw6DeMH+rD2J+A2XTxEDWuzTSWERqTQ1l4GapnezrTXdGDLLESD+CGG\nUu3G2GqEdeo4JuujDhlFWFVvjLnptu4vkkMa5te9/twSV+nJQynBvtIg+8Jux4Fsm63BDnoboVr/\nnX3nCz9fesrk+q1ItNSBf/P/z967xtqyZedB36xaj73P475Pt+1+OE67G5IQ2wLjiCbEOFaCgxQs\npEg4WJGQiIwR4QdECEtI/sEPBAoOIGJjLBMSIYEVEYwNdOJgEz/ibj/aSbe7ncTte286vn37cc+5\n7XvP2Wfv9aiqyY9ZY9asWWNW1Zw1Z+3a+6xPOtpnr7X2WrXWqppzjPF94xu6nzzR+tvtYb05kmAa\nX6N7WE2GtX5LPuu0NPbDOWKyJWNUwiqE+C4hxG8LIV4VQvwAc/9/IoT4VP3vs0KIUgjxUn3f54UQ\nn6nv+2TsN3AdWKpRkRm8EFyuudTDqiUKC3svNippu/G1paO0gK4n9Do2C44hCV745zIWjYOdem9c\nwmpvwPRxzz2HVTOsFquS+liWANsQBbg+htUMbLMZrwVT5jqE23SNArSWGd/5YA9rEwxlmQqWl8yy\nmiMagPFrDH0uAGr2ab73SK+1zniGNc4cVo6tSyQJLmVLxfEs9LBS8a3xQojXw2p+Z1PWo9LYC1fZ\nMhO0RtGhfk+ldjDbgYCbMYfV3LfM+eC2mZZ5m8/zmgzrLarRemFwDqsQIgfwwwD+BIAvAPh1IcRP\nSyn/IT1GSvmXAPyl+vF/GsB/JKX8qvE03yGlfBT1yK8RS2185lyCV1mGq2PZeSwlA/kNYVi5QdJa\ncmEE+ZRshrgecmNtlvYdh8KWO/eZLtnsR9I5rH2SYINtfGZMl7ge1muSQ1dGIWg1Y2LY9IYNP/a2\nuQQr2b4/w5pnWWvGZIYRH941QDM0xhoLDLcdtEyXZg7mSS7L9bDGlgTnnaJsGkmwyV49Cz2sFO/E\n9GWwPR+Aad8ZLWPkJrtE5+ZG/dLMqk+x/NqF21QGZDFhtmessoYoMhNZGUACmIUMKhQs/bNIhTEM\n67cBeFVK+bqU8gDgJwB8d8/j/yyA/y3GwS0VS2185npYXYOdi5ICo/pvF34BdE2XDJdgw/WQgoqQ\ninFZqb6JlgPewr7jUNg9Upu8bw6r3V82x3Gp3zPDtMKevQgs75qLDbPPmHBdcugWwzpjP7c5z24I\nq3xeti01VGIWzrDScywVLtOloWNumS7N3MNKY9I4l+BY5jiusTYptuWyki0V1rMwh9Ue4xdjzbAd\n7oFprLiZmCyVUWxIEdQ/0xT1u4q6NNdCTLT8BAyzU1MSHHL+mS7BwihKPosYk7C+D8Abxu9fqG/r\nQAhxB8B3Afibxs0SwM8KIX5DCPF9oQe6JCy1n45zCV7nfKWuy7Aue8Oy57CaFTezYjyFMT6WsiX7\nuk0uwXZ/LucS3B0xo35PmSQ2bFr7NaWUnbEqwO1fqLn5o9dl8mbOhF3l8/WKmoPShzDnuJ05UMq6\nkDjSDI++k8wIhpZcfQ91Ip9j9qMLxJTwDGucNUmvva0e1kQMa90nTVBzWJd7zsQArasxizqsJHhC\nkbs04jdViFteTMbNUU4zh9VW1C17XQO6Bni6h9UwXQopvJ9cghsMSoI98acB/LIlB/6jUso3hRDv\nAfD/CiH+sZTyF+0/rJPZ7wOAD37wg5EPKy6WGjy7GFZuQSmqCpvVyujHnecYQ9FxjTMqkHZgDSCo\nYkyjflqvsfDPZSxs51XeJbi9Aes5rCkZVqZXhV6zNDat6zIemhulYSBGuE6GVRuQifnceO0+xz7M\nOW5nDhS19HXsd07L3CozHVCX+3l0imLZuDXGnP04ZXRICJqElelhjRSwN4lAc5tpLBgTZj8woBLx\nZ0USHNN/hGfFwxMr+gpysdyxNrb6xezVjPo6rKJuuesaYCWsBtlhMqxaFejFsJqS4GWSZXNhDMP6\nJoAPGL+/v76Nw/fAkgNLKd+sf74F4CehJMYdSCl/TEr5rVLKb33w4MGIw7o+LPWkKazFBFAyJi55\nK2XbdWyJ1TwTXde4prdSsRJtSXBI0HYs21KpPFvedxwKu5ixWWWoZLvXlx7DsZ2pwM3XpdtVMtsk\nTHT7bYZZfCEIIZCJa2BYZbtvcKkM6225RoFmpvT4hLVhZW6CbJ5LzMy1vO/vzNmPc+5Xh7JHEjxS\nuj0EzhlbJT+TnpaFGp3VZlifFUlwXIZV/TTrapMkwVYP5NIIEaC7Npu9mjFRWfFeKgOymCha31+m\nmVXWdMmnh9V43pg92DcRYxLWXwfwYSHENwghNlBJ6U/bDxJCPA/g2wH8lHHbXSHEffo/gD8J4LMx\nDvw6oa2lF3YF2S636v98QFfW8x4pQVt4vtoaXQPY5jxm9T1c4mz3D94uSXAjHQRUwgqgVVlv2A+0\nHpu2h7W7ManbHZLghV1zsUFjTWyssmz2c7Ew3ETnNF16ll2Ci7pIM5YtNaX+N+EaYeeNjmBPzLVg\nbvaJ1s41U0Axja6mgDfwEUmKhVXVTow3z0LCWhe1YzKstsM9MI1xNIsW5Mq+tLF6tvolFfPZVdQt\nf8Sg/f1pSbCxn431JjDRNl26GYrIVBiUBEspCyHEXwDwMwByAH9VSvlbQojvr+//0fqh/yaAvyOl\nfGr8+XsB/GS9CK8A/K9Syr8d8w1cB65rzMQQ+DmsmdN06SYxrDYTJ4ygpTXWJiNJsP93U1SyVUVP\nFTBcBypDOgioIAUADkWFO5v6McyIGfP2FJBMIULd3v7Ob0IwHgPKXKZ7+3UkZmZv+LymS+qn7ZbM\n4TYVlYAuwzomkQMaGRqwvFYVE3QKd+eNDv9dsxbM+x5pX+1jWMtKYp2Hv4b+XBxtLzFB7UCEdZ7h\nWCz3nIkBKmrH9ANovrM4kmDT0KhRFIHdD64LNsOaal/qKupuDsNKhRE9xcJYo+nU8FEAmnNYb4pJ\naiqM6mGVUn4MwMes237U+v2vAfhr1m2vA/jmSUe4QDSL3jUfiAV2DqtDskFOgTfBqANwzWHtMqwU\nVITIVIqyGtX/exNhG3JphtXoY6W32nHmvS5JsMQzx7CaTJKJa0lYK4mztTmTeG5J8PBjb9M1Cqjr\ntOVmOrCONUFSdiOukYaVam4bM7JCXRfq/9Q3KqVs7QmpQCoU11gbYPoayY61SdQfaK8xa8aA77aB\n1FMxr5GKWaemJFYme2nOi82zCZWQyLDVL1migqF9jk4pBMwFu9eUlm4zYQ3pYaVLk9yjzdd61jBG\nEnyChWbRW9Yiz7kE546xD+QUeFPMbLg5rLR+VbItXQSaUQQ+6C6StycY1tboxlgbAK3RNu45rAmP\ni6mkAuq7aM1efEbs3MuqncATrithNRnuuZYIzszEhduWsFKRhmThYxnWLMO1uUn7gGelhkdWlLLb\n9jHX2xwyXQKmf+a2fwCQrofV9HwAlCrptpsu2VL7mLNzze9sTPHFBbOlq0lMJh5kZNjqlymuyL2v\nY0mCxQ2IxcziYYthNUyXQrw4Wi7BN4RgSoVTwhqAperIOZfgtcOgoqiU9PCmXAD2sPMsazOstktw\n0FibSraCkpsgQxkLOgfo8yGG9djqYe32pwDpGdb2xkS3t+WxU77Xm4RKto2/CNeVsGqX4Gy+8TFc\nb5gLc8/kTI2i9hagZWh4rI0R5GbLDHJNNIlZc1smhq/rqjJNl9rPlRpkTGfPRwYQ7TOnJdYumKZo\nSSlK2ZJkPwumS1WtKIvppG07XgPT1kndq5g159rSCrS2+mWVpXFptyXBppx2qdAMa6bWhYIzXQqI\nY0zmdqn+OXPhlLAGYKk6cs4lODfcykx0GNaFXwD2HNZMGLbhBhNEhlMxxtrcJpdguz+VM12y2Q8z\neUwFrldF3d42XXpWFuqicjOsc1+jLdMrMZ8zq49L8Cq/XQlrVZGb5Lh50oUOZpYb5JrgihGjTJek\nsRbMXGTVkuAVx7A2xzcFLvfkVJLgVlF7lcbpdUmwGdYYxTduDusUE6KWGyxdywv7XppjVNdClqiQ\nWXUUdcsnVWyG1SRU1O1hPdTcebH0zyIVTglrAJaqI+dcgte5YOWxKXo6UqK7gDUVNzOY0WNtAhb6\nY9neyFP1Z1wHTEMAoG26RLA34Pl6WJvfmx7WriQ19bEsAdxYGyCd9KoPtkvzXMydjyT4Nsn2AYNh\nHRnYkNu7EObIjuWyZXafPKDW2b7LWkrZKmzNLX3WkmDGvTvW/qnXXuNzMY0FY8LcLwHFsN52STC1\nDcUs0HPy9ihjbYSIVgiJDbuHNRdpYiTWZHNhn4UNkyE3C8zmfhayXrRcghfqnzMXTglrAFYjq99z\ng2dY+YCuqCTyPK5rXkp0mThTEoxOYhPyfsiIinAdSUIqUNDVGWvDmC7pOaz16jDrHFYjMa2MwGqs\nCc1NRykluHEu18KwynbCOlfwpPutxzCs1/C5pESpGdZx61hhseD0HEsFz0r1F6JKa1+b2w3Zbqcw\nEYvx4Mf9pGNYn7WxNjQVIQXDai7XeRb+3OZYlJzMIxdWfGquRfW7Gr8T/3UqOU8/d0yUunUga8Xd\n3BxVn7WrMv9+oerOuXBKWAOQzdxDMxZUWTdZwlXOj7Upda/UDZEEM+NPaIGnURBAY4wRsgEXlWyx\n07dpZAZ9VquehNV28MxmCIDtjcmewzpnP+0SYM9IJMzp0kugtgEArblyyV/XwyU4lSTtumCvy4MM\na2n2GdNzLPfzcM0b7U1YmVEawHxyycMMpkuaefaUSoeAkjeC6mFd7jkTA1T8XEWMd0Ll7S60RlQt\n1XTJes95Fn9P5pzEb8KIwdK4hs3pHOb6RUUvn+/V/PvmvFj2Z5EKp4Q1AEudd8fPYVVyK3tDpcp8\ncwEt673YqKwRBqZcqjB6Txs7eP/3Y4+1Idnx0hfKMbDZd0pY9yUnCaYksX17CnTdn+l2tQFkEb7X\nm4TC6qMmrLL5XHoJZWWYXs2YGPpIgm8fw9rutRtiWIqKc89d7ufBMYlDMkqbcZ+dYe0Za5ONLCwM\nge9hTWP6Z7rqAyphJVf22wqKd2IWPs1xI4QYkuDMSKyXFmN21A4JWjJs2TFwMwwwqaCc1+ZejQKw\nmd5B54oPc26Py1HPufAPIxFOCWsAliqj5eawugIfFYw2FZulB32cJJgSycpMbCZUUE15HWD2TQYf\n9mJQ2Qkr18NqbcAi4ubuPi7LDdB4TWm4BD8rpkskCbWRXTfDOmOvaGUxan3Is2xxQd0U2N4CQ9ee\nmXzcCIZVrzHNbeZazkEzDLbaYuYe1hXDsMaaYx57REof7H1uvVL/v82y4Kpey0hBFaN4+tIDAAAg\nAElEQVS1hJO35xO+MzNRW6zpktVrnWdZ9PVG9wZn6a+FmKDLRzGsmdHDqm73WddNNL3S8xvOLQ2n\nhDUASz1puB5WlwlRST2sC30vNjjTJbqQ20wQbUgBkuCyasm+blM1y8WwHhmGVVhJYspTg/te1e1d\n0x/zGG8rKkcP68rRi54S6vNX/5/TMZursLtwm5y8AUP5MrJnu7CKCnTbUsH3avabC5WlHSTPyz6R\naeHaIdUHpp+D9Fa6Y20mPS0Lu4d1PcFZ/6aAxvjF7AEMkbf3oSX9XGivYmWtzSnWX643+EYxrJmo\nC8yUsBoMaUCbFScVv017ng9W130ANxFLNYDhXIIpmLGDGLuSv7T3YqOyGdbOHFb1PlcTXILtjfw2\n9U3aSQDHsNLbpMBwDklw2ZF6169ZtXtYl3rNxYZ9DhKuww3XTIZWMzKZzTy7kQxrpdh4MSLBXTqo\n127s2tPuYV3+etWwBW21TN+51TCs6ve596xjQZLgbn0/1h4x/1ib9iQBALe6j5VihJiGmXq/tBOr\nwLzfVEE1Y62WVUSwJcEpJilIxxqx9Nas0mhdUK0qVX17l0jymsNqsNq3SfUXglPCGoCbybC2zXUo\nGL0JQQ5APazN78JmWPUg67paHLDQH0vZ6lOij/E2VLNsuTjvEtwOmky2MxWkRMdMi243XYKXes3F\nhithvY55o+rzV/+f09yIS2pcyI1zlGkxvHGwvQWG2FLeJXi514g2VDGu+aGRFVzfHDDfWlBYa6eJ\nhmGd9hrcWJtUpktmIRBo5sveZoaVYoSYhpn8KKLw81LHbwseX2KOWAHSTFKIPd92LlBxIRPtMXDc\nXPGgOaxCNAX9hX8WqXCSBAdgqYEB5xLMSZbovzfJJbivh9Ucv0FBRehYG66HdWmynBDYRjY6YTV2\nRHszmmNx7I61aW4vTUOZhW7gsdHHsM59jSoTMvWF5GK+NcLHJXjK9b40VJWaN2qO3xg1hzW3GNYF\nfxZcMSLP+qWvdmIwd6vGscclOFZvvdOMKsF6VxjnDDDNWf+mQMUIcRlW17kcul+aypKltiNxBmix\n46M5r4WYoDhUCJthbaTCIVJvziV4aefFXDglrAFYaiLDMqyMJLhoXUA34wLge1jVMVdGxbjpx/F/\nP2ojby6Juc09UsKWi/fPYVU/G7YzZcLa7WdTt8uaNbOD1IXvWhNRWgk8YTUhEAqF+d2kMNdwvm7V\nDVhcuE1mXKa50NjARPXmta+RJRcfS5Y9GTmHlUyXZlZbHEu3JDiWQkknAjPIIO3RWZs8fM+8KSCG\nNWbA72YCw56vlF15/9LWNbuYSH3WMWOkJg5pXwtLZxVNtUu7h1XdvzJbPXwkwWYP7ELPi7lwSlgD\nsNRKNplTcAyr2e9zE5u4O0ycKQk2FvoVI4Eei6KSg+z0TUXHdKnecfbMHFY7AE759u1CRONMTNI1\ntI7lNnwXfagMebuJLBOz9+8WLfZuvoCB6/lxYanjH0Kg33c+PjDhZPNL/izcsyvdf2OO+wDmV1sU\nZQUhXPOR28cYCvrO5jCaKaqqlRg/Ewxr3bebR1RkcOfyFEmw6RC/VNOlhi0kb4P4a05j7NTcNoW5\nnguVUTw0TRJN5jyE4Td7Y0UtC176Z5EKp4Q1AEsdBcMxrE0vlCH91GzbzanYlJXb8r8sZUcuFjaH\ntW1GcRMCwLGwR4VsmCDFZrbmkATLTiGieU1WEnzzv4pemEZHJq6FYa1MhnU+SbItTe/DUsc/hMBk\nEseuy0XZ7WFdWiHVBC/3619jKkchzWeW4RQcK6mVOzY0wz/x2pSyu3dnCa55ScoVxufCVNvcNuj5\nxpG+L6A7Bg6g3sXQhLUyzvGlmi6pn7baIWb86O7njvYSSWASHuZ+afYmh/RQ26qUFLNvbwpOCWsA\ntCRpYScN9b+Zid2KkQSbDIYQQrk0Luy92JCyzTyZzf6lMQqEqsUhbFRRVW2G1TAAuumwixk0nJyT\nBNMGPIfpkj2HtS0JNuSOujK+rA08JuyRASbmTBgJ5vUwJRDzhT0zuA+3imE1kpax76usZKeHdclr\nORfkK1nhCEmwVZScayk4FlXLjM9ELLVVyX4u8ddes1hNeFZMl1Z5WMLgQuzxK6Uh1V6qZ0OjdlC/\npzDt5CTBN4FVrKwCe2nEp4DVgufxXmStQhNGkeA27HchOLkEByJFs/lU2APBAV4SXFibljnkeKno\nmvPYLsFNMCNEWPWdZtMSYsm9lgCz8Z+wWWWsS7Aw+lOA1D2s0trw69urttxxqRt4TPSZDc2ZMAIN\nE9PagOeSBDNskwt0fHOxbSlBLDHN8QNG9rCSMdZNSFhdQX7P19c1XVK3z3U+FpVseRuYiKW2cvVD\nxl57i6r9WQLTfB9uCohhTW26NKXXsrXfLfRatpVaKVrKpPNaiPYSSdBiWPOmwFyWTewlpf/nZbt6\np3Bmvik4JayBUBWU6z6KNkqLIQSMsTaMJNgMdBZfvZJuGZm50AOoHdr838+xlK3h8LfK0MVo/Cds\nVlnLJVhaG3CTPKZMWLtugOp22erpMd2DbyvsXj0Toef01GNpGNZsNtmt7Wjdh9VCA7sQUAK2MhnW\ngfdVVoxRy4KvEdcokN45rLYMceZ1+Vi6GdZYaiteBhl/vWMZVj2HdWEBTUSQzwW97RhrKTeiacq8\nbLvwTrctCU4DtIinTuxCwFyoZMOwrjJTAajuV3G2PyNdGs9Lz3OLL9VenBLWQKiTZllnTS/Daix8\njTy0eczchi6+6DJxTcXNft+rLAsyXaLh4uZr0GvfdOgZYWbCmvMMKz3ENEBKBSll/xxWbWIQLvW+\nKeCCScKUQCjoWOxKejZfItQUToYfu9TALgRmwWI8w1pdWyIXAjq0thvuWEmw+j0mSzYGRSlZh2B1\nTHGKBM5RHrElwYx6Yc2MOLtNkIYfgqj7w2MUYble+ylMYGEwaUs1XeqoHeq3HtV0yem+vKzPwoby\nQGkKvEUl63Ovy7D6xDGmmRNwM5L3VDglrIFYYpXDrLYTaKM1N/dGenZzGFYp+YqblLJz3yoXwWNt\n1i1J8PIDwLFwMqy9Pax0e1pJcJ/pku65TbAxLg19ZkOrfOaElel5ns10yaOH9aa4nI+BWbCg63To\nMzdHlNDfLHkt54LRPOtPzOxkLmYf4hgcy/bcUhPR5rCyY23iS/9M2TlhM8H34SagoxYRcdayZr9s\nbssmuKmbDvEUmy1N+mkzrDmdOxHJm6ZtwCreLCzetmGOpMuNYr8ZewUxrNYYqhRmbDcFJ9OlQCyx\nysE5jNKJbsp9TOkZPWbpPWCuOaxccLsKfD+m4yYw/7y/lGB7WPMM+7LLsNI+MQfDXEl73lrzmuZ8\n3cYcbNnn6RT0mQ1lM/aQAt3AxJQ4JX9tD5fgVcQxFdcNs1VjbCLUHj3kX72fG5yhytBe2jFdmln5\n0ucSHMt0hh9rE/892v4VwO0fa9NVi8QJ+CWTWE1hAk3zyKVOonBeixFPHbs1Sf0/rZdGDJgGeOa+\nZBbcQgqsduz7LLsEnxjWQCiGdVknTVlyDGv3ArGTlyWyxTZsJo7kUpzEaZVn3t+NlLJjrnGbjH7s\nBARQDOuRmcM6q0uwXYjImtcsLWfoVZbdiu/ChT5mcTXzesMFJnMlzD4uwTdBBjsWpvTVp4fVnsO6\n5AIbZ6gyJH3VBYxr6u8rehjWWHuEe6zNtOe10ZjmNAvrbe9h5VymYxR1OBn3FJfgyjB9XKq6aw4D\nNLsFALgZY21KQ7prfn+FoWoghtXn8zLXeODEsJ4QgHyBzrp8D2tX7mNXWVXFZtmbVZeJUz8LRuK0\nzvwlwVz/4G1yCdZ9y0bgZZsu2ZJg+rjTzmHtVlLV7bLjjjdFbnUT0JewZtecsGaZ6s2ag2X1cQm+\nTWNtGm+BbPwcVtN06QYU2DhDrSH2xB73NPd8bGW65JjDGmmP4MbapBjlYftXAA3DelvnsHZkrJEC\n/mZEU3PbFFa8cCQ8S4LLAC3mvsAWAm7A3t8yzdIMedWao6q/V4/4tLRMRZ9lhvWUsAYiz5bYX9Ct\nBHO9UJTkmRXrJQc5QDOLikCLmU5YWz2s/qZL9pxS8zWWvlCOAcuwDpgumQZIqcBJvdXtbdc9gMy0\nbv534YJO1Lge1mtOWOdMDCsmqXFBj7W5BeeFeY2OnY/NOosueL3SRTFrnfWRBK8Cgr4pOJY9Y20i\nsdoNc9XclmKUh+1fAajCJXB7x9qwDGuEAr2bYQ2XBF/X6Kax4NR56vaYCav62elhXdZH0YHL5bms\nqnrcoiEJ9vhezdYoeu6lx+upcEpYAzGnRG4sOIaVElgzgeuOrLgZDCvHxB0Z99uQESD0eM506VYk\nrAxr5TJd0gOqiWFNuFOUlewMCFfHouaAPkvueH1jbfKAc3rSsVjny1jX2iiv7SEJvglGQ2PRTcyy\nwT2m4IKkBUczrhmLfduP3dOcBQR9U1BUVWvcmYlYpl988pNgrI3lX2H+/1mSBMd4q7rX0pZrBj63\n6Qa7eNOlhEUyfo1Y/hpvJqxmD6tpmhQyBqtjTHkD2OZUOCWsgchmNCEZC84lmGVYmYr10ourNhMn\nLIa1tQHn/j0qXOV5ziA9NVh3SFsSXLnZzlRQkmDuNZtRBIQl9o3HBOcUSog1imEsbKn9nG68em6d\nD8N6C86Lrgx7+PNWzqK127tO5BIe5ETw41v6A159XVhB8lzXw7Fwj7WJ1TfMqQpSjPLgxputV7fc\ndInrx4/KsDa3TUmseEnpsi5me21OybC2WMUbMNbGlO6an4s5no/u8+thbcdtJ0nwCd5YeZ50c4Bz\nCeZm1lW6yqruyxbOsNLoGs5NljbZjnTU8/3Q402G9VZJghm5KScJtgNJuj0VumNt2htge6FfXt94\nTNA5yBm8xBrFMBaVdb7MKTfVwfuI3Wk1c/KSEjb7pUzGhhnWlZHgAsv+LLhgdHAOq2b7Uf+cl2E9\nMq02hHgMa/v5gDQySM4lmMba3NY5rJxLcIy36jqXg8famAlPvsx1zV6bUxQyuUKAGmuzrM/Chqvg\nYE+f8FVLqdao5veT6dIJ3phzLqELP/ePvoLv+K9/HvuiBMAzrNxYG5s9mbs/zhf8xqB+0vtq97CG\nS4LtShawbBOTsShr9tSurNuSYNuJWYi0dvLmJg1wZlrNY2P3jf/gT30W/9lPfiba800Fxz4R8iyb\nl2GlwNZyrZzjGPo+BxtLZSIIv/r62/gj/8XP4t2r4+BjbfbLt4dVFydHXK+HosIf/6Gfx0996s3B\nx8YEvR/zqx2cw2qxj/O7BLsZ1ljHokeKtXpY1c+Y6y8nt9djbYplXkO++Hf+51/D//Dzr+nfO2qR\nSAV6ewwcQMX/sOcrHAnPkjDUKlJVEv/af/OL+L9/84vBr8HNYU3Rzx0bLpdgO8bJPZNv83n13y/9\nw0iEU8IaCN+TLgX+0Zce4588eoqvvLsHwPew0mbUHmvTDUaXnbByyUt7QW+PP/GXBOse1pYkWP1c\n8mczFrY1OgBsVxn21lgbm9XKE5sdVLJrrgDwzHnsvvHPvvkufuuLj6M931SUlvTRRJ7NG7y4koQ5\njsHHJXipbpqEn/vHb+Erj/d4+GQ3+FhzwDwwbjxXUVUdhnXMZ/HbX36C1x8+xaffeHfwsTFhj84C\nht1wXbMf5/rOlUswfy5GkwQzCphm3uykp26BV64IrDKhC983Hb/6+lfxj7/crOv2ZxurBYo7l7MJ\nBV7TFV9fywtLTGyXb3sm8tWxxG9/5Qk+9+Unwa/BtcbchB5WM/42e1iL2nSJ4Mvwm2ZcgPrsl7rf\npcYpYQ1EaJJ3sS/w1ojgZQwuD2qDeXihEtbSCF4ImmFt9bDWyYARjC6tkmeCq7jR/4khNKXQqzzz\n7schUyqOYU21UD7dF3jrcZxzYQiuhLU91kZ2WK0UfVQmuu7P6ueRcX/O87gL9b6oWgn7FFweCnz5\n3WnfJTfyg5CPMOCJic7oqzkZ1p7PwcaKmTO9JHzqjXcAYNR5Zq/L2QgZOCdDMz+LY1nhd9++7B7X\nF9RxPar3jrmgpa9WANb3Nm3TpbmLFMeycrsER1LhcGNtUszV5cabAd3iJfu3ZYU3vto9l5aEp/sC\nV8eypRyy1SJcC9QbX730nizAj2iaJgk22wGA5UqCXS7BV0cVk07ZV1nH7AEVxhi8e3XEwyfp1rvK\nXItpnKRlugT4J9+mGRcwjcW/6TglrIEIXZj+8t/5HP7cj/9alGPQCWt9EdpaecAcATDkEryshdGE\nduPrkwS35sqFS4JXjEtwqs/mv/3Zz+Hf/vFfTfLcNgpr0QO4HtZukqDYj3THZb+mHldkBe9AfLOB\n3bGMxir88N99FX/mRz8+6Tm4WcCE6xprk9nJ0AxJcx/TbMPueV4SirLCZ76gGMwxARzF0LQGrUZI\nF1mXYOOz+NhnvoQ//kM/jzffuWr93afrRDplAMfBZVQzag6rJUOci3EpKul0CY7FhHFBegoPgcqx\nxpytc+yO/Wvh//WbX8R3/uVfwJPdsLz9ukDnc2tfsxJLey199+qI7/yhX8DHPvtlr9dqWpWa24aK\nL30wTQYXLwkW/LW4i5iw2tMDpl4HP/A3fxP/3v/yyUnP0QdO0l1WspNwrnI/jxWbbMhPLsEn+CKk\nTxJQFe1YVe2rOmF9pBlW2Z3DmncXPrtfc+muY3yQ035f7TlV/uY8jdsw4xKcaHF4+GQ/W8DIMazd\nsTYSVr46aIgyFa45rEdrVjD9P+Z3sTtW2B/jlCq/+M5u8nXdJ4XN6iAr5XfROhYrsJ1z3umhLLHK\nxMixNt2Wh6Xg1YcXDeMw4jzjlC9DlXTzuqbZrWYw8+jigKKS+OVXH7X+jhLW62JY7f60XkmwbZoz\ns7dA0TeHlVQ4U3tYHWwdEHcOtt77rYVeJaz9H+jDJ3scigqPd0W8A4oMOp9N5ZCtFrEllY+vjjiU\nFd72vBZcvZah50KrB3LxpktN8g80+wKdQ9MSVvWza8wW/JQoygq/9DuP8PbTQ/iTDKBlmmUUD+1W\nPXX++T1vysL9TcIpYQ1EqI58X7TlKlNwebQY1srtEmwmcLrKemN6WNXPfoa1uW+dCW95T1F1nyfX\nAUOaz2ZfVDqgTQ1nwmp8TpJhWFP3jnR7WNVPLdE2DmeVCT2eJwb2RRXNGfPx1RGHopp0rvTNYW3m\njQY/vd+xSD4wmaOyuz9W2KzGbU203C2NiQCapBAY58DauLeb63L/39lGe/ZaTgqCT7z2tr7tye6I\nVx9eQIimnWQu2KOzAHIAdf9Np29OB4PzZKyHsprBdKl+PmaPS8Gw8n4G/XsRFV2oUL5EUCxkJkz2\nurrK7WskLMlqlF/NbVP2y5sx1qabfNHtgMmwhp8jKeawfubNd3GxL6IVqDkUpSnpNhhW23TJ0zyy\nkpakODuZLp3giTzwpDlE7Ju7OqhKZ4thtSXBTI8X15+27ISVKpnNbdHnsNbvf81Kgv2PeQwORYVD\nUc1SRVUbTfty3+S5qgDWb9BmO4FpEqcx6PawtjfqTmUy4kK9P5bYRyoYPN4dUclpAQZnvEKYu2+P\naxuY6/X3RYXtyIRV93otcAP/lGFoNOY8Y93bB96WXaS0C6lUHP34a490IPiZN9+FlMA//8EX8c7l\nMVoBdQz4Pvn+768x3Zv/XARU8Sy16VLJ7HEp5mBzrS8AsB3BsFLcMiQdvk5QLMQlrCbDWjDXiO91\nwLmZT+m1LI3ERI+oWti6ZrOFjbeB+j2OJFj9jDmT+ON1wW6X0FjMXNsak8Kq+5l5xjE04aH19wuO\n11PilLAGIvSkOZSK1YmRpFxakmDOJZgW6SPTw6oHzkeWWsaG5AwpbDdZs0cgYA7r0QoWgSZ4SLU4\nhFZ2Q1CW3WIGsViHVsLafowQaQPDzhxWYsw4l+AsrjP3riijffaPr1TxaErwbycsJq4rYdW9SjP2\nih6K8QxrvnCG9euePwMwsoeVGRkxnWFVf/+Vx3u89vApgMYI6jv/wHsAAG8/nY9lrWRXQTAoCbZc\nQ5t+6jTHaEMxJ0OmS9MORtbtGJyxYMxrzmXsdrYeZlhjsGepwfWwcmoR83yj/c8/YVU/7bgkNJYy\nTXuW2upg92PmVg+3lgRPYDJdBMWUj+Ljrz2afFxDKIyWvNZYGzth9TSPrGyX4IUTTClxSlgDoYJn\n/7+jCyaGFNE2XeJcgoUQnSDG7mO5KQyrLREB+EQzpL+4YVibS0JXD5NJgtX3N0fF2pbyANAsFm3U\ntjwXUItj2h7WrrESwPdarbJ4btZlJXEsJfYTZbyEx7URSQyzCTZhndH0COiOEtESpzkkwUWJ7Sof\n9dh8oW6aVwc13uHbvuElAOOCYVtVMGS0JaXsGnJYAbP5up+og7ZPv/EOft/Ld/CND+4BAB49SdfX\nZcNWVACkVnL/TdM3h9bPub7zQ1lhveIZ1jzSdVHJrikefU4p5rDaCfh2lQ0G8w3DulyL0ocX6lw+\nGEk1149vKrD2gYk4O4dVhH9fRWWMtRHNbUtC1/GWGNa2JHhKfMspjbQ8PuDz2B1LfPLzvwch1Hec\nKp6pjO/PlAQXVdUZV+UTb3NzWBfMLyXFKWENhBoF439R0oUcg9lpTJfUIs0xrIA61qOxQFPVPs/H\nBUbXjcqqkAKMm6yZsGaZ/xzWnrE2qRnWlDIVgquHFWiCWi6YTC0Jto2emjmszHcesXfDDE5iFI8e\nX6mEdQrD2iSJ3ft0YDwTrWQnrPaA+JQ4lB4M60J7vT77xXdRVhL/Yp2wjlnvO5/5QGBjPx5Qa7oZ\n1O2LEi/eWeN9L5xrWdyn33gX3/yBF/Dg/hYA8PBintFagFvF4WO6xPkypIRyCebPRztgD0VZcf4B\n6STB9ts5W+eD+9CcBdZQaIaVU5QZyUQMhlUyBcYp+6Vi4tT/iWhYWiHObhuymWA6h6a02lBYzcV7\nIfv/P/jdd7AvKnzLB16Y3LbTh8JQu5gMayfJ91Q0mu7R9NxLVkSmxClhDUQ2or+Iw167qE1f9C+P\nSobYMKxd2SfQHY8w5Jq3NNCh8eY8PBPnPYfV+kyA9OMT5jSx4IoZlBRQMF2xQVPaPhrb6ElXlrXp\nksWwRkrYTJZgavGoKCs8PUyXy9nzJk3EYnJGH4uLYZ2jh/U4vod1qW6aZLj0bb+PEtbh88Jmgmxz\nmM7jmYA5Z/rztqsc/9KHXsYnXn8bX3r3Cl9+vMM3v/8FvHJPJaxzMqyuxKzvtO7I02fs76sqybrv\nE2L5HEgpO0mkZpVmYFjPVsNjbWidnMsoMATaJZjpYTV7oNkeVs8vkZUETyj+l7ItPbev5SXALnzb\npndXhxg9rG5FXcjH8YnXHiHPBP6VDz+YfGx9aI0l0j2sjOmSp5O0rb5I3aa1ZJwS1kDkIixICq3m\ncaDF4epY4um+qOewdr/SlcWw2k6BQ4HRdYN3jVO/0Odpmy75vh9ias3xBekZVqpYp5dY2X0UgCEJ\n7jFdmto7MgTbUED3JjPsUUzTJTOBmNrX8sQY8zCJYWVGKxFME4c5cGJYp+FTb7yD971wjve9eA5g\n3Hlh9xfa5jCux9tFthZ7VPcDf/RDL+OdyyN+4tfeAACLYZ2zh5UbneVpujRjP/Wxvt5cLsH00U9d\nl8qKY57jF0xdo7O262wwkKd1ctGSYK6HlUlY2yqEsL7LvsQqRHZaVXav4vJMl+zWIrttahfBl4Md\nFzSBPPj4a2/jD7/vebxyb6OOMVHBxSSM7LE2HYbUVxJs/f3Szou5cEpYAxHa93mIcEETLg8lXrqr\nLsKHT/ZuhjXPel2CbwrDypvzdKWj6zzzZ1gZt+HURjeHGSXBdh8FAGzytiS4lLLbwzqhJ2cMOqZL\n2v1ZHZN5ODElUm2GddrnT/2r6rkmJKxa+t69z3ZjTA1uVjOwQIZ1ZuZ5LD79hXfwLR94QV9jPpLg\nldGq0ReYcE7adn8UOS5/9EOvAAD++ic+j1Um8Ie+7jmcrXPc365mmwUNqLXETpaGTZe6CYd5e0rQ\nvuByCY4l3axk1x08xRzWkhnfBoxjWHcLlwRLKXtdgs21jGNY94EMqz2H1bzPB0UlrTFu2eLisqrq\nzgQFms84tB/YhOTivcBr4em+wKfeeAcf/dDLek9JxrBK3jSrqvqN8Yaf1zKfXHi8nhKjogIhxHcJ\nIX5bCPGqEOIHmPv/VSHEu0KIT9X/fnDs395UhCase63xn3bRSClxdSzxwZfuAFBSmKKSWiJnwjar\n6cwlW7gmvmQrmW3GqWW6lIWbLpnSr+SS4BnHBNh9FADXw9pNlqbayQ9BSofUmwvGA75XF8zPfOoG\nRg7BU5/LNSPRvG0uhtVmtWaVBJcVNqNNl+rjSjV7KgBvX+zxxlev8E3vfx6rPEOeiVEBnG00ZpvD\n2CgdRTbzoyCG9WueP8Pvf3AX71we8c9+7X2crdXn++D+dmaGtSsJHj2HtX6fQojBvtdYKHpUDwTf\nMRUcXMwz3RcLXGEWUC7Bg2NtjvPtVyF4si+wr8/3IYaVm1Uc0sNqL9VTjBrtXsVsgdLPriTYYliP\nYZ+liX5JsN/n8Wuf/yqKSuKjH3pFG/nFGmVnw/xsTKl0x3TJM96urELGySW4B0KIHMAPA/hTAP4g\ngD8rhPiDzEN/SUr5LfW//9zzb28cQhuf94H9EjZ2xwpSQiesimHtugQD1Pvn7mHNA0yK5oR2iWTH\n2nTvywNcgo8VE/wlML0wESpFCkFZVd3Ze7SAa5dgbkZietOlzFqMAb43OaYUxkwsp8rz2wzr9B5W\ndg6rNncJfnovdFQYMzKZ+2PpzbAuSRL8m19Q81e/+QMvAFDS+zHnGFckGMWwWs7mpl8BBfAA8NEP\nvayO6/0v6PtfubfFoxkZVn7W80hJcCLH8D5oSXDP+Zhl03uo7T43II3pksuJfLvOB9cuXWyfcW6v\nD+g8ft8L56p3sP7gOmoRK+APVb3xMu7mPl9UchoTNwdK2c+wXiWcw6ru8/s8Piz1gmIAACAASURB\nVPHa29jkGf6Fr38RZ+vEDGslDWMvk2FlWps8e1jtz/wkCXbj2wC8KqV8XUp5APATAL575PNP+dtF\nI/NsnCboxXFilefyoFidr3/ZYlgdkmCOYW0W8OVV8kz0SUSOTA/rOstaCfoYNFKp5pKg/6bvYZ1j\nrE2X2bAZVlaWNrGP5lBU+N4f/xX8g9/9PfZ+O1Cj/3LuzzGlMHEZ1iZhjeMSzF3DMzOsVpFoThmm\nTw8rXfdL2sA//YV3IATwh9/3PAB1nY05x+w5vEOKAi6RU4XU5jGHopFXkyyYEmngehjWbtuBv/Q5\ndP/1Be0va+aaJMRYl1zuyUBcQzHuswSAs1VWF8HdrzVVEfRr/+Sr+HP/0696781jQdL2r3tBzT42\nvRkAK2E13qcmEbzH2ridnUOWo26vYha1KPNTn3oTf/FvfHrSc3RmiloFw2YO6wSXYMZ8UAQWb37l\n9bfxLR98AeebvFOgjw31/am11mxVsft+hwqR3PNO6YG9TRgTFbwPwBvG71+ob7PxUSHEbwoh/pYQ\n4g95/u2NQwjDKqVsWLWJFw3NYH3fC+fIRH8P63bVHgpuy5zyLFu0JLgZa9PcRm/zWDCS4Fyxgj4b\nPSUaJrMzxUp9CDQHFJjHdZFj33XCWqrX52Vp02Z+PbrY45dffRt//3ffYe+3A1i7ENEJxlMkrBM/\n/2g9rD0Ja2ZVslOjYVitDXihPaxLYlgfPtnjxTsb3N2uAIQzrEPnO+tsLtrrnimv/s4/8B78xT/x\nEfzrf/hr9f2v3NvMy7BWDMOajZzDmmgt6IPeKx2mS4D/mAoOZdVN5Ok8iNvD6mZYgf71S7sEB7ra\nf/KffhW/9DuP8NgwqYsJGu/3vheU0Rkdb1dR1u3zBsIkwfZ+mU+IGWzGNo/A3Jv4ldffxs/81pcn\nPUdRdVlgoDuHNUZrDBfv+fppPHyyx++rSR3aU1KaLtEy0bTQVB3TpaFWDxu2S3CWneawTsXfB/BB\nKeU3AfjvAfyfvk8ghPg+IcQnhRCffPjwYaTDSoeQDdN06p0qQ6Qk597ZCi/d3eDhxaFmWLtf6fkm\nb20ydk/o0hnWvorbkQlmVgFBLFUGzUA5pdGM+f3P4bpYlO1FE+iaLkmnJDj8/dN56tok7D4gevlj\n2Q2sYgap5oYas4c1BsPKjbXRG+BMO5UdNEwJxHxxKP0T1iWNtbk6lDhfNz2421U+jmG1komh+dgl\nc43YRi2mvHq7yvEffueHca9OpAHFsD7eFbP1JdrBFzBs7EaEXMdcaoZzUTOsDtMlOq6p558yo2rf\nlqJgyjlLAxhlSEPnSKhJ4C5xDywZLn3dC21n7sYboCm+xZAE97HiIedml4mLSyTsjtXk4nglu2wf\n0LxfzbAW/Wx9/2uon7wk2O+5dsdSM6vbOSTBVoG3KBnTJc+YqsO8i+WZDM6FMVHBmwA+YPz+/vo2\nDSnlYynlRf3/jwFYCyFeGfO3xnP8mJTyW6WU3/rgwQOPt3A9CJEBmX2rsRjWO5scr9zb9jKsZ+u8\ntVAR20ZJ3xLd6EzQobWZOPVTz+tsMaw0WH78Z0wM9NYINFOO8mgnrOmDRbs/Bhg3h1WZm4S/7m4g\nYbVlVbZLsF2ZjLVQR5UER2JYXf1lQLe3NzVcDOscr783gowhLHGszeWhxN1tc/wbS+HiQmeU0MAe\n04zisqr3ZjA+IK+mWaxvP51nFqtbEuz+G850L59pFNtRuwSnNV3q64dMkbDaxUsy4epTmzSS4LA1\nbh+BfevDwyd75JnA1zx3Vr+Oej3bzMyO3UJHDaq9q32blgQHvEVuxmnMc3xflLWya1pRNecSSYth\nBdoEjQ9imi7ti0r3riY3XTKKTp2xNhPUIZW04qCTS3Avfh3Ah4UQ3yCE2AD4HgA/bT5ACPE1ot6F\nhBDfVj/v22P+9qYihO3Zt4LkOD2s5+sVHtzf4tHFvrPgEe5YDGtHorDwC6BvDivXk0OJmc+CScZH\nZybDmrA/zvz+5xlr0zOH1TBd4iTBU94/BTcuGVnHdMlizm2jlWgMa8yxNtF6WNVPl3EaMF+vpj1i\nJ+W1YMOHYc2y2jF2QevX5bHE+aZhMcdKgkvrnB+aJ83JO3Or53xIXq1nsc4kC5ZSMk7kA6ZLtYzY\nTHTnGu3AeSTYUK6d016nrx8y5tvkZORAk7D2JaP7geLjEBq5aDqG9eW7G/1eOgxrzl9XtBf4GmHy\nJoXNfb6orGQw9jmu9+IJCVtZgWdYmYQ19Hvm5rCGzCSWUrYY1pSmS1LKFsNqKqLYsTYeX6sqEjS/\nZxEUHTcVq6EHSCkLIcRfAPAzAHIAf1VK+VtCiO+v7/9RAH8GwL8vhCgAXAH4HqmyDPZvE72XWWEP\naB+DmAzrlcGwPri3xatvXQDgN9bzdY4vmgxr2b6AhgKj6wYrEamDHtqUuITVx9xhV5TIM9HqVWok\nwUGH3Yv9zJJg2ywBYBhWNmiaNoeVNjDXJllVspc5b7EqETdwczOd6tL8eFfg/tkKT3bFNJdgxmiK\nMHevZqkDdbuHNe3rUp//WNMloDtX8bpxdShwZ20zrB4J62iGtZt8cOxRX8JKDOtcCSsvo+wPwGyp\nJBC2/4aAPuMhhjWGSzA3UgyIOwfb2cOq94J0DGvTHpKOYX3l3tbwZmj3sOpxUZ1rJGzUoBrJ1r5t\nylxou6gcu09bmzweSjx3tg56jsqSrusYqT5Ms/i+LyrcD3iNPpNNH8/BopKoJLoMa4KElb4mzeIb\niby9ftlO7kPomC7N1A6xRAwmrICW+X7Muu1Hjf//FQB/Zezf3gYESYIjjtJoSYLvb/FWHXBwc1jP\nLUmwvTAunWHlJCKU5Og5rCYTlzeW4mPBMREUQCRnWGeQBNtmCUCXYeXZj/4ZiUPYDQQp0kqS9fdK\n44osSXCsyuLuGK949PjqiAf3t3iyK+K4BDM9rHP3apbWBmzPPU6FopKQEqMZViB8xFgqXB5KfM1z\nTUC4XWWjguHSYhKH5mNzPc/26KdDUeledQ7EsD6aySmYcysfMnarGLns3Axrb8Ia4fxz9fYCcfvV\nXGvMEMNqGkaGM6xxJiS48Ohijwf3tx1vBj0uLOOvK3pcCMNqJ/4hTKD5fCndYJse4niSYIo3KQGL\nsa/GkgTTeap7WBOaLtntGWYLTUfqLfwUGZzp0oLGjs+KWKZLzxyGRg5waBu9TLtoiGE9rxlWl5kC\nPcaUZNr9jEOB0XWDk4hkncSmeTwZZBx9Etai0ps2oZl9Gf+zMRf2WcbaMEGfXYl2sR9Tzo0how1b\nEkwL+5FhAmLOXowhXSI83h01UzXJJZgqy0tgWKkQlDdBHpBeEkyfnxfDmgltQLQEXB5KnG8s06UR\nEUYppWa0gWE3Sb3m5+0g1/ybfVG2+vJtvHxvA2BuhrV9Wyb6kzKu1SWfKWjTkuAe06UYc1j5HlZ/\nVmkIzrE2NQvlak9pK4KmSoJnYlgpYbV8LjJrvQh1CXbNLQcmjLVpFZ/imi7RPjdFEtxJqi0Vmhln\nhhYm+k2X/GI6oDFbSsqw1k9pj4GrZDdh9XV/7sxhnThq8CbjlLAGIsQZ0FwQp8oQqYf1zmaFV+5v\njONiXILX3R7W3AqMykpGlR7FBC8RUT+P1oge8/9ekmDDTZMwRd4zhBgBgA/KSnaCLrsSzRuiTJOk\nDbkEdw0F6HhJEmwxrJG+i9guwS/d2SDPxCSGtXIEk0Da4gkH7czakTilfd1mvNQ40yVgiQxrgTsb\nSxI84hpX0q/m96F5fU3y0R7FRZ+FlHKQYd2ucjx/vp6NYeWcyG1W2EbJsI++srpQFNp0yZ2wxpDo\ncfLSKf2QLlBriL3ON4Y0/Gfa2q9CXYInMrR9kFLi0cUBD+5vO47HWi0ywLD6Fi65/TIPVGVJqeSr\ndmKThmGd0rZis33qJ71faq0C/BlrQuNQ3977Ab9CAH3/Zx2X4IQMqz7HyPhTdopRvu7Pnb7hhSsi\nU+KUsAYiJEgyF/3Qi5lweTR7WM/07U6G9VjqxKMs230IDXsy6ZCSgZeI1EycdpNt7qPEzIeN2hdd\nSbBImCTMPdaGq+Cv8gyZaJsuddmPfgfPIQz2sFpGT833mp5htSXRoXi8O+K581Vn3rEvXIYoQNg5\nPQWaYTVYCfP2VKDPz5thXdDidXkocSfQdMksvA2peDhVjVlIpR6uIXn1K/c28zGsFedEPjyH1VYd\n+BqXhIIC0T5JcBbh/OPkpVPYOheKqpv8AwbD6lin2y0sYWtASob18VWBQ1nhlXubLsPKrGUtJ+36\nccd6BMlY2CPZgCZm8D0fWAO1yIlJDIaV66ek2wFV8Hj+fK3/H4LokmDNsGaTjqsPmmHV55j6vawT\n1pWVfPu5BLfj9WfZdOmUsAYipLdvbzWkT8HVoYQQ6iJsM6x8wlrJtgmBHRip25cpjOckIvRftodV\nM6w+CWvZkQQD6dibuXtYS2asDaASAzov7H5SYNjBcwhjElb2ey2732vMXutdUeLudoVVJqK4BD93\nth5truMCN2+YQLfNxSTasy+bQehpX7dhWMdvTTHdo2Pg6lC2GNaxc1iph5UwpOIprECc/k/nCH2W\nQ8k/uczPAd6JfGAOK5vMzaM2OBRdBY+NGIkFV1BM4aFQVhUbI+geVpckOEILy1SX4T48rM/fB/e3\nHTNB2319ZV1XoUQCV3wJLTLYfbb0/5jffQyXYLufknMJ1glrcA+r+jl1Diuds6QeEEJM3qNdcDKs\npexM5ciFX0GjIxWfOLnhJuOUsAYipO+zLQmeOtamxJ11DiEEHtT9c3RcNmiIPcmC7U2rMXSZdEjJ\nQBf3aCaOeli9JMG8m2bu2SA/FrpXL8+0VColirItAyds8qyXYR1iP4YwZLqknImb3+1xReYhh8jw\nXdgfK5ytstGGOC4UZYWnhxLPna9HM2kuuBw8gWYDnKtXs5Fko/45T8Ic3MO6kIT1UFQoKtmVBI9l\nWC2X8hCGlW4fm7DSHO854Or76/v6SiYxmOs7bxjWHklwFIaVZ57VfTETVj5GGGKf6Py9v11NYFhJ\neht/v6Pz98G9RhJMyafdXmJfV624zOPYSma/DJUE2z2Q6rn6e9h9oefgTog9bcNOIeqxYvX7vTqq\nvRCIMdamuY3+78WwFm2GFVDneYqCSTMGrmZYRXO77RnjzbDaCe/CWmDmxClhDURI32dUSfChmfX3\nYt0/BzgYVkpYj80gbdt0Sd2+zIxVOqqPgMHEMe/HyyW4KNm+uSxRgzudC8+dr7FzzCiNCVtWQtiu\nc72xlJWM3sM6znSpW0lNLgkuKmzXef3+w8/7JzvVS/7c2Wpy9bZxfe3epyVGczGsst3rpivpiSnW\noB7WBY21aczw2pLgMcFbd8B81j/uhen1Mtm+/cjPUjGsh8HjiwHVs96+bUjFofou7b+Z5zunhGHV\nJwmOwHj0jbWJ+TbLqmJN3YYYVlq/nztfh5suFekkwY9MhjVvz2G1GVYq3NK1ZRqi+RQclVqAZ1i9\nJcHSUXyKybAWERhWxgCN9mWaezpVEkzxBhcXeMXbx3YPKzBe7eILu3gohKiVP1XXdMlzvbB7+MXE\nyQ03GaeENRB5wGYS03TpyjD2yDKBl+8qWTDnZkiOlRRM2f0yoYvsXOAlIuonz7BSw/v4z3hfVK1K\nHCFVgztVOZ8/XwWbWPjANtoibPImyZKymyxNDcZ2PTIwKWVtNtL9XllJcESJFPWwTu07fbw7AkDN\nsOaTGVbOEAUwGNaZrlFuJiCA5H2DQT2s+XJ6ep5qMzwjSFqP7WGtrIC1v2eZY1jN6r0Pw3qxL1rG\nfKnAjW8R9VgbVzDKmS6t8nlkcVRYTs+wusfaxDRD5MabAU1Q72JPaY944c6EhDWlJLhmWFmXYGu+\nNdUe6NoyGUefvUAyxRcRWGQomTFuMVUEZMAGTBxr4+i1riqpeoAldMIabLoUSxLsYFhTmC5x46Ko\nV7pjupT7Fds4l+ETw3qCF2jR81lQdACRT9fRX1p9UjRWw+USTH8DkDy0K6FdbsLKSUTUL7QomgvC\nOmuzdGOgJMEcw5ooYa2//+cnVKx9UDIsBdA2hHHK9Sacqlc9Pay05trVQ6AJJszkLWbxgMYYbSey\nou9e1Qnr2bq+ricYWjBBKyFkvZmCyu6b0W0D80iCveawLohhNedjE7b1ej+UeJSVrSLJer9vbkSJ\n6SysA7YRPazAPLNYK8k5kff3/bGmSzM5ZTYuwQOmSxMPhVe3xGdYOXMnYNhBlW5//nyNopJeDvwE\nKoikYljXucDzdWuGep1aOWRJMjXDSr3eExhWzvMB8C8y6B5Wqz0m5n5HmFKY6pPn74qmCK9ec5ok\neLrpUncvOVun6WHl2nlWmRqfZE9ooAR/LLhRQkuN1VPjlLAGgk6gkLlQ989W002Xju1ZfxR0uFyC\ngaayyQ0yptuXCM6MppnDyhuPqPs8JcEcwxrZ+IBwaCWs87gEc8YhGyth7VRPJ0qitdEDs0lyGxP9\nTsfUNaGIwzgQw7qZ2MP6+KqWBJ+vsZ24GarAnL8vvwaGlW8bWGgP60Iqzlc6YTUkwXXBcIhxsL0F\nhnwSGoa1O6IMGP9ZkgfCWzP0sXLOqma/FweW1Um0LtuwzVQ45GJ6IUfKbjtPyOzJIdjFagIF9WMY\nVgBBvgv0NykYrodP9nj57hZZJjoMa8f0xmJYD0WlC0xepktM37F2zfVNWAeKT1Nh7nHTJcHt22is\nE7U2TXcJVj/N7yxkJjGdZ6aZ5naVJ3EJZl2e6/XbZlh996vuKKF5isdLxClhDURIAHeoL6B7Z6vJ\ni7abYe1uRvS4oR7WpQR9NuiwOEmwZhlakosASfCxavU6EFI5sl0Hw8q5z5ouwS72Y8rbN/uW7AWW\n25joNTmJje1IOAX7Y1kzrPmka7GRBK8mKyfsjcmEPT4gNWxWK0XwzCHEJTivK9lLwCUnCR45PqmU\nvLzXVaDhGFaz+k7X9RiXYGAehpV3w+0/t7jrYi6Wgb6zdc9nGEO6aTtEA2nmsNrFaoIQojag63cJ\npmTEd8+qqkaSmiJheHSx1+exnbBWFc+wmoWd+2cr72PjHK9DEit6LvPY1P/jmS6ZbUdTTJecxaNK\n6mLHZJdg7eXQjfe8CCKGYVVF5YSSYEbSbTP8vsx5ZbVqhRZFbgNOCWsgQlhJCiCeO1tHkQSfr5sq\nfh/DemZJgjsMawAjOSf65rAeigpCtJMe6jeKwbCKZC7BjYnFlIrnWNiyFILpEsyzHxN7WA1m1T7n\nOak3vWah+46a2/OIhRUlCc4mS4IfG5Lg7XpaD6vdN2oin1m2bxe1YhYL+hAkCfYcxJ4SNB/73HIJ\nBoYDONsQZ2g+dsmwf2b1ngvYOFCxcw6nYFfbAdAjCZb8HNZZTJfq11j3jLXJxHSGnzXwyfo/lxC4\nxpsB6F0Lzf0K8E9YzedNwrBe7PHKvdrHI1POteYYv/ZYEPXT7PW+f+bfdyl7JMG+e2ZTfGpui6nu\nismwspJgaUqC47gEc/Gen6KRY1inKapc4MYSkRmVPbvWZwybTt6ZeH2pisiUOCWsgQjp6aIL5f7Z\nalJgC7RNlwDoxbrPJXinGdaqJSNrAqNlXgD0EZsbOv2XG4SuZ2B5MqzsWJssjfRiX1TY5BnON2kk\nKjZclXXT2ZaTOJmW9SEwK7t2kMMx5/SanJlWzKRJSYLz0YY4LpimS1MZVld/GTB/VdVOEmxFQypQ\n9d/LJThbzuZ9xfWwjmVYHUUC1zpmz8oF2j3nFHwPJawv13vHXD2snEuwus+DYc3mMdqilhOu2Bfz\nWKSE03QpqiSY6QcmnK1zZyI6lWE1H5+EYX1y0EV7IUR7XFsldcEPAPK8zbAeigr3tiv9/7Goqu53\nlgcWGThWMWZRpr0PxzVd0j2sx3bCGrqvsqZLWfu+MeB6WKcqqlwoHPHKsXAUFUe+kaa3ubsvLDVe\nT4lTwhqIELbnUCo28M5meg+rLQluGNbuV0r9VNoluGPu4S9vnhN9Fbei7Nr0U3Dh837IhMdGHqF6\nzr5enSCfr3Mcyip5wO0y9OmaLrXvH5qROIRdT2XX3cMqWJfgsbJYKSW+/O5u8LgUwzrN5v7xVYFM\nAHc3lPxOMbToSVhnvkaLsp08CSFmSRLGylhNDJkTTcGYc8nE030tCV6bY23UujLMsHZ7nQC3vJAY\n1k7fK0kdRyb/6zzDi3fWszCsPCs1xCR32wbm6ls+0Fibvh7WCMdSMmNtQh1ne1+ndDOsvQlrva69\ncK6KG75JTythipwwVJXEo4u9VgoA7UJsl2Ft7yP7omwkwR7HxkmCQ+dVc5JSX3OePsRiWPvk+RRf\n3tuukYkJkuAek82pDGsq06WKSSxXWdNuZSsax74P1+gy9ZrDf/8b//T38OY7V6Ne6ybglLAGIoTt\nORQqSYmho786tE2Xvv7luwAaUwQTHZfgqmpVjOdyAA1F31yuI7MBUy/q5Ug3vLKSOJQ8w5olCtL3\nRYnNKtOLaYqqH0HWjf8uhvVgMKyx57CaZkvuhLX7msceKcwQcf7x197GR//Ln+tdqPdFabgET+th\nfe58rXrAIjCsXJ8xYPSZJ56DSiiZY5nDjXesjNVELtIxrH/v1Uf4l/+r/w9fenfcpk/n+J0tJwnu\nP89s2T4FJi6Glb4Lu+9Vm8l4JP8v39vi7RlmsbpUHOo+/jvkZkjHDOb7UJQV1jk/airmsfRJpaP2\nsEp+vBkwJAm2TJe8GVZDEhyZYX2yK1BUEi8bCatZiLSVK6ZnR1FWqKRq6QB8XYL9z2UXXJLSWEUZ\ns0gwWRLMMqyNqdbUQjAX79Fa6DWHtaiQifb6mGoOq5Z0m27AWXOu2+9ltCSYOS98JMHf++O/gr/+\n8c+Peq2bgFPCGogQExSSgZqsVgiklLg8thnWb/nAC/jZ//jb8c+97/nO48826mu+MlyCW3Ohls6w\n1h8VP4e16lT8vvaFM6xzgdcfPh31/I3RC8OwJqrkU/HibMCdMQa46i1hs8p1YOvuYQ1/7V1RYpPT\ne7QTVvWT693iGNbmPO3/rL74zhUq2d+Tt6sZ7hg9rBTsTJUX26ymCb1JzXSJcj3PqRyzTYQwrKuE\nDOuX3t2hrCQePRmXzLFjbUZKggtvhpWToTVBDgVLm56RLIS725Xuv00JNb6lfZvuYe15n5z0co79\n6qo2Z+tDjD2C6w3UkuCI79M13gwYYlhtSbAnw9qadRp3r6PZx/e27WtOuwSXvGdHWUq93pAk2OfY\nJMOKN5Jgv++sYq5ltQ/GZ1inmC5xLVg0SYC+47O1UhuFvg4rCQ5QG1DbjxlfbFdZEpNL/f05GFZb\nElzJcecIO9915LpARljnA+vXTcIpYQ1ESOPzvqiwWU2f/UgSUnN0AgB843vusY/f5BnyTBg9rF3X\nMmA5fWA2+iQiXE/OOs/w+1+5h9/5ypNRz99IR5ge1kRulPuiwnad62AopVMwV70ltHp9mCq/mPj+\nd4fSWZVvKqntvzGT5HYfyzi5FSUNrnlzsjaI0C7BU8ba7Ao8V8+dm+wSzJjLEDQrMGUors+xOJKE\n5KZLHkkWIUvYw0rn0FhWgs4903F8rOlSJf16WAstVzWcRRmXYM5Mzsb5OmsZpKVCn1GN67p2mS7N\nsV/trMIwhyyCMV8l+8baTHtuE8rYjT8fztaZe6zNsYQQ0NLZKT2ssfe6KyNRIpju93bfpcmwmr4i\ngF/CyqlQmljK7z2w0w4iFgjpM9/k2TSGVbb7gYFmzTET1il7Ye8cVu82r/a5PnX0nAuc2iXPhI6t\nMmZdH7N+abKG+/uBc0OrfQbWr5uEU8IaiEZHHiAJXuWTqlwURI2tnAghcL7OnS7Bq5kdSH3BV9zU\nz2NZsYnYh997D597a1zC2jTndz/PVPP+9oWaA0qbbEqn4H6Gtd90KRNTTZcqI2G1XYLpNfgAFmgb\ntGhzsIH9hiruV8eCvf9YSkhpVIKnSIJbDOs0l+BqRA/rTIpgVkKeJZTeEg5liTwTejTVGKyyzMtg\nzQd0XdK4msHHHwqcr/NWgKF7WAcKI0Vpz4vsD0ya/qbmtjzLdFBH5+KY5P98nePScb3EBJuYDZiI\nuPrm5jAdUW78QwzrdBaUG2sTKi/tgz3ixUSfIc2OFEGB+xU9/nwdX5LJxUOqENs/FaGsKp3U3g+U\nBNvqoGBJMNerGFFFoBnyO9PmvnPXYlYrDJqENZukNqpqFUbbZDOcYTUxNfZ2gXPzXRkJK+u4P4Zh\n1b2xzW26kDXwYXBqn5uOU8IaiJAkj5KUrVH9C0HIiXi2zttzWE2t/cwOpL7QFTfjbG1Ml/gg/yPv\nvY83vno1KtCkTZp1CTZcN2NirwMAXi4bEyVT/SMo6VRtxuUwkZg0h/VY4sU7yqjDZjz7TJcI9oxJ\nYFgSrFmxA/+4nfF9T2VFH++ahFU915QZd13XSUJuBFlzgEtYV3k66S3B5dbdByXJTHM8tNaOvT5t\nMzzAkASX/c/hYlhdnzmt1y2GNWuq/XpdG1HYvLNZORUJMeEydqP7ONhjIYD5GNarw0yS4N5xP/He\nZ1F1W2gIQwzrdpVr5YD3WJtj0wObimE1FWemN0OnQG8U/+gx9878XYK5FpoQIsN8vK18i2a6pE2z\n1pOuc3ZfyNQcbDp3zvV883CXYFcR27eH1WZYU5kusX4CQmBfdhnWJuEcft4m9g1gWEntc5IEnxA0\nh7WosFllmtUK3YgoiDr3SFjvbHIt+aosWdDKGqS9NHDmPI3pEr8Bf+S9Sh796lsXg89PCxh3YQuR\nJpFXgbkpCb6eHlZTni65jSILr/BLKXFlJqx2D2tFUu+uDFm/PiMJHmRY9/0yTgqYtpphneYSTJLg\n7SpDJZtRGL4oK14tAJg982HH6X8sHMOa3pn1UFZe/asAJS9pPhg6V3wkwfa6rCXBQwyr9ZlrSbAj\nG2edRY3kyYdhVf2L6U8u3tiNEjPX3/Cszhzb1dVISXBa06VJT91CnxP5cN5qJwAAIABJREFUdp07\nHXx1gbX2w9h5rpnmyJNkDOvGHF/SrOs2K5gZhU9K5EIkwex3NnKPssExrFFNlyIVDPhk0mZYp5kZ\nskWtzP9acDGsRSWD92gXSiaxXOUNwxrixQE4xh2NzD1IMWO3Dt5knBLWQISOtSGGVcpm1qQvmll/\n409EUxKsGueb+yh3jdXgHxt8P6P6aQd5hA+/9z4A4HNfGU5YdQLDzmGdySX4GiXBh7LSTsJdWVq4\n9E49r9tZcowkmKuMDy30l1oS3D9TkOT55YQNrMWwjuxVdKEvmMwyoYonczGs7Lw9ZVSSEsEMa6KP\nZYitt3F5KHDXWpe3Y3tYHUyQ6/ormJEruZE87Qs1Rm3dM0OUcL7JRsuep6Bi1hjdn9YnCWZYnVQy\ncBO2Gz+HOAxrW0EEDH8uIeDM1AjbVeYsqtDYt9D9ihLh587X0R3xLxkmaQzDWlXNNXk/cA6r77ns\nAmuuUzOXMaAZ1jubSQkrZ9pFMRIlxU3CGs6wctMK1H1+DKvdvz92LfZFya3FmdDqNdvJHRhX1OD8\nR8b+/UkSfIJGCMO6Pyr2gKo+obJgCiy8JMGbvOUSzDGsSx1EzJnzcMmria9/6Q42eTbKeIkWL86c\nJJlLcNnuCYo9m85Eb8Kaq+JJUUlnlT/07dMG9uJdmt0XIAnmGNbRpkt8AG7OZ2vkmv7X4rGscHko\n8VztnDnWDdaFsuom7yZSzQTmj4VLErJlMqwiHcNK59LYZI5jWEmSO8YlmBsQ7+pjKyuVkLpYmUPt\nSt83koVwZ7NK2kdPCGESS4mOJDhL1Kph4+o4ooc1gjGfy/BO3TfpqVuwJwSYOFu7e1i150KgJFgz\nfOfTeij553ZIgks+YTXNzEx11SoTg7J9E6qFxvWdBSasqRnW8/W0OawuA7RaTbXO1bzuTU/xYwic\n1DpoDuuxapnfAQkTVscoHnqd9hzV9t/0Pi9TyKCCwdBncRWgxFw6TglrIIZGDnCgYKyRiIUtHDR+\nwOdEPF9nRg9rZVWCUN++zIS1TxIM8H1/qzzD739wF58bk7AalUEbWSqX4KOq/lGPxVgGJwScAyFh\nYyRZ0lHZDC1kUCDxotN0qfu90mvq/zM9rEO5pWZYXT2s9H3XagcgbDbgk516nedqOdmGzHUmuCO6\nGFZgvlEegMtcI/2sZhUY+22weZ6un5HO4bEB+hXTw0qS3DFzWLnA2vWZ227vgLpepFR/sy/GJ/8k\nCU79/XKOv9qoxvHanFFQntAZ2sTYsTaTJcFMIhnStzeEUrpNl85Wbln4rt6v1rlAJsLH2rxwJz7D\naho6EUz3e/s96+tKSmOkXdbLMHNQLTTt25p5oX7vwcWkxTNdaiTZUwoGFbcvGC7BdK1sV7nu3/R+\njd5+7vHPsyvKLsOaaO699gnJ2+fZ0THWxvybPnAuwWM9Z04M6wkaPjp0AgVjU6s8VwEnommqUVZt\na3JiW+cYxB6CvjmsAM8cAsA/8zX340iCk7gEV5NMLHwwJAkGVMKqEqb2/bkI7xXTQco538NKH2s3\ngBXs8Q6N+SAM9bCaZjTNBuZ/LT6+OgJANIbVJW8npJKnjz2WXKRPmIkV9EGq0VPAsLy8+3jGdGk9\nbr3vJKzG6C7X4+3ALjeCGVpjxuB8wnXgA7ZPfiAYZd9nIuWLDa4AYSOWJNg91iai6ZLDpBBQ56l7\nDmsz09I0cBwLSpKohzVmEs66BFuSYM60piibhJWIBB+lTV9i5bse0ZZmX/+x1vvdUa2rd2qlXejn\nz7WK0PidfWEmrNPmsHaT4vr1PRWN9vpHBMGUUXYcOCbU7GFtn3/jPWOaQkZz23iXYH8l5tJxSlgD\nMVaeaIKCsbEBjAu6crL262FtuQR7BEbXjb45rIA7Yf3Ie+/jzXeucLHvl/NpSTAT3KWbw6okVsSS\nX5sk2JDEumRp4Qxr48C4ykTXdMklCa5XJW4OKDCid4OMchwyTpZhDfj8H+/qhLXTwxq4UY9IWOe6\nRrljmSNJ4PqOhhBTOmejGWszkmE9ljgP7GF1MaxOl2AHw0r30Ri1MaCgJnUfK2+oon72zWG1axip\nlC82xkiCswg91GXVdWgPUXGNeR3XGnPWY0hj9pYrNj5sDuvz52tIGd4OxUHPYTVMl8xxbfZ1YvqP\n7O2EdaLpUuhYGyrCms8Xc13Tku5NeGGqqqTDmFGgqF2CKSGcMuKNuxZCijcswzpRBeUCF2PlWXMO\ncpJeH0kwNzlhrEuwvR/dZJwS1kCEuHYe6mBsk4/raXKBAnEfSfDZOm8zrIEShesAx8S5+llNfPg9\nyil4qI+16WnsXg5KBulztOOgXRc1w5rQJZiRGxHMGZEus4PQPbMZ6J7hnAly3KZL6vduAKd+Dkph\n9v2sWNvNcArDWkuCLYZ1kulSXw/rdTOsM7z+PoBhjWlOYuPKc6zN032BO2uXJHggYfUca8N9R6ZR\nEwWpY0BJWeo+VpfLqLrPz3RptrE2QwzrhKIeQTJOyKHJTx84hoxw1lNIJ9MlAPVa7ikJtk0GIyYM\nVwc1u9lcN8yxKoXF0OdWUYce7zuKpWJ6qxu5sd97qJg92pT3T4WSdE9TdLniCDr/rw6lfv4ppkuy\nr23A46Po62GNrWhjE1bRxPit73UkQwo4zouxLsGa2DoxrM88dFXYR6JADOtEJuZpkCTYMl2ypAt0\n+xLBMXGuWZ0mPlI7Bf/OgCyYNl+WYU3E3mgDrlnnsHYv94ZhLVmzg2wSw1onhqscZxsuYe0y5/Sa\nACcJJinNkEswSYLdjpeAksBN6WHVDOs59bBOTFilZA3ECKs5GVYmsM1mkAQrhtVvg52DYR07u/Dq\nUOLOtn38QtQmJAPrfVHy0kXXe1OOr+0TxjRqojFqY0BJWcp1COhnT1wyxdIxPiR18aSs+4CHlEwx\nZsKy7zGwH7L3dRhWntAXzJvFj+0681YE7Q6lUrSsmwJpLBALbhZbW/PFLWfkVsJamyyFMKyu/RII\nMV1SP83vZjVw/fvAVnSFFKZcSi06/3dFYzi3mZCwckUtek3fOazXzbAW7O3j423edGmc8kL3dp8k\nwSeEOOtSABFLEjwkVTJxvmkY1sLqYR3bxH1d4Jg4WzrD4QMv3cF2lQ0aL/UyrBGq567XpH5mIeYa\na9O9z2R/WPZjwhxWnbBucnYofeP+zFdTO5Jgb9OlAYZ1lRvXYoAk+KotCW42w7DvUgWT7iU51bnI\noSi7ge0qT58khPSwZgnZNp2wjrg+pZS4dMzt3I4IhqsIDKtZvfdxXKa9ZKz0ORQckzjkEszK02dw\nzN7pgK//M4wzh5V3Qlb3xe1htV+H0Md+7kxJ8Cr3H2tzrFqu7DELI5eHrjGW2Y/aYVgNhooS580q\nwyb3S7J4tQDd55uwdvfCzCOxGcK+luvSdR6i6OLYPqBef6X6TtsMa8Q5rAGO2ftjV2EyZb/vA8c+\nc8UH8zFjir9NUd9fUnx5KJAJ3pvlpuL2vJOZEeKse6hNMCggmyIJPltnzo2HAxkl0LxNtpI304xH\nX7A9rGYTuuNzyDOBb3zPPXzurX6Gta+HNUYwYqMoVXKoklWB7SpLKsVrEtbu5W4aBXEbhYhgunS2\nylUP9cFmWNVPF7PQCeBGqhqeaoZ1oId1nY+Wa3JoGNZ2D+uU3p2+a3pV9wrNAa4/a44kYc/0HQ0h\npTz0So+1Gb4+D2WFspLsfOwxEjk7AR3uYa0Y99x2MO7bwzqWSQ5FSJBvj/sB4rCaQ+DcZznk2fRi\nb/982klP3X6dPpfgtZtlN927ueLjEHa1IU8KSfCOKRKZLsF9hSBKarc1keCTyHBzyxtvE7/3wEtK\nIyas9ffXTCWYwLB29gXoOay0dvvKq024WpPUfX4Mq13IOFvFZ/gB9DKpgG26NL4QxZlx+UiC72xW\no8aa3RScEtZA+OjQCXvNsE5jYi4PZWc4/RDubJrKmj2HtVnAgw4nOTgmbmisDeEj770/2MM65BIc\nO0i3576G9AT5oFlMu/e1XIKr7lw51cM6zXTpbK16l2wZmXsOK+rjtRi+Ee56RVnpQMW1KWuX4InX\n4uMrVcG8u2mqyuq5Joy16dlbshlMjwiFJaMD5kkSfIyCCCnNqHx6WDm3UsJ2NWxCYjOJQwGrzRwB\nbRmxD8N6NlsPa1f2rmcsOj6eiinkzJKwjjQticHw989hjciwWnu/iYb95HtYab8Kcwkucbae3g7F\n4erQNcbarDJUUu0HtjMy18NKDKuv6VJ3v/SPCwHeDXasuc4YkCHSlLnv3IgVQBXCu2NtsnpUnv+x\nx5jDSsUIN8MaN96qmGTexbb6FCL6zosxc1hvkxwYOCWswfA1KpJGADGlbw4IOxFpQX+yV6wQX3Fc\nZsbKS4Kb+/tYqQ+/9x6+9O5Os2EcqLeYex7lRul/zH2wGd0Q10Uf9DGspkuwa+TEVIb1fJO3TL8I\ndLq5Nv1uMK5+9m3gl8bn6OphNRnWqT2sz52v9fFT9XoKw9rnEjyX0QzAz4WcI0nYhySsiRxjSeIL\njEvk+ubejWZYPbwF7N48wGJYPWbaatOlGRhWX/akZGTEczhWj2ZYI0j1K8mNtaH74r1Ptcbw9531\nFO+muwRXOG9JguP2sNrGWLb7PZc8tFyCc/+xNmq/bN8W+p1RwsOaQ0VQ1TQMa52whjCslDxZ75lm\nIu8MR+0pfg5VT9vA2I+V9mCbYU1lukQFU7Olx4yxQ6XerEvw6LE2wyO5bhpOCWsgfPs+TemJuZiG\nIOREpIWEZlTyFcegw0mOIdMll8QJAD7ynmHjpT7pXJ7Fn09rMnxAHQAknH/okvIAaMnTXb0jocnA\nlSUJdpkuufpVOjNhR8wLvtwbCatjREeLYZ1wLT6+Our+VQDa/XuSS3DPuTxHwkiwR18B84wSobYJ\nH+R5qtFTlQ6QxkiC9dy7bZeR24yYS1h1lC/9igLXrFz6G59+4DsTzFh80Nef5tpKy4rv75QyXP0x\nBg3D2v8Zxrguqx4zqpj7T1+ffGMA2PUaMGdscmv5EHbHUrnUTlSXcbg6lB0nVLMQaV8nWauoY0iC\nV7lX4bJvDmuoJJhLeGIyrFPcwHtNl6Q11mbCvhpDEuxSzaUyXdIFB4YJtf9vOrkPPq/DPRoY08M6\nPJLrpuGUsAbC11m3vTBOY1gvmVl/QyBG9knNNPIJa5qk6eGT/aT5fvQZm4uYuZ71BfmNU7BbFszN\n6zKfO7ok2DB6ANQ5MQ/D2v2cTIkMZ/whxBTTpabKyZsuqZ+c0RPgNl3qk38+rc+zs7W7L5iGqGeZ\nmORa+XhX4PnzJmHdJmZY50xYuX7aVaLE0MS+Hn/hg1QMq8k2cozEW493reu2b4zAdgR7U1jsF3e+\n/+7blzpJ65vDWlXwcgme4h7qA5Y9GVBOcHNY5xjF1pgbDkiCaxXKlOS5j1WK+Rb71hgK5m256LGU\n2nMBqF2CvXtYq8mKFhfU7OMehtUqBK2Mc4eKOuQl4ZNgsQmrRzJiomQSHpuJ2x1LvPV45/W8BGJY\nz43WMF/oAjNTPKoqqfuUAUzaV1ULQPs2+1o4lhW++M6V8zn2AwxrbNMljmEd6mcd08bCkQ1NIav/\nb6+OxYlhPUHBtyHe7JWY6iZ6dejO+hsCVVoudiqg5zT1qfrA/q3/8RP47372d4L/ntZ+rr8LcM9h\nBYD3v3iO7SrD64+eOh+jGFb+80xhunRdkmBbPgh0GVauyh8ah5lVznOm76mU3U2aXhNgqqwjTJco\nyXjl3rbXJXhrVYJDrsV3Lg96pA1gOi4HugQzAZAJ0yY/NdhkKLHpkpQyqIc11VgbOl83DlO0f+Ov\n/DJ+5Odf07/3SYIVwzo8h5X3FlDv7fOPnuKP/aW/i1/8nUcA+H5EW+449rM8m0sSzPTJD/WncfOJ\nfZw2Q2G2NPQhdPamCY4tJ2PBuD2s1fAcVus8bRQpzX7lu8btj2qsTRKG9cj0sBr7mpLaN/dlRrxj\nFsj8x9pwI9nUz/Ae1m6MQ9f/j/z8a/juH/5lr+cl6B7WVQSG1SHPvzq0e1iBsO+Z7+du7gOA//03\nvoDv/KFfcMZNtoqNkML0yzyuMQzrWEmv+Zi2aZP6OYZh5QwAbzJOCWsgfCtpB4NhnTqvMUgSTAzr\nXiWsrQso8RzWL757hS++G1YZBMLnsALqe3r+fK1HkHDocyZNwbCa5wJArosJE1bH+BigbbrE97BO\nG2uzXSkmk0vKOct283eX6VLf8Tytz++X726cm7LpHjjFKOnRxQGv3Nvq36cyrNz4DhMp5OkulJKR\nmyZmeItKMTkhY22kjP/Z0PnDnUtVJfHlxzt83iiENRJS3nRpKHiz+wvthPXLNbvy2Tff1be7GFbN\nHnmOtUmdsHJrDAVwLobSZboExE3mbIx3CZ62fx7LCvuiwl1LSp5iDmtVufdLVzJpmwSerbp+BEMg\nQ56pxnQczESJYMZYtskkFW6rql0g8x3FkkISzJn20H1f+L1LfOndXdB5pntYN+E9nCWTPNExF6WM\ntq9WDi8NoFkjvvTOFa6OJd51xHXEINtExCYBww9Au/e7elh9xpWZ4AoZY1sFTqZLJ2j4Mqz7FsM6\nbdEOMl3aDDOsKYLRY1lhd6x0IhECznRprCQYAO6drXSizmHXw7DGMNSwoat/M7kEk9Sb6/XVC3hZ\n1Qxf+/4psz9N10DOWdI1h5WOoZswqZ99rAqxXC/f2+JYShwZiZc5n21KT8uji30rYZ0yIgfgWRYT\nczOs3YJB2oT1YAXGYxGz18sEBeUv3d1gd6xaAQJJzx8+2evbGoaVH2vTJzekcWMsw1q/L1q7X3uo\n+vELLpEz1vK9Rz/wZpVhlYlr7WF1nVqs6VLCPYvQx5ibmDov9Un9vd4/sxNWTHpeDkVVOV31XYY0\ne67A6rnGXZFLcM/onFBcMWNtzHFtnUKQwbCaRR1fhlUlVu3bQs8FrlfRTmyo6P6kx0DShY5LcGSG\nVftV2MqlQOmxq5+bllCK5y4ccR3FWGfWXpJnAutcBLkk96FkSBVzLWfNtEb1sNLfm887bu07mS6d\noOFbVdWS4Hx6lXGK6dKFZljdgVFMUKJKwVYI2DmsQujf+8baAMC97ao3YVaGEvylIIQY7BXwxdyS\nYKr+sT2stVFQY7rUZTtDY0JTqnW+4RhW9dO16TuDgTEJ690NAH5jNntt1rk6j4YMcWw83Re4PJR4\ncL9JWFd5hjwT0xjWPknwBLbbF5wMM7XpkunY6QMf10UfUBD2Ep1LRpBD6+ijCzNhrU2XAiTBdOg8\nw6L+jhzeX3uoWN2KYVi1XMyTYQXAyvZjo5TdJHtIRskVT8xe3VRogvDhOaxA+Pl3oRPWdev22D2s\nUkrWjZjgkkvurc/hbJ2jrPhioAsqYcpxlohhtQv4tLce6kIsF+9Ulmw+ZKyN70xhF7g92o7LiE10\nsYp9UCqyfJKSgo6Dcyan9ZAkx+bn7wuX0gtoPlcq8rjiShfDSrfFZljLWmovWus3jP+HMayce/RY\nw9dTwnqCRmjCul2pBn/fxdHE5aHw1qZ3E9bmPs1QRLBPt6EXlgkMq5uJ46WjNu5tV70Jc1+vF1m2\nxwTvEpwuUOSqt4RGOlXWPTndjWLKHNYzQ0Z2LCUKYwPjZpfRa3LHS3KbMaZLL9fMJxeA743jomvR\nN4AiZs1kWAHUzxXew9o/1ibTgU1q2GwfkF4S3DCsfpvsKlHCahc/zCCPCmAPLziG1X+sDddn3rwv\n9TutYa+/dQEpJduPaDoL+8xhBYCzjb/U0xcV0/cnBhKzikly6WNK2VO965F4m/CdGGCDRq7ZDKvd\ntzcVjRNtf8JqF/ma4L9RBHGP64OWBE8w4+FQVbJmb13Sz9IptS/KdlFnu/bbB6TkDYjouLzeB2No\nZMeYlKg+vvKLpSQ5+K4yrHOlpAibw+qIw4wibUcSHFAA41QYtEZQLEJroYuIcDGsdGyxTZfKimOe\neQOmhi0eIQmuurGbLrgM/L0aM3TqYT0B/qwkXSCmM2yw6RLjijeEO9oleF6G9WJAujEGnCRY/V7/\nHJOw9jGsR/e8wpQuwc0gdn/XRR8UzKJH2GgZmHp9Tu4TmgeYkmAaDWFKyeh5XT2sLvfg/rE26nt+\n5V43ydDHZc2nHDMj0wYxaybDCqjvNNwluP9czrK0AXr7WHhn1pSvr9dIX4Y1kWkcnTsv1gmrOdqG\n1tF3Lo/6++6XBOe95wU3b69hjolhLfTPh0/2bA8rfXRUqPExsLqzSc+wStYNt7mPA2u6lFPxKt26\n2bgEjzRdCjz/tCTY6mEd6u31BV0frjXGNSO1a7rEP84FWTOZZ0Y7VCxFEa3bdpHIdAm2R/mYDKtZ\n1NnkueqjH/k9svL2QAMutofVSmxCGVY9UtFszzn4XzdcP6V9zLTPm9MHfNHPXKufF8ZayKGPYVWm\nYWkYVhNc36r5/zGFKM5/ZEy8LqWsia0Tw3oC/Ctppksw4F/NIxzLCsdSersEn1ljbcyLSQiBTKTp\nB6KFZVoPa7c/AGgSm745rMCIhLWonJLglC7BFJhvV3nQIO+x6Btrk2cCq0zoSij3GYdW+M3KN1e9\nl47v1d3DOrxQX5JRDiWsnCT42P6+twGul8SwPmAZ1kBJsOwmICZWWTbrWBuOYU1p+jS1hzW+6VJj\n4AW0z92nxrzft5+qc+HqUEAIvqq/GShQarkdY9RhM6wA8OrDC7bnmfYlkif7JKzn63kYVvcokO7j\nScbq6tVNLQnerLJBBc9U06UnmmFNKwkeYljXdUuD03RJxy5+DKseMbLJjdeI88W5jLFMl+CykmzA\nTy7BlNSYSe4YxJQEsy7BLobVs4fVZshDFV1cUc0+ZlsSHPI9l5X7NbQkeCCuHGZYYyes3XglY9Zy\n8/9jTrOKid3GrAs0pvBkunQCAP9Nyl70QyXBlyNlSja6kuDugpAkYd31V8LGwMXEaYZ1qIf1bDhh\nnZNhtaWP55u0kuChQGVjzIHl+sukDKvym9JbbmyGZs4dQbcrYe01XdqXyATwwrmbYd0Xpd5YgWkM\n6yv3N63bpzCsRVn1nstZYkmuiZKbfSlEUtOn0B7WVCNOiIV46W5XXn6xb4JGKl7QoHZ7nQJGSILL\nLvvVSMeq+jULvea99vCpg2FVv+8CGFbOGC02eNMl9ZNbZ7neXmD8aIcpuDoUg+wq4Cfx40B7U3JJ\ncE9rCOFs1VX7dFyCPRNWelyTzMSTZDoTVst0yZTam7EbzWGl4wLGy5XLiotJxrNnrefq62GtE2v6\nXvomHnBoTB4bhjykQE7FIVeRTD13O/kP+Z6l7M5htdsGLuqk3Wm61MOwmvFOLAwxrH3reu/z9hQy\n+gq0VyMN424aRu1mQojvEkL8thDiVSHEDzD3f68Q4jeFEJ8RQnxcCPHNxn2fr2//lBDikzEP/jrh\nGyTtOwxrmCzhqkd21od1nmGdC9YlGEiXsFKieiiq4EBeMkEOYCY2/X9PPayupIvGr3BIYTTT6WGt\n+ztTJSOuyihhYwQpLne+kJjJNDfi+p5czHljuuRiVfp7WO9uVrqgw0qCj1WLxQtJWB8+2SMTwMt3\nYzKs/cFkapdeAudYC6RnWO3AaizMvs2YIJbypbuK+TLPpQuDYaXixSXjVkoYKmQUjJO33Zt7sSvw\ntc+f484mx2tvXaAomdFDmmFtt6CMwZ3EPaxSSrZPvm8Oa6MOad8e2ivoA859lsPUlhqXSzAZC0Zj\nWHvM9whbxgBwr4sfdcLjkA67QI8z+xtjtcBc1dfo2YAkuMWwGgUG2yUYAPbluGuAi0tCZ/LqxMQh\n/TRlwL6SYEre6HsLNVdrkqf27WYxwJ5vHhLz9THXuod1oNVsp/cShmFNIQl2jIEj8GNtRjwva7rU\nvo8DKc1uW8I6mPUIIXIAPwzgTwD4AoBfF0L8tJTyHxoP+ycAvl1K+XtCiD8F4McA/BHj/u+QUj6K\neNzXDt85cLqPwKwyBiwafU6UQzhb5+wcVkAtlCkZVkDJNzarTc+jeXALGOBhunS2quU/VcecAYDz\ndnruVJJgc0wAoJI5exZfDHCGLiY2eaYX+D6JU4b+z9nG1aHE+Qu2JNjsYVXH1Q1g269NGKNquDqU\nuLM13BBZSbDNsPq7Bj682OOlu9vOuafmbYb2sPabLqV26SXQS7BFraQ9rGEMa6qxNhS4E8N6aTKs\nuy7D2jdujPrjirLCinl/bCU9bxdFH+8KPHe+xkt3N3jt4QWqniCJEtaxY20AFciGOJCOhcuLoK9X\nkzOjAdKx6iaujtUohnXqiB2SBN876679mRDRe1j72g7OmOKdlvTaDOtI9kwzrMbfR2NYaxWE3SJl\nsqWl1WrRZi4Nl2DPJIt31W/u84E2NHIwaSar6isJtguBnGP/GLgK3+bv57ooES4Jrpiils1cD7kE\nN0m6wwAvOsPKj4EjtCXp9d+MGmvjlgT3/T0Vcs49ia2lY0xk8G0AXpVSvi6lPAD4CQDfbT5ASvlx\nKeXv1b/+CoD3xz3M5aHZpMY9fm9JtDYDc/lcCJUEA2oxudi5JcEpNn9TOhdqvMT1PQHN5jDGJbjv\n9fc9DGsS0yVmrA0QdzadCW261MuwuntYgbAqP8ewmgmkdASwQ5LgvsDw6aHEHZNh5VyCi6rF4ql+\nct8e1oM2djIx1KvYh9JRmCHMxbAS28f15Mwx1sa3h1WbE0V2UL46llhlAs+dq/Vj12JYm7Xk0cUB\ngCrI3XUECPSeXGs+6wZpJUIX+yPub1f40IO7eP3hUxSWmYz593Q9e7sEJ5QEVw6GpmFLu3/TN/vR\nvD8Frg7F4EgbYPqInSf7op7P3n2tTMSTBDefv/uc4Eas7SyGldbW0ZJg3U9oSoIj97A6GNY9MazG\ndWV6drRcgj1H7qi4pH1bKPNvJ9UAWvNipzCsO4thPVuFXeeuaQPm9ZzKJdjs2ywrqeNgVw9rH8Oa\nxnSJMYZjig/q/+qYxpwjtF1wzPuY8X6+XjdLx5jd7H0A3jB+/0IhRwKeAAAgAElEQVR9mwv/LoC/\nZfwuAfysEOI3hBDf53+Iy4R2LPVkWFsuwQGymKsJVP/5Ju/tYU0x49GsgIUnrN1B0oCR2Az1sFLC\n6prZVVTOIDmmJIuwP5YQQs0ABZrKc6pgsW+sDdCWBLuSx5BzozXWxmCR7eNyMaku44Ve06W9csbr\nmzdnS8CDJMEX+45DMD1XuEtwv+lSaoaT4OpVSp0wHxbGsF7WjClXbLnYl9jkGe6frRqGtce9fUgi\n1ze+gN7Xxb7AvbMVPvTgHt585wpPdken0YeWBHt8lqlNl4YUFawk2Bkkh69LYzFeEqx+TpEEP8ew\nq8C0Odg2Grd492PMvYDQUQStumqZPtA5dablovHmjpPizC4s0HxxKjLZ6+oqy1DW7sV2wurDsLqZ\nQJ93ob4bl4qgqiTeuTQYVs+xNp0e1k0eJMl2Fo+YHtYpLsHcHFZzjTDjSJc3yt4ymjKRwnSJM8Bz\nJqwervbNmtl93t446FnuYR0LIcR3QCWs/6lx8x+VUn4LgD8F4D8QQvwxx99+nxDik0KITz58+DDm\nYSXByrNv6mAt+ko6GCIJnpCwrnPDJdiuzGdJGFZzQQl1Cq4qlyS4/jmBYS3qCiwnHQHU4pJCErzJ\nM73ZcXLZmOCGkpvYGhVXl7FVUA/roesSfNVKWOk1+Nd0mTv09m4cynYPq3MOqyUJ9jVdesInrJsJ\nm6HNBNhIPQeVoBlWJhibg2F1OXa7YI9/iQU1x65JWC9bDOsRd7c5HtzftkyXXOvyZoC9YcdaWMzx\nxa7Ave0KH3rPPQDAVx7vnayMHmvj8VmmHmszpKjgTi3X7MepMtwx6JN4m5hquvSk/l75547Xp9v0\nsPYzrG6X4PZYm7Hnys6SZ54FTkjgn5uPh+h6o2PsFnZMSbDlEjzy2LjEymyh8UHVw9CZDOtzZ6vJ\nPaxngaZDWhLsKJIBzblBhbLQsTbc3gOoz/xiRExJhQinAV7kda4akAS3JL0jxvOZz9v5+xEs/tUE\nJeaSMWY3exPAB4zf31/f1oIQ4psA/DiA75ZSvk23SynfrH++BeAnoSTGHUgpf0xK+a1Sym998ODB\n+HdwTaDzJ9R0KVQSrLXpAQOB+xnWNAYWJqsZ6hTsMqOh20YzrMzrD8kQU0mCzcpfaknwGIbVNdZm\nTL+ECy1JMCMj46qH6ndeEmyb0HC4PBRtVsxijKpKzd4zk6KN5wYmpVQM6z2OYe2ft+lC5ahem5gr\nYXUxrKlfv2FY/TZZnzEBPtAMK3PuPt2XuHe2wiv3tnh4YboEOyTBdVA8xLC23Eyta89kWPVjHFX9\nqwUyrE0PXPt2CuC4Xk3XSK5sxFowFZdGwa0PU9neJ7tjZ6QNIZswVswGNzrJxtm6q/zaW/JKb5dg\ni+GLybAOuQRTkam7l2S1JLhR29C6M14S3JWuaqMsX0kwMxaFM136wEt3/MfaMD2sQaZLjh7o1hzW\n+jVW9fiikL2wrLqKOl0IqOQo1Z7yqeDXvik+Ey4UjDrKNdbGx6RtzLgjDn0zwW8yxuxmvw7gw0KI\nbxBCbAB8D4CfNh8ghPgggP8DwJ+TUn7OuP2uEOI+/R/AnwTw2VgHf52gPgjvOayGhXqIJHgqw3os\neQOeVSKG1RzFEMywOiTBOrFxmAkRyMyCkwTb/Tk2lOlFvOHtQLeHkgKAWEYUNhqzDccCnrslwaEm\nEkU9L/isp0/XxZ5o5jygb+3pocTdHtMlmy1Q//eT8T7eFTgUlVMSHPI9uhwYTczOsHKS4KSmS/6s\nINCcJ0VkhvWqHlPDjWR6slP9qg/ub/HoSTOH1ekSPDDmgXWDzFTwS/c92RW4f7bC1798x9m/35gu\n1XNYPXqYqLcrlfNu0wIwnmGl8801hzXl9bAbKwmeOtam/l45ZBElwaRA6FNxbFfdEWu2vFLLPcfO\nYbVMl0Jn0HMg0yWbScozgTwTusDfZezqHtbSkASv/RjWSvKKmJDvrM9ArTIY1ve/eB7OsK4bl+Ag\nhtV1LRrxV1u5FLYX8sx1k+SRL8oqE27TJSvGMhHiWTEE7lxwmi55rBdcjJT3rJeEKeasS8ZgZCCl\nLAD8BQA/A+AfAfgbUsrfEkJ8vxDi++uH/SCAlwH8iDW+5r0A/p4Q4tMAfg3A/yOl/NvR38U1wYd9\nOxRqTtPKTFgnzGENORHNv+GSgSQuwfsC77l/pv7vWFyGwC1ggCEdjcCwumSIKcw99kW7h9J3TIAv\nGikPf/9mZboEt+/TUhzPQ9sVFEg0myTgmMM60nRJF4l63fEUy5VlAttV1mGMbMdKwL/iqmewsgxr\nmHKiYZLcS/JcpkuuvsEsE8HGMmMwtYc19rFRTyqNBLtqMawqyXhwz08S7LrGXewXfeeHosK+qHB/\nu8LZOscHXrwDoIdhPfp/lnd6ZPQxoK/3jtRf/WTnsDKmI0ATJCedw1pLwocwle190pOwioH1zgej\nXIIZhnVXlC15pW8LCz3OdJANKdZzcPWwqtfJ3AxrnqGoqrZLcE7GaOPOf+Vm2709D2DFC2aOZ1OI\nUwnrve0KL93devewaobVKB6HKClcKiDz96neEAAlf+3bmsK5KhgDwHvub4OMNM8inn+EouRmYmfG\n//0YUgKnMBnjn3Ol45zblbCO4oullB8D8DHrth81/v/nAfx55u9eB/DN9u23BZlHf+O+KFvBQ6ib\n6BRtunnyzjaHdVfgvc+f4cuPd5NMl7g9dvRYmzGSYFcPqyHfiCWumFsS3Eh5+AXcdAl29bD6bsA7\na8HUpkvGBuY7hxUYdrN+eihwd+uWPjUFCtslePwGRgmKs4d1iqFFT36RDbz3WHDJMHMhorOYJkJd\ngpter/gMKyVx5+vc6mEt8PK9DR7c3+LJvsDuWNYJq0sS3O8STH3m3WROrcu0dtFa9qEHd/G7X73s\nytCoh7UO5H1cgs2+7xTjtaTjeqc1h5UEO5QHY2YyT8VoSfAEYzpASYLvbd2S4Fg5ueu6NnG25hlW\nc7/iZmr3wd4Ltuts9Eicsc/NFYo2q8zdwyqUXFXKJlHVfeYj12/J9Fr+/+y9d3gc1301fGZmK3YX\nC2BRSYIdLKIkSqIKqWLLVnVkx05TbMexUxwnjtN7ntefv7wpb5qTNz1OviROFL+W4kiJpMi2JFuy\nLFkSVSgWUWIBCaKQ6G2xvczM+8fMvdPunYaFYvnDeR49FBbA7mB35s79/c75nQNoxVXQRoqsOO93\nRAVHGNZsMor2ZCR4rI2NIdc+49Xco9hNsrhtZjRsY4IdF6SpTVTVkAT3ZxO4tFxhPodbVGErGX63\nY7YyrMbjgQpW/UeY3ga+JMHfWQVrS02X/v+GSIANpNk+HQg/67Yabbq5W/xWzacVa030t8fp/4eB\nVw6rWxQIYJIEM17fkASzLwW3yIWw0DYATknwWjEb5Bzl7VNiksFEOtjOkPNZdJNCw+ZZDCuZYWXL\nkFnFm1eTqFwzigbWTB7r8w4qXXIrWMN2lancyuVcjohr4+TtOBaXjYnSYnm8GWEZ1rVyjDUzbPbs\nwlJNM8ohc8xzhRrKLpJgr82w4sGwkk1aWp91JHOsdkae/L6Rwxog1sbFWbsV4Ckq3Ao+runSWzDD\n6lsSvFqGteYmCW7dec1zeTUjzjDkMRsTAUBUn08MnsNq3AtaxXCR6KkoY80w39dY4w3USdvuEuxT\nIaNwlV/BmwyaaY/1MbOb7EqlgfZkFNlkFPWmEqi5zWoe15tK4PPVS9LPihYKQ8pozDVPam007/qz\nCZRq7Oe3JwGYQVRQrVw7morqGLMjeydJFCx/T5A9lZHPa3peH74iNP7yO4xhXS9YV4EguYR1WWmJ\nXKLc0DLbvFhFFsw3X/vFJa2RA2ix2kQ2GUUyKq1ihpW9gJGH3CROgHbRigJbksxi3MxYbWQBCzVd\nYmU+PmDtJMHEwY71HgKk401mWK3fC5vDSm+S+jlHJLrmG63hGmr9XbdGhFuTqCErqMuKwYrFJJTt\nmYK2TECgtZLgWMhYG5YboB2iIKDZamchBryyL9eqRqg1ZcvYhF9QhrXVOax1mQavJ6NWtr6gF6zd\nGS2L99JyBYrKV76QDT9vA0ebSgwZdlNRUdDntijDqjsFO9bxVRSsvLnvVoFruuTSFOSaLq3xDGtD\nn8EPIgkOU1gqOnvOi7VppekSjbVx8XxgZVTWmrJjZCYREen8qBeqtrGbVjJc5Tpftu3GsGrzrdZr\nxMvJ2w5ZYSu/JDF4soCWw8rOVFZUwrBG0K43rFYCzLHaY4mCMuT0GF3M+AA4khbCjseoHEWdpM8G\nU4a1PYlircl8r10ZVg8DvDDQzgU2w8pSKpHf8XxexniOP5fgJhJR0TNB4+2G9YJ1FQiSXVprWBnW\nsPEXFZc5KS8kzAUrY9FZK9OldDyKdCISmmHlLWC0sPG4KAVBQCrOfv2aX4a1hQVr3SEJdmaUthJN\nhmW+GTHJKLJ45iZBWTV7WDngDKXnuReTL5mGFi5NIrsMJhmVaA4fgd2AAjBMl/z+jXMFLU6kI+mU\n8YWNq/IzX/aWzbAyHGuBtZPeEtT1uKegCOK6GAQaw2rI6MySYINh1ebzxxfKAPgSLK+MR4Xz+RNW\nnWzSCBNnMKzsrr6XmRwLdIZ1jRhW1UNRESSHNbLGM6zUfTaQ6VLw1ynVm1BV8F2CxdaZLvHOMTPs\nazTgHGGhPxeUYY2QGdbWxYpUXbKPYy4zrJKFYbXG2vjZl/HOZe2x4E09RXHObZqZeyIJzur3nCDG\nS1WbJJjleu4HXHk+KVhtTY04Yx7aDxSVrQIg89yFWhOCAPTpyj17Uxpw+oRYjsvDAC8MWBnqvBQL\nc1yRF1istnFe8H/PbTzl7Yz1gnUVCMJK1mSnJFhW1MCMSbkuoy0kzW+VBDu7ea2W1JHucToRQToe\nQZEj3/B+Hg/TJR9dpAynYK16zM356WYFhd3BLh6y42nGmekCPv3w68zzieVAaIb5vOTnygU7nipj\nw2dnqTxNlzgzrPyCVft8yfyd/fXMx2VxCQ4Ycj5frKE7HWcW1LGICEVF4OvakP7wP6e1iFhigeVY\nS14fCCaPXyzV8Sv/fpzmP7tBuy6C35L8xB2Fgfmm32aSBMuKinJdi7UhsvDxRX8FK+8co+wX4z1v\nmmZYjYI1xf55MsPasMod/WCtGVby8fCKbNapzXcSX1uGtRrAK4LcSsMcS4FKvfmS4FZJ8HnnmBma\nCsbavNMMbKzvA6uw5aHS0Pw7RFrYWFlcRVHx2//1Jk5Pr/j+W+hzu2TlWiTBjOuqbLtGgjBvvHsX\neSxoJjSrqWw3XdJmWHWGNcAca62pyaaJcoWO5wS8zr3k+XZGM2x8jJYKwZdaF6tNpGMR2uRhpz/w\nGVYjlSHYsT189BLue3GU+b2m4nQJJp8nr5ANksNqcY/X/9dtL1BxUR68nbFesK4CQeY+67Y5EGqh\nHnBju1LhZ7Z5wbyZ4m2MWomSXkBk4nrBGtAsgMDTdMljhhXQNgRMSbAHE7E2LsFshnU1MqmvnpzC\nFw6P46ULi47vsRzszLAWrNbvhWWYWS512hyg03TJ/vHxclgBIBWL0PPKDgfDyjBdssvTALNc09/7\nP1eoUSmoHV6FCQ+0e+1yLr9VsTY8x1p7LqgfPHVqBg8euYhjE8uePxuWYSUbhVavX5WGNUeYbH7J\n+ZeOR5BLa+fBGC1Y3XNYeecFTxJO5IW0sNGbMV2pGD5+8za8a0+v4+cBOObz/CARW+uClScJtn7f\nDO65uEZzywS8fE8WiJQzzLHYGxF2aDP7gZ+WCb+mS4B1X8JqJLHchHmoNay/T6Si5JyfL9bwT89f\nwBMnZ/z9ISa4OTnHoxLKDe39ZalFiDEZjevxUEGYwTuXAWCwK4k3JoMV3zIrFoVluqSfJ0EZVvN9\nOEEZ1oD3KBczPsBZsMakkBFvHKm1KEBfCxtIJyLUXJFtpumDYQ3w96uqij96/DQ+//wo8/sKi2GV\n2ArAIPdRlgzbT6Smm2P92xnrBesqEGQDWbOZLpGNWVDJxGKpjq4Ue7PsBQvDyljAW+24SJ0t9cWF\nNyDvBa8ZVj86/TRPEuwRa0MjC1o8wxq3nQuCsDop3nS+CgB48o1px/dkRXF9j9wYVje5nhsMSbA1\nl828GVYZchfta/axAEAuHcNCsc58zXLNakjGMl1iNSiCSoTmijVqtmNHLMCmxwwjeui/v2DlOdbS\n5k2AWdHT0wUA2rrlhdUyrK1cv0iUDDVdMrH1RVPxGJVEdLZFMbZQAuDCsHpkPDY5m0GSj12oWZk4\nQRDw6fdehgNbOi0/T2Nt6hqrEsTrYK0lwTyTNdccVs51sRoZrh8EMS2RVsWwaoUHVxLcwhlWntTf\nDLIWmosZu0swEIxhrTZkh2cAYNx7F/S1YbFU8/V8ZpRdGNa4ZMzZsoy+7E0duifzcR+gBSvj+rpj\nbz+OjC9Rcz4/YBY8gtF8qjYUdLTFqCQ4SLQNP0Yv6Awr537tJgkO0YTnxxjqM6z6OEbG1UzTec6a\njwtAIKfq1y/lMZmvUv8KO5qKU8XGm2EVA9yvZE5jxEttVfZpGPd2w3rBugqIQpAcVhlxE3sQlmFd\nLNXRlQ5XsHrF2rR6Ns28sUvHo3TTFRQqI5cLMBY1L9MlANwZVq9ZLyM+we/ResPuEiwIQugwb4JJ\nUrC+OeOQkGmGDi6bFNN5ab9P0BzWgHsmYwbMZC4Vs8+wWl/D/possi2XimGBs7EhzFcqIMMaNM5g\nvlBnGi4BwdlaAiN6yL1gXUuXXgKeY22YWVEi8/NTsIZmWE3SuVaBnDcGWx8xGNaaVXrenY5TSbCb\nPBHgb4a55kIiLC7BGU78CYGxyW0GYlcBdlZyK6FyrnfyZZAcVkOGuzYVa5AZVj+unTys2JhzO8LM\nQ/LAKzjMIOMp5hlTreBhSIIDzLCa11tDUaT9PlkbFnysEazndjVd0u8JrLWsYitYRVFAVBJ8NRvJ\nR816K++6vA+qCnztTf+MMcu0h6wFy2XtfWkPKQm2M6zJkEoK3jw5WbKdkuCQBoSc/R6ZYSVjZim9\nMc0y89SMwjwM8AKQRU++oX2WhWqTuYazxq4kTsEK+E8YUXS2mdXkc8+jb4aKvvx2x3rBugoEYSXt\n7EGYiwbQFvVcSIbVLFdjyTpafe83swLp+Gpcgj1ibfzMsHJMn7yyH9fGJVhxbCaDbABYmFquIBYR\nMZWv4sTFvOV7MmO+wgzXGVb9W2FjbSzxPRG26ZJDIqi/Jmuhz6XjXIbVnlHsHmvDYlh9SMEUFfPF\nGjPSBlg9w+rGiAVxF1wN3Bxrte/7zyk8NRWEYXVujP3ALJ1rFcg8dIKeS4Y6wM529mTiWC5rG0iu\nJNhD9s/7/COiqOewNiCJAlcJQmBcr8EcgoH/fpdg9xxW5/uiPWerj1JDNRDDGv78I40IN5fgVs+w\n8vK4AYN9M5+nmuOqUxLst7FRbSiW95Fc44TFNRjW4AWrmyQ4FhHpnCpLLVKh9wKr2imYJNi5Xu/u\ny2BLrg1PvulUO/EgMxg68jV5fzRJsG66VA42w7qaHF3zMQLO4p/G2qz1DKuoXQuFqsawkvW3wJlh\nbaXp0hMm5RrrPG3Kzhlk8jVrzEf06Uchc/xHvGqPddOldTig0fL+ftbOHsRCXDQNWUG+0ggvCTax\nXQ43SmntGNaMvriEdQmWORIR8pCvGdY4Z4aVWr6zb3prYbpUZ8xXJHSzi7CYyldxzxUDkETBcaNk\nOdiZYf7beWxn0D+fdOjtnV2W6RJPIugmCWZt4kp206UYQxLMiDHyihwxY7nSQFNRuQVrWAdCtw0Q\nAZHxr4Wbt+VYXBxrte/7e565Qi0Qe8Jq5PiBOa+wVajqUsI2hiSYNN4IK2Y+F7g5rFI4SbAoGAxr\nJhHhRlMRmIuRoO9l4i2SBPNm4FhrLFcSvAaNRDPKQUyXVtFIKlD3Z54keA1yWH3MsJqLmSrLdCki\n+b5fVZt2SbCNYdVllmEK1nJdtqQfmBGTRMqEMhlWVsHqM73BUAc5vycIAu68rA8vnFvwZTYHsAsT\ncs4vmgrWWEREMioFZljNJo9h85Z5Mmiy5rAY1jBu0H4kwRndyBMIzrAGNV0amStieLaIG3fkAIDZ\nMGcxrKSRyiw4BX9kl8Jg3gFi7MX/PTczsrcz1gvWVUCbKfN30tcdDGtwc5YlXRoSlmE1X8CsXLsW\nxxjaZljDF6w80yVDcuH9HKl4hLmwVRk3LdZrtNx0ydGxDi8JXqk2UKw1sXcggxu2deGJN6xSJNZ8\nhRlupktGDms40yW7S7B5k6PyGFaXgrU7FUddVpjycmOG1VlkENAZVvO16DFfaIZbBiuwCtMlTsad\nGVLIzyIouI61AaWPp/T5VQBY8jvDGqZgXQMDHvv5m4gZsTZFm4zTfC7w2J6IpGVn8xoZvGKOMKwk\n99ULZvIstCR4jV2Cg8yw0veF9ztr1LyxS8LdsJrzz5hhdcthDfy0TPgpWJkzrC2ItTF7GdgLhlVJ\ngl1SE8xrPIthJR9XTLI2L1fLsALAXfv6UZcVfOPMnOdzAe45nmaGFQDak5FApkuOGVbSlAirAnJI\nl8nzWs+RsNGNiqqCNWYtCtq9p1htIhOP0vXQvq9UVdX1XhK0qUz2Ux+8fjMAMOdYWXssksTBY0j9\nqENYzDvg3chaTZrItzPWC9ZVIFCsjY1hDVWwlrRFqivF3ix7wU0SHAlQfPuFeWOXiUdQbyqhZhpU\nD0mwPaKHhUw8gmLdGTJtD9W2o9UZj8ZiautGRv13rO2YWtbmVweySdx5WR/OzRZxfq5Iv68EKFid\nm0njuIOAlcMat8nI+JEV2r9sSbDWrGF1OYmM02y61FRUNEx3BnsmIBDsWiRGGl6S4KA3aqJucC1Y\nqST3rWFYeR1/v6ZLp6a0+dU9/Rlfm9F6WIaVvC8t7LiRc4kUrG1Rbf0ixSPAZlhTLkWl20wXL4dX\n1GediAzOC+bNZFB5dVQSEZWENStYeQ0qwWXswGBYrY+v9bXAcjnnwU8uIg+FahOiwC+MBaF19x4/\na4xRTJpnWNkNVr/jTFWGS7D2uPYa8/rasFRiK2fcUHHLYTXtt3jz+IC1sI3pDsZeUPUf4Skert7c\nie503CIldYPC8Jkg98UlW8GaTUaDmS41FOYMsT2j3As8tQM5TseeJrQkmKeo0yTBdIaVU7DWZQWq\nCgurbDmuqLMp44Yn3pjGFRuzuHJjFgBbCcDaY/FMl8hjfvbbMmfv62XAWK43102X1mGF6LNLAjg3\nY2EkwcRspjMVLtYm6cKwSqLQ0g0fYMx6ZeJRuriEmWP1zmH1fo50IgJVdYZMk+4j78ZDHm/VHBG5\nGdoL5GRUDM2wTuYrAICBbAJ37usHYJ258GRYTW8gj+0MuhmrNqzZbwAcxlI80yXBhWHN6WzWAqPL\nWWLE2gBWxqjWVCAKQFRybuz93FxJd5UvCfaf5WcGz1zGjNXMygUB37E2WPPm9NQKBrIJbOtO+XcJ\nDjHD2uqmEuCMNSHjFNWG7JAEmxlWt01C3IVxMJoE1nUhImrmGkQS7AXzZxbGwCrBmPtuFbxM1txy\nWFkxbObvtxqVADOsqzFdIo6nvPtPK2dYeWZqZhiSYLNLMMt0yf/9yuESbJvnXtSbj01FDVSIAd4z\nrAQ8tQgAx6hWEJdgnuGyJAq447JePHN61tf71JQZsTb610RZRxnWRDQEw2pVOgEhcli5pkva1/bG\nQTwaznRJVng5rEBDVuk1E49oDTZ7wepFQgQZAZrOV3FsYhl37etzbZaz9lgGocIpOH1c15o82vm4\n1+9rjZz1GdZ1mCCJ/mVAddmWwxpiY0s2fbmQDKt5YbcbL0hi6+zzCQjDmopLXPmGH2hD+M7H3Qob\nO3gFM8uy34xWxyfwFtPVSIIpw9qRxIaOJK7clKWudoAuK3F5j1xNl/Qvw0iC7RsJ+99IYy5sb7+X\nSzDAlo+V601IokDf2yRjJo/MY5lviEYum/f7TxhWniQ4TCMK4JvLmEE2MGvNsPKOhTKsPl//1FQB\ne/oz6ErFfEmC6005VKzNWsj27QWLeZNnrGtWhlUQ3I2OYhF+diVPhk0Y1qJPSTDJ6AP4RnJuaGPM\nfbcKfNMl7V/WGsNrnqxFk8IMQxLsv0kQpnheqbrnqrcyh5U0pP1Jgq1NPqfpknPcggd7wUpZ3IZV\nEgwAi2X/smBFUTVDJx7Dai5YOfOF9p/z62zrFmtDcOe+fpTqMl48v+Dr+XhNmSXdYIkYc2WT0RAu\nwVa3fu3xoAyrfly8WBsHw2rN2/ULlTMCJgqC4Yuiz/OzRr3omBfXJdh/KsDXTmn7qLv29SMdjyAW\nETHPSClgSXfpDGuIGVS35yW/z3tfG7KChqyuM6zrsELSM/L8oNaQHQsjEEw6SBb28KZLZnMd6/ck\n0Z/NthnnZov43DfPcy+cYq2BZFRCRBJXWbB6MazeBSt5fbujnNtwvvbc2r+t2gyTRXI1M0F2TOcr\nEAWgT98433lZH45NLNNsVt6iR2ApWG0rQtgZVrvRA2DMlBLGgDcHRA6VtRnopgwrq2DV5jbIMbNi\nOuw3b8Acs+BPEhyLiFxXzyDh84+fnMK3hucB+M1h1Z57rRlWmbOxDeJSXGvKOD9XxN6Bdq1gLdc9\nj7vWVCwRS37RioL1ueE5fOP0LP2aFWsDaOdSUY+MIdcNyeQ1n3ssxCMSV25ImUQbZRMRtY2JJoPz\np6wh70cYhpU1990qhMph5RQGa+2YTdYMPzPVqzmWggdzTqI8WgEeQ2aGfb60KStoKiqXYfXD/lYb\ninU0xFYUL5Rq9P4cJIuV3C99Mawc9st8POR3/NwHZM65bMaNO3JIxyO+ZMGse7QgCJokXFGRjkeo\nWqk9YMFqZ1hJYRmWYXXI8/X3wJHDSkiZgN1+/n5PoH83OV9YZpo1xjiSGUFMl776+hS2daewszcN\nQRDQnWLnwLNIAbdYG0n0n8PKlxSzf79sU5p9J2G9YF0FJBlJoWYAACAASURBVMH/5rEuK6suWMmF\n0tkWUhKsn8ARUXAstEEieggePHIRf/DV0/izr59lfp/MGgBGBESYgrUVOay8kGn7fA3vNVq1aTAk\nwawNQLhW+mS+it5Mgt7Qbh7qAQAcm1gG4F2wmm/YvM1k0D+/ZsveA7TzT1E1WQ/Ad1okm1NWZ5I0\na1iS4HJNRlvcXfrEalAEkQTPFWvoSce5GxW/1/VKtYFf+tJx/MVTwwD85rBq//53MaxBCsPzsyU0\nFRV79IJVUeEpY7Mb0/mFEXES/n35w8dP44+eOEO/Jjf9BIdhNbOd3RntnPSSYMVd5IZuRldNRfEs\nbMwg12yYeeAgzFlQkDXE/jeSL1lrLE8S3K47pp6bLTp+pxWo6OuXn8g0mgkb0nTJ7XNtpekSada6\nbWTpfKN+DnAVQRHrWu4Gu0swy3RpZ28aALsRyYM9xswOc/OLN94AWK+TmOSvYFU59y7L60ckXL+t\ni96H3SCr7MKGHCeRAwMa0xos1sbapBVFAbEQqQQ80yVyjPb7atB8cwJeDqsoGvmzdF/JMPMka6wn\nw+pBENz/8jheOL+A7z+wid7vtVg9BsOqqhbWHjDF2jA/V39kl5tLMO/Xva6LtzPWC9ZVwGvwmUBR\nVDRk1bLoh5UEd7RFLXOBQUA2XaybcBiGdVqfnfyLp8/h8ZPOLmKh2kRG39jRAXlGtIwXPHNYfcXa\nRJmv75X92Gq5IculFnBmlAbBVL6CgY4E/XpLVxsA4OJSGYC+mPplWNdQEkzOf7Ih5jGsNK6IccyE\n3WRJgkv1Jg0TB4wFu2xjWO2bryAy3rlCDd2c+VXA/3X94KsXUa7LmFrRriFDLunNsK51DivPTTSI\nGyoxXNqrS4IBbxdQuzGdX6w21kZRVJybLWJKX88AY8NuMKz6uVvXZljNBWsuFXc1ziFwkwS7NQkU\nRVOrZHxIgs3PEWYeeC0lwTyGxs3xl3cuJqIS3jHUgyfemG7ZjKcZlQA5hqvKYa013SXBYuv8E2ZW\nqohHREvxYwfNSG16FKxR68+5oWozRjIXDE1ZwXKlQQvWINE29qaS429xS0XgFKzxaGtcggk2dCQw\npSud3CArClf6CWgNGoJsMopCzWkgyQM7lii4ZwY3eovMsHLu98Ej3tjMtSgIdMaZXDOsgpVl+Mg6\nLreC/cjYEj7zyEncMtSNn3rnDvp4Lh1j3sdYLs/kfWLtt0Wf44Q8ssFthC+Iw/nbDesF6yqgRcF4\nn3SEVbMujMEv5sVSPbQcGNBO8lhEZBYvfnOhzJjKV7F/UxZXDXbgl790DMMzBcv3zQxrZpWSYNYC\n5lbY2JHSmTdHN44hETWDzu21aNPA2wDEVznDuiGbpF93tGmW7xeXjGLIL8PKM10Kuhezzy0BztkZ\n8pbaP1qvRkR3Os60lrdnj7EC0lnHFWSmZa5QoxJQFvy4BCuKin89PAZAM3VQFNWXXK/V8nQeeGxv\nEIb39PQKYhER27pTdM3y2oxqDGsI0yUpfMEAABNLZVQbCpbLDVqs2bvUyai2fpXrMoq1psUNWBIF\ndKVinhsEMtPFgiyzHVwjkoBqU0a1ofiaYQWMAj5MRJA9K7mV4EmCJZc1xq0wuPvyfkzlqzhxMd/i\nI3U387EjaNyTGV7MucaktOZ6n8pXMZBNuMpY6XiEvhby2KqEzzlIVVUZkmDD2Gmp3ICqAkOEYQ1Q\nsNqbSnbE/DKsZtMlye8Mq/av19ZjIJtEvtKgruM8yBxjSYNhNc6R9mQUqgpmtBsLrBlkVka5FxRF\n8xJhqfMAZxM+bMSbypjnBdiSYNYMK91jhYwYm1mp4pNfOIKBbBJ/+aGrLedOLhXnSoIdueUSXwHo\nN2EkjEswdbiPrpsurcOEiOSvyCMXEDPWJoBcYqFUC53BSpCMSmyJghScYZ1ZqWKwqw2f+8gBtMUj\n+In7XrUszGbpHM+C3A94Oay0sPEjCSYMq70b58Ww2rr/T74xbZl1CwqjYHXOd4aRBKuqisl8BQNZ\ng2EVBAGbOpOYWNQZVk+XYFMnmmOoEGaG1TErGrFucnhyP6/Z5FyaPUfCY1jNN+YaoygK5hJcR0+G\nfw0aM6z8zcCzw3O4MF/CgS2daMgq5ks1E5PEf23KsK5xDiuP7Q3C8J6eLmBXXxoRSfRVsGpxT/J/\nC8M6PGPISgnLStmbiNVxutrQClY729mdjq+SYdX+Zc3aLZetMjgvkAI+VMG6pi7B7ooKdqyN9i9r\nLbh9by8iooDHXWYEz80W8fnnLwQ+1krdOdLAA10jGeffm5MrtDnFgldcUSslwTMrVfS1J1x/xs6c\n0nlAx1rub//CKh4SpmY9WRM2dCSRjEqBGFa7k7cdrjOsZM7blhDgJts3g3zWbsU/AHpf9mJZtVgU\n5+PkODuSxj2HsK0rPpyCtYaBc4+TDOGZwVNqkevZ0QgOMCtqBm+/JwjG35wxjZrZC3eqYnNZ/+Kc\ntVhRVHzyC0dQrDXx9x89gI42672+Ox3DfLHmUD3IitPlmc6wsopvny7BvEhCQeDvAyrrM6zrYEEU\n/BV5dcaiTRbTIAPpq2VYAW2h4i06QYoSVVUxvaJ1bPuzCfzuBy7H6EIZr40Z8xpmZ0uy2QoTa6Py\nhvD1s9fPDCudobWZFXi6BNskwZ998gx+7yunfB03C7zFNEhMgBnL5QaqDQUDHUnL44NdbZjQJcGe\nsTZrkMNacWFYDUkweQ3nJt382nbkUnEa8WRGuW6dYW2zvR5A5FFsSbBXZ73akLFQqqG/Pcn9GT8M\n67+8MIqeTBw/dtM2ABrLahSsfhyr3yqG1XosBhPmTxK8p78dgOFq7rYZbSoqFDVckRVEqszC2VlD\nGUKMyqq2GUbLDGutSRUbBO/bvwF3XNbv+jpaLiH7Gpc5GZkRUaCzv0EZ1m+3GVYeK0XMZVhrjCGV\ndj5fR1sMh3bk8PhJviz4vhdH8T//600UApjUANrn7FsS7HJd3vfiKD7zyEluE0CLK3JzCW6df8L0\nShX9WfeClTSMqpRh5Xku+DPuMQpeZ0JCranQdTyXiqErFQtWsHpED5nPfwf7RWXzTlbQVw4r595l\nx4CufJr2KFi1YtB5kpP1wDrDqv2/n2gbsq4yXZ5DMKysv3dnTxoHt3fhCj2nlCCsJJgfa2M0b8ha\nmHFhWN3MNBNRdkbs+bkiXhtfxq/fvYfev8zIpWOoNRUaoWc+ZociyXWGVfCVZ86bbXZTRK6bLq2D\nCb9RMFRWY5OeAMEY1sVSY/UFa0xiboojAWdY8xWtUCId28v1xYoUSYDePdYLRcJ82V16/cCLYXWL\nbCEgG0z7QqPJZfgXttH91zZUF5cqODdbZA7e+4HRcXbeQJqKimZARz2SwbrBthHRGNYKVFUN5hK8\nlpJgW8afIRG0/i6NK+IccxeHYS3XZcsiTTdV5hlWxuctiQKiEl8iRHBhvgRVBbb3pLg/4+USPDpf\nwjNn5/Dh6zdjS06bNZ5crnINLezHCbx1Batj1pBIgj1utHOFGuaLdewd0G74JDfazQGUvF9hiizy\nvoTNkT43U6SbjUl9Y1m2zTCaHadLNdnh2Pupd+3EJ2/dATe45bCSy96+6RFFQwbnVtjYf4e8XlCs\n6QyryznOYxLJ7/AKg7v29ePCfAnDHPOls/qYyqXlCvP7PFTq/iXBxtiI83vji2WoKpjmUNWGjLqs\neEqCW1GvqqqKmXzNs2AlhjxkLaxyG6z+JMGExTMXTGaXYBrVl45z5wN5IJnq3FgbS744u5hgNS+D\nzbC6/5xfhpXF0AEmSXCbdYYVgC+nYOPzY0TMBWQ+efuIbFsUD3ziEDbYmuZ+mrcscAkK00N0X8lw\nCeads2bwmPSzutrm2q2dzN/rSrFz4FmfH2lA8GaTfTGsnEhHPy7B66ZL67DATYeuKCrt+rI2YxFJ\nmyX1231SFBVL5TVkWH0aSBFMr+jZn3oHsb89gagkYHzRKFhLdUM6J4kC2mJSKIZVu2hZsgj/kuB4\nREJMEh0FM4txM8PMKi2VG3QxeGV0yffxm0HPBcl+A9Fv4gEXd5LBat+IDHa2odKQsVCq6zca98Wb\nwP5e0oI9YJHEagSQIp1siFWVPRNDJcG8GdZUDIvluuN8Ldea7CLD7BLckJlmDBr75f7ej8yVALgX\nrBFJhCjwb9L3vTgGSRDwQzdsNm1mKqb4Dv7rv2UFq8pmWMnXXk06s+ESoL236XgEiyX+Bssr7N0N\n5HwJK5U+O1vANZu1DQoxkrPPMFIDr4asyziDbwbcNsOEYbVv1CKiUbD4dQleDcO6trE22r9s9oQn\nCXaf7b7zsj4IAvDV152yYFVVcWZaK1gvLgYrWMsNmc5pesHNdIncD8/Y/B0Ao3nLi8gCWjfDuliq\noy4r6PeQBAOa3LfmybB6G9do37dK6wG9KNbdeM1RfRrDGiDWxmNjbmVYbWoRIgmWnAWree1WVZXJ\n3vs1XSL35SmPhokWi+J8nDy/hWHV51mJAZEbDLaRoegK2JiSObOlPIQZewO8CQrAIEDS8QhKddly\n7flhWOMcl+QzMwWIArCjJ838vVxa23/P2xrmLLk0Gc3gmiZx7uPm+7vCiMsB3NeFSoO4ga/PsK7D\nBF6RV28qOPj7T+GBVya0r2X2ZsxvNw/QummyotIOT1hoDCtHohBgI0w6hv1Z7XgkUcCmzjaML2g3\naFVVtRlW0804xXB08wNFYXcyvWYd7UgnIijWbJLgpn9J8KUl46bz8oVFX69pB49hTVIGOph0jczc\n2bubg7pT8MRimXszJFgLhlVjKGx/o60r75a3BrjNsMahqsCSLWS+VJeRijmLDGusDdvYx8/s0sic\n1n3d1s0vWLXnYudtKoqKB49M4D1XDKC3PYGuVAyxiEiNlwD3c5ncENc61oY8vyNvz6fpEykSdusF\nK6CxrP4Y1uCFoCAIesc5+Aw4cQi+YlMWnW1Ruq7ZZxjpDCvDJdgv3JoibgwrgW9JsGk+LygSa2i6\n1OTIngHtM2SdVrJHYdDbnsCBzZ3MOdb5Yh1L+vxvUIa1qmc6+wHPdKneVDCpv+5ZZsHqPZsstEgS\nTO/XPgpWswGgYbpkPZeIkqXkYSZEziWW0V21IVui+rpSMSy5NLV4z81jwq2NWOv3DKMg53GZ92S/\n8dDr+In7XnU8t9F8cT/GRFRCVyqGqZVwDCs5znaGJNjPDCuPYQ3TmFI4x8jDqnJYOWsEAKRMe1iy\nJprPQ3rOujKs7PGMs9MFbM2luMVuN4NhpSo2DovPzVFlXNczK1Vc+VtP4Jtn5wC4uwSv57CuIxB4\nRd7p6RXMFmo4MqaxcKTDZN9AuEnE7CBSmbUyXZJEMVDBOqPfAM0mDpu72mhHudbUAsdJnAygzRuE\nNV3i6fi1Y/e3iKbiEko1uyTYKV01w+wSTGJiulIxvDIatmBlL6aXDWib+2Pj3pltZkzlq4iIArpt\nzrWDXVoBe3Gp4smwus+wal8HnWG1Z+8BThkZr5NK7eA5uwHS5bTLgjWXYGPzR7r61lgbHsPKN8Qh\nGJkvYUM24dm51Mx1nDfDqZUqVqpNHNqeA6C91wPZBCbzVVokus1ji6bmyVpCocdiZyX8mS6NzJfQ\n2RZFznROdqXiWHTJDvSzyXCDdgMP/nsXlyqoNhTs6ktjIJs0CtYGWxJcqDVRaciWdc0v4lE3SbDO\nsHJm7YAApktUEhwi1iYaQb2prMk5Rhp+AwxZKo9h9dPIufvyfpyaWsHYQsnyuLlIvGgaVfGDii2K\nxQ0ip5EzuVyhhQ1p4phB7oUZl3OpVaZLMytsJQ4LCdN5SmdQbefSYKfWEB2bt77ndlQ5pk3kWjBH\n9eVSMaY3AQ/lQDOs/hlWc8F6ZHwJr4451VSqT4YV0JoEXgyrwjE0Ys2wEnmwH0kwv0EePJVA5uzD\neDAY1qCxNmwZLHlp82iE4Y1ija4DPBhWzlp8dqaAXX0Zxm9ooHsPk3SdXJ/2PZbbPoZXcD5zZhal\nuoyj40v6c3MiHUWBOYIArOewroMDntPXcT0oelRfzFmxNoC7CYcdZunMapCMsSXBkhhsIzy9UoUg\nAL0ZdsFK5E4tYVg5Fy0prvzKVNLxKEMS7MGwmlyCSZf+fVcO4I3JPJcNrTVl/OHjp7Fcds7j8CRW\nV2zsQCIq4qWAzO1UXnN+tN9INukbiomlMtMQwAy3WR/ya62cYTWbLoWJK8oxupz1poK6rFgYVlEU\nHGZWvJnlOMeEwYyRuSK2c6RClufiNKIu6JJiM0M7kNU2M34kZpG3qGCleXucjrHX648tlLAlZ2Wh\ncx5yv9XMsJJjC8OwkqJmZ29G+yzoDGvTshEmkWAkTsluuuQHmgySvd43Odeo+TMImsMaShJM8mbX\ngGUdXSgjKgkONQjANxHh5dOacdc+zezKngVOisSOtmhghrVcd29kmmF3kicg98KNHUkOw0oyJV0k\nwWJrclingxSsETPDyi54ejJxtCci3NlhgiqXYZVQa2imS2RP05WKo9pQPCNg7M/tRxLMY1jt10hM\n0rwkZP2/8YUylssNLNlma40ixXvv4SeLlWeMyCpY07EIBMGf6RJ3hjUSnGHlRe/wYLhBu6/L5XoT\nv/+VU8jrDU3+DKvOqtr2lAAsyjk/zc+Efv6ZUW3IGF0oYVc/v2ClmeKmvYehHLH+LFnPg8TaPHt2\nHoBRO3AZVoG/LlCGNURE3Lc71gvWVYB3kz02oeXCjeodX3Jh2BeNIJJgwiattmC9Y28fvuuKAcfj\nkigGkhpO56vIpeKWBX9zVxvylQby5Yape2wsLmmGo5sf8AqboJJgjeG1S4LdNyZmSfDFpQoy8Qhu\nv6wPigq8xmFDX7mwhL995rxjAwXwXYJjEREHtnTi8MiCr7+FYHK5gg0dzk1IOh5BZ1sUE4sVz86o\ntWC1fo+870EdpLVYG14Oq0J/zm1WhSc/6iZzJKZNBLVyt23qzTEdtaaMfKWBzjYno+ElCVZVFSNz\nJdf5VQLedX1hXtvcmZ+DsHpes3qA8b6sdcG6WKppM+e2oowySR7nwuh8ySGb7myLYZFhlEWwmhlW\ngKhdgv8ecQge6ktjoCNBJfaVhuLYCCejEuYK2kbF7zypGa4Mq+ouCQT8M6zkV8LG2gBYE+Ol0fkS\nBrvauCYkYUyXAG38YU9/Bs8Nz1seH54toLMtiis2ZmkmtV9UG7JvSR29R6jsgvW2vb2YylcdjFjB\nh5lWqxjW6XwVogDXDGmCzV1tODaxDFlRuQY2giBgqC/DNJMyg1uwRkVUm5okmKjGcim2coYHco7y\n7t9xHwyrMw/dMM2bylco2TBiY5KN6C/v4+zPehesPAdeVsEqigLaE1FfkmCuyWMseIzedL6CrpR/\nZQnx6fAqWJ8bnsffPTuCf9TjpxRuDqv2r3k0guwvzUREteF9L9HWYusad36uCEUFdvXxm9KJqIRM\nPGKZYSV9UjvDKoqa+zlzvWMwrLKi4lvntDXsgj5aJ3Pk0V6S4JgkIhIiIu7bHd95f9FbCJ4O/fhF\nrZCZL9axUm2gLmsXxmokwYab3uoK1nuvG8Sv3LXb8TivS8yDZpFvl6EarB5xbjMvLql4JJRLsGdh\n45dhTUQs0hEt+9GdYRVNBdvFpTI2diZxzeZOSKKAly+wi8thfRN8miED491AAOCGbTmcmSkwmVke\ntDB4dszKYFcbLuoMq2shJGouuYAbw+p/18Q1eojYGVaO3IU0IriSYD0mxdTlLFOjAevmpS0WoR3H\n0XntvdjR67wh2c027Jgr1lCoNbHdY34V4F/XI/MltMUk9GaM62Ygm8DMShUNmW26YwYJIl/rgvXc\nbBFbcm2I2m54ER+S4GpDxmS+Sh2QCXJpzSiLh9oqGVYx5AzruZki+tsTaE9EMZBNYrncQKUuo8pw\niU1GJRPDGm6Gtd5U2PEtsrskUBIF36615HMKG2sDrFHBulDCthz7+uHNavpp5ADAoR05vDq2aNmE\nnpnW5H2bOtss/gNeUFXVYbrlBhLLY78uJhbLiEVE3DLUAwAYtrGsfhhWwcXYMQim81X0ZOK+NrHf\nf2ATpvJVPDs8x1UEAcBQb9pHwcqRBOsMlzmqr9NHXrMZlYaMqCQ41ikCt3xxnjEZad7WmwpG5w0Z\n+QVbwWo43HvvPQaySeQrDVfmmNdUJsdpLlgBzXgpCMNql3SbWXQ/UFUVxy/msX9Th+/fiVOG1f11\nyHXxfw6PodqQ+aZL+oMZBsNq3tfVmjIiouB6rrNMl4gKYreLJBiAw82ax7AC2ufHjaWxrXevX8oj\nX2mgOx2j4w2KixkXb12o1JvfkXJgYL1gXRU0py/rYyvVBs7PFXH5Ri3SYXS+ZOSwMrp5/gtWbaPU\n2ba6gpUHshn2y7JO56uOPMrNesE6tlBGoeY0lMgkIp4mDSxwzXlE67F7wS5JrssKVNVpvGCGwbBq\n826bOpNIxSO4fGMWr1xgOwUTmdTp6RXH9wyXYFbB2gVV9W/opCgqpvNVDDAYVkCbM5pYLKOpKJ4b\nPnI89rdZDMGw0s63/SYZM+IMAL7EyCuHtSMZhShY50jIDctesJolwWRztZNRsHrNsBoOwd6S4BjH\nXOeCzjyaNzkDHUk0FRUzK9r17XYuU4a1RbmMPJybLWKI8R75MV0irBKLYXWT+xkyrnA32gineeiF\ns7MFDOkddbNrc7nRZDQ/DIY1nOmSvhlmUME8B06zuYifzTFgbOxYa4wXyNxuqyXBqqpibKHskIoT\niKLAyWHV/vUa+zi4PYdqQ8GJi3n6emdninrBmsRCqe5balqXtRneIJs+lsRvbKGMwc4k9ugSwzPT\n1uLOlyTYRfoXBNMrVV+GSwBw294+5FIxfOmVCVd55c7eNBZKddcCs9Zks6AJneFaLNVpA7IrYMFa\n9ogeMjeFJdu6Sr52FKym7NBR00w0UccQ+M1hBYx1xS2L1c1cB2AUrIkoVnw0//kzrGKga3xisYLF\nUh37BwMUrD7zzc/OFBGVBCyU6njk2CUXRZ2xFhKkGZJgrzEv7dic43hnprXj2OrRlM6l4xZJMI9h\n1R5jF6wRyblePHd2DoIA3HvtIJbLDSyX69zzws0l2B7v952E9YJ1FZAEgXZXCE5ezENVgQ9ctRGA\ntknlsQduM012LJYaSMUk33M1QRG0MGExrJt1VmV8kc2wphmZWX7A67jRWBvfM6xWhtePDJG8rqxq\nLsFkNvT6rZ04NrHM7FKeowVrwbHZqDW14pHV/ds/2IFYxP8c64IeVbCBw7Bu6kri0nIFTdnbLIEU\n7U6GlTDvvg4JgJG9Z9/wxSQRgmA1XWJ9dF5xRaIooCsVt8hyyGY0ZTNESppcT4dnCxAEtmU9z9mX\nwE+kjfFc7Ov6AkMqO6BvIokpjNvG3JhhDaF99YmGrGBsocws6v1IkgkTsZUxwwrw5X6rnmF1kUjx\nQByCiclGv2ljWakrjliTRLRFBStjAycrqmNTDRifeZDXI0uLWyOOh7WaYZ0t1FBpyNjW3cb8vqck\n2OO0uGFbFwQBOHxeU71M5qso1prY1a8VrAB8s6zVuvb5+GVYteNzNkzGF8vY3NWGjR1JpGKSY461\nwLhHOp63hZJgP/OrgHYNfs/VG/H1UzPU5Zi17yBrhBvLyp9hFVGpy1gqMyTBPgvWqocxlrlhw2NY\nHSSCKTt0dL6EeETE1lwbl2H1IwkmCig3WTDLZRYwuQTbmhrZpE9JsAvDKisqVfZ44ZiuGrwqUMHq\nTxJ8dqaAm3d2Y09/Bv/4LU0W7Ka8YhesVobVa5/MUkENzxSwvTvNZewJcilrDjxlWBnnQkQUuE15\nR8E6PI/LN2RxtR6xNrpQhsyJdHSVBAcwjHu7Yb1gXQVExtwUubDft38DAE2GWOOwakQi5geLpRq6\nVikHdkOQyIxqQ8ZyueHo2KbjEeRSMa1grTm7x6l4xOHS6wdeHTffM6y2WBs6W+zDJThfrqNQa2Kj\nbhhy/bYc6rJCDbbMODdbRCwiYrncoMwZfc0mP/c1EZVw9WAHXuJIje0g83Ys101AY1gbsorZQs2T\noSDnpn1xJV8GYVh5MjBBECwzpWpISTCgzbGau5w8K3fz652bLWJTZ5JtuuQxwzoyV0QiKnKbA2aw\nZljrTQUTi2WHpJiw48QUxi02wMz2rxXGFkpoKiqzYPUjCSZSJnvBStgTexQRwWpnWCVRQJNnm8gB\ncQgmbDL5bCfzVU1WxZjBJsfpd57UDPNm2A6eMRpLBucFKncMwbCulSSYbPi5DCtPEuzDdAkAOtpi\n2Nvfjhd1D4Cz04a8jxSsF30aL5HxgqAMq3mcRlVVTOgFqygK2NmXYRSsDS0X3eVz4r0vQRGEYQWA\nH7xuEA1ZxX+8dgkAu5E0pDd6yAgMC/RewDCcnClUoajG2kD2N36zWL1k2+Zjtp8/5Fqzx2jFTCqI\n0YUStuZS2NGTpg1LAr85rIBZuRGOYU3HI45zpD0R9SUJdnMJBvw3po6NLyMRFS1RZV6gbLWLcqkp\nKxiZK2FXXwY/dtM2nJ3Rmh9uBAXLJbhYte7rPBlWhsnimZmCq+ESQS4dt7hZ0zWKcR1LosAd9TA3\nuArVBl4bX8ItQ920qTc6X4LKm+f1cAkO0mx7O2G9YF0FJNF5Mzk+sYytuTb0tSewIZvA6IJJEsyx\ndveDhVJ91RmsbggSmTFNM1idm/fBLk2GSgpWy4B8IoK6rPhmlQn4M6zav35dglOxCKoNBU19x88z\nlDCDPPeYPgRPNj/XbtG6YPZ4m4ViDYulOt61W5tbssuCvWZmb9iew5uTK74s6yeXtc+BN8NKjpXH\n3phBbi7299mew/qFw2P4yutTrs/FkwQD1vw3Tert/H0/jQj7HAlhWB2mS7EIyiZJ8E6OpDce9ZAE\nz2ubFz85dKzu7fhiGYoKbLMxtKRIIqYwbueyUbCuXcVKZdM9zhu3H9OlC/NldLZFafQCQacHe8Ib\nm/ALnp+AG0gBMWRjWKeWK3qsDdvlGnAy+X4QMxWsGY+yAgAAIABJREFUqqriT548Q6PPZI7pSjiG\nVWePGHPyXjAkwcGVMG4grpe8DGNeDmuj6T3bTXBwew5HxpZQa8r0s93Vl6aqGL/GSxWPuBQW7LFK\ny+UGCrUm9XXY3Zd2FKzFWtOzEcF7X4KgVGuiUG0y79c8DPVlcM3mDiyU6ohKbFnjhmwCqZiE4Zng\nDGsiKtJ9BClYM/EIopKARZ9ZrF5Ozm4FK082HzcVWaMLZWztbsO27hRGF0qWhoTfHFbAuq7woLiY\nrtnlwIDOsPrYI/DffyNX2g+OX1zG5RuynuyjGaRYc9vvjS2WUZcV7OxN47uv2kDPBdZ7QRlWCwlC\n8oBNsTacJAAz4rbouWKtiYtLFex2MVwi6E7HsFiq070ynbPnMKHsv8W6XhweWURTUXHLUA82dbZB\nELSZfzeXYJ7fTLnuHGf5TsF6wboKsOZWjk/kqc5/a3fKIgmOS06JZM3kmPrCuXnMFthduMVSfdUZ\nrG4IEplBLfIZHVsSbcOMtSFh4wFZVr45j17Y+JxhtWd2GeZA3jOsNKJALwI7UzHs7ss45LtkfvWe\nKzWG3W68pHX/+K93cFsXFBV41UfOK2VYeTOsXYb8zi3WBjBu7o4cVn2F0AyqZPz2Y2/iU198DQ8e\nuch9LiIJtksqAS23lxT/XqZLbsVhLmWdIyGfacpRZIio1mXIioqR+RKTOQTITIubJLjIlBKzn8vJ\nsF6gG3brc3S0RRGPiFR653YuG9eo9vX4QpnmK7YKpGDd0essLCQfawQr0gYw5H48p2A3cxc/4Emk\nZEXlXkvDtpnmRFRCZ1sUY3pzgedyDYR0Cdb/tnpTwQvnF/CXT5/DPzw3Qo+zZQwrKVhDMKyGS7DR\n1DtxMVg2NAtukTaAziTaPr98uYH/89I4dvamfTUyDm7vQq2p4PhEHmdmCujNxNHRFkNPOo6YJPqW\nBJOGWhCGta89bplzJPcLci3s6stgvlinpl2AJgn2+lxbMcNqRNoEa3j/4HWDAPjXpCAI2OlhvFTh\nSoIlNHSKiMSUCYKALpf4q0pdxslLefq1l5OzJdbGdmlFOE0d8rdWmzLGF8rYmkthW08K1YZC30cg\nWA5rIiqhKxXDlMtazbv+JYFdsPo1XeIpV8jebXTBO5+4ISs4eSkfSA5M4GUsOkwbSxkkohI+csNm\nAOxGAHmvzckT8YiEmCRaR70asudoiZ0sMh+HF3KpGBQV1ByT3HdYn9+Hrt+M2/f2Oh6PiFZFxnPD\nc2iLSbhmSwcSUQkbskmMzpdCuQTb8+i/k7BesK4CkihaTprpfBXTK1XqpLZV78zx5rPiUWNu7vGT\n0/jwP7yE63/vKXz3X30Lf/b1s5YIGLOb3logHMPKLlgvLVewXK4jJomWm11al3IEnWPlmS7RvE6f\nDCu1QNdlwX7yukRbwUq69QBw/bYuHBlbssyBkE3wtVs6MZBN4PSUnWGVXZmPqzd3IiaJeGnEu2Cd\nzlcRi4jcRsZG0+bQ68ZKOs32bp5kYljfmFxBvamgvz2BX33wOB45don5XDxnQgA4sKUTR8eXICuq\n9rkyFmM/+bq5tHWOhBeWTRjdi0tl1JuKS8HKlwTXmwomliq+5le153IaOpDNrN0lVRC0TTzZvLn9\nzeS9aioaQ/fD//QSfuXfj/s6JhbenFzBxKJ1w3JutoiNHUnKtJnhp2BlRdoAhtyPJwleqxnWL740\nhu//3It4bdxpkDY8U0B/e8KyIRzIJjEyp31WrgzrKmZYa00Zf/PMOQDAC+cXaOYj61qgDKtL9Ikd\n5FoPlcNqy0r+/POjeP9fP+84T+x4YzLv+jNukTaA0zVTVVX8j4dfx3yxhj+9d78vw6kbtuW0OdaR\nBZydKVD5oigK2NCRoHPiXgjDsN60sxsvXVik5/GY/l4QI0KyETazrCvVhmukDaAbO66yYJ3R79d9\nASTBgNZ0bYtJrvfHHR4Fa7WhMBla87iIeV/TlYpzTZc+983zeP9fP0+Lfm1j7j3DKokCoxHLZljJ\nNTO2UEJdVrC1O0XXM/McK1lq/Ppn9LcnuKZLqqpy9zj92YRDlQNokuBqw1utxmNYr9EVYkThYcZL\nIwuW3Nkz0wXUmkogwyWCeNR97I2w8+S+/JGDW5COR9DNiF9i5bACGstq3itXm4rn/D5pUJPGAzkO\nXwWrfmxELUQjjhhr26/dvQe37e1zPC6JVv+b54bncXB7ju6Xt3a34cJC2dUl2NV0aV0SvA47JNG6\neSNxNuTC3pZL6XOM2kLFjLXRF5T7XhzDxo4kfvWu3YiIAv78qWH8+VPDALQFbeEtZlifOTNLc+Ls\ncAsh39zVBlnRHBrtC0tal28UA2ax8sx5jLxOf89jt0D3k9dFCojxxTKSOgNDcOOOHMp1KwNxfraI\nVEzCQDaBPf0ZJ8PaVFxny5IxCfsHszjsw3jp5GQeW7rauJu5RFRCX7u2uPplWO0/Zs5hPTKq3dy+\n9JOHcMO2LvzSl47jqwx58LjetWU1WK7d2olSXcbp6RXPuCI3gqg7HUeh1qQ35BLXdEmLtXFzCAbc\nO8Hji5o0x2/BGouIDgOnC/Ml5FIxh1QWsM4gu8mgyWeoqCrOzBQwtlDGyxcWA0vsAe06/+g/vYzf\n/I/XLY+fmysyY38Ac/OCfaMkkTb2+VXAkPvxJMF+mkduYKldVFXFv7w4BgB43pbRCVgdggkGsgm6\nMWXF2pBjDCKNIyDX2CsXFvH8uQVcNdiBfKWBk5fykFU+wwKElASHYKvpbJt+PX3r3BxUFfjm2Tnu\n78iKio/908v45S/xmydukTaAts6U6zLdQD5ybBKPnZjCL9w+hCt9Rmlk26K4bKAdz5+bx/BM0bL5\n3NiZpHPiXgjDsN60sxvluoyjemOEFO+DXVrTkBTPZ033g6CS4GpDxlOnZnwfEwGZneSNjvCQjkfw\nwes2W5Q6dgz1ZjC94syYJag2ZGbj0nxumqP6cqkYd414/tw8ZEWlWeVeM6xkLWG6tNJrhF2wEkfn\nLbk2bNdVMSOWgtW/6RIAbOhIUBWNHW7RTX9671X403v3Ox4n95GZvPu8b42zx+lKxbC9J4UjY9Z9\nxlKpjg//w0v49CMn6WNHJ4IbLhF4eUOc1X0lyN6stz2BF3/z3fiBA5scP0u2Ofa1MJ2wpj/UGrJj\nZtoOsi968k3tejozU0AiKrqe6wTkfCWNEzeGlQdRNK7ricUyLsyXcMtQN/3+1lwKY26SYJdG1rpL\n8DqYsDsDHp9YRkQUsG+DFmlDOnNnZwqIMOytSfbj8EwBL44s4IcObsan3rUT//HTN+Hmnd34un5z\nKtVl1JvKmjKs5vDzExeX8SOffwWf++Z55s9O56tIxyPMTRRxCn5zasW5sMR1htVHwWrumKm8WJuA\nDCsd0LcxrG6SYFIMl+syNnUmLcXhwe1aR//5c4ZJ0vBsATv7MhAEAXsG2nF+rmjpMNabiuds2Q3b\ncjh5Ke/6Ps2sVPHC+QW854oB1+ca1BlhT5dgWrDaOtH6l4qq4tWxRWzuasNgVxv+8WPX4YqNWfzm\nf77ucEp+5NgktubamAHc1+gOeK+NLXlLgt0YVlsEAjVdijuLjGpDdp3NBIBsWwyFapO58TpPHIK7\n/UuC7fOwI3Ns5hGwNn7c/mbyvaas4qlTswC0Bsix8eCSzaPjS5gv1vDyhUXKKCmKivOzJe6cLzmH\neOZGRIWwleEEKwgCOttils69GWvBsB4eWcS52SIkUaBmPATlehNnZ4rYO9BueXygI4GlsnYOONh6\n/eswDsGAsUn/m2fOI5uM4s8/eBUA4Fvn5tHkMKwkKiGMJDgUw2oyY6k1ZcrAPHOGX7Aev7iM+WId\nL48uMllMr0gbQNtAfvn1Kdz9Z8/h7589j//nkZM4sKUTP/XOHYGO/+D2HF66sIhaU7HkKW7qaFvT\nGdZDO3IQBa2oArSmXXc6TpUKvZk4sskozprYSH+SYGNjet+Lo/jxf3mVyYq5wW2ExwufvmcvHvrk\njdzvD3k4BdeaMnM0xFxAmaP6OlMxJsNarjcpIfCi7gTtJX0UBAExSWSb1ni4BBMmfFt3Cn3tcSSj\nEi7MOQtWv1FT/dmERVJshpuxWCwiMhtP5Fq6439/E7/8peNMBQmgSZslkZ1Ve2BzJ46MLVkk58+f\n15oCX3l9iipNjk8sI5eKUU+MIPDKNx+eKThYzUwi6h5rY2dYY9aC1Q/D+gMHBrFvQzt+46ETmFmp\n4uxMAUO9GV8GnoT9JQovN4aVB0kwfo/s89+5q4d+f1u3RnYtluqcSEcXSfC6S/A6WLA7Ax6/uIw9\nAxlaAG01FayszQOZdfvC4THEJBE/eO0g/d679/RiZK6EsYUSnfta04KVRFbIKr740jgA4Msnppjz\nM24W+UQCNVeoOTZ2dEDeo2A9N1vENb/zNSo51QxJnD9HLuSIT4qVHA+Zd/DjTGq+2dkX7M5UDJcN\ntOOF8wZ7MzxjGPvs6c+gIasYMc02aaZL7ovJDdu7ICsqXhrhuwU/emxSj0/a4Ppc5Jg9c1jpDKv1\ncXPc0ZGxZWo2lYpH8Ct37sZyuYEn3pimPz+Vr+DwhQV84OqNzJvOps4k+trjeHVsiZ+v68t0yXrT\nmFyuICaJDvaa5M2dmy2iOx1nMpwAcMtQN2RFxXNnnUxckEgbgM+w8gpWs/OwK8MqGZ/F10/NYHtP\nCoIARzHmB1/TO8t1WaGu1JN5zWyIx0KTc2SZI+vlRdoQdLmwJ61wCbbfwP/18CiyySh+8LpBasZD\n8K3hedSbCm41bRIAKwvFcgkGwjkEA8b7N5Wv4mOHtmBLLoW9A+341vA8FN4Mm/52hGNYQ7gE679T\nqWuzoNWGgk2dSbxwfp4r7fvG6Vm6Pj96fNLxfa9IGwD41x+/AX/wvVcgHhXxv75yGoqi4n/fe5Wr\ngy4Lh7bn6P+bHT83diYxV6gxY8jsCMOwtiei2D/YgedIwbpYxuYu41wSBAG7+zIWhrVQbSATd5cE\nazOs2v9//U2tSfXlE+6md3ZM56toT0RCbWJFRqPdDKJQOMcxXloqNZhsD9kjtScilr1RLhVjzrm/\nOrqEhqwim4zaGFb38yMWEZnXVYTT1DEY1gLiERF9mQQEQcC27pRlRtnIYXV9eYqBbBLL5QbTfdvI\n8fRf8LxzVw++/HM34/sPbMLjJ6fwvX/zAj71xdccDUE3x9xrt3ZiqdywMMfPnZ1HJh5BTBLxd9/U\n5uuPTSzjqsEO38W5GcmoRBuAdhCHYLvKhQfy9mRsa2EmYY1L9MOwxiIi/vyDV6PSkPFLXzqG09PO\nwpkHI6JNZ1jV4AyreZzwsRNT2NOfsWS8k4bE9ErVJYeV/dzrpkvrYMIcVq8oKk5M5On8KqAVb6IA\nzBfrzEUjHpFQbsh46LVLuOfKAboJB7SCFQCePj1LLbTXsmAlm+F8pYFHj08il4phdKGMN20zmIC7\nRX5fe4IWDfaNHekmFzwK1r955hxqTQWff34UAN9BjzzmVxKcsZsuUZdgF4bVtEhvZHQYb9yRw2tj\ny6jUZeQrDcwWanQB3tOvsTdnTJsUt1gbguu3dSGTiODLLm68/3n0EvYPdlgWORaIxCU8w6p9PTpf\nxnyxRmdfAO1v35Jrow0OwFxIb2S+jiAIOLBF6+zyc1itr80CuRbmSzUsler4z6PaNWS/qSajWt7c\nqekV7GQYCRFcs7kTHW1RpuRuZK6Inkzcc96MwM6wFmtNzBZqzFkkwM6w8p+XNE9mVmo4NrGM9+/f\niH0b2injEARfe3MG127pRCwi4jldLuslm26LRXBoew4PvXaJOm2bwYu0IejisCeAxrCKAgIXKATm\ntRjQFAhPvDGDe6/dhFt39TiY6KdPzyITj+C6bV2W5zHLs+1zvKSADeMQDBjXWDIq4Udu2gYAuHmn\n5mxbrDWZ5zthWAMVrKuYYY3oTZ9KQ8aL5xcgCMAv3L4L5brMNa966tQsrt3ShQNbOvHw0UuOJqdX\npA2gNcA+eP1mPPozN+Oxn70ZD37yRqrWCYLr9DxWwGD/AKNxx5NlmhGGYQWAm3d24/jEMlaqDYwv\nOhnlob40zswY2dxBGNblch2vji1CEICvnpziOoSyML1SDSwH9otNnW2IR0Scm3MWrNWGjOeG53Bw\nW87xPXIt5Gyzil2pGAq1pkNG+uLIAiKigB+5cSvOz5Uwu1L1lAQD2jXAM60h37f8vL7+XFquWFzh\nt/WkbDOswVg1I9rGef4ZOZ7BCsJ9G7L4ve+5Ai/9j9vxy3fswpNvTOPOP3sW3zg9S3+m6pJJeoDM\nseqjPqqq4rnhOdyyqxv3XjuI/zh6EcMzBZyfK4aSAwOa4uHwyAJzvGx0QXMIHur1VyhS0yXbfTgV\nj9CRIICo2Lyv3Z29aXzmvfvw/LkFzBVqTEUYCx1tMYiCMcNKFEd+55kBY5xwcrmCI2NLNAaTwNzc\nY56/AttLQlFUVBvKuunSOpwQRQGqqp0kZ2YKKNSaloI1FhFpkcPaPMQiWpelWGvihw9tsXxvSy6F\nHT0pPH16lhqVrKnpkn6xPfTaRZTrMv74B66EJArMbu50vso1cJBEgW4O7J0wY4aUX7COL5TxyLFJ\nDGQTODaxjFNTK96SYJ83DfL6hiSYnRdqeQ3Tc5sNlwhu3NmNuqzgyNgS3fCTjdL2nhSikoBTU1rB\nqqoqFkvs5oUZ8YiEu/b142tvzDAZgTPTBbw5tYLv8WBXAf+S4BinYCVfkviea7caBasoCvjgdZvx\n0oVF+rc/fGwS+wc7qLqAhQNbunBxqYLpfJWzSSeNCP4xd6dJl7OOz78winJdxidvdcoHycJ9ZrrA\nLcTIa75rdy++cWbWcSMYmS858lPdYGdYSaQH7zk26C7PLHMQ+zECWrGpqsBte3txaHsORyeWuczR\nudki3v/Xz1vcNc/PFTEyX8L79m/ADdu68NzwHP1ZgF+wAsCP3rQVl5YrlKE1gxdpQ9CV4kuCtUZO\n+K6wXSL1xZfGoagqPnJwCzXjIUy0oqh46vQs3rG7xyGVMzcPkjEbWx9dHcNKNo4fvH6QruU3D/XQ\n9SPCcNcghxdEEixyNuN+kYxJqNSbeHFkHpcNtOPuy/sRlQTmHOt0voo3p1bw7r29+MBVG3B2pkjX\nOwKvSBs7Lt+YdUi1/SKbjGLfhnbLXByAQNE2hGENylLcvLMbigo8e3YOU/mKYx5ud38GhWoT/3Vi\nCrKiolyXPc8lQdCKo2fOzEFRgY8d2oqpfBVHJ/zLgmdWqujjKKJWC0kUsL0nTV1WzXjmzCxKdRnv\n3e8cWyFjMfY9Dc1rtkXbHB5ZwP7BDtymO66+OLKAsg831JjEZlhJI8i+5pgLnS2mhsn27hQmlipU\nZUBloAEkwQA7i5UwrEEkpWak4xH87G1DePhTN6GrLYYf/edX8P89q7Gjbgzr9u40OtqieFWfYz0/\nV8RkvopbhnrwiXdsh6ICv/ilY1BVhDJcAoD3XjmAelOhslczhk3RU35A7o1ObxQrw1r1wbASfOj6\nQdy1r08/Dn+FsyRqbtbzuhJACcWwag1Wsr9+75XWa4RE2wCcvS9HEhx27Xq7YL1gXQWojFbVZLQx\nScSte6wSM8I28CTBALBvQzuuZiwI797Ti5dGFjGxqN1kc2uYw0outodeu4i9A+14125tM/yV162y\nYFlRMVesWZgIO8iNmrWwAO4uwX/7zfOQBAGf/9HrEJNEPPDyuD7r6PxZarrkd4bVLgkmhgQ+Ym0A\nq+suwfVbuxARBTx/fh7n9AB10jGMSiJ29KRpFuujxydxfq6E2y9zusbZ8d4rB1CoNfEsY5P48LFL\nkEQB793vXbBu0mVpnqZLEieHVX/g6PgyMvGIoxv6A9duQlQS8MDL4zg7U8CpqRVPmTLp7B4dX3Y3\nXXJ1CdauhfGFEv75+Qu487I+5g2HFBkNWfXs5N62txdL5QY1TiEYmSt6MtlmxCMaq0tYyBFOpA0B\nYT+8OuzkXHz9Uh4D2QT2bWjHoR051JsKd4bpj584jeMTy/idx96k1zEpNm+/rA+3DHXj7EwR0/kq\nzs8V0ZWKuTbGbtvbh8GuJFU/mDG2UHJtVLhJgutNJXSBBegMq34Db8gK7n95HO/c1YMtuRSybVEL\nE31yMo+5Qo0ZN2CWZ/NibcLOsA71pvHpe/bi528boo9dt1VzBS/XZU6OX/AZVp6hjF8koxKWKw28\nNr6MQ9tzSMcjuG5rF3OO9WmdzXn3nl7cc+UGRETB4R7uFWnTavzW+/bhdz9wueUx0jj2Y7xE5uG9\nshztuHpzJ5JRCf/2ygQU1RiPIXjflRuwf1MWP3f/UfzCvx0D4GSL7BAFAYoCPHV6Ft3pGH7xjl2I\nRUR8+cS06++ZMZWvYiDE/KpfDPWmqTu+Gf91Ygq5VMwi0yYg7619rbF7EwCaQuXExTwObc9h34Ys\nMvEIXji3gHpTWQXDanzf8vOmBpa5wbKtOwVZUTGhz2gHlQSTdYVVsNIZ1nD1KsW+DVk8+rM34a59\nffjDx7V1v+aSSSqKAp1jBYBn9XGYm3d2Y7CrDe/fvwEnL2l7l/0+jc/suGazlpbw2HEn8XF2xrtB\nagZvPCIdt5ku+fAJIRAEAX/0ffvx63fvwY07necpD7lUnMYvNV1Ms3gQ9XHC/zoxiSs3ZR1qDBJt\nA7DPC7urOgH18lgvWNdhB1kIl0p1PHjkIr77qg3ozVhvDGTRY7EHZEPx0UNbmMzKu/f0oS4rdC6o\nK732sTaFahMfvn4QgiDgu64YcMiC54s1yIrq2rElnUnHDGuMMJzsgnUqX8FDRy7i3us2YU+/1tn/\nz6OXUGnIoWcdzaAFs/76VR/OpG4zrIDG2l412IEXzi9geKaIuIlVB4C9A+04M11AvtLA7zx2Cvs3\nZfHB6zZ7HutNO7vR2RbFYzaGW1FUPHL0Et4x1M20freDMKxe3VtuDqv+ZaUh4+otnY73ujsdx52X\n9eOh1y7i316Z0ArpK90L1n0b2pGIitzPlXYWXVanlB638C8vjmGl2sSn3rWT+XNmlszrxnjLUA8i\nooCnTJKqhWINS+UGdvicXwWM95KwrBfmShAEa8feDNL88ZK2m9/72/b2QhAEXLe1C6IAHGbIgo9P\nLOOJN2awp1/LC/7GGe3v+tqbM7h8Yzs2diRxy5DWYHtueA7nZotcwyXzMXzs0Fa8PLpoYW0BjUnj\nyYEBbXOarzQsMVAE2mx3+NuRFhOg3cDvf3kcs4UafvigoVo5tD2Ho+MaE/31U9rM5Tt3OQvWfh+S\n4LAFqygK+Pgt29FhMplpi0VwzZYO+jfYQWNtPGYd7a8DrI5hfeG8VhAc2qFt4t65qwdnZgoOSePT\np2exqTOJod40ulIxvGNXDx49PmmRrHpF2rQa127twq27rZ9tXyaOiChQU6hqQ8afPHmGsr9mVBsy\nBCF4wR+LiLhhexeV2NsL1s5UDA9+8kZ86l078NgJ7Z7uJ4e1Lit45sws3rW7F9lkFO8Y6vEtC27I\nCuaLtTVjWAGtYL20XEHZJMss15t4+tQs7r68nynzp5JgDsNqLlhfGV2ErKg4uD0HSRRw/bYuupbZ\nVRCs13FjWHmxNoBVwk6jbXQ/A8MlOBjDOs2QBLu5BAdFPCLhj75vP3ozcfzCvx3DUtld0XXNlk6c\nnythqVTHc8Nz2N6dooTDT+mKpe3dKa5qxguiKOCeKwbw7PAc8rZZ1rOzBQx2sSPUmM/FcUy3F6zV\nRjC1TrYtik/euiPQ75hj9ZQQn58kCliuNHDiYt7BrhKQcy5IDit5H4KOM7xdsF6wrgLkBP3C4TFU\nGjJ+TJ9LMoMyrIxF+7qtXbh9by++ez973u/arZ3IJCI4MraEWEREag27JmRRT0YlvP9q7Xju2tfn\nkAWTDqGb4+BmDsMqigJSMYlbsP79syOQVRU/+Q5tofzg9YNYqTaxXG4wC/qgOaySKCAZNTK7CMPq\nxyUYYM+wAtos5+sXl3FkfAk7etKWhWt3fwZT+So+88hJLJZq+L3vucLXwhaVRNx9+QC+fmrGYtTw\n8ugiJvNVfOBq9jljx4aOJN575QBusM3q2cGLtTHfkA9s7gQLH75hM5bKDXz++Qu4eWc3ejLuhXRU\nEmlUhVtckdvnKggCutNx5CsN3DLUzZUsJaPGOehVsGaTUVy3tcsyx/pX39DyMg8yWAIeaN6mfn5d\nmC9iQzbJPc+yySiSUcnTPMxasGosfSYRxRUbs0zjpc8+eQZdqRge+MRBbOtO4Q++ehqzK1W8Nr6E\nO/b2A9CMwbrTcTw3PI9zs/xIGzN+4NpBtMUk/PMLo/Qxt0gbArIZXWaYcKyWYZVEAflyAz93/1F8\n5pE3cGBLp6VoObQjh7qs4LWxJTx9egbXbO5kMsmJqEQf55kuhclgdQNpGjDNNUjBGsQlmMywhpwH\nTkYlzBVqEAXQGV/yXn7TxLJWGzKePzePd+/ppevzB67eiKl8FS+ZYrm8Im3eCkQkEf3ZBC7pkuC/\nfHoYf/n0Ofz8A0cdG7+KnmMYxmTm5p1GNAWrQRWVRPzqXXtw/08cxC1D3Z7rsigImCvUUKg26TV/\nz5X9vmXBs4UaVDWcQ7BfDPWloaqGOR2gNTIqDZnbvCTFgYNhJaMeJSOu5fD5BUQlgSpzDu3IYbag\nfd8Pw8qOBdGPw8bEmYs7s9u5PYs1aA4rWVcmWQwrLXhasx3PtkXxpz94FUYXSnhueN5VQUZMFA+P\nLODwyKIlWmVXXwY/+c7t+CFT4y8M3rt/AxqyiifetKoChmcK2OVzfhXQ3uu2mOT4PFNxLbqOvI8a\nq7y2pU0uHTdmWEMWrOR47+FcI2T9YLpci06GtSkr+K1H30BEFHD5xqzvY3k7wdenKgjC3YIgnBEE\n4ZwgCL/B+L4gCMJf6N8/IQjCNX5/9+0MUuTdd3gMN+7I4bINzrkbyrAyLqD9gx34h49dx3Xvi0oi\n3qG7WOZSsVA3UL8gG6P37R9Auy5TyqXjDllHnQtQAAAUzElEQVTwNM1085YE22dYAX1AnlGwTuer\nuP/lcXzP1Rvp7x/ansNW/aLlSUcFIdjshzmzy0/2I1ks4hERPRxG80Z9duno+LLD8W6P7lT5yLFJ\nfPTQ1kALyfuuHEC5LtNuMgA8eOQiUjEJd17W7+s5JFHAX334GhzY4r4xIhsI3gwrYJ1fNePQds18\nSVGBD1ztLVMGjBvlaphzsrn56VvZ7CpgFBmZeAS9HoU0oDGXZ2eKmFgs48jYEv75hVF89NCWQJ8b\neS+J9PzCfMnVYVgQBAx0JDzlZeT9aItJFpndwR05HJtYtjQ2Xjg/j+eG5/HTt+5AR1sMv3rXbpyd\nKeLnHjgKVQXu0GXpgiDgHUPdeOrUDJbKDV/yrGwyiu+7ZhMePTZJs+jcIm0IWOwJQbnubUbmBkkU\ncWamgK+8PoVfumMXHvjEQcv5c63ORD987BJOXlphhrkTkM09L9YmiDzXD27Sixx3hjWYS3AsIoa+\nX5C/84qNWXov2NWXRn97wjLHenhkAZWGTA0CAeCOvX1IxST8x2sXAfiLtHmrsKkziYtLFbwxmcff\nfXMEe/ozOH4xj88/f8Hyc+VVxELcrG/43e4XgNYA+9cfv8HzfRFMzQfy3Lfv7bPIghuygsdOTNLs\nVzP83K9XC7JmmDPHHzs+hZ5MHNdzCvIEd4ZVe8/Ma8SLIwu4erCTfibm5qHnDCu3YOUwrKavzc23\njjZtVIKMdxDPgCCXWH97gn4eZhixNv6fywsHt+doJJTburp/sAMRUcDfPTuCSkOmzTOC33zPXvz4\nzU4iJgj2b8pisCtpIT4asoIL8yUM+ZwbBbT3mrUOUjPNehNNWUFTUVflh+AHuVQMc4UaFEUNx7Dq\nJ841mzuYo2aAUTswz1+GS/D/+sppfPPsHH77/ZeH9gD4dofnJSIIggTgrwG8B8BlAD4kCMJlth97\nD4Ah/b9PAPjbAL/7tgXZWC+XG/j4LeyLmpx0Ybvd79Y722tpuAQAg51JpOMRfPTQVsvj91xplQUT\nSQvPdAkwMayMxSWdiDhcgkfmirj3714EAPy0yThHEAR88HpNPsszXQrqrJeJR2ghUW3ozqQuCw1Z\nLDZ2JLkbwKs3d9Ab8JBtw08Wjp5MHL90565Ax3rD9hy603E8dmISqqris0+cwYNHLuJ7r9nU8pwt\nnumSMSfMN14QRQEfv3kblQf7wQHXgtV4Xjfs25DFLUPdOLidX4yTDvyO3rSvDTwpZB4/OY1ff+gE\nBtoT+LW793j+nhm7+zMQBOD7PvcCHjl2CSMukTYEA9mE5w2PnOs37+y2sLWHtufQkFU6i0TOlYFs\nAh/Ru+PvubwfVw124PDIIjZ2JLF3wNgo3LKrGyW92PU7T/SxG7eiLiv47BNnUGvKVFrph2E1b0an\n81X8wgNH8fgb04HmhO24alMWB7Z04tGfuRk/d9uQw0ypXWeiHzyiFVK3MeZXCYgJloNhXaVLMA9a\nYRhhfv67+jIY6k0HKjhEQVhV8U/+zoM7jMJAEATcursH3xqep5Lup0/PIhmVbAWEhO++aiP+/chF\n/NXTw5hZ8Y60eauwsaMN44tl/PpDJ9DRpikPbtvTi88+eYY6XANAtc53VvXC7j5NsTDY1RbaRMcM\n8hQ3bO+i99NMwpAFP/DyON712WfwM188iu/68+ccJokzevan2/16tdiSS2Egm8DvfvlNvDK6iGKt\niW+cmcU9Vwxw1zRSUORsY07ZZBSiYKwRK9UGTl7KW87FywbakU1qjRRPhlXiFKwcJ21RFBCVtOvH\nzkpv605heKaAv33mPH7twRPIxCOB5rI3dGgM/5GxJfzp187iE/e9is8+cYa6+gZxmfWDX7x9F67d\n0ulqGJiISti3MYtjE8uIiILlfW4VBEHAPVdswPPn5qnp3thCSfeV8L/mb+9OMUmhtMnMk2SmrzXD\nesXGLIq1Jn72/qP03hmUYQXgcAc2gzSz/EiC7395HP/0/AX86E1b8eEbvEfO3q7wc+e9HsA5VVVH\nAEAQhAcAvB/Am6afeT+A+1SNhjssCEKHIAgDALb6+N23LchJt70nhVsZ81CA1tWN6B3vMLh1dw8E\nYe0L1p29GZz4f+90XBx37evHpx8+if/56Jv4sZu3YWxRM9Cwz55YnyuNe6/dhJtt3TpAW1zMDOur\no4v4+H2vQhIE3P8TBx2b1u8/sAl/8uQZjmmVFHhjkYpH8OroEj7+L6/gjckVxCPu0i9BZ3F5cmBy\nHNdt1WaX7Bv+3kwcH7p+M95zeT9lK/xCEgV81xX9+NKrE/iZ+4/iyyem8KHrB/GZ97W+50MaKoLt\nbSY30b0D7a4sz0cObsFHDrJnsVm4RpcXs2NtvCXBAPD733sFFEV1fU2yofFbiG3rTmF7Twp//OQZ\n1JsKPv+j1wWeWTywpRMP//RN+PTDJ/HzDxyjz/t/27v34Cjre4/j7282N5IAuYeEXMiNQAgESJCb\nCha5g1RLkVYFGXuoHXp1pueAxx61c6Z2PNae80cL1qOj9XipY9XSU0cLnaO0IyIXQQQK5X4HAbko\nFwV+54/dxJA8u9lcdwmf1z/JPvts5reZ7/72+T7P9/n+QilIS7qipM6LL8aYM7KIWxp9yQ1r0Pgr\nzme8snY/6/ae5JHbBtZ/PsyMRZP7cftv3mN8Zc4V/7PRDcoYw/0/lWWnMHdkEc+u3MPq3ScYkOe/\nAh1Owrpu7yccOX2eTQdP8fyqvVy87PjeV8o8uzyH674JFdzXzD4jSjPYsP8UBendQh4o9QqcPGg8\n57S1S3AwvhjjR+P7esZZTVEay+4b06K/FxvTtoS1LmYaN8sZ0zeLl1bvY/jP/kJZVgrbjp5hdFlG\nkzn4oVsqOf/FJR778zaWb/EfjEfLFdajZy5w9MwFfvXNoaQmxfPvt1Yx/vEVLHp1I89/azhmxrkv\nLrW6aYmZ8cObywl/0ZnQ6ubfmxtVBEwd1IvlW46w8NWNVOf35McTK3jm3d0seGEdK3cW8sDUShLj\nfPW38HTkFdY4Xwy/mz+Su595nzv+exVTB+Zy4eLloPfmwZefoZxGPT98MUZqUjzr951k25Ez7D1+\nlsvuyliMiTGGF6fz581Hmr2HNT42Jkgzs7rKKa/eIj7yUhObHAsVZybzytr9rNnzCeMrc3hwemWL\njst69Uxk+ZajfG3xu8SY/8T+X/7+ZVf6cJZiaYn42Bhe/vbIZq8C1xalsWHfSWqK0lp9f35zpg3K\nZck7O3hz02HG9M3ilbX+xmzhduYF/xzvpe4WjV8u28brHxyke2LsFd9pHeG2ob05/tkFfvbG3+vX\nMW9JwpoQ58MMpgwM/hmpO8nnWRJsxucXL/PS+3tZtesEf9xwkDF9s/jXKf1b+E6uLuFEZ29gX4PH\n+4HhYezTO8zXXrXqJrR5o4uDnk2N9cVQlJHU6okgIyWB24bkU9Gr9VcfwuX1HtKT41k4qR9L3tnB\nvf+zFvBfbQx19jjOF8OjM6s9n0tJiOWDvSeZ8/T7OOdYtct/xeeZecM8D2oyUxJ47p7hTRpYAMwZ\nVXTFPRfhGFmawR/WH+DAyfOUZaeEdW+iz8xzSZuGRpVm8td/HGsyAZsZj9w2sEVjbGjaoDx+u3IP\nf/rwEP88qYLvjCntkNLw4FdY/T9rirzLgeu0dExpyfGUZiV7nlWuK58Pp9Nfc1cx6q5Eh5uIAYzr\nl82Tf93FrUN6c1NF8CtxoVQXpPL6gtG8sGoPz723p9kv0O+PK+frtfkh9zEzfjqjqsn25IRYBuX3\nZPHbO1j89g66xfm4vbaAmTVX/r3hJRk8Nbe2yZp62d0T6Z/bgz3HPyOvBQe2D8+oYmy/bH7y+kcs\n3XAw5JI2QH2J5H+8tRXwf8GP65fNA1MrW7XmZkuNLMngiXd2Mq5fTsh4nT2s0LOjc1KD8vL2Ns+j\n/0FrzRqWz+DC1nX1BP/7jI3xN/Rq6ObAQfrWw/61GbvF+fh6bUGT1yfE+nh8VjXFmck8vmwbEP6S\nNh2prmnehMocpgz0V4Lk9uzGwsn9eOD1j5j4nys4efYLPv70QqvXnQTqqxraQ9301rDsGmDSgFw2\njj7N9eUZ3FSRXd8k8bG3tvLEip08v2ovGckJXHaO+NgYUlvZNCdchRlJ/P7eUcx/bg2vfXCA3J6J\n9SclvdQUprH4jqGe378jStJ5Y+NhJvxyBXE+/4mjIY3ieWRphj9hjQv9WeyeGMvJs00TwWDrsNZt\n8zrxdnP/bLYePsMPxpWH1em/sVm1BRjG8JJ0ri/LJDUpnnOfX2LzoVPs/Pgzz67lbRXOVf6aojSe\n+tuu+tvPOsKAvB4UZybz4NJN9UsDFWUkNbmFqjXqTn68vGY/0wbl8m/TK5s0P21vZsb8G0vJS+3G\nfb/bALSs2u/OEYWMKE4PWflQt7SNVyKcEGhaufDVjWSmxDO9Oo+HZwxo9TrmV4uoWV3WzObjLyem\nsPDquKQ9vDidrw7OY+bQ0Aea/zV7SJvaTP9ilnfy11n+6cYS5o3uw8qdx/nTh4dadPDf2PTqPM5+\nfonT5/yNVyZU5vDTGVUhz1QGSyqzuye2eGK6f0p/7m/hWai7R/UJec8bwNxRRZRkJbeprNFLbVEa\nc0b615KcGuKMdVuN6ZvFwZPnmjT26pEYx8yafGZ5HJi21b1jSjntscTRDWWZLLmzhooWnH0NpjA9\nia8NzWdyVXilygC3Dytk34lz/GRa265k+2KMu0b24a5GZfZe8lK7tWnZj2/dUML/fniQiQN6Mb4y\nJ2jnxWBx/J2xpYFuxi078XBTRTbLfjSGxW9vb/bKY0ZKAkvuHIpz/hMIRRnJbWq01FIjSjKYXp3H\nHc2UTFX17ul5z3JhRhIzBufVd86NVjVF6c3esx7K9Oo8yrJTmjSXivPFhJ1YmxnfH1dOaVYKK3ce\nC3qfVmcaXZbJpAG9eHjGgCvi/JvXFbLp4CkOnjzPkII0cnomclNFxx28t8RXAverNl7TtVu8r0ml\nTZwvhkVT+jO2Ipv3dh7n6JnzHDl9gfKc8G6HaKu05Hieu2c4j765larePUImSzExxuQgV5d+fUcN\n+06c5d0dx/jb9uOUZiU3uYo/dVAua3Z/4lki2tCPJ/bz7JkxpDCVaYNy63tMNHTniCIGenz+J1Xl\nMqmq9d/Bg/JT65sN1ukW72vz57WtbijP5JbqPG4Ns5Fja9RVHvxxwyFGlKRzfXkmFTnd2yUuhxSk\nMnVgLjNr81t9grm1pg3KI6dHIk+u2ElxC1YSCOfYNTHOx4KxZZ7fN3eP6kN5dgrVBamUZCZ3yuc7\nGpjzWMvnih3MRgIPOecmBh4vAnDOPdJgnyeAt51zLwYebwXG4i8JDvlaL7W1tW7NmjWte0ciIiIi\nIiIStcxsrXOuNpx9wzm9vRooN7NiM4sHZgNLG+2zFJgT6BY8AjjlnDsU5mtFREREREREmmi2JNg5\nd9HMvgu8BfiAp51zm8zs3sDzS4A3gCnAduAsMC/UazvknYiIiIiIiEiX0mxJcCSoJFhERERERKRr\nau+SYBEREREREZFOp4RVREREREREopISVhEREREREYlKSlhFREREREQkKilhFRERERERkaikhFVE\nRERERESikhJWERERERERiUpKWEVERERERCQqKWEVERERERGRqKSEVURERERERKKSElYRERERERGJ\nSkpYRUREREREJCopYRUREREREZGopIRVREREREREopISVhEREREREYlK5pyL9BiaMLOPgT2RHkcj\nmcCxSA9CrlmKP4kkxZ9EimJPIknxJ5HU1eOvyDmXFc6OUZmwRiMzW+Ocq430OOTapPiTSFL8SaQo\n9iSSFH8SSYq/L6kkWERERERERKKSElYRERERERGJSkpYw/ebSA9ArmmKP4kkxZ9EimJPIknxJ5Gk\n+AvQPawiIiIiIiISlXSFVURERERERKKSEtZmmNkkM9tqZtvNbGGkxyNdn5ntNrONZrbezNYEtqWb\n2TIz+0fgZ1qkxyldg5k9bWZHzeyjBtuCxpuZLQrMh1vNbGJkRi1dRZD4e8jMDgTmwPVmNqXBc4o/\naRdmVmBm/2dmm81sk5n9ILBd8590uBDxp/nPg0qCQzAzH7ANGA/sB1YD33DObY7owKRLM7PdQK1z\n7liDbY8CJ5xzPw+cOElzzv1LpMYoXYeZ3Qh8CvzWOVcV2OYZb2ZWCbwIXAfkAcuBvs65SxEavlzl\ngsTfQ8CnzrnHGu2r+JN2Y2a5QK5zbp2ZdQfWAl8F7kbzn3SwEPE3C81/TegKa2jXAdudczudc58D\nLwEzIjwmuTbNAJ4N/P4s/klNpM2ccyuAE402B4u3GcBLzrkLzrldwHb886RIqwSJv2AUf9JunHOH\nnHPrAr+fAbYAvdH8J50gRPwFc03HnxLW0HoD+xo83k/oYBJpDw5YbmZrzWx+YFuOc+5Q4PfDQE5k\nhibXiGDxpjlROsv3zOzDQMlwXUmm4k86hJn1AYYAq9D8J52sUfyB5r8mlLCKRJ/rnXODgcnAgkDJ\nXD3nr+NXLb90CsWbRMBioAQYDBwCfhHZ4UhXZmYpwO+BHzrnTjd8TvOfdDSP+NP850EJa2gHgIIG\nj/MD20Q6jHPuQODnUeA1/CUfRwL3O9Td93A0ciOUa0CweNOcKB3OOXfEOXfJOXcZeJIvy94Uf9Ku\nzCwOf7LwvHPu1cBmzX/SKbziT/OfNyWsoa0Gys2s2MzigdnA0giPSbowM0sO3HyPmSUDE4CP8Mfd\n3MBuc4E/RGaEco0IFm9LgdlmlmBmxUA58H4ExiddWF2yEHAr/jkQFH/SjszMgKeALc65xxs8pflP\nOlyw+NP85y020gOIZs65i2b2XeAtwAc87ZzbFOFhSdeWA7zmn8eIBV5wzr1pZquBl83sHmAP/i5y\nIm1mZi8CY4FMM9sPPAj8HI94c85tMrOXgc3ARWDBtdKhUDpGkPgba2aD8Zdi7ga+DYo/aXejgbuA\njWa2PrDtfjT/SecIFn/f0PzXlJa1ERERERERkaikkmARERERERGJSkpYRUREREREJCopYRURERER\nEZGopIRVREREREREopISVhEREREREYlKSlhFREREREQkKilhFRERERERkaikhFVERERERESi0v8D\nOKIcbIwxlu4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d232e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9 / 20\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2081, -1.5635, -0.5152,  0.8762, -0.0473, -0.4229, -0.2700,  0.1604,\n",
      "          1.1832, -0.7530, -0.2606, -0.2768, -1.5446, -2.7352,  0.7070, -1.7938,\n",
      "         -0.5443, -0.3804,  0.8926,  0.1083]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(673125930893312., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [0/32 (0%)]\tLoss: 673125930893312.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.9852,  0.0467, -0.8575,  0.9739,  1.4174,  1.6476,  0.2295,  0.1096,\n",
      "          0.7954, -1.2355,  2.5410,  1.3267,  0.5221, -0.8805, -1.2089,  1.7282,\n",
      "          1.7631, -0.6375, -0.1258, -0.8138]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1425600938051108864., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [1/32 (3%)]\tLoss: 1425600938051108864.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3837, -0.8343,  1.0476, -0.8376,  0.0162, -0.3184, -0.4273, -0.3416,\n",
      "         -0.1954,  0.1177, -0.4446, -0.1725,  0.7973,  0.7926,  0.1488, -0.8038,\n",
      "          0.3576, -0.1448, -1.9911, -1.9639]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(681490707193528320., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [2/32 (6%)]\tLoss: 681490707193528320.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.0563,  1.8845,  0.6986, -1.0932, -0.0329, -1.2096, -2.4271,  0.2877,\n",
      "         -0.7044,  0.4817,  0.9687, -0.7719,  0.2667,  0.1455, -0.5901, -0.4640,\n",
      "         -0.0887, -1.4079,  0.9294, -1.5532]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(20418227795939819520., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [3/32 (9%)]\tLoss: 20418227795939819520.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.5184,  0.3461, -1.1302,  1.0271,  0.3932, -0.5840, -2.1046, -0.8165,\n",
      "         -1.7468,  0.8187, -0.2124, -0.1870, -0.0870,  0.5399, -1.9740,  1.6496,\n",
      "          0.2167, -0.1404,  0.9403,  0.0942]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(11413887271431045120., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [4/32 (12%)]\tLoss: 11413887271431045120.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.2866,  2.6772,  1.3400, -1.2877,  0.7381,  1.3234,  0.0234,  0.5846,\n",
      "         -1.1511,  0.4183,  0.2035, -0.5469,  0.3731,  2.1435, -0.0564, -1.7681,\n",
      "         -0.8160, -1.3077,  0.7905,  0.7895]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(3682479121067147264., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [5/32 (16%)]\tLoss: 3682479121067147264.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.1284, -0.6322,  0.6176,  0.0259,  0.8407, -0.3708, -0.8976,  0.3299,\n",
      "          0.4874, -0.3220,  0.0886, -1.0266, -0.3763, -1.1281,  1.7223, -0.5579,\n",
      "         -0.3277,  0.9408, -0.5342,  1.6009]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(171314803644563456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [6/32 (19%)]\tLoss: 171314803644563456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.3966, -2.1563,  0.1311, -1.7428, -0.2799,  0.2956, -0.3415, -0.0884,\n",
      "         -0.1256,  1.8244,  1.8976,  1.4043, -0.1115, -0.4298,  0.2499, -1.2084,\n",
      "         -0.5547,  0.4237, -0.6393, -1.6204]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(1026129259665555456., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [7/32 (22%)]\tLoss: 1026129259665555456.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0061, -0.2337,  0.1707,  1.7531, -0.7186, -1.2888, -0.2848, -0.0640,\n",
      "          0.9000,  0.7166, -1.4883,  0.2486,  0.2739,  1.2364, -0.1418, -0.7985,\n",
      "          0.3763, -1.4622, -0.6789,  2.3523]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(119241552247190978560., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [8/32 (25%)]\tLoss: 119241552247190978560.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-1.1530, -0.6261,  0.7899, -2.3107, -0.6780,  1.0542, -0.4058, -1.4367,\n",
      "         -0.4961,  1.1490,  1.1126,  0.9684, -1.0246, -1.8478, -0.5278, -0.4126,\n",
      "         -0.0649, -0.2863,  0.8036,  0.1019]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(2520466579443941376., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [9/32 (28%)]\tLoss: 2520466579443941376.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.3979, -1.1635, -0.2823, -0.3418,  0.6522, -0.0811,  1.2262,  1.0333,\n",
      "         -0.2468,  2.9837, -0.3238,  0.4593,  0.8114,  0.0283, -0.5667, -0.1913,\n",
      "          1.0879,  0.1426,  0.0033, -0.7826]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(13218407953960271872., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [10/32 (31%)]\tLoss: 13218407953960271872.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 1.6864, -0.5442,  2.3066, -0.4372,  0.0958,  1.9944, -0.0060, -0.5527,\n",
      "          1.4770,  0.1228, -0.2000,  1.2627, -1.7019,  1.0102,  0.9597, -0.8236,\n",
      "         -1.3145,  0.0528, -0.0478, -0.3425]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(568431053245513728., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [11/32 (34%)]\tLoss: 568431053245513728.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.1320, -0.6330,  0.6284,  1.2043, -0.4377,  1.5770,  0.0950, -0.8221,\n",
      "         -0.0279, -0.7500, -0.3481, -0.5745, -0.4729, -1.0099, -1.3275, -0.5990,\n",
      "          1.3333, -0.3399,  0.3230, -0.6084]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(144827926697352364032., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [12/32 (38%)]\tLoss: 144827926697352364032.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[ 0.0002, -1.1433, -1.5787,  1.4409,  0.3384, -1.1151,  0.6840,  0.3918,\n",
      "         -0.7980, -0.4026, -0.8580, -1.2647, -0.3170, -0.3072,  0.1899,  0.0302,\n",
      "          2.0936,  0.1592,  0.8488,  0.1690]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(6439071595012030464., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9 [13/32 (41%)]\tLoss: 6439071595012030464.000000\n",
      "Starting Encoding\n",
      "----------------------------\n",
      "Encode - Forward Pass Finished\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "----------------------------\n",
      "logvar (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (after encoding) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "Reparametrization...\n",
      "logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "mu (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<DropoutBackward>)\n",
      "0.5*logvar (in reparametrization) = \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]], grad_fn=<MulBackward>)\n",
      "std (in reparametrization) = \n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<ExpBackward>)\n",
      "eps (in reparametrization) = \n",
      "tensor([[-0.7003,  0.3953, -1.2689, -0.2425,  0.7580,  0.6493, -0.0737, -1.3069,\n",
      "         -0.1683,  0.9444,  1.0299,  0.8360, -1.0095,  1.1460,  0.1275,  1.8789,\n",
      "          0.6460,  0.4240, -0.7167, -0.3876]])\n",
      "----------------------------\n",
      "Starting Decoding\n",
      "Last ReLU output shape = torch.Size([1, 1, 128, 128, 128])\n",
      "--------------------------------------\n",
      "Calculating Loss...\n",
      "MSE Loss = tensor(129342009107569180672., grad_fn=<MseLossBackward>)\n",
      "KLD Loss = tensor(-0., grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1514-2b21df931e1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" / \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Plotting Training Losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1512-c9e88f4b4df6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    loss_history = []\n",
    "    #for epoch in range(1, args.epochs + 1):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"Epoch = \" + str(epoch) + \" / \" + str(epochs))\n",
    "        \n",
    "        train(epoch)\n",
    "        \n",
    "        # Plotting Training Losses\n",
    "        plt.figure(figsize=(16,8))\n",
    "        plt.plot(loss_history)\n",
    "        plt.show()\n",
    "        \n",
    "        # Plotting X and Reconstructed X\n",
    "        \n",
    "        \n",
    "        test(epoch)\n",
    "        \n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             sample = torch.randn(64, 20).to(device)\n",
    "#             sample = model.decode(sample).cpu()\n",
    "#             save_image(sample.view(64, 1, 28, 28),\n",
    "#                        'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
