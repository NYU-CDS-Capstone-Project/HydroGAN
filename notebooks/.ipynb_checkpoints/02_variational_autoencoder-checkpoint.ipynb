{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from: https://github.com/pytorch/examples/tree/master/vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify to accept hard coded arguments\n",
    "batch_size = 1\n",
    "epochs = 20\n",
    "no_cuda = False\n",
    "log_interval = 1\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HydrogenDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, h5_file, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h5_file (string): name of the h5 file with 32 sampled cubes.\n",
    "            root_dir (string): Directory with the .h5 file.\n",
    "        \"\"\"\n",
    "        file_size = os.path.getsize(root_dir + h5_file) / 1e6 # in MBs\n",
    "        print(\"The file size is \" + str(int(file_size)) + \" MBs\")\n",
    "        \n",
    "        # self.subcubes = h5py.File('../data/sample_32.h5', 'r')\n",
    "        self.subcubes = h5py.File(root_dir + h5_file, 'r')['sample32']\n",
    "        self.h5_file = h5_file\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        # Function called when len(self) is executed\n",
    "        \n",
    "        #print(len(self.subcubes))\n",
    "        return len(self.subcubes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This can be implemented in such a way that the whole h5 file read \n",
    "        using h5py.File() and get_sample() function is called to return\n",
    "        a random subcube. This won't increase memory usage because the\n",
    "        subcubes will be read in the same way and only the batch will\n",
    "        be read into memory.\n",
    "        \n",
    "        Here we have implemented it so that it can be used with data\n",
    "        generated by get_sample() function.\n",
    "        \n",
    "        The output of this function is one subcube with the dimensions\n",
    "        specified by get_sample() implementation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # default version -> error in training because of dimensions\n",
    "        #sample = self.subcubes[idx]\n",
    "        \n",
    "        # reshaped version to add another dimension\n",
    "        sample = self.subcubes[idx].reshape((1,128,128,128))\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file size is 268 MBs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.HydrogenDataset at 0x11b8b16a0>"
      ]
     },
     "execution_count": 1281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_subcubes = HydrogenDataset(h5_file=\"sample_32.h5\",\n",
    "                                    root_dir = \"../data/\")\n",
    "sampled_subcubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "train_loader = DataLoader(\n",
    "        dataset=sampled_subcubes,\n",
    "        #batch_size=args.batch_size, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        **kwargs)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        dataset=sampled_subcubes,\n",
    "        #batch_size=args.batch_size, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The Encoding Layers\n",
    "        nn.Conv3d \n",
    "        nn.MaxPool3d \n",
    "        \n",
    "        out_channels is the number of different filters we convolute \n",
    "        over the whole sampled subcube.\n",
    "        \n",
    "        So the first convolutional layer's in_channel should be 0 (?)\n",
    "        \n",
    "        In addition, the next layer's in_channel should be equal to\n",
    "        the previous layer's out_channels (all examples show that\n",
    "        this is the case)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convolutional Layer 1\n",
    "        self.encode_conv1 = nn.Conv3d(in_channels=1, \n",
    "                                      out_channels=8, \n",
    "                                      kernel_size=(4,4,4), # == 4\n",
    "                                      stride = (2,2,2), # == 2\n",
    "                                      padding=(1,1,1)) # == 1\n",
    "        nn.init.xavier_uniform_(self.encode_conv1.weight) #Xaviers Initialisation\n",
    "        \n",
    "        self.encode_relu1 = nn.ReLU()\n",
    "        self.encode_maxpool1 = nn.MaxPool3d(kernel_size=(2, 2, 2), \n",
    "                                             stride=(2, 2, 2),\n",
    "                                            return_indices = True)\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        self.encode_conv2 = nn.Conv3d(in_channels=8, \n",
    "                                      out_channels=16, \n",
    "                                      kernel_size=(4,4,4), # == 4 \n",
    "                                      stride = (2,2,2),\n",
    "                                      padding=(1,1,1))\n",
    "        nn.init.xavier_uniform_(self.encode_conv2.weight) #Xaviers Initialisation\n",
    "        \n",
    "        self.encode_relu2 = nn.ReLU()\n",
    "        self.encode_maxpool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), \n",
    "                                             stride=(2, 2, 2),\n",
    "                                            return_indices = True)\n",
    "\n",
    "        # Convolutional Layer 3\n",
    "        self.encode_conv3 = nn.Conv3d(in_channels=16, \n",
    "                                      out_channels=32, \n",
    "                                      kernel_size=(4,4,4), # == 4 \n",
    "                                      stride = (2,2,2),\n",
    "                                      padding=(1,1,1))\n",
    "        nn.init.xavier_uniform_(self.encode_conv3.weight) #Xaviers Initialisation\n",
    "        \n",
    "        self.encode_relu3 = nn.ReLU()\n",
    "#         self.encode_maxpool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), \n",
    "#                                              stride=(2, 2, 2),\n",
    "#                                             return_indices = True)\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Fully Connected Layers after 3D Convolutional Layers\n",
    "        First FC layer's input should be equal to \n",
    "        last convolutional layer's output\n",
    "        8192 = 8^3 * 16 \n",
    "            8^3 = (output of 2nd convolutional layer)\n",
    "            16 = number of out_channels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.encode_fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, \n",
    "                      out_features=5096), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #init.xavier_normal(self.fc1.state_dict()['weight'])\n",
    "        \n",
    "        self.encode_fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features = 5096,\n",
    "                      out_features = 5096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #init.xavier_normal(self.fc2.state_dict()['weight'])\n",
    "        \n",
    "        \"\"\"\n",
    "        The last fully connected layer's output is the dimensions\n",
    "        of the embeddings?\n",
    "        \"\"\"\n",
    "        self.encode_fc31 = nn.Sequential(\n",
    "            nn.Linear(in_features=5096,\n",
    "                      out_features=32))\n",
    "        self.encode_fc32 = nn.Sequential(\n",
    "            nn.Linear(in_features=5096,\n",
    "                      out_features=32))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        The Decoding Layers\n",
    "        nn.Conv3d -> nn.ConvTranspose3d\n",
    "        nn.MaxPool3d -> nn.MaxUnpool3d\n",
    "        \"\"\"\n",
    "        \n",
    "        self.decode_fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=32,\n",
    "                      out_features=5096))\n",
    "        \n",
    "        self.decode_fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=5096, \n",
    "                      out_features=5096), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #init.xavier_normal(self.fc1.state_dict()['weight'])\n",
    "        \n",
    "        self.decode_fc3 = nn.Sequential(\n",
    "            nn.Linear(in_features = 5096,\n",
    "                      out_features = 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        #init.xavier_normal(self.fc2.state_dict()['weight'])\n",
    "        \n",
    "        \n",
    "        self.decode_conv1 = nn.ConvTranspose3d(in_channels=32, \n",
    "                                              out_channels=16, \n",
    "                                              kernel_size=(4,4,4),\n",
    "                                              stride = (2,2,2),\n",
    "                                              padding=(1,1,1))\n",
    "        self.decode_relu1 = nn.ReLU()\n",
    "        self.decode_maxunpool1 = nn.MaxUnpool3d(kernel_size=(2, 2, 2), \n",
    "                                                     stride=(2, 2, 2))\n",
    "        #init.xavier_normal(self.group1.state_dict()['weight'])\n",
    "        \n",
    "        self.decode_conv2 = nn.ConvTranspose3d(in_channels=16, \n",
    "                                              out_channels=8, \n",
    "                                              kernel_size=(4,4,4),\n",
    "                                              stride = (2,2,2),\n",
    "                                              padding=(1,1,1))\n",
    "        self.decode_relu2 = nn.ReLU()\n",
    "        self.decode_maxunpool2 = nn.MaxUnpool3d(kernel_size=(2, 2, 2), \n",
    "                                                     stride=(2, 2, 2))\n",
    "        \n",
    "        self.decode_conv3 = nn.ConvTranspose3d(in_channels=8, \n",
    "                                              out_channels=1, \n",
    "                                              kernel_size=(4,4,4),\n",
    "                                              stride = (2,2,2),\n",
    "                                              padding=(1,1,1))\n",
    "        self.decode_relu3 = nn.ReLU()\n",
    "        self.decode_maxunpool3 = nn.MaxUnpool3d(kernel_size=(2, 2, 2), \n",
    "                                                     stride=(2, 2, 2))\n",
    "        \n",
    "        \n",
    "    # Encoding part of VAE\n",
    "    def encode(self, x):\n",
    "#         h1 = F.relu(self.fc1(x))\n",
    "#         return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "        print(\"Starting Encoding\")\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        out = self.encode_conv1(x)\n",
    "#         print(\"First Conv output shape = \" + str(out.shape))\n",
    "        #print(out.shape)\n",
    "        out = self.encode_relu1(out)\n",
    "#         print(\"First ReLU Layer output shape = \" + str(out.shape))\n",
    "        size1 = out.size()\n",
    "        out, ind1 = self.encode_maxpool1(out)\n",
    "#         print(\"First MaxPooling output shape = \" + str(out.shape))\n",
    "#         print(\"Ind1 shape = \" + str(ind1.shape))\n",
    "#         #print(\"Size1 = \" + str(size1))\n",
    "#         print(\"----------------------------\")\n",
    "        \n",
    "        out = self.encode_conv2(out)\n",
    "#         print(\"Second Conv output shape = \" + str(out.shape))\n",
    "        out = self.encode_relu2(out)\n",
    "#         print(\"Second ReLU Layer output shape = \" + str(out.shape))\n",
    "        size2 = out.size()\n",
    "        out, ind2 = self.encode_maxpool2(out)\n",
    "#         print(\"Second MaxPooling output shape = \" + str(out.shape))\n",
    "#         print(\"Ind2 shape = \" + str(ind2.shape))\n",
    "        #print(\"Size2 = \" + str(size2))\n",
    "#          print(\"----------------------------\")\n",
    "        \n",
    "        out = self.encode_conv3(out)\n",
    "#         print(\"Last Conv output shape = \" + str(out.shape))\n",
    "        out = self.encode_relu3(out)\n",
    "#         print(\"Last ReLU output shape = \" + str(out.shape))\n",
    "        size3 = out.size()\n",
    "#         out, ind3 = self.encode_maxpool3(out)\n",
    "#         print(\"Last Conv Layer output shape = \" + str(out.shape))\n",
    "#         print(\"Ind3 shape = \" + str(ind3.shape))\n",
    "        #print(\"Size3 = \" + str(size3))\n",
    "#         print(\"----------------------------\")\n",
    "\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        out = out.view(1, -1)\n",
    "#         print(\"Last Conv Layer output shape after reshaping \\n \\\n",
    "#                 (Input to first FC layer) = \" + str(out.shape))\n",
    "        \n",
    "        out = self.encode_fc1(out)\n",
    "        out = self.encode_fc2(out)\n",
    "        out_mu = self.encode_fc31(out)\n",
    "        out_logvar = self.encode_fc32(out)\n",
    "        \n",
    "        print(\"Encode - Forward Pass Finished\")\n",
    "        print(out_mu.shape)\n",
    "        print(out_logvar.shape)\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "#         return out_mu, out_logvar, [ind1,ind2,ind3], [size1,size2,size3]\n",
    "        return out_mu, out_logvar, [ind1,ind2], [size1,size2]\n",
    "    \n",
    "\n",
    "    # Reparametrization Trick\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    \n",
    "    # Decoding part of VAE\n",
    "    def decode(self, z, indices_list, size_list):\n",
    "#         h3 = F.relu(self.fc3(z))\n",
    "#         return torch.sigmoid(self.fc4(h3))\n",
    "        print(\"----------------------------\")\n",
    "        print(\"Starting Decoding\")\n",
    "#         print(\"z shape = \" + str(z.shape))\n",
    "        \n",
    "        out = self.decode_fc1(z)\n",
    "#         print(\"1st FC output shape = \" + str(out.shape))\n",
    "        out = self.decode_fc2(out)\n",
    "#         print(\"2nd FC output shape = \" + str(out.shape))\n",
    "        out = self.decode_fc3(out)\n",
    "#         print(\"Last FC output shape = \" + str(out.shape))\n",
    "        \n",
    "        out = out.view(1, 32, 4, 4, 4)\n",
    "#         print(\"First Deconv input shape = \" + str(out.shape))\n",
    "#         print(\"After last convolution (encoding stage) output shape = \" +\\\n",
    "#                   str(indices_list[1].shape))\n",
    "        out = self.decode_conv1(out)\n",
    "#         print(\"First Deconv output shape = \" + str(out.shape))\n",
    "        out = self.decode_relu1(out)\n",
    "#         print(\"First ReLU output shape = \" + str(out.shape))\n",
    "        # maxunpooling needs indices\n",
    "\n",
    "#         out = self.decode_maxunpool1(out,\n",
    "#                              indices = indices_list[1])\n",
    "        out = self.decode_maxunpool1(out,\n",
    "                                     indices = indices_list[1],\n",
    "                                     output_size = size_list[1])\n",
    "#         print(\"2nd MaxUnpool ouput shape = \" + str(out.shape))\n",
    "        \n",
    "        out = self.decode_conv2(out)\n",
    "#         print(\"2nd Deconv output shape = \" + str(out.shape))\n",
    "        out = self.decode_relu2(out)\n",
    "#         print(\"2nd ReLU output shape = \" + str(out.shape))\n",
    "        out = self.decode_maxunpool1(out,\n",
    "                     indices = indices_list[0])\n",
    "#         out = self.decode_maxunpool2(out,\n",
    "#                                      indices= indices_list[1],\n",
    "#                                      output_size = size_list[1])\n",
    "        \n",
    "        out = self.decode_conv3(out)\n",
    "        out = self.decode_relu3(out)\n",
    "#         out = self.decode_maxunpool1(out,\n",
    "#                              indices = indices_list[0])\n",
    "        # there is no last maxunpool in https://github.com/pgtgrly/Convolution-Deconvolution-Network-Pytorch/blob/master/Neural_Network_Class.py\n",
    "#         out = self.decode_maxunpool2(out,\n",
    "#                                      indices= indices_list[0],\n",
    "#                                      output_size = size_list[0])\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "    # Forward Pass\n",
    "    def forward(self, x):\n",
    "#         mu, logvar = self.encode(x.view(-1, 784))\n",
    "        mu, logvar, indices_list, size_list = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "#         print(\"z = \")\n",
    "#         print(z)\n",
    "        return self.decode(z, indices_list, size_list), mu, logvar\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     print(param.name)\n",
    "#     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Calculating Loss...\")\n",
    "#     print(\"recon_x shape = \" + str(recon_x.shape))\n",
    "    \n",
    "#     BCE = F.binary_cross_entropy(recon_x, \n",
    "#                                  x.view(-1, 1, 128, 128, 128), \n",
    "#                                  reduction='sum')\n",
    "#     print(\"BCE Loss = \" + str(MSE))\n",
    "\n",
    "    MSE = F.mse_loss(recon_x, \n",
    "                             x.view(-1, 1, 128, 128, 128), \n",
    "                             reduction='sum')\n",
    "    \n",
    "    print(\"MSE Loss = \" + str(MSE))\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    print(\"KLD Loss = \" + str(KLD))\n",
    "\n",
    "    return MSE\n",
    "#     return BCE + KLD\n",
    "#     return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enumerate(train_loader))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(train_loader))[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "#     for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "#         print(data)\n",
    "        \n",
    "        #print(\"Batch size = \" + str(data.shape))\n",
    "        \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "#         print(\"Reconstructed Input = \\n \" + str(recon_batch))\n",
    "#         print(\"Real Input = \\n \" + str(data))\n",
    "#         print(\"Reconstructed Input Shape = \\n \" + str(recon_batch.shape))\n",
    "#         print(\"Real Input Shape = \\n \" + str(data.shape))\n",
    "        \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if batch_idx % args.log_interval == 0:\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "#         for i, (data, _) in enumerate(test_loader):\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n], \n",
    "                                        recon_batch.view(batch_size, 1, 128, 128, 128)[:n]])\n",
    "                                      #recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "#                                         recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "#                 save_image(comparison.cpu(),\n",
    "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    loss_history = []\n",
    "    #for epoch in range(1, args.epochs + 1):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"Epoch = \" + str(epoch) + \" / \" + str(epochs))\n",
    "        \n",
    "        train(epoch)\n",
    "        \n",
    "        # Plotting Training Losses\n",
    "        plt.figure(figsize=(16,8))\n",
    "        plt.plot(loss_history)\n",
    "        plt.show()\n",
    "        \n",
    "        test(epoch)\n",
    "        \n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             sample = torch.randn(64, 20).to(device)\n",
    "#             sample = model.decode(sample).cpu()\n",
    "#             save_image(sample.view(64, 1, 28, 28),\n",
    "#                        'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
