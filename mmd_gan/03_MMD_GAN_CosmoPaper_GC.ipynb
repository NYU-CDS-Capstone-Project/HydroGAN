{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/OctoberChang/MMD-GAN - accompanying the paper MMD-GAN: Towards Deeper Understanding of Moment Matching Network.\n",
    "\n",
    "To check GPU usage, open new terminal inside Jupyter and nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To run with sbatch, \n",
    "* change the jupyter notebook parameters\n",
    "    * batch_size\n",
    "    * nz (= output channels in the embedding)\n",
    "    * lr\n",
    "    * optimizer_choice\n",
    "    * dist_ae\n",
    "    * left_clamp & right_clamp\n",
    "    * redshift_raw_file = raw data file like fields_z=0.0.hdf5\n",
    "    * redshift_file = transformed data file like minmax_scale_neg11_redshift0.h5\n",
    "    * inverse_transform = one of minmax11 / minmaxneg11 / std_noshift / std based on the transformed data file\n",
    "    * gen_iterations_limit\n",
    "* change the file name inside the run-mmdgan-110919.sbatch file\n",
    "* do: sbatch run-mmdgan-110918.sbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To transfer files to google drive\n",
    "* module load rclone/1.38\n",
    "* rclone copy /scratch/jjz289/data/mmd_gan_code/folderX/ remote1:folderX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Presentation\n",
    "\n",
    "Note the following parameters for debug:\n",
    "* batch_size\n",
    "* nz\n",
    "* lr\n",
    "* optimizer_choice\n",
    "* dist_ae\n",
    "* left_clamp\n",
    "* right_clamp\n",
    "* redshift_raw_file\n",
    "* redshift_file\n",
    "* inverse_transform\n",
    "* gen_iterations_limit\n",
    "* encoder architecture\n",
    "* decoder architecture\n",
    "\n",
    "Following graphs should be included (the last saved ones):\n",
    "* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip installs for google cloud compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /jet/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: h5py in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six in /jet/lib/python3.6/site-packages (from h5py)\n",
      "Requirement already satisfied: numpy>=1.7 in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from h5py)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.8.2 in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from scipy)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /jet/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in /jet/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /jet/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /jet/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: setuptools in /jet/lib/python3.6/site-packages/setuptools-36.0.1-py3.6.egg (from kiwisolver>=1.0.1->matplotlib)\n",
      "Requirement already satisfied: six in /jet/lib/python3.6/site-packages (from cycler>=0.10->matplotlib)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /jet/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.9.0 in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg (from pandas)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /jet/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2011k in /jet/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /jet/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /jet/lib/python3.6/site-packages/numpy-1.13.3-py3.6-linux-x86_64.egg\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install h5py\n",
    "!pip install scipy\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import h5py\n",
    "import timeit\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle as pkl\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run in Jupyter = True\n"
     ]
    }
   ],
   "source": [
    "run_in_jupyter = False\n",
    "try:\n",
    "    cfg = get_ipython().config \n",
    "    run_in_jupyter = True\n",
    "except:\n",
    "    run_in_jupyter = False\n",
    "    pass\n",
    "\n",
    "if run_in_jupyter:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "else: \n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "print(\"Run in Jupyter = \" + str(run_in_jupyter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import colors\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mode = \"training\"   # training OR continue = continue if load another model is loaded and continued to train\n",
    "continue_train_folder = \"jupyter-output-6\"    # the folder where the previous run is for the saved model to be trained further\n",
    "                            # make sure that the below parameters are the same as well\n",
    "netD_iter_file = \"netD_iter_0.pth\"         # netD_iter_xx.pth file that contains the state dict under models/\n",
    "netG_iter_file = \"netG_iter_0.pth\"         # netG_iter_xx.pth file that contains the state dict under models/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16       # BATCH_SIZE: batch size for training\n",
    "nc = 1                # NC: number of channels in images\n",
    "cube_size = 128       # for our dataset more like one edge of the subcube\n",
    "lr = 5e-5               # LR: learning rate - default: 5e-5\n",
    "max_iter = 150         # MAX_ITER: max iteration for training\n",
    "optimizer_choice = \"rmsprop\"     # adam or rmsprop\n",
    "dist_ae = 'L2'                  # \"L2\" or \"L1\" -> Autoencoder reconstructruced cube loss choice,  \"cos\" doesnt work\n",
    "manual_seed = 1\n",
    "sample_size_multiplier = 128\n",
    "n_samples = batch_size * sample_size_multiplier      # on prince, number of samples to get from the training cube\n",
    "Diter_1 = 100    # default: 100\n",
    "Giter_1 = 1      # default: 1\n",
    "Diter_2 = 5      # default: 5\n",
    "Giter_2 = 1      # default: 1\n",
    "gen_iterations_limit = 25   # default = 25\n",
    "edge_sample = cube_size\n",
    "edge_test = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n_samples / batch_size > 100, \"The gen_iterations wont work properly!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model\n",
    "model_choice = \"conv\"     # \"conv\" or \"conv_fc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run utils/power_spectrum_utils.py\n",
    "else:\n",
    "    from utils.power_spectrum_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for p in netD.encoder.parameters():\n",
    "    p.data.clamp_(left_clamp, right_clamp)\n",
    "\"\"\"\n",
    "left_clamp =  -0.01     # default: -0.01\n",
    "right_clamp = 0.01    # default: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 8\n",
    "stride = 4\n",
    "padding = 2\n",
    "\n",
    "ch_mult = 30         # channel multiplier -> increases this fold in every conv layer\n",
    "\n",
    "full_conv_limit = 1  # = full deconv limit = number of conv layers with batchnorm\n",
    "full_deconv_limit = full_conv_limit\n",
    "\n",
    "just_conv_limit = 1 + full_conv_limit   # + full_conv_limit because of layer counting method in class defnitions\n",
    "just_deconv_limit = just_conv_limit\n",
    "\n",
    "leakyrelu_const = 0.01 # leakyrelu\n",
    "\n",
    "full_fc_limit = 2    # no of FC layers if available\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nz = 32                # not used in training, change code in testing - NZ: number of channels, hidden dimension in z and codespace\n",
    "conv_bias = True\n",
    "deconv_bias = True\n",
    "fc_bias = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_init = \"normal\"    # normal OR xavier (doesn't work right now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_multiplier = 1e0           # the norm multiplier in the 3D visualization\n",
    "scatter_size_magnitude = False  # change scatter point radius based on the value of the point \n",
    "if run_in_jupyter:\n",
    "    plot_show_3d = True            # shows the 3d scatter plot\n",
    "    plot_save_3d = False           # whether to save or not as png \n",
    "    plot_save_other = False\n",
    "    plot_show_other = True\n",
    "else:\n",
    "    plot_show_3d = False            # shows the 3d scatter plot\n",
    "    plot_save_3d = True           # whether to save or not as png \n",
    "    plot_save_other = True\n",
    "    plot_show_other = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run utils/logging_utils.py\n",
    "else:\n",
    "    from utils.logging_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./\"  # this goes to \n",
    "data_dir = \"../\"\n",
    "new_output_folder = get_output_folder(run_in_jupyter = run_in_jupyter)\n",
    "# new_output_folder = \"drive-output-XX\"   # for batch processing\n",
    "experiment = root_dir + new_output_folder + \"/\"       # : output directory of saved models\n",
    "# print(experiment)\n",
    "\n",
    "model_save_folder = experiment + \"model/\"\n",
    "redshift_fig_folder = experiment + \"figures/\"        # folder to save mmd & related plots\n",
    "redshift_3dfig_folder = experiment + \"3d_figures/\"   # folder to save 3D plots\n",
    "testing_folder = experiment + \"testing/\"   # folder to save 3D plots\n",
    "\n",
    "save_model_every = 10               # (every x epoch) frequency to save the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 0          # WORKERS: number of threads to load data\n",
    "redshift_info_folder = root_dir + \"redshift_info/\"   # save some info here as pickle to speed up processing\n",
    "redshift_raw_file = \"fields_z=0.0.hdf5\"\n",
    "redshift_file = \"redshift0_4th_root.h5\"    # redshift cube to be used\n",
    "    # standardized_no_shift_redshift0.h5\n",
    "    # minmax_scale_01_redshift0.h5\n",
    "    # minmax_scale_neg11_redshift0.h5\n",
    "    # redshift0_4th_root.h5\n",
    "    # redshift0_6th_root.h5\n",
    "    # redshift0_8th_root.h5\n",
    "    # redshift0_16th_root.h5\n",
    "inverse_transform = \"4_root\"    # minmax01 / minmaxneg11 / std_noshift / std\n",
    "                                    # 4_root / 6_root / 8_root / 16_root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_testing = False              # True if doing testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "if run_in_jupyter:\n",
    "    %run utils/debug_utils.py\n",
    "else:\n",
    "    from utils.debug_utils import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdas\n",
      "log('asdas') output = None\n"
     ]
    }
   ],
   "source": [
    "print(\"log('asdas') output = \" + str(log(\"asdas\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Parameters:\n",
      "Batch Size = 16\n",
      "Number of Samples = 2048\n",
      "Learning Rate = 5e-05\n",
      "Number of Epochs = 150\n",
      "Optimizer = rmsprop\n",
      "Autoencoder Reconstruction Loss  = L2\n",
      "gen_iterations_limit = 25\n",
      "Diter_1 = 100\n",
      "Giter_1 = 1\n",
      "Diter_2 = 5\n",
      "Giter_2 = 1\n",
      "Length of Edge of a Sampled Subcube = 128\n",
      "one edge of the test partition of the whole cube = 512\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Parameters:\")\n",
    "print(\"Batch Size = \" + str(batch_size))\n",
    "print(\"Number of Samples = \" + str(n_samples))\n",
    "\n",
    "print(\"Learning Rate = \" + str(lr))\n",
    "print(\"Number of Epochs = \" + str(max_iter))\n",
    "print(\"Optimizer = \" + str(optimizer_choice))\n",
    "print(\"Autoencoder Reconstruction Loss  = \" + str(dist_ae))\n",
    "print(\"gen_iterations_limit = \" + str(gen_iterations_limit))\n",
    "print(\"Diter_1 = \" + str(Diter_1))\n",
    "print(\"Giter_1 = \" + str(Giter_1))\n",
    "print(\"Diter_2 = \" + str(Diter_2))\n",
    "print(\"Giter_2 = \" + str(Giter_2))\n",
    "\n",
    "print(\"Length of Edge of a Sampled Subcube = \" + str(cube_size))\n",
    "print(\"one edge of the test partition of the whole cube = \" + str(edge_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Parameters:\n",
      "Number of Channels in Input = 1\n",
      "Left clamp = -0.01\n",
      "Right clamp = 0.01\n",
      "Parameter Init Method = normal\n",
      "Convolution Bias = True\n",
      "Deconvolution Bias = True\n",
      "FC (Encoder & Decoder) Bias = True\n",
      "Channel Multiplier = 30\n",
      "Convolution with BatchNorm count = 1\n",
      "FC Layer count = 2\n",
      "LeakyReLU constant = 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Parameters:\")\n",
    "print(\"Number of Channels in Input = \" + str(nc))\n",
    "# print(\"Hidden Dimension (codespace) (nz)= \" + str(nz))\n",
    "print(\"Left clamp = \" + str(left_clamp))\n",
    "print(\"Right clamp = \" + str(right_clamp)) \n",
    "print(\"Parameter Init Method = \" + str(model_param_init))\n",
    "print(\"Convolution Bias = \" + str(conv_bias))\n",
    "print(\"Deconvolution Bias = \" + str(deconv_bias))\n",
    "print(\"FC (Encoder & Decoder) Bias = \" + str(fc_bias))\n",
    "print(\"Channel Multiplier = \" + str(ch_mult))\n",
    "print(\"Convolution with BatchNorm count = \" + str(full_conv_limit))\n",
    "print(\"FC Layer count = \" + str(full_fc_limit))\n",
    "print(\"LeakyReLU constant = \" + str(leakyrelu_const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMD Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_MMD = 1.0\n",
      "lambda_AE_X = 8.0\n",
      "lambda_AE_Y = 8.0\n",
      "lambda_rg = 16.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MMD Parameters\n",
    "\n",
    "errD = torch.sqrt(mmd2_D) + lambda_rg * one_side_errD \n",
    "       - lambda_AE_X * L2_AE_X_D - lambda_AE_Y * L2_AE_Y_D\n",
    "       \n",
    "errG = torch.sqrt(mmd2_G) + lambda_rg * one_side_errG\n",
    "\n",
    "The explanations can be found in Ratio Matching MMD Nets (2018) in \n",
    "Equation 3.\n",
    "\n",
    "\"\"\"\n",
    "lambda_MMD = 1.0   # not used anywhere\n",
    "lambda_AE_X = 8.0  # used in above calc only \n",
    "lambda_AE_Y = 8.0  # used in above calc only\n",
    "lambda_rg = 16.0 #16.0   # used in both err calcs\n",
    "\n",
    "print(\"lambda_MMD = \" + str(lambda_MMD))\n",
    "print(\"lambda_AE_X = \" + str(lambda_AE_X))\n",
    "print(\"lambda_AE_Y = \" + str(lambda_AE_Y))\n",
    "print(\"lambda_rg = \" + str(lambda_rg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_list = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sigma for MMD\n",
    "\"\"\"\n",
    "base = 1e0\n",
    "sigma_list = [1, 2, 4, 8, 16, 32, 64]\n",
    "sigma_list = [sigma / base for sigma in sigma_list]\n",
    "print(\"sigma_list = \" + str(sigma_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum variance estimated = 1e-30\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "used at:\n",
    "def _mmd2_and_ratio(K_XX, K_XY, K_YY, \n",
    "                    const_diagonal=False, \n",
    "                    biased=False):\n",
    "    mmd2, var_est = _mmd2_and_variance(K_XX, K_XY, K_YY, \n",
    "                                       const_diagonal=const_diagonal, \n",
    "                                       biased=biased)\n",
    "    loss = mmd2 / torch.sqrt(torch.clamp(var_est, min=min_var_est))\n",
    "    return loss, mmd2, var_est\n",
    "    \n",
    "torch.clamp(input, min, max, out=None) → Tensor\n",
    "    Clamp all elements in input into the range [ min, max ] \n",
    "    and return a resulting tensor\n",
    "\"\"\"\n",
    "\n",
    "min_var_est = 1e-30 # 1e-30, default:1e-8\n",
    "print(\"minimum variance estimated = \" + str(min_var_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting Parameters:\n",
      "Visualization Multiplier = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPlotting Parameters:\")\n",
    "print(\"Visualization Multiplier = \" + str(viz_multiplier))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Parameters:\n",
      "Output folder = ./jupyter-output-21/\n",
      "model_save_folder folder = ./jupyter-output-21/model/\n",
      "redshift_fig_folder folder = ./jupyter-output-21/figures/\n",
      "redshift_3dfig_folder folder = ./jupyter-output-21/3d_figures/\n",
      "testing_folder folder = ./jupyter-output-21/testing/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving Parameters:\")\n",
    "print(\"Output folder = \" + str(experiment))\n",
    "print(\"model_save_folder folder = \" + str(model_save_folder))\n",
    "print(\"redshift_fig_folder folder = \" + str(redshift_fig_folder))\n",
    "print(\"redshift_3dfig_folder folder = \" + str(redshift_3dfig_folder))\n",
    "print(\"testing_folder folder = \" + str(testing_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Parameters:\n",
      "Redshift File Used = redshift0_4th_root.h5\n",
      "redshift_info_folder = ./redshift_info/\n",
      "redshift_raw_file = fields_z=0.0.hdf5\n",
      "inverse_transform = 4_root\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Parameters:\")\n",
    "print(\"Redshift File Used = \" + str(redshift_file))\n",
    "print(\"redshift_info_folder = \" + str(redshift_info_folder))\n",
    "print(\"redshift_raw_file = \" + str(redshift_raw_file))\n",
    "print(\"inverse_transform = \" + str(inverse_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Parameters:\n",
      "In testing = False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting Parameters:\")\n",
    "print(\"In testing = \" + str(in_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other Parameters:\n",
      "Seed = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOther Parameters:\")\n",
    "print(\"Seed = \" + str(manual_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File used for analysis = ../redshift0_4th_root.h5\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(data_dir + redshift_file, 'r')\n",
    "print(\"File used for analysis = \" + str(f.filename))\n",
    "f = f['delta_HI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Info Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trial folder if it doesn't exist\n",
    "if Path(experiment).exists() == False:\n",
    "    os.mkdir(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create redshift info folder if it doesn't exist\n",
    "if Path(redshift_info_folder).exists() == False:\n",
    "    os.mkdir(redshift_info_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run utils/data_utils.py\n",
    "else:\n",
    "    from utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data Summary Statistics:\n",
      "File = redshift0_4th_root.h5\n",
      "Min of data = 0.0\n",
      "Max of data = 367.0622863769531\n",
      "Mean of data = 0.4414861036653747\n",
      "Stddev of data = 1.0323245023357703\n",
      "\n",
      "Raw Data Summary Statistics:\n",
      "File = fields_z=0.0.hdf5\n",
      "Min of raw data = 0.0\n",
      "Max of raw data = 18153447424.0\n",
      "Mean of raw data = 10170.681640625\n",
      "Stddev of raw data = 3474200.75\n"
     ]
    }
   ],
   "source": [
    "min_cube,max_cube,mean_cube,stddev_cube = get_stats_cube(redshift_info_folder = redshift_info_folder,\n",
    "                                           redshift_file = redshift_file,\n",
    "                                           data_dir = data_dir)\n",
    "min_raw_cube,max_raw_cube,mean_raw_cube,stddev_raw_cube = get_stats_cube(redshift_info_folder = redshift_info_folder,\n",
    "                                           redshift_file = redshift_raw_file,\n",
    "                                           data_dir = data_dir)\n",
    "print(\"\\nTransformed Data Summary Statistics:\")\n",
    "print(\"File = \" + str(redshift_file))\n",
    "print(\"Min of data = \" + str(min_cube))\n",
    "print(\"Max of data = \" + str(max_cube))\n",
    "print(\"Mean of data = \" + str(mean_cube))\n",
    "print(\"Stddev of data = \" + str(stddev_cube))\n",
    "\n",
    "print(\"\\nRaw Data Summary Statistics:\")\n",
    "print(\"File = \" + str(redshift_raw_file))\n",
    "print(\"Min of raw data = \" + str(min_raw_cube))\n",
    "print(\"Max of raw data = \" + str(max_raw_cube))\n",
    "print(\"Mean of raw data = \" + str(mean_raw_cube))\n",
    "print(\"Stddev of raw data = \" + str(stddev_raw_cube))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figures folder if it doesn't exist\n",
    "if Path(redshift_fig_folder).exists() == False:\n",
    "    os.mkdir(redshift_fig_folder)\n",
    "if Path(redshift_3dfig_folder).exists() == False:\n",
    "    os.mkdir(redshift_3dfig_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run utils/plot_utils.py\n",
    "else:\n",
    "    from utils.plot_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run dataset.py\n",
    "else:\n",
    "    from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run test_3d_plot.py\n",
    "else:\n",
    "    from test_3d_plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on prince\n",
    "sampled_subcubes = HydrogenDataset(h5_file=redshift_file,\n",
    "                                    root_dir = data_dir,\n",
    "                                    f = h5py.File(data_dir + redshift_file, 'r')[\"delta_HI\"],\n",
    "                                    s_test = edge_test, \n",
    "                                    s_train = edge_sample,\n",
    "                                    s_sample = edge_sample, \n",
    "                                    nsamples = n_samples,\n",
    "                                   min_cube = min_cube,\n",
    "                                  max_cube = max_cube,\n",
    "                                  mean_cube = mean_cube,\n",
    "                                  stddev_cube = stddev_cube,\n",
    "                                   min_raw_cube = min_raw_cube,\n",
    "                                  max_raw_cube = max_raw_cube,\n",
    "                                  mean_raw_cube = mean_raw_cube,\n",
    "                                  stddev_raw_cube = stddev_raw_cube,\n",
    "                                  rotate_cubes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "trn_loader = torch.utils.data.DataLoader(sampled_subcubes, \n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle=True, \n",
    "                                         num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking 3D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # dont run this in batch\n",
    "# if run_in_jupyter:\n",
    "#     test_3d_plot(edge_test = edge_test, \n",
    "#                  edge_sample = edge_sample,\n",
    "#                  f = h5py.File(data_dir + redshift_file, 'r')[\"delta_HI\"], \n",
    "#                  scatter_size_magnitude = scatter_size_magnitude,\n",
    "#                  viz_multiplier = viz_multiplier,\n",
    "#                  plot_save_3d = plot_save_3d,\n",
    "#                  inverse_transform = inverse_transform,\n",
    "#                  sampled_subcubes = sampled_subcubes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run utils/mmd_utils.py\n",
    "    %run utils/model_utils.py\n",
    "    %run utils/conv_utils.py\n",
    "\n",
    "else:\n",
    "    from utils.mmd_utils import *\n",
    "    from utils.model_utils import *\n",
    "    from utils.conv_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & copy the decoder and encoder files to output folder for easier loading of architectures when resuming training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run_mode != \"continue\":\n",
    "if model_choice == \"conv\":\n",
    "    if run_in_jupyter:\n",
    "        %run models/decoder_v03.py\n",
    "        %run models/encoder_v03.py\n",
    "    else:\n",
    "        from models.decoder_v03 import *\n",
    "        from models.encoder_v03 import *\n",
    "        \n",
    "    shutil.copy(\"models/decoder_v03.py\",experiment)\n",
    "    shutil.copy(\"models/encoder_v03.py\",experiment)\n",
    "elif model_choice == \"conv_fc\":\n",
    "    if run_in_jupyter:\n",
    "        %run models/decoder_FC_v03.py\n",
    "        %run models/encoder_FC_v03.py\n",
    "    else:\n",
    "        from models.decoder_FC_v03 import *\n",
    "        from models.encoder_FC_v03 import *\n",
    "\n",
    "    shutil.copy(\"models/decoder_FC_v03.py\",experiment)\n",
    "    shutil.copy(\"models/encoder_FC_v03.py\",experiment)\n",
    "    \n",
    "# if run_mode == \"continue\":\n",
    "#     if model_choice == \"conv\":\n",
    "#         if run_in_jupyter:\n",
    "#             %run continue_train_folder/decoder_v02.py\n",
    "#             %run continue_train_folder/encoder_v02.py\n",
    "#         else:\n",
    "#             from continue_train_folder.decoder_v02 import *\n",
    "#             from continue_train_folder.encoder_v02 import *\n",
    "#     elif model_choice == \"conv_fc\":\n",
    "#         if run_in_jupyter:\n",
    "#             %run continue_train_folder/decoder_FC_v03.py\n",
    "#             %run continue_train_folder/encoder_FC_v03.py\n",
    "#         else:\n",
    "#             from continue_train_folder.decoder_FC_v03 import *\n",
    "#             from continue_train_folder.encoder_FC_v03 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run models/NetD.py\n",
    "    %run models/NetG.py\n",
    "else:\n",
    "    from models.NetD import *\n",
    "    from models.NetG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run one_sided.py\n",
    "else:\n",
    "    from one_sided import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if args.experiment is None:\n",
    "#     args.experiment = 'samples'\n",
    "# os.system('mkdir {0}'.format(args.experiment))\n",
    "\n",
    "if model_save_folder is None:\n",
    "    model_save_folder = 'samples'\n",
    "os.system('mkdir {0}'.format(model_save_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(seed=args.manual_seed)\n",
    "# random.seed(args.manual_seed)\n",
    "# torch.manual_seed(args.manual_seed)\n",
    "# torch.cuda.manual_seed(args.manual_seed)\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "np.random.seed(seed=manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed(manual_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discriminator\n",
      "Encoder = encoder_v02.py\n",
      "Decoder = decoder_v02.py\n",
      "Output = torch.exp(out)\n",
      "\n",
      "Generator\n",
      "Decoder = decoder_v02.py\n",
      "Output = torch.exp(out)\n"
     ]
    }
   ],
   "source": [
    "# construct encoder/decoder modules\n",
    "\n",
    "if model_choice == \"conv\":\n",
    "    print(\"\\nDiscriminator\")\n",
    "    D_encoder = Encoder(full_conv_limit = full_conv_limit,\n",
    "                        just_conv_limit = just_conv_limit,\n",
    "                         kernel_size = kernel_size,\n",
    "                         stride = stride,\n",
    "                         padding = padding,\n",
    "                         ch_mult = ch_mult,\n",
    "                         conv_bias = conv_bias,\n",
    "                         leakyrelu_const = leakyrelu_const)\n",
    "    D_decoder = Decoder(ch_mult = ch_mult,\n",
    "                         kernel_size = kernel_size,\n",
    "                         stride = stride,\n",
    "                         padding = padding,\n",
    "                         deconv_bias = deconv_bias,\n",
    "                         leakyrelu_const = leakyrelu_const,\n",
    "                       full_deconv_limit = full_deconv_limit,\n",
    "                        just_deconv_limit = just_deconv_limit,\n",
    "                       D_encoder = D_encoder)\n",
    "    print(\"\\nGenerator\")\n",
    "    G_decoder = Decoder(ch_mult = ch_mult,\n",
    "                         kernel_size = kernel_size,\n",
    "                         stride = stride,\n",
    "                         padding = padding,\n",
    "                         deconv_bias = deconv_bias,\n",
    "                         leakyrelu_const = leakyrelu_const,\n",
    "                        full_deconv_limit = full_deconv_limit,\n",
    "                        just_deconv_limit = just_deconv_limit,\n",
    "                       D_encoder = D_encoder)\n",
    "\n",
    "elif model_choice == \"conv_fc\":\n",
    "#     print(\"\\nDiscriminator\")\n",
    "    D_encoder = Encoder(full_conv_limit = full_conv_limit,\n",
    "                         full_fc_limit = full_fc_limit,\n",
    "                         ch_mult = ch_mult,\n",
    "                         conv_bias = conv_bias,\n",
    "                         fc_bias = fc_bias,\n",
    "                         leakyrelu_const = leakyrelu_const)\n",
    "    D_decoder = Decoder(ch_mult = ch_mult,\n",
    "                         deconv_bias = deconv_bias,\n",
    "                         leakyrelu_const = leakyrelu_const,\n",
    "                        full_deconv_limit = full_deconv_limit,\n",
    "                        full_fc_limit = full_fc_limit,\n",
    "                        fc_bias = fc_bias,\n",
    "                        D_encoder = D_encoder) \n",
    "#     print(\"\\nGenerator\")\n",
    "    G_decoder = Decoder(ch_mult = ch_mult,\n",
    "                         deconv_bias = deconv_bias,\n",
    "                         leakyrelu_const = leakyrelu_const,\n",
    "                        full_deconv_limit = full_deconv_limit,\n",
    "                        full_fc_limit = full_fc_limit,\n",
    "                        fc_bias = fc_bias,\n",
    "                        D_encoder = D_encoder)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netD: NetD(\n",
      "  (encoder): Encoder(\n",
      "    (conv_net): Sequential(\n",
      "      (Conv_1): Conv3d(1, 30, kernel_size=(8, 8, 8), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "      (BatchNorm_1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leakyrelu_1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "      (Conv_2): Conv3d(30, 900, kernel_size=(8, 8, 8), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (deconv_net): Sequential(\n",
      "      (DeConv_1): ConvTranspose3d(900, 30, kernel_size=(8, 8, 8), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "      (BatchNorm_1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leakyrelu_1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "      (DeConv_2): ConvTranspose3d(30, 1, kernel_size=(8, 8, 8), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = NetD(D_encoder, D_decoder)\n",
    "# print(\"type netD: \", type(netD))\n",
    "print(\"netD:\", netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netG: NetG(\n",
      "  (decoder): Decoder(\n",
      "    (deconv_net): Sequential(\n",
      "      (DeConv_1): ConvTranspose3d(900, 30, kernel_size=(8, 8, 8), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "      (BatchNorm_1): BatchNorm3d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leakyrelu_1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "      (DeConv_2): ConvTranspose3d(30, 1, kernel_size=(8, 8, 8), stride=(4, 4, 4), padding=(2, 2, 2))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = NetG(G_decoder)\n",
    "print(\"netG:\", netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oneSide: ONE_SIDED(\n",
      "  (main): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "one_sided = ONE_SIDED()\n",
    "print(\"oneSide:\", one_sided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the models to be used when continuing the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(netD, experiment + \"netD\")\n",
    "# torch.save(netG, experiment + \"netG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if run_mode == \"continue\":\n",
    "    print(\"Loading saved models and parameters from file...\")\n",
    "    netD = torch.load(f = continue_train_folder + \"/netD\")\n",
    "    netG = torch.load(f = continue_train_folder + \"/netG\")\n",
    "    print(type(netD))\n",
    "    print(type(netG))\n",
    "    \n",
    "    netD.load_state_dict(state_dict=torch.load(continue_train_folder + \"/model/\" + netD_iter_file))\n",
    "    netG.load_state_dict(state_dict=torch.load(continue_train_folder + \"/model/\" + netG_iter_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_jupyter:\n",
    "    %run utils/network_viz.py\n",
    "else:\n",
    "    from utils.network_viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(netD.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x = torch.randn(1,1,cube_size,cube_size,cube_size).requires_grad_(True)\n",
    "# y = netD.encoder(Variable(x))\n",
    "# g = make_dot(y,\n",
    "#          params=dict(list(netD.encoder.named_parameters()) + [('x', x)]))\n",
    "# g.view(directory=experiment, filename=\"netD_encoder_viz\")\n",
    "\n",
    "# z = netG.decoder(Variable(y))\n",
    "# g = make_dot(z,\n",
    "#          params=dict(list(netG.decoder.named_parameters()) + [('z', z)]))\n",
    "# g.view(directory=experiment, filename=\"netG_decoder_viz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ONE_SIDED(\n",
       "  (main): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG.apply(lambda x: weights_init(x,init_type = model_param_init))\n",
    "netD.apply(lambda x: weights_init(x,init_type = model_param_init))\n",
    "one_sided.apply(lambda x: weights_init(x,init_type = model_param_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Encoder:\n",
      "torch.Size([30, 1, 8, 8, 8])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([900, 30, 8, 8, 8])\n",
      "torch.Size([900])\n",
      "\n",
      "Discriminator Decoder:\n",
      "torch.Size([900, 30, 8, 8, 8])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 1, 8, 8, 8])\n",
      "torch.Size([1])\n",
      "\n",
      "Generator Decoder:\n",
      "torch.Size([900, 30, 8, 8, 8])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 1, 8, 8, 8])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "see the parameters of the networks\n",
    "\n",
    "The convolutional kernels:\n",
    "torch.Size([2, 1, 4, 4, 4])\n",
    "\n",
    "What are these for?\n",
    "torch.Size([4])\n",
    "\"\"\"\n",
    "print(\"Discriminator Encoder:\")\n",
    "for p in netD.encoder.parameters():\n",
    "    print(p.shape)\n",
    "print(\"\\nDiscriminator Decoder:\")  \n",
    "for p in netD.decoder.parameters():\n",
    "    print(p.shape)\n",
    "print(\"\\nGenerator Decoder:\")  \n",
    "for p in netG.decoder.parameters():\n",
    "    print(p.shape)\n",
    "    \n",
    "# for name, param in netD.encoder.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(str(name) + str(param.shape) + str(param.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put variable into cuda device\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "errD.backward(mone)\n",
    "optimizerD.step()\n",
    "\n",
    "errG.backward(one)\n",
    "optimizerG.step()\n",
    "\"\"\"\n",
    "one = torch.tensor(1.0).cuda()\n",
    "#one = torch.cuda.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device 0\n"
     ]
    }
   ],
   "source": [
    "gpu_device = 0        # GPU_DEVICE: gpu id (default 0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "#     args.cuda = True\n",
    "    cuda = True\n",
    "#     torch.cuda.set_device(args.gpu_device)\n",
    "    torch.cuda.set_device(gpu_device)\n",
    "    print(\"Using GPU device\", torch.cuda.current_device())\n",
    "else:\n",
    "    raise EnvironmentError(\"GPU device not available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ONE_SIDED(\n",
       "    (main): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ngpu > 1:\n",
    "    print(\"Let's use\", ngpu, \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    netG = nn.DataParallel(netG).cuda()\n",
    "    netD = nn.DataParallel(netD).cuda()\n",
    "    one_sided = nn.DataParallel(one_sided).cuda()\n",
    "\n",
    "netG.to(device)\n",
    "netD.to(device)\n",
    "one_sided.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netD.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cuda:\n",
    "#     netG.cuda()\n",
    "#     netD.cuda()\n",
    "#     one_sided.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_choice == \"rmsprop\":\n",
    "#     setup optimizer\n",
    "    optimizerG = torch.optim.RMSprop(netG.parameters(), \n",
    "                                     lr=lr)\n",
    "    optimizerD = torch.optim.RMSprop(netD.parameters(), \n",
    "                                     lr=lr)\n",
    "elif optimizer_choice == \"adam\":\n",
    "    # Why not try adam?\n",
    "    optimizerG = torch.optim.Adam(netG.parameters(), \n",
    "                                     lr=lr)\n",
    "    optimizerD = torch.optim.Adam(netD.parameters(), \n",
    "                                     lr=lr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 12500.512866438\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch = 1 / 150\n",
      "----------------------------------------------- \n",
      "\n",
      "len(trn_loader) = 128\n",
      "Optimize over NetD\n",
      "gen_iterations = 0\n",
      "j / Diter = 1 / 100\n"
     ]
    }
   ],
   "source": [
    "time_loop = timeit.default_timer()\n",
    "print(\"time = \" + str(time_loop))\n",
    "\n",
    "time_1_list = []\n",
    "time_2_list = []\n",
    "\n",
    "gen_iterations = 0  # the code default is = 0\n",
    "\n",
    "# lists for tracking - Discriminator side\n",
    "mmd2_D_before_ReLU_list = []\n",
    "mmd2_D_after_ReLU_list = []\n",
    "one_side_errD_list = []\n",
    "L2_AE_X_D_list = []\n",
    "L2_AE_Y_D_list = []\n",
    "errD_list = []\n",
    "\n",
    "# lists for tracking - Generator side\n",
    "mmd2_G_before_ReLU_list = []\n",
    "mmd2_G_after_ReLU_list = []\n",
    "one_side_errG_list = []\n",
    "errG_list = []\n",
    "# errG = torch.Tensor(np.array(0.0))\n",
    "# print(errG.item())\n",
    "\n",
    "# lists for tracking count of nonzero voxels\n",
    "log_nonzero_recon_over_real_list = []\n",
    "\n",
    "# list for tracking gradient norms for generator and discriminator\n",
    "grad_norm_D = []\n",
    "grad_norm_G = []\n",
    "\n",
    "# lists for tracking the sum of all cubes in a minibatch\n",
    "sum_noise_gen = []\n",
    "sum_noise_gen_recon = []\n",
    "sum_real = []\n",
    "sum_real_recon = []\n",
    "\n",
    "fixed_noise_set = 0\n",
    "\n",
    "for t in range(max_iter):\n",
    "    print(\"\\n-----------------------------------------------\")\n",
    "    print(\"Epoch = \" + str(t+1) + \" / \" + str(max_iter))\n",
    "    print(\"----------------------------------------------- \\n\")\n",
    "    \n",
    "    data_iter = iter(trn_loader)\n",
    "    print(\"len(trn_loader) = \" + str(len(trn_loader)))\n",
    "    i = 0\n",
    "    plotted = 0\n",
    "    plotted_2 = 0\n",
    "    plotted_3 = 0\n",
    "    plotted_4 = 0   # grad norm plotting controller\n",
    "    \n",
    "    while (i < len(trn_loader)):\n",
    "        \n",
    "        # ---------------------------\n",
    "        #        Optimize over NetD\n",
    "        # ---------------------------\n",
    "        print(\"Optimize over NetD\")\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        What does the below if-else do?\n",
    "        Trains the discriminator for a lot more when the training\n",
    "        is starting, then switches to a more frequent generator\n",
    "        training regime.\n",
    "        \"\"\"\n",
    "        print(\"gen_iterations = \" + str(gen_iterations))\n",
    "        if gen_iterations < gen_iterations_limit or gen_iterations % 500 == 0:\n",
    "            Diters = Diter_1\n",
    "            Giters = Giter_1\n",
    "        else:\n",
    "            Diters = Diter_2\n",
    "            Giters = Giter_2\n",
    "\n",
    "        for j in range(Diters):\n",
    "            if i == len(trn_loader):\n",
    "                break\n",
    "\n",
    "            time_1 = time.time()\n",
    "            print(\"j / Diter = \" + str(j+1) + \" / \" + str(Diters))\n",
    "            # clamp parameters of NetD encoder to a cube\n",
    "            # do not clamp parameters of NetD decoder!!!\n",
    "            # exactly like numpy.clip()\n",
    "            \"\"\"\n",
    "            Given an interval, values outside the interval are clipped to the interval edges. \n",
    "            For example, if an interval of [0, 1] is specified, values smaller than 0 become 0, \n",
    "            and values larger than 1 become 1.\n",
    "            \n",
    "            Below code clamps the encoder parameters of the \n",
    "            dsicriminator between -0.01 and 0.01\n",
    "            \"\"\"\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                for p in netD.module.encoder.parameters():\n",
    "#                 for p in netD.encoder.parameters():\n",
    "                    p.data.clamp_(left_clamp, right_clamp)\n",
    "            else:\n",
    "                for p in netD.encoder.parameters():\n",
    "                    p.data.clamp_(left_clamp, right_clamp)\n",
    "\n",
    "            data = data_iter.next()\n",
    "#             print(\"data shape = \" + str(data.shape))\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            netD.zero_grad()\n",
    "\n",
    "#             x_cpu, _ = data\n",
    "#             x_cpu = data\n",
    "#             x = Variable(x_cpu.cuda().float())\n",
    "            x = Variable(data.to(device).float())\n",
    "#             x = Variable(data.cuda().float())\n",
    "        \n",
    "        \n",
    "            batch_size = x.size(0)\n",
    "#             print(\"batch_size = \" + str(batch_size))\n",
    "\n",
    "            # output of the discriminator with real data input\n",
    "            \"\"\"\n",
    "            2097152^(1/3) = 128 (= one side of our cube so the\n",
    "            reconstructed cube is the same size as the original one)\n",
    "            This one just acts like an autoencoder\n",
    "            \"\"\"\n",
    "            f_enc_X_D, f_dec_X_D, f_enc_X_size = netD(x)\n",
    "#             sum_real.append(x.sum())\n",
    "#             sum_real_recon.append(f_dec_X_D.sum())\n",
    "#             print(\"netD(x) outputs:\")\n",
    "#             print(\"f_enc_X_D size = \" + str(f_enc_X_D.size()))\n",
    "#             print(\"f_dec_X_D size = \" + str(f_dec_X_D.size()))\n",
    "#             print(\"f_dec_X_D min = \" + str(f_dec_X_D.min().item()))\n",
    "#             print(\"f_dec_X_D max = \" + str(f_dec_X_D.max().item()))\n",
    "#             print(\"f_dec_X_D mean = \" + str(f_dec_X_D.mean().item()))\n",
    "            \n",
    "#             print(\"nz = \" + str(nz))\n",
    "            noise = torch.cuda.FloatTensor(f_enc_X_size).normal_(0, 1)\n",
    "            \n",
    "#             noise = torch.cuda.FloatTensor(f_enc_X_size[0], \n",
    "#                                             f_enc_X_size[1], \n",
    "#                                             f_enc_X_size[2], \n",
    "#                                             f_enc_X_size[3],\n",
    "#                                             f_enc_X_size[4]).normal_(0, 1)\n",
    "#             noise = Variable(noise)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                #noise = Variable(noise, volatile=True)  # total freeze netG\n",
    "                noise = Variable(noise)\n",
    "#             print(\"noise shape = \" + str(noise.shape))\n",
    "\n",
    "            # output of the generator with noise input\n",
    "#             y = Variable(netG(noise).data)\n",
    "            y = Variable(netG(noise))\n",
    "#             sum_noise_gen.append(y.sum())\n",
    "#             print(\"y shape = \" + str(y.shape))\n",
    "#             print(\"y[0] shape = \" + str(y[0].shape))\n",
    "#             print(\"y[0][0] shape = \" + str(y[0][0].shape))\n",
    "#             sample_cube_viz = y[0][0].cpu().detach().numpy()\n",
    "#             print(\"sample_cube_viz shape = \" + str(sample_cube_viz.shape))\n",
    "        \n",
    "            # output of the discriminator with noise input\n",
    "            # this tests discriminator \n",
    "            f_enc_Y_D, f_dec_Y_D, _ = netD(y)\n",
    "#             sum_noise_gen_recon.append(f_dec_Y_D.sum())\n",
    "#             print(\"netD(y) outputs:\")\n",
    "#             print(\"f_enc_Y_D size = \" + str(f_enc_Y_D.size()))\n",
    "#             print(\"f_dec_Y_D size = \" + str(f_dec_Y_D.size()))\n",
    "#             print(\"f_dec_Y_D min = \" + str(f_dec_Y_D.min().item()))\n",
    "#             print(\"f_dec_Y_D max = \" + str(f_dec_Y_D.max().item()))\n",
    "#             print(\"f_dec_Y_D mean = \" + str(f_dec_Y_D.mean().item()))\n",
    "\n",
    "\n",
    "\n",
    "            # compute biased MMD2 and use ReLU to prevent negative value\n",
    "            mmd2_D = mix_rbf_mmd2(f_enc_X_D, \n",
    "                                  f_enc_Y_D, \n",
    "                                  sigma_list,\n",
    "                                  biased=True)\n",
    "#             mmd2_D = poly_mmd2(f_enc_X_D, f_enc_Y_D)\n",
    "#             mmd2_D = linear_mmd2(f_enc_X_D, f_enc_Y_D)\n",
    "            \n",
    "#             print(\"mmd2_D before ReLU = \" + str(mmd2_D.item()))\n",
    "            mmd2_D_before_ReLU_list.append(mmd2_D.item())\n",
    "            mmd2_D = F.relu(mmd2_D)\n",
    "#             print(\"mmd2_D after ReLU = \" + str(mmd2_D.item()))\n",
    "            mmd2_D_after_ReLU_list.append(mmd2_D.item())\n",
    "\n",
    "            # compute rank hinge loss\n",
    "#             print('f_enc_X_D:', f_enc_X_D.size())\n",
    "#             print('f_enc_Y_D:', f_enc_Y_D.size())\n",
    "            one_side_errD = one_sided(f_enc_X_D.mean(0) - f_enc_Y_D.mean(0))\n",
    "#             print(\"one_side_errD = \" + str(one_side_errD.item()))\n",
    "            one_side_errD_list.append(one_side_errD.item())\n",
    "            \n",
    "            # compute L2-loss of AE\n",
    "            \"\"\"\n",
    "            x = real cube (x batch_size)\n",
    "            y = cube generated by the Generator with noise input\n",
    "            f_dec_X_D = AE reconstructed real cube\n",
    "            f_dec_Y_D = AE reconstructed noise-input cube\n",
    "            \"\"\"\n",
    "#             print('f_dec_X_D:', f_dec_X_D.size())\n",
    "#             print('f_dec_Y_D:', f_dec_Y_D.size())\n",
    "#             print('x:', x.size())\n",
    "#             print('y:', y.size())\n",
    "            L2_AE_X_D = match(x.view(batch_size, -1), f_dec_X_D, dist_ae)\n",
    "            L2_AE_Y_D = match(y.view(batch_size, -1), f_dec_Y_D, dist_ae)\n",
    "            \n",
    "#             print(\"L2-loss of AE, L2_AE_X_D = \" + str(L2_AE_X_D.item()))\n",
    "#             print(\"L2-loss of AE, L2_AE_Y_D = \" + str(L2_AE_Y_D.item()))\n",
    "            L2_AE_X_D_list.append(L2_AE_X_D.item())\n",
    "            L2_AE_Y_D_list.append(L2_AE_Y_D.item())\n",
    "            \n",
    "\n",
    "\n",
    "#             print(\"lambda_rg = \" + str(lambda_rg))\n",
    "            errD = torch.sqrt(mmd2_D) + lambda_rg * one_side_errD - lambda_AE_X * L2_AE_X_D - lambda_AE_Y * L2_AE_Y_D\n",
    "#             print(\"errD shape = \" + str(errD.shape))\n",
    "#             print(\"errD = \" + str(errD.item()))\n",
    "            errD_list.append(errD.item())\n",
    "            errD.backward(mone)\n",
    "            optimizerD.step()\n",
    "            \n",
    "            time_2 = time.time()  \n",
    "            time_2 = time_2 - time_1\n",
    "            time_2_list.append(time_2)\n",
    "#             print(np.mean(np.array(time_2_list)))\n",
    "\n",
    "            \"\"\"\n",
    "            fixed_noise was used in the original implementation for \n",
    "            generating some image from the same noise input to see\n",
    "            the evolution\n",
    "            \"\"\"\n",
    "            if fixed_noise_set == 0:\n",
    "            \n",
    "                fixed_noise = torch.cuda.FloatTensor(f_enc_X_size).normal_(0, 1)\n",
    "                if model_choice == \"conv_fc\":\n",
    "                    fixed_noise = fixed_noise[0]  # plot just one cube\n",
    "                    fixed_noise = fixed_noise.view(1,-1)\n",
    "                print(\"Fixed Noise size = \" + str(fixed_noise.size()))\n",
    "#                 fixed_noise = torch.cuda.FloatTensor(1, \n",
    "#                                                     f_enc_X_size[1], \n",
    "#                                                     f_enc_X_size[2], \n",
    "#                                                     f_enc_X_size[3],\n",
    "#                                                     f_enc_X_size[4]).normal_(0, 1)\n",
    "                fixed_noise = Variable(fixed_noise, \n",
    "                                       requires_grad=False)\n",
    "                fixed_noise_set = fixed_noise_set + 1\n",
    "        \n",
    "\n",
    "            \n",
    "            # Plotting Discriminator Plots\n",
    "            if j % 2 == 0 and plotted < 1:\n",
    "                if True:\n",
    "#                 try:\n",
    "                    \"\"\"\n",
    "                    Plotting Different Discriminator Related Values\n",
    "                    \"\"\"\n",
    "                    print(\"\\nPlotting Different Discriminator Related Values\")\n",
    "    \n",
    "                    plot_list = [mmd2_D_before_ReLU_list,mmd2_D_after_ReLU_list,\n",
    "                                 one_side_errD_list, L2_AE_X_D_list,\n",
    "                                 L2_AE_Y_D_list, errD_list ]\n",
    "                    plot_title_list = [\"mmd2_D_before_ReLU_list\", \"mmd2_D_after_ReLU_list\",\n",
    "                                       \"one_side_errD_list\", \"L2_AE_X_D_list\",\n",
    "                                       \"L2_AE_Y_D_list\", \"errD_list - D loss goes to 0: failure mode\"]\n",
    "                    for plot_no in range(len(plot_list)):\n",
    "                        mmd_loss_plots(fig_id = plot_no, \n",
    "                                        fig_title = plot_title_list[plot_no], \n",
    "                                        data = plot_list[plot_no], \n",
    "                                        show_plot = plot_show_other, \n",
    "                                        save_plot = plot_save_other, \n",
    "                                        redshift_fig_folder = redshift_fig_folder,\n",
    "                                      t = t,\n",
    "                                      dist_ae = dist_ae)\n",
    "\n",
    "                    \"\"\"\n",
    "                    Plotting the sum of values across a minibatch\n",
    "                    \"\"\"\n",
    "                    print(\"\\nPlotting the sum of values across a minibatch\")\n",
    "                    plot_minibatch_value_sum(sum_real = sum_real,\n",
    "                             sum_real_recon = sum_real_recon,\n",
    "                             sum_noise_gen = sum_noise_gen,\n",
    "                             sum_noise_gen_recon = sum_noise_gen_recon,\n",
    "                             save_plot = plot_save_other,\n",
    "                             show_plot = plot_show_other,\n",
    "                             redshift_fig_folder = redshift_fig_folder,\n",
    "                             t = t)\n",
    "\n",
    "                    \n",
    "                    # plot output of the discriminator with real data input\n",
    "                    # and output of the discriminator with noise input\n",
    "                    # on the same histogram \n",
    "                    # selecting a random cube from the batch\n",
    "                    random_batch = random.randint(0,batch_size-1)\n",
    "#                     real_ae_cube = f_dec_X_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "#                     noise_ae_cube = f_dec_Y_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "#                     noise_gen_cube = y[random_batch][0].cpu().detach().numpy()\n",
    "#                     real_cube = x[random_batch][0].cpu().detach().numpy()\n",
    "                    \n",
    "                    # full minibatch power spectrum plot\n",
    "                    real_ae_cube = f_dec_X_D.view(batch_size,1,cube_size,cube_size,cube_size).cpu().detach().numpy()\n",
    "#                     print(real_ae_cube.shape)\n",
    "                    noise_ae_cube = f_dec_Y_D.view(batch_size,1,cube_size,cube_size,cube_size).cpu().detach().numpy()\n",
    "#                     print(noise_ae_cube.shape)\n",
    "                    noise_gen_cube = y.cpu().detach().numpy()\n",
    "#                     print(noise_gen_cube.shape)\n",
    "                    real_cube = x.cpu().detach().numpy()\n",
    "#                     print(real_cube.shape)\n",
    "                                        \n",
    "                    # inverse transform the real and generated cubes back to normal\n",
    "                    real_ae_cube = inverse_transform_func(cube = real_ae_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                    noise_ae_cube = inverse_transform_func(cube = noise_ae_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                                 sampled_dataset = sampled_subcubes)\n",
    "                    noise_gen_cube = inverse_transform_func(cube = noise_gen_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                    real_cube = inverse_transform_func(cube = real_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                    \n",
    "                    # using the inverse-transformed randomly selected samples\n",
    "                    sum_real.append(real_cube.sum())\n",
    "                    sum_real_recon.append(real_ae_cube.sum())\n",
    "                    sum_noise_gen.append(noise_gen_cube.sum())\n",
    "                    sum_noise_gen_recon.append(noise_ae_cube.sum())\n",
    "                    \n",
    "                    print(\"real_ae_cube max = \" + str(real_ae_cube.max()) + \", min = \" + str(real_ae_cube.min()) \\\n",
    "                     + \", mean = \" + str(real_ae_cube.mean()))\n",
    "                    print(\"noise_ae_cube max = \" + str(noise_ae_cube.max()) + \", min = \" + str(noise_ae_cube.min())\\\n",
    "                         + \", mean = \" + str(noise_ae_cube.mean()))\n",
    "                    print(\"noise_gen_cube max = \" + str(noise_gen_cube.max()) + \", min = \" + str(noise_gen_cube.min())\\\n",
    "                         + \", mean = \" + str(noise_gen_cube.mean()))\n",
    "                    print(\"real_cube max = \" + str(real_cube.max()) + \", min = \" + str(real_cube.min())\\\n",
    "                         + \", mean = \" + str(real_cube.mean()))\n",
    "                    \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    Power Spectrum Comparisons\n",
    "                    \"\"\"\n",
    "                    print(\"\\nPower Spectrum Comparisons\")\n",
    "#                     plot_power_spec_aggregate(real_cube = real_cube,        # should be inverse_transformed\n",
    "#                                     generated_cube = noise_gen_cube,   # should be inverse_transformed\n",
    "#                                     raw_cube_mean = sampled_subcubes.mean_val, \n",
    "#                                     save_plot = plot_save_other,\n",
    "#                                     show_plot = plot_show_other,\n",
    "#                                      redshift_fig_folder = redshift_fig_folder,\n",
    "#                                      t = t,\n",
    "#                                     threads=1, \n",
    "#                                     MAS=\"CIC\", \n",
    "#                                     axis=0, \n",
    "#                                     BoxSize=75.0/2048*128)\n",
    "                    plot_power_spec(real_cube = real_cube,        # should be inverse_transformed\n",
    "                                    generated_cube = noise_gen_cube,   # should be inverse_transformed\n",
    "                                    raw_cube_mean = sampled_subcubes.mean_val, \n",
    "                                    save_plot = plot_save_other,\n",
    "                                    show_plot = plot_show_other,\n",
    "                                     redshift_fig_folder = redshift_fig_folder,\n",
    "                                     t = t,\n",
    "                                    threads=1, \n",
    "                                    MAS=\"CIC\", \n",
    "                                    axis=0, \n",
    "                                    BoxSize=75.0/2048*128)\n",
    "    \n",
    "                    \"\"\"\n",
    "                    2D Visualizations\n",
    "                    \"\"\"\n",
    "                    visualize2d(real = real_cube, \n",
    "                                fake = noise_gen_cube, \n",
    "                                raw_cube_mean = sampled_subcubes.mean_raw_val, \n",
    "                                redshift_fig_folder = redshift_fig_folder,\n",
    "                                t = t,\n",
    "                                save_plot = plot_save_other, \n",
    "                                show_plot = plot_show_other)\n",
    "                    \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    Select Random Single Cubes\n",
    "                    Subset them by taking only values greater than 0\n",
    "                    Even though they are inverse transformed, some values may be negative\n",
    "                    due to the activation function and output function used\n",
    "                    \"\"\"\n",
    "                    real_ae_cube = real_ae_cube[real_ae_cube > 0.0]\n",
    "                    noise_ae_cube = noise_ae_cube[noise_ae_cube > 0.0]\n",
    "                    noise_gen_cube = noise_gen_cube[noise_gen_cube > 0.0]\n",
    "                    real_cube = real_cube[real_cube > 0.0]\n",
    "#                     real_ae_cube = real_ae_cube[np.nonzero(real_ae_cube)]\n",
    "#                     noise_ae_cube = noise_ae_cube[np.nonzero(noise_ae_cube)]\n",
    "#                     noise_gen_cube = noise_gen_cube[np.nonzero(noise_gen_cube)]\n",
    "#                     real_cube = real_cube[np.nonzero(real_cube)]\n",
    "#                     recon_plot = recon_plot[np.greater(recon_plot, 0)]\n",
    "                    \n",
    "#                     print(\"len(real_plot) - nonzero elements = \" + str(len(real_plot)))\n",
    "#                     print(\"len(recon_plot) - nonzero elements = \" + str(len(recon_plot)))\n",
    "    #                 log_nonzero_real_list.append(len(real_plot))\n",
    "    #                 log_nonzero_recon_list.append(len(recon_plot))\n",
    "\n",
    "#                     log_nonzero_recon_over_real_list.append(len(recon_plot) / len(real_plot))\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    Plotting Nominal and Log Histograms\n",
    "                    \"\"\"\n",
    "                    print(\"\\nPlotting Nominal Histogram and PDFs\")\n",
    "                    mmd_hist_plot(noise = noise_gen_cube, \n",
    "                                  real = real_cube, \n",
    "                                  recon_noise = noise_ae_cube, \n",
    "                                  recon_real = real_ae_cube,\n",
    "                                  epoch = t, \n",
    "                                  file_name = 'hist_' + str(t) + '.png', \n",
    "                                  plot_pdf = False,\n",
    "                                  log_plot = False,\n",
    "                                  plot_show = plot_show_other,\n",
    "                                  redshift_fig_folder = redshift_fig_folder)\n",
    "    \n",
    "                    mmd_hist_plot(noise = noise_gen_cube, \n",
    "                                  real = real_cube, \n",
    "                                  recon_noise = noise_ae_cube, \n",
    "                                  recon_real = real_ae_cube,\n",
    "                                  epoch = t, \n",
    "                                  file_name = 'pdf_' + str(t) + '.png', \n",
    "                                  plot_pdf = True,\n",
    "                                  log_plot = False,\n",
    "                                  plot_show = plot_show_other,\n",
    "                                  redshift_fig_folder = redshift_fig_folder) \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    Plotting the log histograms & PDF\n",
    "                    \"\"\"\n",
    "                    print(\"\\nPlotting the log histograms & PDF\")\n",
    "                    mmd_hist_plot(noise = noise_gen_cube, \n",
    "                                  real = real_cube, \n",
    "                                  recon_noise = noise_ae_cube, \n",
    "                                  recon_real = real_ae_cube,\n",
    "                                  epoch = t, \n",
    "                                  file_name = 'hist_log_' + str(t) + '.png', \n",
    "                                  plot_pdf = False,\n",
    "                                  log_plot = True,\n",
    "                                  plot_show = plot_show_other,\n",
    "                                  redshift_fig_folder = redshift_fig_folder)\n",
    "    \n",
    "                    mmd_hist_plot(noise = noise_gen_cube, \n",
    "                                  real = real_cube, \n",
    "                                  recon_noise = noise_ae_cube, \n",
    "                                  recon_real = real_ae_cube,\n",
    "                                  epoch = t, \n",
    "                                  file_name = 'pdf_log_' + str(t) + '.png', \n",
    "                                  plot_pdf = True,\n",
    "                                  log_plot = True,\n",
    "                                  plot_show = plot_show_other,\n",
    "                                  redshift_fig_folder = redshift_fig_folder)                     \n",
    "\n",
    "#                 except:\n",
    "#                     pass\n",
    "                \n",
    "                plotted = plotted + 1\n",
    "                \n",
    "                \n",
    "                \n",
    "#             if plotted_2 < 1 and t % 5 == 0 and t > gen_iterations_limit:\n",
    "            if plotted_2 < 1 and t % 5 == 0:\n",
    "                # reshaping DOESNT WORK due to nonzero() -> reshaping 1D to 3D with cube_size edges\n",
    "                # so just getting them again works.\n",
    "                real_ae_cube = f_dec_X_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "                noise_ae_cube = f_dec_Y_D[random_batch].cpu().view(128,128,128).detach().numpy()\n",
    "                noise_gen_cube = y[random_batch][0].cpu().detach().numpy()\n",
    "                real_cube = x[random_batch][0].cpu().detach().numpy()\n",
    "                y_fixed = netG(fixed_noise)[0][0].cpu().detach().numpy()\n",
    "                \n",
    "                real_ae_cube = inverse_transform_func(cube = real_ae_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                noise_ae_cube = inverse_transform_func(cube = noise_ae_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                noise_gen_cube = inverse_transform_func(cube = noise_gen_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                real_cube = inverse_transform_func(cube = real_cube,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                y_fixed = inverse_transform_func(cube = y_fixed,\n",
    "                                                  inverse_type = inverse_transform, \n",
    "                                             sampled_dataset = sampled_subcubes)\n",
    "                \n",
    "                print(\"y_fixed shape = \" + str(y_fixed.shape))\n",
    "                print(\"real_ae_cube shape = \" + str(real_ae_cube.shape))\n",
    "                print(\"noise_ae_cube shape = \" + str(noise_ae_cube.shape))\n",
    "                print(\"noise_gen_cube shape = \" + str(noise_gen_cube.shape))\n",
    "                print(\"real_cube shape = \" + str(real_cube.shape))\n",
    "                \n",
    "            \n",
    "            \n",
    "#                 # Plot the 3D Cubes\n",
    "                print(\"\\nFixed Noise Input Cube\")\n",
    "                visualize_cube(cube=y_fixed,      ## array name\n",
    "                                         edge_dim=real_ae_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         #stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                            size_magnitude = scatter_size_magnitude,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = plot_show_3d,\n",
    "                               plot_save = plot_save_3d,\n",
    "                                         save_fig = redshift_3dfig_folder + 'fixed_noise_' + str(t) + '.png',\n",
    "                      raw_cube_max = sampled_subcubes.max_raw_val)                \n",
    "\n",
    "                print(\"\\nReconstructed, AutoEncoder Generated Real Cube\")\n",
    "#                 recon_real_viz = \n",
    "                visualize_cube(cube=real_ae_cube,      ## array name\n",
    "                                         edge_dim=real_ae_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         #stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                            size_magnitude = scatter_size_magnitude,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = plot_show_3d,\n",
    "                               plot_save = plot_save_3d,\n",
    "                                         save_fig = redshift_3dfig_folder + 'recon_ae_real_' + str(t) + '.png',\n",
    "                      raw_cube_max = sampled_subcubes.max_raw_val)\n",
    "                \n",
    "                print(\"\\nReconstructed, AutoEncoder Generated Noise-Input Cube\")\n",
    "#                 recon_fake_viz = \n",
    "                visualize_cube(cube=noise_ae_cube,      ## array name\n",
    "                                         edge_dim=noise_ae_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         #stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                            size_magnitude = scatter_size_magnitude,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = plot_show_3d,\n",
    "                               plot_save = plot_save_3d,\n",
    "                                         save_fig = redshift_3dfig_folder + 'recon_ae_noisegen_' + str(t) + '.png',\n",
    "                      raw_cube_max = sampled_subcubes.max_raw_val)\n",
    "                \n",
    "                print(\"\\nNoise-Input Generated Cube\")\n",
    "#                 sample_viz = \n",
    "                visualize_cube(cube=noise_gen_cube,      ## array name\n",
    "                                         edge_dim=noise_gen_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         #stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                            size_magnitude = scatter_size_magnitude,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = plot_show_3d,\n",
    "                               plot_save = plot_save_3d,\n",
    "                                         save_fig = redshift_3dfig_folder + 'noisegen_' + str(t) + '.png',\n",
    "                      raw_cube_max = sampled_subcubes.max_raw_val)\n",
    "                \n",
    "                print(\"\\nReal Cube\")\n",
    "#                 real_viz = \n",
    "                visualize_cube(cube=real_cube,      ## array name\n",
    "                                         edge_dim=real_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                                         start_cube_index_x=0,\n",
    "                                         start_cube_index_y=0,\n",
    "                                         start_cube_index_z=0,\n",
    "                                         fig_size=(10,10),\n",
    "                                         #stdev_to_white=-2,\n",
    "                                         norm_multiply=viz_multiplier,\n",
    "                                            size_magnitude = scatter_size_magnitude,\n",
    "                                         color_map=\"Blues\",\n",
    "                                         plot_show = plot_show_3d,\n",
    "                               plot_save = plot_save_3d,\n",
    "                                         save_fig = redshift_3dfig_folder +'real_' + str(t) + '.png',\n",
    "                      raw_cube_max = sampled_subcubes.max_raw_val)\n",
    "\n",
    "#             sample_viz.show()\n",
    "\n",
    "                plotted_2 = plotted_2 + 1 # to limit one 3d plotting per epoch\n",
    "                \n",
    "        print(\"\\n Finished optimizing over NetD \\n\")\n",
    "\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Optimize over NetG\n",
    "        # ---------------------------\n",
    "        \"\"\"\n",
    "        Because i is increased in each training loop for the\n",
    "        discriminitor, the below condition of if i == len(trn_loader)\n",
    "        is True in every epoch.\n",
    "        Should an i = 0 be added to the beginning of the netG optimization?\n",
    "        Look at paper to see how the training method is.\n",
    "        \"\"\"\n",
    "        print(\"Optimize over NetG\")\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        print(\"Giters = \" + str(Giters))\n",
    "        for j in range(Giters):\n",
    "            print(\"i = \" + str(i))\n",
    "            print(\"len(trn_loader) = \" + str(len(trn_loader)))\n",
    "            if i == len(trn_loader):\n",
    "                print(\"Breaking from the Generator training loop\")\n",
    "                break\n",
    "\n",
    "            print(\"j / Giter = \" + str(j+1) + \" / \" + str(Giters))\n",
    "            data = data_iter.next()\n",
    "            i += 1\n",
    "            netG.zero_grad()\n",
    "\n",
    "#             x_cpu, _ = data\n",
    "            x_cpu = data\n",
    "            x = Variable(x_cpu.cuda().float())\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            # output of discriminator with real input\n",
    "            f_enc_X, f_dec_X, f_enc_X_size = netD(x)\n",
    "\n",
    "            noise = torch.cuda.FloatTensor(f_enc_X_size).normal_(0, 1)\n",
    "            \n",
    "#             noise = torch.cuda.FloatTensor(f_enc_X_size[0], \n",
    "#                                             f_enc_X_size[1], \n",
    "#                                             f_enc_X_size[2], \n",
    "#                                             f_enc_X_size[3],\n",
    "#                                             f_enc_X_size[4]).normal_(0, 1)\n",
    "#             noise = Variable(noise)\n",
    "            \n",
    "            # output of the generator with noise input\n",
    "            y = netG(noise)\n",
    "\n",
    "            # output of the discriminator with noise input\n",
    "            f_enc_Y, f_dec_Y, _ = netD(y)\n",
    "\n",
    "            # compute biased MMD2 and use ReLU to prevent negative value\n",
    "            mmd2_G = mix_rbf_mmd2(f_enc_X, \n",
    "                                  f_enc_Y, \n",
    "                                  sigma_list, \n",
    "                                  biased=True)\n",
    "#             mmd2_G = poly_mmd2(f_enc_X, f_enc_Y)\n",
    "#             mmd2_G = linear_mmd2(f_enc_X, f_enc_Y)\n",
    "    \n",
    "            mmd2_G_before_ReLU_list.append(mmd2_G)\n",
    "            mmd2_G = F.relu(mmd2_G)\n",
    "            mmd2_G_after_ReLU_list.append(mmd2_G)\n",
    "\n",
    "            # compute rank hinge loss\n",
    "            one_side_errG = one_sided(f_enc_X.mean(0) - f_enc_Y.mean(0))\n",
    "            one_side_errG_list.append(one_side_errG)\n",
    "\n",
    "            errG = torch.sqrt(mmd2_G) + lambda_rg * one_side_errG\n",
    "            print(\"errG = \" + str(errG.item()))\n",
    "#             print(\"one = \") + str(one)\n",
    "            errG_list.append(errG.item())\n",
    "            errG.backward(one)\n",
    "            optimizerG.step()\n",
    "\n",
    "            gen_iterations += 1\n",
    "            \n",
    "            if plotted_3 < 1:\n",
    "                \"\"\"\n",
    "                Plotting Generator Related Values\n",
    "                \"\"\"\n",
    "                plot_list = [mmd2_G_before_ReLU_list,mmd2_G_after_ReLU_list,\n",
    "                             one_side_errG_list, errG_list ]\n",
    "                plot_title_list = [\"mmd2_G_before_ReLU_list\", \"mmd2_G_after_ReLU_list\",\n",
    "                                   \"one_side_errG_list\",\"errG_list\"]\n",
    "                for plot_no in range(len(plot_list)):\n",
    "                    mmd_loss_plots(fig_id = plot_no, \n",
    "                                    fig_title = plot_title_list[plot_no], \n",
    "                                    data = plot_list[plot_no], \n",
    "                                    show_plot = plot_show_other, \n",
    "                                    save_plot = plot_save_other, \n",
    "                                    redshift_fig_folder = redshift_fig_folder,\n",
    "                                  t = t,\n",
    "                                  dist_ae = dist_ae)           \n",
    "            \n",
    "                plotted_3 = plotted_3 + 1\n",
    "\n",
    "        run_time = (timeit.default_timer() - time_loop) / 60.0\n",
    "        print(\"run_time = \" + str(run_time))\n",
    "        try:\n",
    "            print('[%3d/%3d][%3d/%3d] [%5d] (%.2f m) MMD2_D %.10f hinge %.6f L2_AE_X %.6f L2_AE_Y %.6f loss_D %.6f Loss_G %.6f f_X %.6f f_Y %.6f |gD| %.4f |gG| %.4f'\n",
    "                % (t, max_iter, i, len(trn_loader), gen_iterations, run_time,\n",
    "                     mmd2_D.item(), one_side_errD.item(),\n",
    "                     L2_AE_X_D.item(), L2_AE_Y_D.item(),\n",
    "                     errD.item(), errG.item(),\n",
    "                     f_enc_X_D.mean().item(), f_enc_Y_D.mean().item(),\n",
    "                     grad_norm(netD), grad_norm(netG)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # plotting gradient norms for monitoring\n",
    "        grad_norm_D.append(grad_norm(netD))\n",
    "        grad_norm_G.append(grad_norm(netG))\n",
    "        \n",
    "        if plotted_4 < 1:\n",
    "            plt.figure(figsize = (10,5))\n",
    "            plt.title(\"grad_norms - if they are over 100 things are screwing up\")\n",
    "            plt.yscale('log')\n",
    "            plt.plot(grad_norm_D, \n",
    "                     color = \"red\", \n",
    "                     label = \"grad_norm_D\")\n",
    "            plt.plot(grad_norm_G, \n",
    "                     color = \"blue\", \n",
    "                     label = \"grad_norm_G\")\n",
    "            plt.legend()\n",
    "            plt.savefig(redshift_fig_folder + 'grad_norms_' + str(t) + '.png', \n",
    "                        bbox_inches='tight')\n",
    "            plt.show() \n",
    "            plt.close()\n",
    "            #             plt.show()\n",
    "            \n",
    "            plotted_4 = plotted_4 + 1\n",
    "\n",
    "\n",
    "    if t % save_model_every == 0:\n",
    "        print(\"Saving the model state_dict()\")\n",
    "        torch.save(netG.state_dict(), \n",
    "                   '{0}/netG_iter_{1}.pth'.format(model_save_folder, t))\n",
    "        torch.save(netD.state_dict(), \n",
    "                   '{0}/netD_iter_{1}.pth'.format(model_save_folder, t))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_testing == False:\n",
    "    assert in_testing, \"Stopping here, because not in testing...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The folder models were saved in: \" + str(model_save_folder))\n",
    "model_files = [f for f in listdir(model_save_folder) if isfile(join(model_save_folder, f))]\n",
    "model_files\n",
    "\n",
    "netG_files = [f for f in model_files if \"netG\" in f]\n",
    "netG_files\n",
    "\n",
    "max_iter_netG = max(netG_files, key=lambda x: int(x[10:-4]))\n",
    "max_iter_netG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G_decoder = Decoder(cube_size, \n",
    "                    nc, \n",
    "                    k=nz, \n",
    "                    ngf=16)\n",
    "\n",
    "netG_test = NetG(G_decoder)\n",
    "# print(\"netG:\", netG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_test.load_state_dict(torch.load(model_save_folder + max_iter_netG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netG_test.eval()\n",
    "netG_test.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Cube with Trained Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.cuda.FloatTensor(1, \n",
    "                                nz, \n",
    "                                1, \n",
    "                                1,\n",
    "                                1).normal_(0, 1)\n",
    "noise.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = Variable(noise)\n",
    "\n",
    "    # output of the generator with noise input\n",
    "    y = netG_test(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_batch = random.randint(0,batch_size-1)\n",
    "noise_gen_cube = y[0][0].cpu().detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noise-Input Generated Cube\")\n",
    "#                 sample_viz = \n",
    "visualize_cube(cube=noise_gen_cube,      ## array name\n",
    "                         edge_dim=noise_gen_cube.shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                         start_cube_index_x=0,\n",
    "                         start_cube_index_y=0,\n",
    "                         start_cube_index_z=0,\n",
    "                         fig_size=(10,10),\n",
    "                         stdev_to_white=-2,\n",
    "                         norm_multiply=viz_multiplier,\n",
    "                         color_map=\"Blues\",\n",
    "                         plot_show = True,\n",
    "                         save_fig = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file = testing_folder + \"noise_gen_cube\",\n",
    "    arr = noise_gen_cube,\n",
    "    allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a real subcube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcd = define_test(s_test = 1024,\n",
    "                     s_train = 128)\n",
    "print(testcd)\n",
    "\n",
    "trial_sample = get_samples(s_sample = 128, \n",
    "                            nsamples = 1, \n",
    "#                             h5_filename = redshift_file, \n",
    "                            test_coords = testcd,\n",
    "                            f = f)\n",
    "trial_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Sampled Cube\")\n",
    "#                 sample_viz = \n",
    "visualize_cube(cube=trial_sample[0],      ## array name\n",
    "                         edge_dim=trial_sample[0].shape[0],        ## edge dimension (128 for 128 x 128 x 128 cube)\n",
    "                         start_cube_index_x=0,\n",
    "                         start_cube_index_y=0,\n",
    "                         start_cube_index_z=0,\n",
    "                         fig_size=(10,10),\n",
    "                         stdev_to_white=-2,\n",
    "                         norm_multiply=viz_multiplier,\n",
    "                         color_map=\"Blues\",\n",
    "                         plot_show = True,\n",
    "                         save_fig = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file = testing_folder + \"real_cube\",\n",
    "    arr = trial_sample[0],\n",
    "    allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Generated vs. Real with Power Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pyfftw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd seda_pylians/Pylians\n",
    "# import Pk_library as PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
